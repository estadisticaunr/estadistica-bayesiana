[
  {
    "objectID": "computo/instalacion.html#rstan",
    "href": "computo/instalacion.html#rstan",
    "title": "InstalaciÃ³n de herramientas comutacionales",
    "section": "RStan",
    "text": "RStan\n\nWindows\n\n\nUbuntu\n\n\nMac OS\n\n\nVerificaciÃ³n"
  },
  {
    "objectID": "computo/instalacion.html#librerias-adicionales",
    "href": "computo/instalacion.html#librerias-adicionales",
    "title": "InstalaciÃ³n de herramientas comutacionales",
    "section": "Librerias adicionales",
    "text": "Librerias adicionales\n\n{brms}\n{ggplot2}\n{dplyr}\n**Estaria bueno pinear las dependencias usando {here} o algo similar\n\n\nVerificaciÃ³n"
  },
  {
    "objectID": "computo/instalacion.html#dependencias-optativas",
    "href": "computo/instalacion.html#dependencias-optativas",
    "title": "InstalaciÃ³n de herramientas comutacionales",
    "section": "Dependencias optativas",
    "text": "Dependencias optativas\n\nQuarto\nâ€¦ ?"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Este es el subtituloâ€¦\n\n\n\n Â  Licenciatura en EstadÃ­stica\n Â  Facultad de Ciencias EconÃ³micas y EstadÃ­stica (UNR)\n Â  1Â° Cuatrimestre 2023"
  },
  {
    "objectID": "index.html#profesores",
    "href": "index.html#profesores",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Profesores",
    "text": "Profesores\n\n\nNacho Evangelista\n\n Â  email_de_nacho@mail.com\n Â  MiÃ©rcoles (7:00-9:00) y Viernes (7:00-9:00)\n\n\n\nTomÃ¡s Capretto\n\n Â  email_de_tomi@mail.com\n Â  Lunes (11-13hs) y MiÃ©rcoles (7-9hs)"
  },
  {
    "objectID": "info/enlaces_utiles.html",
    "href": "info/enlaces_utiles.html",
    "title": "Enlaces Ãºtiles",
    "section": "",
    "text": "Awesome Bayesian Statistics. Es un listado de recursos en lÃ­nea (y gratuitos!) relacionados al mundo de la EstadÃ­stica Bayesiana."
  },
  {
    "objectID": "info/programa.html",
    "href": "info/programa.html",
    "title": "Programa",
    "section": "",
    "text": "FundamentaciÃ³n\nLa EstadÃ­stica Bayesiana es un enfoque de la inferencia estadÃ­stica que se basa en utilizar probabilidades para representar el conocimiento disponible sobre el conjunto de parÃ¡metros de un modelo y actualizar esa informaciÃ³n utilizando la Regla de Bayes a partir de la observaciÃ³n de un conjunto de datos. El conocimiento inicial se representa con una distribuciÃ³n de probabilidad a priori, la informaciÃ³n contenida en los datos observados se modeliza con una funciÃ³n de verosimilitud y ambas fuentes de informaciÃ³n se combinan para obtener una distribuciÃ³n de probabilidad a posteriori. La informaciÃ³n a posteriori puede ser utilizada para extraer conclusiones sobre el fenÃ³meno en estudio y realizar predicciones sobre datos no observados o eventos futuros.\nLos mÃ©todos bayesianos requieren, salvo en casos muy simples, una complejidad computacional que resultaba inalcanzable hace algunos aÃ±os. Gracias a desarrollos revolucionarios en el Ã¡mbito de la computaciÃ³n, la principal barrera para la implementaciÃ³n de los modelos bayesianos desapareciÃ³ y la utilizaciÃ³n de estos se ha incrementado masivamente en mÃºltiples campos cientÃ­ficos. Esta creciente popularidad se debe a que la inferencia bayesiana brinda un marco teÃ³rico consistente que permite la incorporaciÃ³n de informaciÃ³n a priori, el desarrollo de un aprendizaje secuencial, la obtenciÃ³n de inferencias y predicciones en forma de distribuciones de probabilidad, el tratamiento de datos faltantes, los anÃ¡lisis con pocos datos, entre otras ventajas.\n\n\nObjetivos\nQue quienes cursen la materia logren:\n\nentender las caracterÃ­sticas y los conceptos fundamentales de la EstadÃ­stica Bayesiana;\ndescribir las caracterÃ­sticas principales de la EstadÃ­stica Bayesiana;\ncomprender la complejidad analÃ­tica de la inferencia bayesiana y la necesidad de la utilizaciÃ³n de un enfoque computacional para superar estas dificultades;\nser capaces de aplicar mÃ©todos bayesianos a problemas reales utilizando software especÃ­fico; e\ninterpretar los resultados del proceso de anÃ¡lisis bayesiano de datos.\n\n\n\nContenidos\n\nUnidad 1: IntroducciÃ³n y Fundamentos de la EstadÃ­stica Bayesiana\n\nProbabilidad para cuantificar la incertidumbre. Modelos de probabilidad. Regla de Bayes. Inferencia bayesiana. DistribuciÃ³n a priori, funciÃ³n de verosimilitud, distribuciÃ³n a posteriori.\n\nUnidad 2: Inferencia Bayesiana\n\nModelos de distribuciones conjugadas. Modelos de un parÃ¡metro. Modelo beta-binomial. Enfoque intuitivo. DistribuciÃ³n a posteriori como compromiso entre la verosimilitud y la distribuciÃ³n a priori. Razonamiento secuencial. Modelo normal-normal. Modelo gammaâ€“Poisson. Modelos de varios parÃ¡metros. Modelo normal â€“ normal-gamma-inversa. Modelo Dirichletâ€“multinomial.\nElecciÃ³n de distribuciones a priori: no informativas (impropias, de Jeffrey) y dÃ©bilmente informativas. Medidas de resumen de la distribuciÃ³n a posteriori. Intervalos de credibilidad. DistribuciÃ³n predictiva a posteriori. Nociones de teorÃ­a de la decisiÃ³n bayesiana. Riesgo bayesiano. Estimador de Bayes.\n\nUnidad 3: MÃ©todos Computacionales\n\nLimitaciones del enfoque analÃ­tico: cÃ¡lculo de probabilidades y determinaciÃ³n de la distribuciÃ³n a posteriori. Soluciones: anÃ¡lisis de datos simulados y aproximaciÃ³n de grilla. IntroducciÃ³n al cÃ³mputo bayesiano. Nociones bÃ¡sicas de mÃ©todos de cadenas de Markov â€“ Montecarlo (MCMC). Algoritmo de Metropolisâ€“Hastings. Montecarlo Hamiltoniano. DiagnÃ³stico de mÃ©todos MCMC.\nProgramaciÃ³n probabilÃ­stica. Alternativas. Sintaxis de modelos. Ejemplos. DiagnÃ³stico. Medidas de resumen a partir de las cadenas obtenidas. Visualizaciones.\n\nUnidad 4: Modelos Lineales\n\nModelos lineales. ElecciÃ³n de distribuciones a priori. RegularizaciÃ³n. DiagnÃ³stico de modelos. Predicciones basadas en distribuciones de probabilidad. Pruebas predictivas a priori y a posteriori. Densidad predictiva a posteriori logarÃ­tmica evaluada punto a punto (lppd). Deviance. Criterios de informaciÃ³n: AIC, BIC, WAIC. Validacion cruzada. Sobreajuste y subajuste. ValidaciÃ³n cruzada utilizando muestreo por importancia mediante suavizado Pareto (PSIS-CV).\n\nUnidad 5: Modelos Avanzados\n\nRegresiÃ³n logÃ­stica. RegresiÃ³n Poisson. ComparaciÃ³n de grupos. Modelos de variable latente. FormulaciÃ³n grÃ¡fica. AnÃ¡lisis de sensibilidad.\nEl enfoque multinivel: modelos jerÃ¡rquicos. Modelo beta-binomial jerÃ¡rquico. Shrinkage de parÃ¡metros. VariaciÃ³n en el intercepto. VariaciÃ³n en la pendiente. Pooling de estimaciones. Problemas de estimaciÃ³n."
  },
  {
    "objectID": "info/aprobacion.html",
    "href": "info/aprobacion.html",
    "title": "Condiciones de aprobaciÃ³n",
    "section": "",
    "text": "Instancias de evaluaciÃ³n\n\nðŸ“ Parcial â€“ escrito e individual, se aprueba con 6, hay una instancia de recuperaciÃ³n;\nðŸ’»ðŸ’»ðŸ’» Trabajos prÃ¡cticos cortos â€“ grupales (hasta tres personas), se hacen por fuera del horario de clase, se entrega informe;\nðŸ“ˆ Trabajo prÃ¡ctico final â€“ realizaciÃ³n grupal, defensa individual.\n\n\n\nCondiciones de aprobaciÃ³n\n\nPromociÃ³n\n\nLas y los estudiantes que hayan aprobado el parcial o su recuperatorio (con nota \\(P\\)), los tres trabajos prÃ¡cticos cortos (con promedio simple \\(T\\)) y hayan entregado el trabajo prÃ¡ctico final, accederÃ¡n a una instancia de evaluaciÃ³n oral donde se discutirÃ¡ el trabajo prÃ¡ctico final y se evaluarÃ¡n de manera general todos los contenidos conceptuales de la asignatura; esta instancia puede incluir la realizaciÃ³n de algunas actividades en computadora (el trabajo prÃ¡ctico final y la instancia oral tendrÃ¡n nota \\(O\\)).\nLa nota final se obtendrÃ¡ segÃºn \\(0.3\\ T + 0.4\\ P + 0.3\\ O\\)\n\nRegularidad\n\nQuienes no alcancen la condiciÃ³n de promociÃ³n podrÃ¡n quedar en condiciÃ³n de estudiante regular si aprueban el parcial o su recuperatorio y aprueban al menos dos de los trabajos prÃ¡cticos cortos. Para alcanzar la aprobaciÃ³n de la asignatura, los y las estudiantes en condiciÃ³n de regulares deberÃ¡n presentar el trabajo final en una mesa de examen y aprobar una instancia oral de defensa del trabajo y de evaluaciÃ³n integral de los contenidos de la materia. Esta instancia puede incluir la realizaciÃ³n de algunas actividades en computadora.\n\nLibres\n\nAquellas personas que no alcancen la promociÃ³n de la asignatura ni la condiciÃ³n de estudiante regular quedarÃ¡n en condiciÃ³n de estudiante libre. Los y las estudiantes en condiciÃ³n de libre deberÃ¡n presentar un trabajo prÃ¡ctico y rendir un examen teÃ³rico-prÃ¡ctico sobre la totalidad de los temas de la asignatura."
  },
  {
    "objectID": "info/faq.html",
    "href": "info/faq.html",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Preguntas frecuentes"
  },
  {
    "objectID": "info/docentes.html",
    "href": "info/docentes.html",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Docentes"
  },
  {
    "objectID": "info/bibliografia.html",
    "href": "info/bibliografia.html",
    "title": "BibliografÃ­a",
    "section": "",
    "text": "BibliografÃ­a principal\n\nJohnson, Ott, y Dogucu (2022) McElreath (2020) Gelman y Hill (2006) Kruschke (2014) Reich y Ghosh (2019)\n\n\n\nGelman, Andrew, y Jennifer Hill. 2006. Data Analysis Using Regression and Multilevel-Hierarchical Models. 1st edition. Cambridge University Press.\n\n\nJohnson, Alicia A., Miles Q. Ott, y Mine Dogucu. 2022. Bayes Rules! An Introduction to Bayesian Modeling. 1st edition. Chapman; Hall/CRC. https://www.bayesrulesbook.com/.\n\n\nKruschke, John. 2014. Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan. 2nd edition. Academic Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2nd edition. Chapman; Hall/CRC.\n\n\nReich, Brian J., y Sujit K. Ghosh. 2019. Bayesian Statistical Methods. 1st edition. Chapman; Hall/CRC.\n\n\n\n\nBibliografÃ­a complementaria\n\nGelman etÂ al. (2013), Gelman, Hill, y Vehtari (2021), Downey (2021), Lee y Wagenmakers (2014), Davidson-Pilon (2015), Nicenboim, Schad, y Vasishth (2022), Barr (2021), Carlin y Louis (2008), Hoff (2009), MacKay (2003), Lambert (2018), Murphy (2022), Murphy (2023), Bishop (2006), Martin, Kumar, y Lao (2021), Theoridis (2020), Clyde etÂ al. (2022), Ma, Kording, y Goldreich (2022)\n\n\n\n\n\nBarr, Dale J. 2021. Learning statistical models through simulation in R: An interactive textbook. 1st edition. https://psyteachr.github.io/stat-models-v1/.\n\n\nBishop, Christopher M. 2006. Pattern Recognition and Machine Learning. 1st edition. Springer.\n\n\nCarlin, Bradley P., y Thomas A. Louis. 2008. Bayesian Methods for Data Analysis. 3rd edition. Chapman; Hall/CRC.\n\n\nClyde, Merlise, Mine Ã‡etinkaya-Rundel, Colin Rundel, David Banks, Christine Chai, y Lizzy Huang. 2022. An Introduction to Bayesian Thinking. 1st edition. https://statswithr.github.io/book/.\n\n\nDavidson-Pilon, Cameron. 2015. Bayesian Methods for Hackers: Probabilistic Programming and Bayesian Inference. 1st edition. Addison-Wesley Data; Analytics Series.\n\n\nDowney, Allen B. 2021. Think Bayes: Bayesian Statistics in Python. 2nd edition. Oâ€™Reilly Media. http://allendowney.github.io/ThinkBayes2/.\n\n\nGelman, Andrew, John B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, y Donald B. Rubin. 2013. Bayesian Data Analysis. 3rd edition. Chapman; Hall/CRC.\n\n\nGelman, Andrew, Jennifer Hill, y Aki Vehtari. 2021. Regression and Other Stories. 1st edition. Cambridge University Press. https://users.aalto.fi/~ave/ROS.pdf.\n\n\nHoff, Peter D. 2009. A First Course in Bayesian Statistical Methods. 1st edition. Springer.\n\n\nLambert, Ben. 2018. A Studentâ€™s Guide to Bayesian Statistics. 1st edition. SAGE Publications Ltd.\n\n\nLee, Michael D., y Eric-Jan Wagenmakers. 2014. Bayesian Cognitive Modeling: A Practical Course. 1st edition. Cambridge University Press.\n\n\nMa, Wei Ji, Konrad P. Kording, y Daniel Goldreich. 2022. Bayesian Models of Perception and Action: An Introduction. 3rd edition. http://www.cns.nyu.edu/malab/bayesianbook.html.\n\n\nMacKay, David J. C. 2003. Information Theory, Inference and Learning Algorithms. 1st edition. Cambridge University Press.\n\n\nMartin, Osvaldo A., Ravin Kumar, y Junpeng Lao. 2021. Bayesian Modeling and Computation in Python. 1st edition. Chapman; Hall/CRC.\n\n\nMurphy, Kevin P. 2022. Probabilistic Machine Learning: An Introduction. 1st edition. The MIT Press. https://probml.ai/.\n\n\nMurphy, Kevin P. 2023. Probabilistic Machine Learning: Advanced Topics. 1st edition. The MIT Press. https://probml.ai/.\n\n\nNicenboim, Bruno, Daniel Schad, y Shravan Vasishth. 2022. An Introduction to Bayesian Data Analysis for Cognitive Science. https://vasishth.github.io/bayescogsci/book/.\n\n\nTheoridis, Sergios. 2020. Machine Learning: A Bayesian and Optimization Perspective. 2nd edition. Academic Press."
  },
  {
    "objectID": "info/calendario.html",
    "href": "info/calendario.html",
    "title": "Calendario",
    "section": "",
    "text": "Semana\nFecha\nUnidad\nTemas\nApunte\nLectura sugerida\nOtras actividades\n\n\n\n\n1\n2023-03-20\n1\nProbabilidad para cuantificar la incertidumbre. Repaso de probabilidad. Modelos de probabilidad. Regla de Bayes.\n\n\n\n\n\n2\n2023-03-27\n1\nInferencia bayesiana. Distribucion a priori, funcion de verosimilitud y distribucion a posteriori.\n\n\n\n\n\n\n\n2\nConjugaciÃ³n. Modelos conjugados a un parÃ¡metro. Modelo beta-binomial. Posterior como compromismo entre verosimilitud y prior. Razonamiento secuencial.\n\n\n\n\n\n3\n2023-04-03\n2\nModelos conjugados a un parÃ¡metro. Modelo normal-normal. Modelo gamma-poisson. Modelos de varios parametros. Normal-normal-gamma-inversa. Modelo Dirichlet-multinomial.\n\n\nPresentaciÃ³n TP 1\n\n\n4\n2023-04-10\n2\nMedidas de resumen de la distribucion a posteriori. Distribucion predictiva a posteriori. Teoria de decision bayesiana. Estimador de Bayes.\n\n\n\n\n\n5\n2023-04-17\n3\nLimitaciones en el enfoque analÃ­tico. AproximaciÃ³n mediante grilla de puntos. Limitaciones en la aproximaciÃ³n mediante grilla de puntos. Necesidad de contar con otro tipo de tÃ©cnicas. SoluciÃ³n de problemas mediante tÃ©cnicas de simulaciÃ³n. ObtenciÃ³n de muestras de distribuciones de probabilidad.\n\n\nEntrega TP 1\n\n\n6\n2023-04-24\n3\nIntroducciÃ³n al cÃ³mputo bayesiano. Nociones bÃ¡sicas de cadenas de Markov y de muestreo mediante el mÃ©todo de Algoritmo de MetrÃ³polis-Hastings. Monte Carlo Hamiltoniano. DiagnÃ³stico de mÃ©todos de MCMC. Monte Carlo basado en cadenas de Markov.\n\n\n\n\n\n7\n2023-05-01\n3\nProgramaciÃ³n probabilÃ­stica. IntroducciÃ³n a Stan. SintÃ¡xis bÃ¡sica de modelos en Stan. EspecificaciÃ³n de modelos en Stan. ObtenciÃ³n del posterior. DiagnÃ³sticos. AnÃ¡lisis del posterior. Responder preguntas usando las muestras del posterior.\n\n\nParcialPresentaciÃ³n TP 2\n\n\n8\n2023-05-08\n4\nRepaso de modelos lineales. EstimaciÃ³n clÃ¡sica (MCO y MV). Limitaciones. InterpretaciÃ³n frecuentista de los Intervalos de Confianza. Modelos lineales bajo el enfoque bayesiano. Uso de distribuciones a priori. EstimaciÃ³n. Intervalos de Credibilidad y su interpretaciÃ³n. ElecciÃ³n de distribuciones a priori. Predicciones basadas en distribuciones de probabilidad. DistribuciÃ³n predictiva a posteriori.\n\n\n\n\n\n9\n2023-05-15\n4\nModelos lineales. IntroducciÃ³n a brms. Reemplazo de Stan por brms. DiagnÃ³sticos y selecciÃ³n de modelos. lppd. Deviance. AIC, BIC, WAIC. ValidaciÃ³n cruzada. Sobreajuste y subajuste. PSIS-CV.\n\n\nEntrega TP 2PresentaciÃ³n TP 3\n\n\n10\n2023-05-22\n4\nEjercitaciÃ³n integradora de modelos lineales bayesianos usando R y brms.\n\n\n\n\n\n11\n2023-05-29\n5\nExtensiÃ³n de los modelos lineales considerando funciones de verosimilitud no-normales. IntroducciÃ³n a MLG. Predictor lineal. FunciÃ³n de enlace. FunciÃ³n de verosimilitud. MenciÃ³n a modelos para datos de conteo y para probabilidades. Modelos para datos de conteo. Verosimilitud Poisson. FunciÃ³n de enlace logarÃ­tmica, y otras funciones.\n\n\nEntrega TP 3\n\n\n12\n2023-06-05\n5\nEjercitaciÃ³n con modelos para datos de conteo. Modelos para probabilidades. Verosimilitud Bernoulli. FunciÃ³n de enlace logit. InterpretaciÃ³n de coeficientes.\n\n\nPresentaciÃ³n TP Final\n\n\n13\n2023-06-12\n5\nâ€¦\n\n\n\n\n\n14\n2023-06-19\n5\nâ€¦\n\n\n\n\n\n15\n2023-06-26\n5\nâ€¦\n\n\nDefensa oral del TP Final\n\n\n16\n2023-07-03\n5\nâ€¦"
  },
  {
    "objectID": "notas/planificacion.html",
    "href": "notas/planificacion.html",
    "title": "Contenidos detallados",
    "section": "",
    "text": "Actividad Rocklets\n\n\nRepaso\n\nRepaso de probabilidad, distribuciones conjuntas, distribuciones marginales\nPrÃ¡ctica 0 (ver quÃ© ejercicios)\n\n\n\nIntroducciÃ³n\n\nProbabilidad para cuantificar la incertidumbre\n\nDefiniciones de probabilidad\n\nClasica\nFrecuentista\nBayesiana (subjetiva)\n\nProbabilidades subjetivas\nLÃ³gica y razonamiento plausible (ver Jaynes)\nDutch book\n\nRegla de Bayes\n\nHistoria: Bayes, Price, Laplace\nPresentaciÃ³n tradicional de la Regla de Bayes\n\nLey de la probabilidad total\n\nPrÃ¡ctica 1 (ver quÃ© ejercicios)\n\nInferencia bayesiana: problema original de Bayes, problema de la percepciÃ³n del suelo mojado, problema de las bolas (Â¿hecho en vivo con Sugus?), problema del globo terrÃ¡queo (Â¿hecho en vivo?), problema de detecciÃ³n de gluten (ver Downey).\n\nDiscutir modelos generativos (probabilidad hacia adelante e inversa).\nPrÃ¡ctica 1 (ver quÃ© ejercicios)\nIdea intuitiva: Â¿quÃ© es el prior? Â¿quÃ© es la funciÃ³n de verosimilitud? Â¿quÃ© es el posterior?\n\n\n\n\nModelos de distribuciones conjugadas\n\nModelo beta-binomial\n\nDemostraciÃ³n\nEnfoque intuitivo\nDistribuciÃ³n a posteriori como compromiso entre likelihood y prior\nRazonamiento secuencial\nResumen de la distribuciÃ³n a posteriori: media, moda, intervalos de credibilidad. CÃ¡lculos a mano, cÃ¡lculos exacto con funciones de R. Simulaciones (vamos a introducir la idea de utilizar simulaciones para resolver problemas)\nPredicciones: simulaciones. Problema del amanecer.\nPrÃ¡ctica 2\n\nElecciÃ³n de la distribuciÃ³n a priori\n\nPrÃ¡ctica 2\n\nModelo normal-normal\n\nEnfoque intuitivo\nDistribuciÃ³n a posteriori como compromiso entre likelihood y prior\nRazonamiento secuencial\nPredicciones: distribuciÃ³n predictiva. Incertidumbre propia del sampleo + incertidumbre.\n\nModelo Gamma-Poisson\nOtros modelos de distribuciones conjugadas para una variable (ver PrÃ¡ctica 2)\nModelos de varias variables\n\nâ€¦\n\nGrid approximation de un problema para estimar N y theta."
  },
  {
    "objectID": "trabajos_practicos/01_tp1.html",
    "href": "trabajos_practicos/01_tp1.html",
    "title": "TP1: AplicaciÃ³n de modelos conjugados a reviews de Google Maps",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "trabajos_practicos/01_tp1.html#descubriendo-la-distribuciÃ³n-de-dirichlet",
    "href": "trabajos_practicos/01_tp1.html#descubriendo-la-distribuciÃ³n-de-dirichlet",
    "title": "TP1: AplicaciÃ³n de modelos conjugados a reviews de Google Maps",
    "section": "Descubriendo la distribuciÃ³n de Dirichlet",
    "text": "Descubriendo la distribuciÃ³n de Dirichlet\nLa distribuciÃ³n Dirichlet es en realidad una familia de distribuciones. Se trata de una familia de distribuciones de probabilidad continuas y multivariadas. La distribuciÃ³n de Dirichlet en \\(K \\geq 2\\) es la distribuciÃ³n de probabilidad del vector aleatorio \\(X=[X_1, X_2 \\dots, X_K]\\) dimensiones tiene como parÃ¡metro al vector \\(\\mathbf{\\alpha} = [\\alpha_1, \\alpha_2, \\dots,\\alpha_K]\\).\n\\[\nf(x_1,x_2,\\dots,x_k \\mid \\alpha_1, \\alpha_2,\\dots,\\alpha_K) =\n    \\frac{1}{B(\\pmb{\\alpha})} \\prod_{i=1}^K x_i^{\\alpha_i-1}\n\\]\ndonde los \\(\\alpha_i \\in \\mathbb{R}^+\\) y \\(B(\\pmb{\\alpha})\\) es la constante que hace que la integral sea unitaria.\nEl soporte de la distribuciÃ³n Dirichlet es tal que \\(\\sum_{i=1}^{K} x_i = 1\\) y \\(x_i \\in [0,1]\\). Es decir, los \\(x_i\\) suman 1. Si consideramos, por ejemplo, \\(K=3\\), el vector \\([x_1, x_2, x_3]\\) pertenece al triÃ¡ngulo en \\(\\mathbb{R}^3\\) que tiene por vÃ©rtices a los puntos \\((1,0,0)\\), \\((0,1,0)\\) y \\((0,0,1)\\). AsÃ­, si \\(x_1=1\\) entonces \\(x_2=x_3=0\\).\nMÃ¡s simple aÃºn, cuando \\(K=2\\), el vector \\([x_1,x_2]\\) pertenece al segmento en \\(\\mathbb{R}^2\\) que tiene por extremos a los puntos \\((1,0)\\) y \\((0,1)\\).\nNotar que esta caracterÃ­stica hace que los \\(x_1, x_2, \\dots, x_K\\) puedan representar las probabilidades de un experimento con \\(K\\) resultados posibles.\nA tÃ­tulo informativo, el soporte de la distribuciÃ³n Dirichlet en \\(K\\) dimensiones es lo que se conoce como simplex (estÃ¡ndar) de \\(K-1\\) dimensiones. El \\(3\\)-simplex es un triÃ¡ngulo y el \\(2\\)-simplex es un segmento. En general, un \\(K-1\\)-simplex es la envolvente convexa de \\(K\\) vÃ©rtices y, a su vez, es la colecciÃ³n de todas las combinaciones convexas de puntos en el conjunto (Teorema de CarathÃ©odory).\nLos pÃ¡rrafos anteriores, delirantemente matemÃ¡ticos, muestran una virtud particular de la distribuciÃ³n Dirichlet de \\(K=3\\) dimensiones. Esta distribuciÃ³n, a pesar de ser de una variable aleatoria en \\(\\mathbb{R}^3\\), puede representarse perfectamente de manera grÃ¡fica en dos dimensiones (aunque utilizando un sistema de coordenadas peculiar: las coordenadas baricÃ©ntricas), como si se tratara de una distribuciÃ³n bivariada.\n\n\n\n\n\nComo los valores posibles del vector aleatorio tridimensional yacen en un plano, la distribuciÃ³n de probabilidad puede representarse grÃ¡ficamente con facilidad\n\n\n\n\n\n\nMostrar que, cuando \\(K=2\\), la distribuciÃ³n de Dirichlet es la distribuciÃ³n beta de parÃ¡metros \\(a=\\alpha_1\\) y \\(b=\\alpha_2\\)"
  },
  {
    "objectID": "trabajos_practicos/01_tp1.html#relaciÃ³n-entre-la-distribuciÃ³n-dirichlet-y-la-multinomial",
    "href": "trabajos_practicos/01_tp1.html#relaciÃ³n-entre-la-distribuciÃ³n-dirichlet-y-la-multinomial",
    "title": "TP1: AplicaciÃ³n de modelos conjugados a reviews de Google Maps",
    "section": "RelaciÃ³n entre la distribuciÃ³n Dirichlet y la multinomial",
    "text": "RelaciÃ³n entre la distribuciÃ³n Dirichlet y la multinomial\nCuando un experimento puede tener dos resultados posibles, uno de ellos tiene probabilidad \\(p\\) y el otro probabilidad \\(1-p\\). Si coleccionamos \\(N\\) realizaciones independientes del experimento, el nÃºmero de Ã©xitos es una variable aleatoria con distribuciÃ³n binomial. Estudiamos que era natural utilizar la distribuciÃ³n beta como distribuciÃ³n a priori para \\(p\\), dado que la distribuciÃ³n a posterioriÂ tambiÃ©n era beta.\nAnÃ¡logamente, cuando un experimento puede tener tres resultados posibles, el primero tiene probabilidad \\(p_1\\), el segundo tiene probabilidad \\(p_2\\) y el tercero, probabilidad \\(p_3 = p_1 - p_2\\). Necesariamente debe ser \\(p_1 + p_2 + p_3 = 1\\). Si coleccionamos \\(N\\) realizaciones independientes del experimento, el nÃºmero de ocurrencias de cada resultado posible es un vector aleatorio con distribuciÃ³n multinomial. Por lo visto hasta aquÃ­, todo parece indicar que, si queremos realizar inferencias sobre \\(p_1\\), \\(p_2\\) y \\(p_3\\), serÃ­a natural utilizar la distribuciÃ³n Dirichlet de tres dimensiones como distribuciÃ³n a priori para las probabilidadesâ€¦\nEn efecto, cuando la distribuciÃ³n a priori es Dirichlet y la verosimilitud es multinomial, la distribuciÃ³n a posteriori tambiÃ©n es Dirichlet.\n\nSabemos que para una verosimilitud binomial, si la distribuciÃ³n a priori de la probabilidad de Ã©xito \\(p\\) es beta de parÃ¡metros \\(a\\) y \\(b\\) y se observan \\(s\\) Ã©xitos en \\(N\\) intentos independientes, la distribuciÃ³n a posteriori es beta de parÃ¡metros \\(a' = a + s\\) y \\(b' = b + (N - s)\\).\nHallar, por analogÃ­a con el caso anterior, los parÃ¡metros de la distribuciÃ³n a posteriori que se obtiene si la verosimilitud es multinomial con tres resultados posibles, la distribuciÃ³n a prioriÂ es Dirichlet de parÃ¡metros \\([\\alpha_1, \\alpha_2, \\alpha_3]\\) y se obtuvieron \\(s_1\\) veces el primer resultado y \\(s_2\\) veces el segundo resultado, sobre un total de \\(N\\) intentos."
  },
  {
    "objectID": "trabajos_practicos/01_tp1.html#aplicaciÃ³n",
    "href": "trabajos_practicos/01_tp1.html#aplicaciÃ³n",
    "title": "TP1: AplicaciÃ³n de modelos conjugados a reviews de Google Maps",
    "section": "AplicaciÃ³n",
    "text": "AplicaciÃ³n\nAsumiremos ahora que las reviews de un local tienen distribuciÃ³n multinomial de parÃ¡metros \\([p_1, p_2, \\dots, p_5]\\). Es decir, la probabilidad de que un usuario asigne 1â­ es \\(p_1\\), de que asigne 2â­ es \\(p_2\\), y asÃ­ sucesivamente. Llamaremos \\(n_1\\) al nÃºmero de calificaciones de 1â­, \\(n_2\\) al nÃºmero de calificaciones de 2â­, y asÃ­ sucesivamente. \\(n_1 + n_2 + n_3 + n_4 + n_5 = N\\) serÃ¡ el nÃºmero total de reviews.\nSe puede verificar que el nÃºmero esperado de reviews de \\(i\\)â­ serÃ¡ \\(N p_i\\). Por lo tanto, la puntuaciÃ³n esperada serÃ¡:\n\\[\n\\frac{1}{N} (1\\cdot N p_1 + 2\\cdot N p_2 + 3\\cdot N p_3 + 4\\cdot N p_4 +5\\cdot N p_5) =\n    \\sum_{i=1}^5 i \\cdot p_i\n\\]\n\nElija dos combinaciones de posibles valores de \\(p_i\\) que den un valor esperado de 4.1â­. Piense en una combinaciÃ³n que represente acuerdo entre los clientes y otra que indique la presencia de opiniones dispares.\nEscriba una funciÃ³n que, dada una combinaciÃ³n de valores de \\(p_i\\), simule el proceso de calificaciÃ³n de un cliente.\nConstruya una funciÃ³n que simule la calificaciÃ³n de \\(U\\) clientes.\nSimule 1000 veces el proceso de 15 clientes que evalÃºan una cafeterÃ­a de 4.1â­ y el proceso de 100 clientes que evalÃºan la misma cafeterÃ­a. Â¿QuÃ© se observa?\n\nUtilizaremos este nuevo modelo para realizar inferencias sobre las puntuaciones de Arto y Orlan.\n\nLos datos se generan siguiendo una distribuciÃ³n multinomial. Â¿CuÃ¡les son los parÃ¡metros de esa distribuciÃ³n multinomial? Â¿QuÃ© distribuciÃ³n a priori serÃ­a conveniente utilizar? Â¿CÃ³mo estÃ¡ parametrizada esa distribuciÃ³n a priori?\nElija los parÃ¡metros de la distribuciÃ³n a priori de modo tal que la creencia inicial sea uniforme sobre los posibles valores de los \\(p_i\\). Â¿QuÃ© implicancias tiene para la puntuaciÃ³n en â­ la distribuciÃ³n a priori elegida?\nCon los datos de la introducciÃ³n, obtenga la distribuciÃ³n a posteriori de los \\(p_i\\) para cada cafeterÃ­a.\nÂ¿CuÃ¡l es la probabilidad de que Orlan sea mejor que Arto?"
  },
  {
    "objectID": "trabajos_practicos/03_tp3.html",
    "href": "trabajos_practicos/03_tp3.html",
    "title": "TP3: Estudio de modelos lineales mediante simulaciones",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "trabajos_practicos/03_tp3.html#simulaciones",
    "href": "trabajos_practicos/03_tp3.html#simulaciones",
    "title": "TP3: Estudio de modelos lineales mediante simulaciones",
    "section": "Simulaciones",
    "text": "Simulaciones\nEl archivo â€¦ contiene 100 observaciones que se usarÃ¡n para identificar los parÃ¡metros de un modelo, mientras que el archivo â€¦ tiene 20 observaciones que se usarÃ¡n para evaluar los resultados del proceso de inferencia.\nSe sabe que los datos fueron generados utilizando un modelo de la forma:\n\\[\ny_i \\sim \\mathcal{N}(\\theta_3 x_i^3 + \\theta_2 x_i^2 + \\theta_1 x_i + \\theta_0, \\sigma^2)\n\\]\naunque no se conocen los valores de los \\(\\theta_i\\) ni de \\(\\sigma\\)\nEn primer lugar, se estudiarÃ¡ el efecto de la cantidad de datos utilizados para el ajuste del modelo.\n\nUtilizando priors vagos para los parÃ¡metros del modelo, analice los resultados obtenidos al utilizar 10, 20, 50 o 100 observaciones de los datos de entrenamiento. Compare las distribuciones a posteriori de los parÃ¡metros y las predicciones sobre los datos de test.\n\nEn segundo lugar, se investigarÃ¡ quÃ© efecto tiene la elecciÃ³n de distribuciones a priori centradas en valores errÃ³neos de los parÃ¡metros de la regresiÃ³n.\n\nConsidere las siguientes distribuciones a priori [â€¦]. Compare, como hizo en el caso anterior, los resultados en las estimaciones utilizando 10, 20, 50 y 100 observaciones.\n\nFinalmente, se considera el caso donde se propone un modelo errÃ³neo.\n\nUtilizando priors vagos, ajuste polinomios de grado 3, 4, 5 y 6 utilizando 20 observaciones. Compare grÃ¡ficamente el ajuste en los datos de entrenamiento con el ajuste en los datos de evaluaciÃ³n. Â¿QuÃ© ocurre si se utilizan todos los datos?\nUtilice ahora priors de regularizaciÃ³n (centrados en 0) para polinomios de grado 3, 4, 5 y 6 utilizando 20 observaciones. Pruebe diferentes grados de regularizaciÃ³n. Compare grÃ¡ficamente el ajuste en los datos de entrenamiento con el ajuste en los datos de evaluaciÃ³n.\nEscriba una funciÃ³n que calcule el lppd para un conjunto de observaciones. Compare lppd para los polinomios de grados 3, 4, 5 y 6 ajustados con 20 observaciones. Compare la mÃ©trica utilizando los datos de entrenamiento y de evaluaciÃ³n."
  },
  {
    "objectID": "trabajos_practicos/03_tp3.html#enfriamiento-de-agua-en-un-termo",
    "href": "trabajos_practicos/03_tp3.html#enfriamiento-de-agua-en-un-termo",
    "title": "TP3: Estudio de modelos lineales mediante simulaciones",
    "section": "Enfriamiento de agua en un termo",
    "text": "Enfriamiento de agua en un termo\nEn un paÃ­s matero como Argentina, era de esperarse que aparecieran casi tantos termos como personas. Es difÃ­cil decir si la cantidad de variantes de termos en el mercado nacional cambiÃ³, pero es indudable que, tras el furor del termo color verde militar, la elecciÃ³n de un termo adquiriÃ³ un papel relevante en el ritual del mate.\nDe acero, de vidrio, con capa aisladora. Diferentes configuraciones dan lugar a distintas capacidades de mantener la temperatura y, obviamente, a distintos rangos de precios. Dejando de lado la cuestiÃ³n monetaria, centrÃ©monos en estudiar cÃ³mo varÃ­a la temperatura de un lÃ­quido en el interior de un termo en funciÃ³n del tiempo transcurrido.\nLa temperatura es una medida del grado de agitaciÃ³n de las partÃ­culas de una sustancia. Un lÃ­quido (o sÃ³lido, o gas) estÃ¡ mÃ¡s caliente que otro si sus partÃ­culas tienen (en promedio) mayor grado de agitaciÃ³n. Sabemos por evidencia empÃ­rica que si un cuerpo se pone en contacto con otro que tiene una temperatura menor, hay una transferencia de energÃ­a que hace que el primero se enfrÃ­e y el segundo se caliente, hasta que alcanzan el denominado equilibrio tÃ©rmico.\nDe manera similar, esto es lo que ocurre con el agua que dejamos dentro del termo: en algÃºn momento, llega al equilibrio tÃ©rmico con el ambiente. La salvedad necesaria acÃ¡ es que, como el ambiente es grande, no aumenta su temperatura con la energÃ­a que pierde el agua del recipiente.\nAhora bien, el ritmo con el cual el agua caliente pierde energÃ­a no es constante. FÃ­sicamente, mientras mayor sea la diferencia de temperatura entre dos cuerpos, mÃ¡s rÃ¡pido fluirÃ¡ la energÃ­a (y mÃ¡s rÃ¡pido cambiarÃ¡ la temperatura). Si estudiamos la temperatura del agua en el termo en funciÃ³n del tiempo, notaremos que el ritmo con el que cambia decrece a medida con el que transcurre el tiempo.\nLa lectura del pÃ¡rrafo anterior deberÃ­a permitir asociar el concepto de ritmo de cambio con la nociÃ³n matemÃ¡tica de derivada. En efecto, la derivada de la temperatura respecto al tiempo varÃ­a con el tiempo. En otras palabras, la pendiente no es constante.\nLas leyes que rigen el universo pueden muchas veces formularse en tÃ©rminos de lo que en matemÃ¡tica se conoce como ecuaciÃ³n diferencial. En este caso, la temperatura del agua en el termo satisface la siguiente ley:\n\\[\n\\frac{\\mathrm{d}T(t)}{\\mathrm{d}t} = r [T_{\\text{amb}}-T(t)]\n\\]\ndonde \\(T_{\\text{amb}}\\) es la temperatura ambiente (un valor fijo y conocido), \\(r\\) es una constante y \\(T(t)\\) es la funciÃ³n (en principio desconocida) que describe la temperatura del agua del termo en funciÃ³n del tiempo.\nNo se trata de una ecuaciÃ³n algebraica donde la soluciÃ³n es un valor numÃ©rico sino de una ecuaciÃ³n donde la soluciÃ³n es una funciÃ³n. Buscamos una funciÃ³n \\(T(t)\\) que satisfaga la ecuaciÃ³n: su derivada debe cambiar con el valor que toma la funciÃ³n.\nUna funciÃ³n que satisface esa ecuaciÃ³n es:\n\\[\nT(t) = T_{\\text{amb}} + (T_i - T_{\\text{amb}})e^{-rt}\n\\]\nsiendo \\(T_i\\) la temperatura a la que estÃ¡ inicialmente el agua en el termo (un valor fijo y conocido).\n\nVerificar que la funciÃ³n anterior satisface la ecuaciÃ³n diferencial\nGrafique \\(T(t)\\) para \\(T_{\\text{amb}} = 20 \\text{ CÂ°}\\) y \\(T_i = 90 \\text{ CÂ°}\\), para dos valores de \\(r\\), \\(r_1=0.1\\) y \\(r_2 = 0.3\\). Â¿QuÃ© representa \\(r\\)?\nSegÃºn su experiencia con termos, Â¿cuÃ¡l es un valor realista de \\(r\\)?\n\nEstudiaremos a continuaciÃ³n un conjunto de mediciones de temperatura de agua en un termo en funciÃ³n del tiempo transcurrido.\nLeonel tiene un termo Estanliâ„¢ que comprÃ³ por Amason y se dispone a despejar la duda de cualquier usuario de termos Estanliâ„¢: Â¿cuÃ¡nto dura el agua caliente? Pone agua en la pava elÃ©ctrica, la vierte en el termo y registra la temperatura en algunos momentos posteriores. Ese dÃ­a, el reporte meteorolÃ³gico indica una temperatura de \\(T_{\\text{amb}} = 23\\text{ CÂ°}\\). Las temperaturas que registrÃ³ Leonel son las siguientes:\n\n\n\n\n \n  \n    t (h:mm) \n    T (Â°C) \n  \n \n\n  \n    1:20 \n    92.0 \n  \n  \n    2:30 \n    90.5 \n  \n  \n    4:00 \n    81.4 \n  \n  \n    5:15 \n    80.8 \n  \n  \n    8:30 \n    74.2 \n  \n\n\n\n\n\nPara simplificar la construcciÃ³n de un modelo, en lugar de considerar la temperatura del agua en el termo, se considerarÃ¡ la diferencia entre la temperatura del agua y la temperatura ambiente \\(T-T_{\\text{amb}}\\). AdemÃ¡s, se llamarÃ¡ \\(T_{\\text{diff}}\\) a la diferencia de temperatura entre la temperatura inicial del agua y la temperatura ambiente \\(T_i - T_{\\text{amb}}\\).\n\\[\nT(t) - T_{\\text{amb}} = T_{\\text{diff}} e^{-rt}\n\\]\n\nVerifique que el logaritmo natural de la nueva variable (\\(T(t) - T_{\\text{amb}}\\)) es una funciÃ³n lineal de \\(t\\).\nÂ¿QuÃ© representan \\(\\beta_0\\) y \\(\\beta_1\\)?\n\nAjustaremos un modelo lineal a los datos transformados.\n\nEn funciÃ³n del enunciado del problema y de su conocimiento de termos, elija una distribuciÃ³n a priori para \\(\\beta_0\\), \\(\\beta_1\\) y \\(\\sigma\\). Â¿CuÃ¡les son las implicancias de sus distribuciones a priori? Realice pruebas predictivas a priori.\nAjuste el modelo lineal utilizando R\nEncontrar el posterior de \\(r\\), de \\(T_{\\text{diff}}\\) y de la temperatura inicial del agua \\(T_i\\)\nPredecir la temperatura a la que estarÃ¡ el agua transcurridas 12:00 h del inicio de la experiencia.\nHalle la distribuciÃ³n a posteriori del tiempo que le toma al agua llegar a \\(30 \\text{ CÂ°}\\)"
  },
  {
    "objectID": "trabajos_practicos/descripcion.html",
    "href": "trabajos_practicos/descripcion.html",
    "title": "Generalidades",
    "section": "",
    "text": "Para aprobar la materia es necesario completar tres trabajos prÃ¡cticos cortos. La denominaciÃ³n cortos hace referencia a que los trabajos son guiados y las tareas a realizar estÃ¡n delimitadas.\nLos trabajos prÃ¡cticos tienen como objetivo repasar y afianzar los conocimientos adquiridos durante las clases, adquirir prÃ¡ctica en la aplicaciÃ³n de conceptos trabajados, mejorar las habilidades de programaciÃ³n y el uso de R, e incorporar algunos conceptos complementarios.\nCada trabajo prÃ¡ctico serÃ¡ presentado y discutido en clase. Se destinarÃ¡ una fracciÃ³n de la clase a comenzar a pensar algunas de las actividades.\nLa fecha de entrega de cada trabajo prÃ¡ctico serÃ¡ de dos semanas luego de la fecha de presentaciÃ³n. Se podrÃ¡ entregar el trabajo prÃ¡ctico una semana despuÃ©s de la fecha de entrega con una penalizaciÃ³n del 25% de la nota final.\nPara cada trabajo prÃ¡ctico, cada grupo deberÃ¡ entregar un informe en formato pdf donde se resuelvan las actividades propuestas. El informe debe estar obligatoriamente elaborado utilizando \\(\\mathrm{\\LaTeX{}}\\) (a travÃ©s de Quarto, RMarkdown o alguna otra variante). Tener en cuenta que los apartados presentados en el enunciado del trabajo prÃ¡ctico constituyen una guÃ­a de actividades a resolver y no deben responderse uno a uno como si se tratara de un cuestionario. El informe deberÃ¡ permitir una lectura fluida de los resultados y anÃ¡lisis presentados. Cuando la resoluciÃ³n de una problemÃ¡tica consista en una funciÃ³n o porciÃ³n de cÃ³digo en R, el cÃ³digo deberÃ¡ mostrarse en el informe.\nSe evaluarÃ¡n los siguientes aspectos del informe: presentaciÃ³n, redacciÃ³n (claridad, coherencia y cohesiÃ³n), estÃ©tica, resultados obtenidos, profundidad del anÃ¡lisis."
  },
  {
    "objectID": "trabajos_practicos/00_tp0.html",
    "href": "trabajos_practicos/00_tp0.html",
    "title": "TP0: DistribuciÃ³n de Rocklets azules",
    "section": "",
    "text": "Descargar PDF\n\n\nDistribuciÃ³n de Rocklets azules"
  },
  {
    "objectID": "trabajos_practicos/02_tp2.html",
    "href": "trabajos_practicos/02_tp2.html",
    "title": "TP2: ImplementaciÃ³n del algoritmo de Metropolis-Hastings",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "trabajos_practicos/02_tp2.html#metropolis-hastings-en-2d",
    "href": "trabajos_practicos/02_tp2.html#metropolis-hastings-en-2d",
    "title": "TP2: ImplementaciÃ³n del algoritmo de Metropolis-Hastings",
    "section": "Metropolis-Hastings en 2D",
    "text": "Metropolis-Hastings en 2D\nSe desean tomar muestras de una normal bivariada asimÃ©trica cuya funciÃ³n de densidad viene dada por\n\\[\nf(\\mathbf{x}) =\n    2\\ \\phi_2(\\mathbf{x} \\mid \\mathbf{0}, \\pmb{\\Omega})\n    \\ \\Phi(\\pmb{\\alpha}^T\\mathbf{x})\n    \\qquad \\mathbf{x} \\in \\mathbb{R}^2\n\\]\nsiendo \\(\\phi_2(\\mathbf{x}\\mid\\mathbf{0},\\mathbf{\\Omega})\\) la funciÃ³n de densidad de la normal bivariada de media \\(\\mathbf{0}\\) y matriz de covarianza \\(\\mathbf{\\Omega}\\), \\(\\Phi(\\pmb{\\alpha}^T\\mathbf{x})\\) es la funciÃ³n de probabilidad acumulada de la normal estÃ¡ndar \\(\\mathcal{N}(0,1)\\) y \\(\\pmb{\\alpha} \\in \\mathbb{R}^2\\) es un vector de parÃ¡metros.\n\nEn este caso, se tiene:\n\\[\n\\mathbf{\\Omega} = \\begin{bmatrix}1.5 & 0.6 \\\\ 0.6 & 1.5 \\end{bmatrix}\n\\]\ny\n\\[\n\\pmb{\\alpha} = [2 \\quad 0]\n\\]\n\n\n\n\n\nFunciÃ³n de densidad de la que se desean obtener muestras\n\n\n\n\n\nEscriba una funciÃ³n que implemente el algoritmo de Metropolis-Hastings para tomar muestras de una funciÃ³n de probabilidad bivariada dada. Separe en funciones cada una de los pasos del algoritmo. La probabilidad de salto serÃ¡ normal bivariada de matriz de covarianza variable. Otorgue flexibilidad al algoritmo haciendo que reciba como argumento la matriz de covarianza de la probabilidad de transiciÃ³n.\n\nSe utilizarÃ¡ una normal bivariada para proponer un salto en el algoritmo de Metropolis-Hastings. Se explorarÃ¡ el efecto de diferentes distribuciones de probabilidad para el salto, en funciÃ³n de diferentes matrices de covarianza \\(\\mathbf{\\Sigma}\\). Si se representa a \\(\\mathbf{\\Sigma}\\) de la siguiente manera\n\\[\n\\mathbf{\\Sigma} =\n    \\begin{bmatrix} \\sigma_1 & 0 \\\\ 0 & \\sigma_2 \\end{bmatrix}\n    \\begin{bmatrix} 1 & \\rho \\\\ \\rho & 1\\end{bmatrix}  \n    \\begin{bmatrix} \\sigma_1 & 0 \\\\ 0 & \\sigma_2 \\end{bmatrix}\n\\]\ndonde \\(\\sigma_i\\) representa el desvÃ­o estÃ¡ndar de la componente \\(i\\) y \\(\\rho\\) la correlaciÃ³n entre las variables \\(X_1\\) y \\(X_2\\), entonces se deberÃ¡n ensayar los siguientes casos:\n\n\\(\\sigma_1 = \\sigma_2\\) y \\(\\rho = 0\\)\n\\(\\sigma_1 > \\sigma_2\\) y \\(\\rho = 0\\)\n\\(\\sigma_1 < \\sigma_2\\) y \\(\\rho = 0\\)\n\\(\\sigma_1 = \\sigma_2\\) y \\(\\rho > 0\\)\n\\(\\sigma_1 = \\sigma_2\\) y \\(\\rho < 0\\)\n\nTO DO: Hacer grÃ¡ficos\n\nPara al menos dos de los cinco casos anteriores, comparar las trayectorias seguidas por las cadenas al obtener muestras de \\(f(x)\\)."
  },
  {
    "objectID": "trabajos_practicos/02_tp2.html#aplicaciÃ³n-tiempo-de-reacciÃ³n-humano-proponer-un-prior-para-sigma-y-uno-para-mu",
    "href": "trabajos_practicos/02_tp2.html#aplicaciÃ³n-tiempo-de-reacciÃ³n-humano-proponer-un-prior-para-sigma-y-uno-para-mu",
    "title": "TP2: ImplementaciÃ³n del algoritmo de Metropolis-Hastings",
    "section": "AplicaciÃ³n: Â¿tiempo de reacciÃ³n humano? Â¿proponer un prior para sigma y uno para mu?",
    "text": "AplicaciÃ³n: Â¿tiempo de reacciÃ³n humano? Â¿proponer un prior para sigma y uno para mu?"
  },
  {
    "objectID": "practica/practica_00.html",
    "href": "practica/practica_00.html",
    "title": "PrÃ¡ctica - Unidad 0",
    "section": "",
    "text": "Descargar PDF\n\n\nDe las siguientes expresiones cual(es) se corresponde(n) con el enunciado â€œla probabilidad de que Argentina gane la copa del mundo el 18 de Diciembre de 2022â€?\n\n\\(P(\\text{18 de Diciembre de 2022} | \\text{Argentina campeon})\\)\n\\(P(\\text{Argentina campeon})\\)\n\\(P(\\text{Argentina campeon}, \\text{18 de Diciembre de 2022}) / P(\\text{18 de Diciembre de 2022})\\)\n\\(P(\\text{Argentina campeon} | \\text{Diciembre})\\)\n\\(P(\\text{Argentina campeon} | \\text{18 de Diciembre de 2022})\\) \n\nEnuncie con palabras cada una de las expresiones del punto anterior. \nSegÃºn la definiciÃ³n de probabilidad condicional\n\nÂ¿CuÃ¡l es el valor de \\(P(A | A)\\)?\nÂ¿CuÃ¡l es la probabilidad de \\(P(A, B)\\)?\nÂ¿CuÃ¡l es la probabilidad de \\(P(A, B)\\) en el caso que \\(A\\) y \\(B\\) sean independientes?\nCuando se cumple que \\(P(A | B) = P(A)\\)?\nEs posible que \\(P(A | B) > P(A)\\)? Cuando?\nEs posible que \\(P(A | B) < P(A)\\)? Cuando? \n\nSea \\(X\\) una variable aleatoria con soporte \\(X \\in \\mathcal{S} = [1, \\infty)\\). Encuentre la constante \\(c\\), en funciÃ³n de \\(\\theta\\), que haga que \\(f(x) = c \\exp(-x / \\theta)\\) sea una funciÃ³n de densidad de probabilidad vÃ¡lida. \nSuponga \\(X \\sim \\text{Uniforme}(a, b)\\). Su soporte es \\(\\mathcal{S} = [a, b]\\) y su funciÃ³n de densidad de probabilidad es \\(f(x) = 1 / (b - a)\\) para todo \\(x \\in \\mathcal{S}\\).\n\nPruebe que \\(f(x)\\) es una funciÃ³n de densidad de probabilidad vÃ¡lida.\nEncuentre la media y la varianza de \\(X\\). \n\nSegÃºn personas expertas en un problema determinado, se indica que el valor de un parÃ¡metro debe ser positivo y su distribuciÃ³n a priori debe tener media igual a 5 y varianza igual a 3. Encuentre una distribuciÃ³n que satisfaga estas condiciones. \nSean \\(X_1\\) y \\(X_2\\) dos variables aleatorias con funciÃ³n de probabilidad conjunta dada por la siguiente tabla\n\n\n\n\n\n\\(X_1\\) / \\(X_2\\)\n\\(X_2=0\\)\n\\(X_2=1\\)\n\n\n\n\n\\(X_1=0\\)\n\\(0.15\\)\n\\(0.15\\)\n\n\n\\(X_1=1\\)\n\\(0.15\\)\n\\(0.20\\)\n\n\n\\(X_2=2\\)\n\\(0.15\\)\n\\(0.20\\)\n\n\n\n\n\ndonde la celda de la primer fila y primer columna se lee \\(P(X_1=0, X_2=0)=0.15\\)\n\nObtenga la distribuciÃ³n marginal de \\(X_1\\).\nObtenga la distribuciÃ³n marginal de \\(X_2\\).\nObtenga la distribuciÃ³n condicional de \\(X_1\\) dado \\(X_2\\).\nObtenga la distribuciÃ³n condicional de \\(X_2\\) dado \\(X_1\\). \n\nSean \\(X_1\\) y \\(X_2\\) tales que \\((X_1, X_2)\\) siguen una distribuciÃ³n normal bivariada con \\(\\mathbb{E}(X_1) = \\mathbb{E}(X_1)\\) = 0, \\(\\text{Var}(X_1) = \\text{Var}(X_2 = 1)\\) y \\(\\text{cor}(X_1, X_2) = \\rho\\)\n\nEncuentre la distribuciÃ³n marginal de \\(X_1\\).\nEncuentre la distribuciÃ³n condicional de \\(X_1\\) dado \\(X_2\\). \n\nSuponga una urna \\(S\\) contiene un 40% de bolas verdes y un 60% de bolas rojas, y otra urna \\(E\\) contiene un 60% de bolas verdes y un 40% de bolas rojas. Una persona arroja una moneda de un peso argentino y selecciona una bola de una de las dos urnas dependiendo de si la moneda en sol o escudo. Si la moneda cae en sol, saca una bola de la urna \\(S\\) y si la moneda cae en escudo, saca una bola de la urna \\(E\\).\nConsidere las siguientes variables aleatorias:\n\\[\n\\begin{aligned}\nX &=\n    \\begin{cases}\n    1 & \\text{Si la moneda cae en sol} \\\\\n    0 & \\text{Si la moneda cae en escudo}\n    \\end{cases}\n\\\\\n\\\\\nY &=\n    \\begin{cases}\n    1 & \\text{Si la bola es verde} \\\\\n    0 & \\text{Si la bola es roja}\n    \\end{cases}\n\\end{aligned}\n\\]\n\nEncuentre la distribuciÃ³n conjunta de \\(X\\) e \\(Y\\) en una tabla.\nEncuentre \\(\\mathbb{E}(Y)\\). Â¿CuÃ¡l es la probabilidad de que la bola sea verde?\nEncuentre \\(\\text{Var}(Y | X = 0)\\), \\(\\text{Var}(Y | X = 1)\\) Y \\(\\text{Var}(Y)\\). Considerando a la varianza como una medida de incertidumbre, explique de manera intuitiva por que algunas variancias son mas grandes que otras.\nSuponga que observa que la bola es verde. Â¿CuÃ¡l es la probabilidad de que la moneda haya caido en escudo? \n\n\n\n\n\n\nMoneda de un peso argentino acuÃ±ada en 1995\n\n\n\n\nLas luces de giro en los automÃ³viles se utilizan para indicar que se va a realizar alguna acciÃ³n determinada. La acciÃ³n depende del escenario donde se conduzca (urbano, ruta, rotonda, etc.) y la luz que se encienda (izquierda o derecha). En el uso urbano, se debe colocar la luz de giro correspondiente para indicar que se va a girar en un sentido determinado. Sin embargo, esto no siempre se realiza. Muchas veces sucede que un vehÃ­culo no muestra luz de giro, y sin embargo gira. Aunque menos frecuente, tambiÃ©n se da que el vehÃ­culo colca la luz de giro, pero no gira. La probabilidad de girar dado que se colca la luz de giro es 0.87 y la probabilidad de girar dado que no se coloca la luz de giro es 0.21. Si observa que un vehÃ­culo coloca la luz de giro, Â¿cuÃ¡l es la probabilidad de que efectivamente doble?\nProblema del cumpleaÃ±os\nHay \\(k\\) personas en una sala. Suponga que el cumpleaÃ±os de cada persona tiene la misma probabilidad de ocurrir en cualquiera de los 365 dÃ­as del aÃ±o (se excluye el 29 de Febrero) y que los cumpleaÃ±os de las personas son independientes entre si. Â¿CuÃ¡l es la probabilidad de que al menos un par de personas en el grupo cumplan los aÃ±os el mismo dÃ­a? \nProblema de concordancia de de Montmort\nConsidere un mazo de \\(n\\) cartas bien mezcladas, etiquetadas con nÃºmeros del 1 a \\(n\\). Se seleccionan las cartas de a una y se la da vuelta, diciendo en voz alta el nÃºmero de cartas dadas vueltas desde 1 a \\(n\\). Para ganar el juego tiene que coincidir el nÃºmero que se dice en voz alta con el nÃºmero de la carta que se estÃ¡ dando vuelta â€“ por ejemplo, si la sÃ©ptima carta dada vuelta contiene el nÃºmero 7. Â¿CuÃ¡l es la probabilidad de ganar? Â¿Depende de \\(n\\)? \nProblema de los dos sobres\nSupongamos que te presentan dos sobres con dinero. Un sobre contiene el doble de dinero que el otro, pero a simple vista son indistinguibles. Se te pide que escogas uno de los sobres. Antes de abrirlo se te ofrece la posibilidad de cambiarlo por el otro. Â¿CambiarÃ­as el sobre? Â¿Por quÃ©?   \n\n\n\n\n\nReferencias\n\nHoff, Peter D. 2009. A First Course in Bayesian Statistical Methods. 1st edition. Springer.\n\n\nMartin, Osvaldo A., Ravin Kumar, y Junpeng Lao. 2021. Bayesian Modeling and Computation in Python. 1st edition. Chapman; Hall/CRC.\n\n\nReich, Brian J., y Sujit K. Ghosh. 2019. Bayesian Statistical Methods. 1st edition. Chapman; Hall/CRC."
  },
  {
    "objectID": "practica/practica_01.html",
    "href": "practica/practica_01.html",
    "title": "PrÃ¡ctica - Unidad 1",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "practica/practica_01.html#regla-de-bayes",
    "href": "practica/practica_01.html#regla-de-bayes",
    "title": "PrÃ¡ctica - Unidad 1",
    "section": "Regla de Bayes",
    "text": "Regla de Bayes\n\nEscribir la expresiÃ³n matemÃ¡tica para cada una de las siguientes descripciones verbales:\n\nProbabilidad de un parametro dados los datos observados\nLa distribucion de probabilidad de los parametros antes de ver los datos\nLa verosimilitud de los datos para un valor dado de los parÃ¡metros\nLa probabilidad de una observaciÃ³n nueva dados los datos observados\nLa probabilidad de una observaciÃ³n antes de ver los datos\nTo Do Revisar texto. No se si es mejor usar â€œdado/dadaâ€ o â€œcondicional aâ€, u otra expresiÃ³n.\nTo Do Algunas descripciones no estan cubiertas en la Unidad 1. \n\nEl test infalible\nEn una poblaciÃ³n dada, una de cada mil personas tiene una enfermedad. Se toma una persona al azar de la poblaciÃ³n, se le aplica un test para detectar dicha enfermedad, y el resultado es positivo. El test se caracteriza por dar positivo el 99% de las veces que una persona tiene la enfermedad. AdemÃ¡s, dicho test tiene una tasa de falsos positivos del 5%.\n\nÂ¿CuÃ¡l es la probabilidad de que la persona tenga efectivamente la enfermedad?\nSi realizamos el mismo anÃ¡lisis una segunda vez sobre el mismo paciente y obtenemos nuevamente positivo\n\nÂ¿CuÃ¡l seria la probabilidad que el paciente estÃ© enfermo?\nÂ¿Y si diera negativo?\nÂ¿Es el a priori el mismo para el segundo anÃ¡lisis que para el primero? \n\n\nÂ¿Es verdad que existen los vampiros? VersiÃ³n CrepÃºsculo\nEdward quiere probarle a Bella que los vampiros existen. SegÃºn Bella, hay una probabilidad del 5% de que los vampiros existan. TambiÃ©n cree que la probabilidad de que exista alguien con la piel brillante dado que los vampiros existen es del 70%, y que la probabilidad de que alguien tenga la piel brillante si los vampiros no existen es del 3%. Edward lleva a Bella al bosque y le muestra que de hecho su piel brilla como un ðŸ’Ž Â¿CuÃ¡l es la probabilidad que existan los vampiros? \n\n\n\n\n\nRobert Pattinson como Edward en CrepÃºsculo\n\n\n\n\nLos M&Ms azul fueron introducidos en el aÃ±o 1995 (antes habÃ­a dos tipos de marrÃ³n)\n\nAntes de 1995, la mezcla de colores en una bolsa de M&Ms era: 30% marron, 20% amarillo, 20% rojo, 10% verde, 10% naranja y 10% marrÃ³n bronceado.\nLuego de 1995, la mezcla pasÃ³ a ser: 24% azul, 20% verde, 16% naranja, 14% amarillo, 13% rojo y 13% marrÃ³n.\n\nUn amigo tiene dos bolsas de M&M y nos dice que una bolsa es de 1994 y la otra es de 1996, pero no nos dice cuÃ¡l es cuÃ¡l. Nos da un M&M de cada bolsa: uno es amarillo y el otro es verde (ambos posiblemente estÃ©n vencidos). Â¿CuÃ¡l es la probabilidad de que el amarillo venga de la bolsa de 1994?\nÃrboles enfermos\nUn vivero de la ciudad se destaca por vender una variedad de Ã¡rboles nativos, incluyendo al jacarandÃ¡, ceibo, ombÃº, entre otros. Lamentablemente, el 18% de los Ã¡rboles del vivero estan infectados con moho. Los Ã¡rboles enfremos se componen en un 15% por jacarandÃ¡s, 80% de ceibos, y 5% de otras especies 1. Los Ã¡rboles sanos se componen por un 20% de jacarandÃ¡s, 10% de ceibos, y 70% de otras especies. Con el objetivo de monitorear cuanto se propagÃ³ la enfermedad, una de las personas que trabaja en el vivero selecciona al azar uno de los Ã¡rboles para testear.\n\nÂ¿CuÃ¡l es la probabilidad a priori de que el Ã¡rbolo tenga moho?\nResulta que el Ã¡rbol seleccionado es un ceibo. Â¿CuÃ¡l es la probabilidad de haber seleccionado un ceibo?\nÂ¿CuÃ¡l es la probabilidad a posteriori de que el ceibo seleccionado tenga moho?\nCompare las probabilidades a priori y a posteriori de que el Ã¡rbol tenga moho. Â¿CÃ³mo afecta el anÃ¡lisis el saber que el Ã¡rbol es un ceibo? \n\n\n\n\n\n\nFlor del Ceibo, la flor nacional\n\n\n\n\nTransporte El Impuntual\nUna cierta empresa de transporte regional, que decidimos llamar â€œEl Impuntualâ€, tiene servicios que van desde Rosario hasta Wheelwright varias veces al dÃ­a, todos los dÃ­as de la semana. Un 30% de los viajes salen a la maÃ±ana, otro 30% salen a la tarde, y el restante 40% salen a la noche. Los pasajeros suelen estar muy frustrados ya que un 25% de los viajes salen tarde. De estos viajes demorados, el 40% corresponden a la maÃ±ana, un 50% suceden a la tarde, y el 10% restante ocurre a la noche.\nLucio y Franco son dos amigos del pueblo, y se volvieron a sus casas en colectivos diferentes.\n\nLucio se fue en uno de los colectivos de la maÃ±ana. Â¿CuÃ¡l es la probabilidad que su viaje estÃ© demorado?\nEl colectivo de Franco no estÃ¡ demorado. Â¿CuÃ¡l es la probabilidad de que estÃ© viajando en uno de los colectivos de la maÃ±ana? \n\n\n\n\n\n\nFoto de Markus Winkler en Unsplash\n\n\n\n\nBebÃ© panda\nSupongamos que hay dos especies de osos panda. Ambas especies son igual de frecuentes y viven en la misma regiÃ³n. Es mÃ¡s, lucen de la misma forma y comen la misma comida. AÃºn no existe una prueba genÃ©tica que pueda diferenciarlos. Lo Ãºnico que los diferencia es la cantidad de crÃ­as que suelen tener. Las madres de la especie A dan luz a mellizos el 10% del tiempo. Y las madres de la especie B dan a luz mellizos el 20% del tiempo. En todos los otros casos, estas madres dan a luz un solo bebÃ© panda.\nUsando un poco la imaginaciÃ³n, supongamos que somos la persona encargada de un programa de reproducciÃ³n de pandas. Tenemos una panda femenina que acaba de dar a luz a un par de mellizos, pero no sabemos a que especie pertenece.\n\nÂ¿CuÃ¡l es la probabilidad que la mamÃ¡ panda sea de la especie A?\nÂ¿CuÃ¡l es la probabilidad que vuelva a tener mellizos en la prÃ³xima pariciÃ³n?\nUn tiempo despuÃ©s sos encontramos con que en la segunda pariciÃ³n da a luz a un Ãºnico bebÃ© panda. Â¿CuÃ¡l es la probabilidad de que este panda sea de la especie A? \n\n\n\n\n\n\nFoto de Stone Wang en Unsplash\n\n\n\n\nDemuestra la validez de la siguiente expresiÃ³n de la regla de Bayes\n\\[\nP(B_j | A) = \\frac{P(A | B_j) P(B_j)}{\\sum_{k=1}^{K}P(A | B_k) P(B_k)}\n\\]\ndonde \\(A\\) es un evento cualquiera y \\(\\{B_1, \\cdots, B_K\\}\\) forman una particiÃ³n. Para ello siga los siguientes pasos\n\nDemuestre que \\(P(B_j | A) P(A) = P(A | B_j) P(B_j)\\).\nDemuestre que \\(P(A) = P(A \\cap B_1) + P(A \\cap \\{\\cup_{k=2}^{K}B_j\\})\\).\nDemuestre que \\(P(A) = \\sum_{k=1}^{K} P(A \\cap B_j)\\).\nJunte las partes para formar la regla de Bayes.  \n\nHouse of Cards\nHay 538 miembros en el Congreso de Estados Unidos. Supongamos que se auditan sus inversiones y se encuentra que 312 de ellos obtuvieron rendimientos por encima del mercado. Asumamos que un miembro honesto del Congreso tiene solo una probabilidad del 50% de tener rendimientos por encima del mercado, pero uno deshonesto que opera con informaciÃ³n confidencial tiene una chance del 90% de hacerlo. Â¿CuÃ¡ntos miembros del Congreso son honestos? \nEstÃ¡s a punto de subir a un aviÃ³n rumbo a Seattle. QuerÃ©s saber si tenÃ©s que llevar un paraguas. LlamÃ¡s a tres amigos que viven en Seattle y les preguntÃ¡s si estÃ¡ lloviendo. Cada uno de ellos tiene una probabilidad de 2/3 de decirte la verdad y 1/3 de mentirte para hacerte una broma. Los tres responden que sÃ­ estÃ¡ lloviendo. CuÃ¡l es la probbailidad de que realmente estÃ© lloviendo en Seattle? Se puede asumir que llueve el 10% del tiempo. \nDos personas dejaron rastros de sangre en la escena del crimen. La sangre de Oliver, un sospechoso, es analizada y resulta ser de tipo â€˜0â€™. Los rastros de sangre de la escena son de tipo â€˜0â€™ (un tipo comÃºn en la poblaciÃ³n, presente en el 60% de las personas) y de tipo â€˜ABâ€™ (un tipo raro, con una frecuencia del 1% en la poblaciÃ³n). Â¿Estos datos representan evidencia de que Oliver estaba presente en la escena del crimen? \nNos encontramos con alguien en la calle y nos dice que tiene dos hijxs. Le preguntamos si algunx de ellxs es mujer y nos responde que sÃ­. Â¿CuÃ¡l es la probabilidad de que ambxs sean niÃ±as? \nElvis Presley tenÃ­a un hermano varÃ³n que naciÃ³ en el mismo parto pero que muriÃ³ al poco tiempo. Â¿CuÃ¡l es la probabilidad de que Elvis tuviera un gemelo? Alguna informaciÃ³n adicional: en 1935, cuando Elvis naciÃ³, 1/3 de los hermanxs del mismo parto eran gemelxs y 2/3 mellizxs; ademÃ¡s, la probabilidad de que dos mellizxs sean del mismo sexo biolÃ³gico puede estimarse en 50%, mientras que dos gemelxs son siempre del mismo sexo biolÃ³gico. \nDos cajones contienen medias. Uno de ellos tiene igual cantidad de medias blancas y negras. El otro contiene un nÃºmero igual de medias rojas, verdes y azules. Se elige un cajÃ³n al azar, se sacan dos medias sin mirar y resultan ser las dos iguales. Â¿CuÃ¡l es la probabilidad de que las medias sean blancas? SupÃ³ngase que sacar la primera media no altera las proporciones. \nProsecutorâ€™s Fallacy\nSally Clark era una abogada britÃ¡nica que fue errÃ³neamente sentenciada a prisiÃ³n perpetua en 1999 por la muerte de sus dos hijos bebÃ©s. Su hijo mayor, Christopher, muriÃ³ con 11 semanas en diciembre de 1996 y su hijo mÃ¡s joven, Harry, con 8 semanas en enero de 1998. Durante el juicio, la defensa argumentÃ³ que las muertes se debieron al sÃ­ndrome de muerte sÃºbita del lactante (SIDS). Clark fue condenada a partir del testimonio del pediatra Sir Roy Meadow, quien argumentÃ³ en la corte lo siguiente:\n\nEn familias sanas, la chance de muerte por SIDS es de \\(\\frac{1}{8500}\\)\nLa probabilidad de dos muertes por SIDS en la misma familia es aproximadamente \\(\\frac{1}{8500^2} \\approx \\frac{1}{73000000}\\)\nEs, por ende, muy poco probable que Clark sea inocente\n\nLuego de pasar 3 aÃ±os en prisiÃ³n, Clark fue liberada en 2003 luego de que se determinara que el testimonio experto de Meadows era equivocado. Dos mujeres, a las cuales el testimonio de Meadows habÃ­a enviado a prisiÃ³n, tambiÃ©n fueron liberadas.\n\nIdentifica una falla en la probabilidad de \\(\\frac{1}{73000000}\\) dada por Meadows\nIncluso aceptando el nÃºmero anterior como correcto, Â¿cuÃ¡l es el problema de interpretar esa probabilidad como la probabilidad de inocencia de Clark?"
  },
  {
    "objectID": "practica/practica_01.html#popurrÃ­",
    "href": "practica/practica_01.html#popurrÃ­",
    "title": "PrÃ¡ctica - Unidad 1",
    "section": "PopurrÃ­?",
    "text": "PopurrÃ­?\nTodos como que caen dentro de â€œregla de bayesâ€. Tenemos que ver como los dividimos\n\nSea \\(X_1 \\sim \\text{Bernoulli}(\\theta)\\) una variable que indica si una especie de Ã¡rboles se halla en un determinado bosque y \\(\\theta \\in [0, 1]\\) representa la probabilidad a priori de que la especie se encuentre en el bosque. Una investigadora selecciona una muestra de \\(n\\) Ã¡rboles del bosque y encuentra que \\(X_2\\) de ellas pertenecen a la especie de interÃ©s.\nEl modelo luego es \\[\n\\begin{array}{lc}\nX_2|X_1 \\sim \\text{Binomial}(n, \\lambda X_1) & \\text{con } \\lambda \\in [0, 1]\n\\end{array}\n\\]\n\\(\\lambda\\) representa la probabilidad de detectar la especie, dado que la especie se encuentra en el bosque.\nEncuntre expresiones matemÃ¡ticas en tÃ©rmino de \\(n\\), \\(\\theta\\) y \\(\\lambda\\) para las siguientes probabilidades:\n\n\\(P(X_1 = 0, X_2 = 0)\\)\n\\(P(X_1 = 0)\\)\n\\(P(X_2 = 0)\\)\n\\(P(X_1 = 0 | X_2 = 0)\\)\n\\(P(X_2 = 0 | X_1 = 0)\\)\n\\(P(X_1 = 0 | X_2 = 1)\\)\n\\(P(X_2 = 0 | X_1 = 1)\\)\nExplique de manera intuitiva cÃ³mo es que las probabilidades calculadas en (iv)-(vii) cambian segÃºn \\(n\\), \\(\\theta\\) y \\(\\lambda\\).\nAsuma \\(\\theta=0.5\\), \\(\\lambda=0.1\\) y \\(X_2 = 0\\) Â¿CuÃ¡n grande debe ser \\(n\\) para que se puede concluir con 95% de confianza que la especie no se encuentra en el bosque? \n\nEn un estudio que utiliza mÃ©todos de la EstadÃ­stica Bayesiana para predecir el nÃºmero de especies que serÃ¡n descubiertas en el futuro se reporta que la cantidad de especies marinas bivalvas2 descubiertas cada aÃ±o entre 2010 y 2015 fue 64, 13, 33, 18, 30 y 20.\nSi se representa con \\(Y_t\\) a la cantidad de especies descubierta en el aÃ±o \\(t\\), y asumiendo:\n\\[\n\\begin{aligned}\nY_t | \\lambda &\\underset{iid}{\\sim} \\text{Poisson}(\\lambda) \\\\\n\\lambda       &\\sim \\text{Uniforme}(0, 100)\n\\end{aligned}\n\\]\nGraficar la distribuciÃ³n a posteriori de \\(\\lambda\\). \nSea \\(n\\) la cantidad desconocida de clientes que visitan una tienda en un dia cualquiera. El nÃºmero de clientes que realizan una compra es \\(Y\\) y se cumple que\n\\[\nY | n \\sim \\text{Binomial}(n, \\theta)\n\\]\ndonde \\(\\theta\\) es la probabilidad de compra, dado que se produce la visita a la tienda. La distribuciÃ³n a priori de \\(n\\) es \\(n \\sim \\text{Poisson}(5)\\). Bajo el supuesto que \\(\\theta\\) es conocido y que \\(n\\) es desconocido, graficar la distribuciÃ³n a posteriori de \\(n\\) para todas las combinaciones de \\(Y \\in \\{0, 5, 10 \\}\\) y \\(\\theta \\in \\{0.2, 0.5\\}\\). Explique cual es del efecto de cambiar \\(Y\\) y \\(\\theta\\) sobre la distribuciÃ³n a posteriori.  \nUn amigo arroja un dado y anota en secreto el nÃºmero que sale (llamÃ©moslo \\(T\\)). A continuaciÃ³n, nosotros, con los ojos vendados, arrojamos el dado varias veces. No podemos ver el nÃºmero que sale pero nuestro amigo nos dice si el nÃºmero que sacamos es mayor, menor o igual a \\(T\\).\nSupongamos que nos da la secuencia: \\(G,\\ G,\\ C,\\ I,\\ C,\\ C,\\ C, I,\\ G,\\ C\\) (siendo \\(G\\) mÃ¡s grande, \\(C\\) mÃ¡s chico e \\(I\\) igual). Â¿CuÃ¡l es la distribuciÃ³n a posteriori de los valores de \\(T\\)? \nHay dos monedas en una caja. Una de ellas es una moneda comÃºn y la otra es una moneda que tiene dos caras.\n\nSe elige una moneda al azar, se arroja, y se obtiene cara. Â¿CuÃ¡l es la probabilidad de que la moneda elegida sea la falsa?\nSe elige una moneda al azar y se arroja al aire tres veces, obteniÃ©ndose tres caras. Â¿CuÃ¡l es la probabilidad de que la moneda elegida sea la falsa?\n\nCansada de los experimentos de arrojar una moneda cientos de veces al aire, una estudiante diseÃ±a un sistema de reconocimiento de imÃ¡genes que determina si saliÃ³ cara o ceca y registra el resultado.\nLÃ³gicamente, el sistema diseÃ±ado no es perfecto sino que presenta una tasa de error. En particular, la probabilidad de que clasificar mal es de 0.2 (20% de las veces que sale cara, el sistema dice ceca, y viceversa).\nSe arroja la moneda 250 veces y el sistema detecta 140 caras,\n\nÂ¿CuÃ¡l es la distribuciÃ³n a posteriori de \\(\\theta\\), la probabilidad de obtener cara?\nÂ¿QuÃ© ocurre a medida que la probabilidad de clasificar mal varÃ­a? \n\nEn las Jornadas Rosarinas de Ciencia de Datos, una expositora estÃ¡ dando una charla en un salÃ³n cuando el personal de seguridad la interrumpe porque cree que puede haber mÃ¡s de 1000 personas en la sala, superando el mÃ¡ximo permitido.\nLa expositora piensa que hay menos de 1000 personas y se ofrece a demostrarlo, aunque piensa que contarlas podrÃ­a llevar mucho tiempo.\nDecide hacer un experimento:\n\nPregunta cuÃ¡ntas personas nacieron el 11 de mayo. Dos personas levantan la mano.\nPregunta cuÃ¡ntas personas nacieron el 23 de mayo. Una persona levanta la mano.\nPregunta cuÃ¡ntas personas nacieron el 1 de agosto. Nadie levanta la mano.\n\nÂ¿CuÃ¡ntas personas hay en la sala? O, mejor dicho, Â¿cuÃ¡l es la probabilidad de que haya mÃ¡s de 1000 personas en la sala? \nSupongamos que existe un idioma con seis palabras:\n\\[\n\\text{\\{perro, parra, farra, carro, corro, tarro\\}}\n\\]\nUn anÃ¡lisis lingÃ¼Ã­stico exhaustivo de esta lengua ha descubierto que todas las palabras son igualmente probables, excepto por â€˜perroâ€™, que es \\(\\alpha\\) veces mÃ¡s probable que las otras. AdemÃ¡s:\n\nCuando se tipean, un caracter se introduce errÃ³neamente con probabilidad \\(\\theta\\);\nTodas las letras tienen la misma probabilidad de producir un error de tipeo;\nSi una letra se tipeÃ³ mal, la probabilidad de cometer un error en otro caracter no cambia;\nLos errores son independientes a lo largo de una palabras.\n\n\nÂ¿CuÃ¡l es la probabilidad de escribir correctamente â€˜tarroâ€™?\nÂ¿CuÃ¡l es la probabilidad de tipear â€˜cerroâ€™ o â€˜curroâ€™ al querer escribir â€˜carroâ€™?\nUtilizando la Regla de Bayes, desarrollar un corrector gramatical para esta lengua. Para las palabras tipeadas â€˜farraâ€™, â€˜birraâ€™ y â€˜locosâ€™, hallar la probabilidad de que cada palabra del diccionario sea la palabra que se habÃ­a querido escribir. Utilizar las siguientes combinaciones de parÃ¡metros:\n\n\\(\\alpha=2\\) y \\(\\theta = 0.1\\)\n\\(\\alpha=50\\) y \\(\\theta = 0.1\\)\n\\(\\alpha=2\\) y \\(\\theta = 0.9\\)"
  },
  {
    "objectID": "practica/practica_01.html#conceptuales",
    "href": "practica/practica_01.html#conceptuales",
    "title": "PrÃ¡ctica - Unidad 1",
    "section": "Conceptuales",
    "text": "Conceptuales\n\nVoy a conseguir esa pasantÃ­a\nLa empresa de tecnologÃ­a en la que todo el mundo quiere trabajar tiene varias vacantes para pasantes en ciencia de datos. Luego de leer la descripciÃ³n de la bÃºsqueda, te das cuenta que sos una persona calificada para el puesto: estos son tus datos. Tu objetivo es averiguar si te van a ofrecer el puesto: esta es tu hipÃ³tesis.\n\nDesde la perspectiva de una persona con un razonamiento frecuentista, Â¿QuÃ© es lo que se responde al evaluar la hipÃ³tesis de que te ofrecen el puesto?\nRepita el punto anterior considerando la perspectiva de una persona con un razonamiento Bayesiano.\nÂ¿QuÃ© pregunta tiene mÃ¡s sentido responder: la frecuentista o la Bayesiana? Justifica tu respuesta. \n\nBeneficios de la EstadÃ­stica Bayesiana\nUna amiga te cuenta que estÃ¡ interesada en aprender mÃ¡s sobre EstadÃ­stica Bayesiana. ExplÃ­cale lo siguiente:\n\nÂ¿Por quÃ© es Ãºtil el enfoque Bayesiano?\nÂ¿CuÃ¡les son las similitudes entre el enfoque frecuentista y el Bayesiano? \n\n\n\n\n```"
  },
  {
    "objectID": "practica/practica_04.html",
    "href": "practica/practica_04.html",
    "title": "PrÃ¡ctica - Unidad 4",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "practica/practica_04.html#ideas",
    "href": "practica/practica_04.html#ideas",
    "title": "PrÃ¡ctica - Unidad 4",
    "section": "Ideas",
    "text": "Ideas\n\nModelo lineal basico con datos simulados\nModelo lineal con predictores numericos y categoricos\nModelo lineal con transformaciones\n\nEn predictores y/o respuesta\n\nEleccion de distribuciones a priori\n\nPriors de regularizacion\n\nCaso donde hay muchos predictores numericos\n\nPruebas predictivas a priori para evaluar cuan vagos o restrictivos son los priors\n\nPruebas predictivas a posteriori\n\nNo estoy seguro que poner aca\nlppd?\n\nEvaluacion/seleccion de modelos\n\nDeviance\nCriterios de informacion\nCV\nPSIS-CV\nBayesiano al palo: No selecciono variables, uso priors que hagan seleccion de variable y uso ese resultado\n\nSobreajuste y subajuste"
  },
  {
    "objectID": "practica/practica_04.html#preguntas",
    "href": "practica/practica_04.html#preguntas",
    "title": "PrÃ¡ctica - Unidad 4",
    "section": "Preguntas",
    "text": "Preguntas\n\nUsamos RStan o brms?\n\nMe inclino por usar brms.\nPero no estaria mal que hagamos uno o dos modelos con RStan."
  },
  {
    "objectID": "practica/practica_05.html",
    "href": "practica/practica_05.html",
    "title": "PrÃ¡ctica - Unidad 5",
    "section": "",
    "text": "Descargar PDF\n\n\nConsidere un modelo para datos de conteo con un predictor lineal \\(X\\) que toma valores entre -3 y 50\n\\[\n\\begin{aligned}\nY_i   &\\sim \\mathrm{Poisson}(\\lambda_i) \\\\\n\\log(\\lambda_i) &= \\beta X \\\\\n\\end{aligned}\n\\]\n\nGenere 1000 valores de \\(X\\), asuma un valor conocido (y fijo) para \\(\\beta\\), simule los correspondientes valores de \\(\\lambda_i\\) y los de \\(Y_i\\). Â¿CÃ³mo es \\(\\lambda\\) en funciÃ³n de \\(X\\)? Â¿Es lineal la relaciÃ³n entre \\(X\\) e \\(Y\\)? Â¿QuÃ© ocurre con la varianza de \\(Y\\) en funciÃ³n de \\(X\\)? Â¿CÃ³mo es la distribuciÃ³n marginal de \\(Y\\)?\nAhora aÃ±ada incertidumbre al valor de \\(\\beta\\) (Â¿cÃ³mo se hace esto?) y simule nuevamente valores para \\(\\lambda_i\\) y \\(Y_i\\). Compare los resultados.\n\nConsidere un modelo de clasificaciÃ³n con un predictor lineal \\(X\\) que toma valores entre -30 y 10\n\\[\n\\begin{aligned}\nY_i   &\\sim \\mathrm{Bernoulli}(\\theta_i) \\\\\n\\log\\left(\\frac{\\theta_i}{1-\\theta_i}\\right) &= \\beta X \\\\\n\\end{aligned}\n\\]\n\nGenere 1000 valores de \\(X\\), asuma un valor conocido (y fijo) para \\(\\beta\\), simule los correspondientes valores de \\(\\theta_i\\) y los de \\(Y_i\\). Â¿CÃ³mo es \\(\\theta\\) en funciÃ³n de \\(X\\)? Â¿Es lineal la relaciÃ³n entre \\(X\\) e \\(Y\\)?\nAhora aÃ±ada incertidumbre al valor de \\(\\beta\\) (Â¿cÃ³mo se hace esto?) y simule nuevamente valores para \\(\\theta_i\\) y \\(Y_i\\). Compare los resultados.\n\nUtilice el conjunto de datos de las elecciones presidenciales de Estados Unidos del aÃ±o 2016 que se provee en Reich y Ghosh (2019). Elabore un modelo de regresiÃ³n lineal bayesiano donde la variable respuesta es la diferencia porcentual entre el porcentaje de votos que obtuvo el candidato Republicano en el 2016 versus los que tuvo en el 2012 en cada condado y utilice todas las demÃ¡s variables como predictoras.\n\nUtilice distribuciones a priori normales no informativas. Interprete las distribuciones a posteriori marginales de los coeficientes de regresiÃ³n.\nCalcule los residuos \\(\\mathbf{r} = \\mathbf{y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}\\) donde \\(\\hat{\\boldsymbol{\\beta}}\\) es la media a posteriori del vector de coeficientes de regresiÃ³n. Â¿Puede concluir que los residuos sigan una distribuciÃ³n normal? Â¿QuÃ© condados presentan los residuos mÃ¡s grandes y mÃ¡s pequeÃ±os? Â¿QuÃ© puede indicar sobre estos condados?\nTo Do: Compartir datos de forma accesible \n\nUtilice el conjunto de datos sobre el control de armas en Estados Unidos. Estos datos provienen de un estudio transversal. Para el estado \\(i\\), sea \\(Y_i\\) el numero de homicios y \\(N_i\\) el tamaÃ±o de la poblaciÃ³n.\n\nAjuste el modelo \\(Y_i | \\boldsymbol{\\beta} \\sim \\text{Poisson}(N_i\\lambda_i)\\) donde \\(\\text{log}(\\lambda_i) = \\mathbf{X}_i\\boldsymbol{\\beta}\\). Use distribuciones a priori no informativas y \\(p = 7\\) de las covariables en \\(\\mathbf{X}_i\\): el intercepto, los cinco â€œconfoundersâ€ \\(\\mathbf{Z}_i\\), y el nÃºmero de leyes relacionadas a armas. Justifique que el sampler ha convergido y explorado suficientemente la distribuciÃ³n a posteriori y resuma la distribuciÃ³n a posteriori de \\(\\boldsymbol{\\beta}\\).\nTo Do: No puse los puntos (b) y (c) porque no se si estan dentro del plan\nTo Do: Ver como presentamos el tema de las variables a incorporar en el modelo\n\nDescargue el conjunto de datos babynames en R y calcule el log-odds de un bebÃ© llamado â€œSophiaâ€ en cada aÃ±o luego de 1950.\nlibrary(babynames)\ndat <- babynames\ndat <- dat[dat$name == \"Sophia\" & dat$sex == \"F\" & dat$year > 1950, ]\nyr <- dat$year\np <- dat$prop\nt <- dat$year - 1950\nY <- log(p / (1 - p))\nSea \\(Y_t\\) el log-odds muestral en el aÃ±o \\(t + 1950\\). Ajuste el siguiente modelo auto-regresivo de orden 1:\n\\[\n\\begin{aligned}\nY_t   &= \\mu_t + \\rho(Y_{t - 1} + \\mu_{t - 1}) + \\varepsilon_t \\\\\n\\mu_t &= \\alpha + \\beta t \\\\\n\\varepsilon &\\underset{iid}{\\sim} \\text{Normal}(0, \\sigma^2) \\\\\n\\alpha, \\beta &\\sim \\text{Normal}(0, 100^2) \\\\\n\\rho &\\sim \\text{Uniforme}(-1, 1) \\\\\n\\sigma^2 &\\sim \\text{InvGamma}(0.1, 0.1)\n\\end{aligned}\n\\]\n\nInterprete los parÃ¡metros del modelo (\\(\\alpha\\), \\(\\beta\\), \\(\\rho\\) y \\(\\sigma^2\\))\nAjuste el modelo utilizando RStan para \\(t > 1\\). Verifique la convergencia y reporte la media a posteriori e intervalos del 95% para los parÃ¡metros.\nGrafique la distribuciÃ³n predictiva a posteriori para \\(Y_t\\) en el aÃ±o 2020. \n\nEn este ejercicio se llevarÃ¡ a cabo un meta-anÃ¡lisis, es decir, un anÃ¡lisis que combina el resultado de varios estudios. Los datos provienen del paquete rmeta en R.\nlibrary(rmeta)\ndata(cochrane)\ncochrane\n          name ev.trt n.trt ev.ctrl n.ctrl\n1     Auckland     36   532      60    538\n2        Block      1    69       5     61\n3        Doran      4    81      11     63\n4        Gamsu     14   131      20    137\n5     Morrison      3    67       7     59\n6 Papageorgiou      1    71       7     75\n7      Tauesch      8    56      10     71\nLos datos provienen de siete ensayos aleatorizados que evalÃºan el efecto de la terapia con corticosteroides en la muerte neonatal. Para el ensayo \\(i \\in \\{1, \\dots, 7 \\}\\) \\(Y_{i0}\\) representa el nÃºmero de eventos que ocurren en el grupo de control de tamaÃ±o \\(N_{i0}\\) y \\(Y_{i1}\\) representa el nÃºmero de eventos que ocurren en el grupo tratado de tamaÃ±o \\(N_{i1}\\).\n\nAjuste el modelo \\(Y_{ij} | \\theta_j \\underset{indep}{\\sim} \\text{Binomial}(N_{ij}, \\theta_j)\\) con \\(\\theta_0, \\theta_1 \\sim \\text{Uniforme}(0, 1)\\). Â¿Se puede concluir que el tratamiento estÃ¡ asociado a una reducciÃ³n de la tasa de muerte?\nAjuste el modelo \\(Y_{ij} | \\theta_j \\underset{indep}{\\sim} \\text{Binomial}(N_{ij}, \\theta_j)\\) con\n\n\\(\\text{logit}(\\theta_{ij}) = \\alpha_{ij}\\)\n\\(\\boldsymbol{\\alpha}_i = (\\alpha_{i0}, \\alpha_{i1})^T \\underset{iid}{\\sim} \\text{Normal}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})\\)\n\\(\\boldsymbol{\\mu} \\sim \\text{Normal}(0, 10^2I_2)\\)\n\\(\\boldsymbol{\\Sigma} \\sim \\text{InvWishart}(3, I_2)\\)\n\nInterprete los resultados indicando si estos sugieren que el tratamiento estÃ¡ asociado a una reducciÃ³n en la tasa de muerte.\nDibuje un DAG para ambos modelos.\nDiscuta las ventajas y desventajas de ambos modelos.\nÂ¿CuÃ¡l modelo es el preferido para estos datos? \n\nUtilice el conjuto de datos airquality que viene con el paquete datasets que se carga automÃ¡ticamente al crear una sesiÃ³n de R.\nhead(airquality)\n  Ozone Solar.R Wind Temp Month Day\n1    41     190  7.4   67     5   1\n2    36     118  8.0   72     5   2\n3    12     149 12.6   74     5   3\n4    18     313 11.5   62     5   4\n5    NA      NA 14.3   56     5   5\n6    28      NA 14.9   66     5   6\nCompare los siguientes modelos utilizando 5-fold cross-validation:\n\\[\n\\begin{array}{l}\n\\mathcal{M}_1: \\text{Ozone}_i \\sim \\text{Normal}(\\beta_1 + \\beta_2 \\text{Solar.R}_i, \\sigma^2) \\\\\n\\mathcal{M}_2: \\text{Ozone}_i \\sim \\text{Normal}(\\beta_1 + \\beta_2 \\text{Solar.R}_i + \\beta_3 \\text{Temp}_i + \\beta_4 \\text{Wind}_i, \\sigma^2)\n\\end{array}\n\\]\nElija priors para ambos modelos explicando su elecciÃ³n. \nAccidente del Challenger\nEl 28 de enero de 1986, el vuelo nÃºmero veinticinco del programa estadounidense de trasbordadores espaciales acabÃ³ en un desastre cuando uno de los propulsores del Challenger explotÃ³ poco despuÃ©s del despegue. En el accidente murieron los siete tripulantes. La comisiÃ³n que investigÃ³ el accidente concluyÃ³ que el accidente fue causado por una falla en un o-ring en una juntura de uno de los propulsores. Esta falla se debiÃ³ a un diseÃ±o defectuoso que volviÃ³ al o-ring excesivamente sensible a factores externos, entre ellos la temperatura. De los veinticuatro vuelos previos, existÃ­a informaciÃ³n de fallas de o-rings para veintitrÃ©s de ellos (el otro se perdiÃ³ en el ocÃ©ano). Estos datos fueron discutidos la noche previa al incidente. No obstante, los datos de los siete vuelos en los que hubo fallas llevaron a la conclusiÃ³n de que no habÃ­a una evidencia clara.\n\n\n\n\n\n\n \n  \n    T (Â°F) \n    Falla \n  \n \n\n  \n    66 \n    0 \n  \n  \n    70 \n    1 \n  \n  \n    69 \n    0 \n  \n  \n    68 \n    0 \n  \n  \n    67 \n    0 \n  \n  \n    72 \n    0 \n  \n  \n    73 \n    0 \n  \n  \n    70 \n    0 \n  \n  \n    57 \n    1 \n  \n  \n    63 \n    1 \n  \n  \n    70 \n    1 \n  \n  \n    78 \n    0 \n  \n  \n    67 \n    0 \n  \n  \n    53 \n    1 \n  \n  \n    67 \n    0 \n  \n  \n    75 \n    0 \n  \n  \n    70 \n    0 \n  \n  \n    81 \n    0 \n  \n  \n    76 \n    0 \n  \n  \n    79 \n    0 \n  \n  \n    75 \n    1 \n  \n  \n    76 \n    0 \n  \n  \n    58 \n    1 \n  \n\n\n\n\n\n\nCurvas de crecimiento de tiranosÃ¡uridos\nSe analizan datos de 20 fÃ³siles de tiranosÃ¡uridos para estimar las curvas de crecimiento de cuatro especies: Albertosaurio, Daspletosaurio, Gorgosaurio y Tiranosaurio. Los datos se toman de la Tabla 1 de Erickson etÂ al. (2004) y se muestran en la FiguraÂ 1. El objetivo es determinar la curva de crecimiento, esto es, determinar el peso esperado por edad para todas las especies.\nEn el panel izquierdo de la FiguraÂ 1 se puede observar que hay una relaciÃ³n no lineal entre la edad y el peso. TambiÃ©n se observan ciertos patrones comunes a las especies. Por ejemplo, la relaciÃ³n positiva entre las variables o el decrecimiento en la tasa de cambio conforme la edad es mayor.\n\n\n\n\n\nFiguraÂ 1: (Izquierda) Edad (aÃ±os) vs Peso (kilogramos). (Derecha) Los mismos datos luego de aplicar la transformaciÃ³n logarÃ­tmica a ambas variables.\n\n\n\n\nSea \\(Y_{ij}\\) el peso y \\(X_{ij}\\) y la edad de la muestra \\(i\\) de la especie \\(j\\), con \\(j = 1, 2, 3, 4\\). Se propone el siguiente modelo:\n\\[\nY_{ij} = f_j(X_{ij}) \\epsilon_{ij}\n\\]\ndonde \\(f_j\\) es la verdadera curva de crecimiento para la especie \\(j\\) y \\(\\epsilon_{ij} > 0\\) es un error multiplicativo.\n\nÂ¿Por quÃ© tiene sentido proponer un error multiplicativo?\nÂ¿CuÃ¡l es un valor sensato para la media de la distribuciÃ³n del error?\nUtilice una distribuciÃ³n log-normal para el error, \\(\\log (\\epsilon_{ij}) \\sim \\text{Normal}\\). Proponga valores para la media y la varianza de forma tal que satisfagan la condiciÃ³n del punto anterior.\n\nEsto da lugar un al siguiente modelo log-normal para \\(Y_{ij}\\):\n\\[\n\\log (Y_{ij}) \\sim \\text{Normal}\n(\\log [f_j(X_{ij})] + \\mu_{\\log \\epsilon}, \\sigma^2_{\\log \\epsilon})\n\\]\ncon \\(\\mathbb{E}(Y_{ij}) = f_j(X_{ij})\\).\nA continuaciÃ³n se proponen cuatro modelos que varÃ­an segÃºn la relaciÃ³n funcional que se propone para \\(f_j\\) y la naturaleza de las distribuciones a priori que se utilizan.\nModelo 1\nObservando el panel derecho de la FiguraÂ 1 se puede concluir que luego de transformar ambas variables con la funciÃ³n logaritmo la relaciÃ³n se ve aproximadamente lineal. Por lo tanto, se propone el siguiente modelo log-lineal:\n\\[\n\\log [f_j(X)] = a_j + b_j \\log(X)\n\\]\ndonde \\(a_j\\) y \\(b_j\\) representan al intercepto y pendiente de la especie \\(j\\). La curva de crecimiento en la escala original resulta \\(f_j(X) = \\exp (a_j)X^{b_j}\\). Considere los siguientes priors:\n\\[\n\\begin{aligned}\na_j &\\sim \\text{Normal}(0, 10) \\\\\nb_j &\\sim \\text{Normal}(0, 10) \\\\\n\\sigma^2_j &\\sim \\text{InvGamma}(0.1, 0.1)\n\\end{aligned}\n\\]\n\nEscriba un programa en Stan que implemente el modelo y obtenga el posterior con RStan.\nAnalice los coeficientes del modelo y las curvas de crecimiento. Realice grÃ¡ficos que permitan observar la curva ajustada y su incertidumbre para cada especie.\n\nModelo 2\nEste modelo es el mismo que el Modelo 1, excepto que las especies tienen la misma varianza, \\(\\sigma^2_j = \\sigma^2\\) y los coeficientes de regresiÃ³n son modelados de manera jerÃ¡rquica. Utilice los siguientes priors:\n\\[\n\\begin{aligned}\n\\mu_a    &\\sim \\text{Normal}(0, 10) \\\\\n\\sigma_a &\\sim \\text{InvGamma}(0.1, 0.1) \\\\\n\\mu_b    &\\sim \\text{Normal}(0, 10) \\\\\n\\sigma_b &\\sim \\text{InvGamma}(0.1, 0.1) \\\\\na_j      &\\sim \\text{Normal}(\\mu_a, \\sigma^2_a) \\\\\nb_j      &\\sim \\text{Normal}(\\mu_b, \\sigma^2_b) \\\\\n\\sigma^2 &\\sim \\text{InvGamma}(0.1, 0.1)\n\\end{aligned}\n\\]\n\nEscriba un programa en Stan que implemente el modelo y obtenga el posterior con RStan.\nAnalice los coeficientes del modelo y las curvas de crecimiento. Genere grÃ¡ficos similares a los producidos en el punto anterior. Describa similitudes y diferencias respecto del modelo 1. Justifique su respuesta.\nÂ¿QuÃ© problemas detecta los modelos 1 y 2? Considere como evoluciona el peso conforme la edad segÃºn el modelo.\n\nModelo 3\nComo alternativa al componente log-lineal anterior, se propone la siguiente curva de crecimiento logÃ­stico:\n\\[\nf_j(X) = a_j + b_j \\frac{\\exp [d_j (\\log(X) - c_j)]}{1 + \\exp [d_j(\\log(X) - c_j)]}\n\\]\nEste modelo tiene cuatro parÃ¡metros:\n\n\\(a_j\\) es el peso esperado cuando la edad es 0\n\\(b_j\\) es el peso mÃ¡ximo esperado (o la cota superior del peso)\n\\(\\log (c_j)\\) es la edad a la que la especie \\(j\\) alcanza la mitad del peso mÃ¡ximo\n\\(d_j > 0\\) determina la tasa de crecimiento del peso conforme aumenta la edad\n\nPara que la curva sea positiva y creciente para todas las edades, se debe cumplir que \\(a_j \\gt 0\\), \\(b_j \\gt a_j\\) y \\(d_j \\gt 0\\). Se pueden satisfacer estas restricciones expresando los parÃ¡metros en funciÃ³n de parÃ¡metros cuyo dominio es \\(\\mathbb{R}\\).\n\n\\(a_j = \\exp (\\alpha_{j1})\\)\n\\(b_j = \\exp (\\alpha_{j2})\\)\n\\(c_j = \\alpha_{j3}\\)\n\\(d_j = \\exp (\\alpha_{j4})\\)\n\nConsidere las siguientes distribuciones a priori para los parÃ¡metros del modelo:\n\\[\n\\begin{aligned}\n\\alpha_{jk} &\\sim \\text{Normal}(0, 10) \\\\\n\\sigma^2_j  &\\sim \\text{InvGamma}(0.1, 0.1)\n\\end{aligned}\n\\]\n\nEscriba un programa en Stan que implemente el modelo y obtenga el posterior con RStan.\nAnalice los diagnÃ³sticos de la inferencia realizada.\nGrafique las curvas estimadas para cada especie junto a sus intervalos de credibilidad e interprete los resultados.\n\nModelo 4\nEste modelo es el mismo que el Modelo 3, excepto que las especies tienen la misma varianza, \\(\\sigma^2_j = \\sigma^2\\) y los coeficientes de regresiÃ³n son modelados de manera jerÃ¡rquica. Utilice los siguientes priors:\n\\[\n\\begin{aligned}\n\\mu_k             &\\sim \\text{Normal}(0, 10) \\\\\n\\sigma^2_k        &\\sim \\text{InvGamma}(0.1, 0.1) \\\\\n\\log(\\alpha_{jk}) &\\sim \\text{Normal}(\\mu_k, \\sigma^2_k) \\\\\n\\sigma^2          &\\sim \\text{InvGamma}(0.1, 0.1)\n\\end{aligned}\n\\]\n\nEscriba un programa en Stan que implemente el modelo y obtenga el posterior con RStan.\nAnalice los diagnÃ³sticos de la inferencia y compare con los resultados del modelo 3.\nGrafique las curvas estimadas para cada especie junto a sus intervalos de credibilidad e interprete los resultados. Compare con los resultados del modelo 3. Â¿QuÃ© diferencias observa? Â¿Por quÃ© se dan?\nEscriba una sÃ­ntesis comparando todos los modelos desarrollados. Comente ventajas y desventajas de cada uno de ellos, explicando a que se deben en cada caso Â¿QuÃ© modelo resulta mÃ¡s conveniente para estimar la curva de crecimiento de los tiranosÃ¡uridos? Justifique su respuesta.\n\nNota: Queremos usar los priors del libro? O mejor usamos otra cosa? Estoy mirando los InvGamma por ejemplo. Ãdem con la notaciÃ³n de varianza vs desvÃ­o estÃ¡ndar. \n\n\n\n\n\nReferencias\n\nDavidson-Pilon, Cameron. 2015. Bayesian Methods for Hackers: Probabilistic Programming and Bayesian Inference. 1st edition. Addison-Wesley Data; Analytics Series.\n\n\nErickson, Gregory M, Peter J Makovicky, Philip J Currie, Mark A Norell, Scott A Yerby, y Christopher A Brochu. 2004. Â«Gigantism and comparative life-history parameters of tyrannosaurid dinosaursÂ». Nature 430: 772-75.\n\n\nReich, Brian J., y Sujit K. Ghosh. 2019. Bayesian Statistical Methods. 1st edition. Chapman; Hall/CRC."
  },
  {
    "objectID": "practica/practica_03.html",
    "href": "practica/practica_03.html",
    "title": "PrÃ¡ctica - Unidad 3",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "practica/practica_03.html#mÃ©todos-computacionales",
    "href": "practica/practica_03.html#mÃ©todos-computacionales",
    "title": "PrÃ¡ctica - Unidad 3",
    "section": "MÃ©todos Computacionales",
    "text": "MÃ©todos Computacionales\n\nSea \\(X \\sim \\text{Normal}(\\mu=3, \\sigma=1.2)\\).\n\nElabore un grÃ¡fico que permita visualizar la funciÃ³n de densidad de probabilidad de \\(X\\).\nÂ¿CuÃ¡l es la probabilidad de que \\(X\\) sea menor a 2.5?\nÂ¿CuÃ¡l es la probabilidad de que \\(X\\) sea mayor a 4?\nÂ¿CuÃ¡l es la probabilidad de que \\(X\\) sea mayor 2 y menor 3?\n\nSea \\(X \\sim \\text{Beta}(\\alpha=10, \\beta=2)\\)\n\nElabore un grÃ¡fico que permita visualizar la funciÃ³n de densidad de probabilidad de \\(X\\).\nÂ¿CuÃ¡l es la probabilidad de que \\(X\\) sea menor a 0.5?\nÂ¿CuÃ¡l es la probabilidad de que \\(X\\) sea mayor a 0.8?\nÂ¿CuÃ¡l es la probabilidad de que \\(X\\) sea mayor 0.25 y menor 0.75?\n\nResponda los dos puntos anteriores sin evaluar la funciÃ³n de densidad ni la funciÃ³n de distribuciÃ³n de las variables aleatorias mencionadas. Para eso genere muestras que provengan de las correspondientes distribuciones y utilÃ­celas para responder las preguntas mencionadas. Reflexione sobre las ventajas y desventajas de utilizar un enfoque basado en la simulaciÃ³n para resolver problemas.\nUna variable aleatoria \\(X\\) toma valores en el conjunto \\(\\{2, 4, 6, 8, 10\\}\\) con igual probabilidad. Encuentre la media y el desvÃ­o estÃ¡ndar de las variables \\(X\\) e \\(Y = 2X + 1\\). \nEn un problema determinado la distribuciÃ³n a posteriori de la parÃ¡metro de inteÅ•es \\(\\alpha\\) es \\(\\Gamma(k=3, \\theta=1.5)\\), donde \\(k\\) es el parÃ¡metro de forma y \\(\\theta\\) es el parÃ¡metro de escala. Calcule la probabilidad de que \\(\\alpha^2\\) sea mayor a 10. \nSean \\(X\\) e \\(Y\\) dos variables aleatorias independientes con distribuciÃ³n uniforme en el intervalo \\([0, 1]\\).\n\nÂ¿CuÃ¡l es la probabilidad de que \\(X \\le Y\\)?\nGrafique los puntos muestreados coloreando de acuerdo a si la muestra satisface el evento antes mencionado o no.\n\nDos estudiantes de estadÃ­stica deciden encontrarse en la fotocopiadora de la Facultad entre las 10 y las 11 de la maÃ±ana, eligiendo el tiempo de llegada al azar. La estudiante A esperarÃ¡ 10 minutos luego de llegar. Si el estudiante B no llega en ese intervalo, se irÃ¡. Lo mismo hace el estudiante B, pero este decide esperar 14 minutos. Â¿CuÃ¡l es la probabilidad de que se produzca el encuentro en la fotocopiadora entre la estudiante A y el estudiante B?\nUna mÃ¡quina que se utiliza para ensamblar telÃ©fonos celulares en una fÃ¡brica en Tierra del Fuego cuenta con tres componentes crÃ­ticos para su funcionamiento. Ante una falla en cualquiera de estos componentes, la mÃ¡quina se detiene. Las probabilidades de que estos elementos operen correctamente durante un dÃ­a cualquiera son \\(p_1 = 0.8\\), \\(p_2 = 0.9\\) y \\(p_3 = 0.7\\). Responda las siguientes preguntas utilizando tÃ©cnicas de simulaciÃ³n:\n\nÂ¿CuÃ¡l es la probabilidad de que la mÃ¡quina falle en el primer dÃ­a de uso?\nÂ¿CuÃ¡l es la probabilidad de que la mÃ¡quina siga funcionando luego de 10 dÃ­as?\nÂ¿CuÃ¡l es la probabilidad de que la mÃ¡quina falle en el dÃ­a 7 de uso?\nSea \\(T=\\) Cantidad de dÃ­as que la mÃ¡quina funciona ininterrumpidamente. Grafique la funciÃ³n de densidad de probabilidad de \\(T\\).\n\nEste tuit propone un problema muy interesante. Una urna contiene una bola azul y una amarilla. Se elije una bola al azar y se la vuelve a colocar junto con otra bola adicional del mismo color. Se repite este proceso indefinidamente. Â¿QuÃ© ocurre con la proporciÃ³n de bolas azules en la urna a medida que repetimos mÃ¡s y mÃ¡s veces?\n\nTiende a 1/2\nTiende a 0 Ã³ a 1\nNo se estabiliza\nNinguna de las anteriores\n\nEscriba un programa en R para responder esta pregunta utilizando simulaciones. Genere grÃ¡ficos que faciliten la comprensiÃ³n del resultado.\nÂ¿CuÃ¡nto vale \\(\\pi\\)?\nImagine un cÃ­rculo de radio \\(r\\) y un cuadrado de lado \\(2r\\), ambos centrados en el mismo punto, que de manera arbitraria puede ser el punto \\((0, 0)\\). Obtenga muestras de una distribuciÃ³n uniforme en el plano \\((x, y)\\), cuyo dominio estÃ¡ acotado por el cuadrado antes mencionado. Para cada muestra extraida, determine si se encuentra dentro del cÃ­rculo o no â€“ todos las muestras se encontrarÃ¡n dentro del cuadrado. Utilice esta informaciÃ³n para estimar el valor de \\(\\pi\\).\n\n\n\n\n\n\n\n\n\nDatos Ãºtiles\n\nArea de un cÃ­rculo: \\(\\pi \\cdot r^2\\).\nArea de un cuadrado: \\(a^2\\), donde \\(a\\) es la longitud del lado.\n\nSe seleccionan dos puntos de manera uniforme e independiente dentro de un cÃ­rculo. Â¿CuÃ¡l es la probabilidad de que la distancia entre dos puntos sea menor al radio?\n\nIntentar hacer a mano?\nResuelva el problema utilizando R\nElabore una visualizaciÃ³n que facilite la comunicaciÃ³n de los resultados\n\nEn la Copa del Mundo de la FIFA 2014, Alemania jugÃ³ contra Brasil en la semifinal. Los alemanes hicieron el primer gol a los 11 minutos y el segundo a los 23. Asuma que el tiempo entre goles sigue una distribuciÃ³n exponencial. Elija una distribuciÃ³n a priori para el tiempo entre goles (puede ser conjugada o no). En ese momento del partido,\n\nÂ¿CuÃ¡l es la distribuciÃ³n a posteriori del tiempo entre goles de Alemania?\nÂ¿CuÃ¡ntos goles cabrÃ­a esperar que Alemania hiciera al finalizar los 90 minutos?\nÂ¿CuÃ¡l era la probabilidad de que Alemania hiciera mÃ¡s de 5 goles (cosa que ocurriÃ³)? \n\nGrid approximation para una skew-normal. Estimar los parÃ¡metros \\(\\xi\\) (posiciÃ³n), \\(\\omega\\) (escala) y \\(\\alpha\\) (asimetrÃ­a). \\[\nf(x) = \\frac{2}{\\omega} \\phi\\left(\\frac{x-\\xi}{\\omega}\\right)\\Phi\\left( \\alpha \\frac{x-\\xi}{\\omega} \\right)\n\\] \nUna compaÃ±Ã­a pesquera de Comodoro Rivadavia se encuentra probando un nuevo mÃ©todo para estimar el peso de los peces que extrae del Mar Argentino. El objetivo de este mÃ©todo es obtener una estimaciÃ³n lo suficientemente buena del peso de cada pescado sin tener que pesarlos uno por uno, ya que es un proceso costoso en tiempo y labor. Para eso, seleccionaron una muestra de pescados, los pesaron y les midieron ciertos aspectos morfolÃ³gicos (ancho, alto y largo). En el futuro, esperan recolectar estas mismas medidas morfolÃ³gicas mediante una cÃ¡mara especializada y utilizar el modelo para estimar el peso.\nEl modelo propuesto por el equipo de investigaciÃ³n es el siguiente:\n\\[\n\\begin{aligned}\n\\log(\\text{Peso}_i) &\\sim \\text{Normal}(\\mu, \\sigma) \\\\\n\\mu_i  &= \\beta_0 + \\beta_1 \\log(\\text{Largo}_i) \\\\\n\\sigma &\\sim \\text{Gamma}(k, \\theta)\n\\end{aligned}\n\\]\nEl peso se encuentra medido en gramos y la longitud en centÃ­metros. El equipo provee las muestras que obtuvieron del posterior. Las mismas se pueden leer en R utilizando el siguiente bloque de cÃ³digo.\n\nurl <- paste0(\n    \"https://raw.githubusercontent.com/estadisticaunr/estadistica-bayesiana/\",\n    \"main/datos/fish-market-posterior.csv\"\n)\ndf_posterior <- readr::read_csv(url)\nhead(df_posterior)\n\n# A tibble: 6 Ã— 3\n  intercepto pendiente sigma\n       <dbl>     <dbl> <dbl>\n1      -4.44      3.08 0.408\n2      -4.30      3.05 0.431\n3      -4.49      3.12 0.433\n4      -4.04      2.96 0.341\n5      -4.76      3.18 0.413\n6      -4.65      3.15 0.350\n\nAnalice de manera grÃ¡fica y analÃ­tica los posteriors marginales de los parÃ¡metros del modelo. Realice las transformaciones de parÃ¡metros que crea conveniente para facilitar la comprensiÃ³n del anÃ¡lisis.\nConsidere un pescado cuya longitud es de 30 centÃ­metros.\n\nObtenga y grafique la distribuciÃ³n a posteriori del peso medio.\nObtenga y grafique la distribuciÃ³n predictiva a posteriori del peso.\nInterprete los resultados.\n\nGrafique la curva de regresiÃ³n junto a una banda de credibilidad del 95% en el plano de las variables originales y en el plano de las variables transformadas-\nAgregue a los grÃ¡ficos anteriores una banda de credibilidad del 95% para la distribuciÃ³n predictiva a posteriori. Interprete los resultados.\n\nConsidere la siguiente familia de distribuciones normales en 2D\n\\[\nf(\\mathbf{x} | \\pmb{\\Sigma}, \\pmb{\\mu} = \\mathbf{0})\n= \\frac{1}{\\det(2\\pi\\pmb{\\Sigma})^{-\\frac{1}{2}}}\n\\exp[{-\\frac{1}{2} \\mathbf{x}^T \\pmb{\\Sigma}^{-1} \\mathbf{x}}]\n\\]\ny las siguientes matrices de covarianza\n\\[\n\\begin{array}{c}\n    \\pmb{\\Sigma}_1 = \\begin{bmatrix}\n    1 & 0 \\\\ 0 & 1\n    \\end{bmatrix}\n    &\n    \\pmb{\\Sigma}_2 = \\begin{bmatrix}\n    1 & 0.2 \\\\ 0.2 & 1\n    \\end{bmatrix}\n    \\\\ \\\\\n    \\pmb{\\Sigma}_1 = \\begin{bmatrix}\n    1 & 0.5 \\\\ 0.5 & 1\n    \\end{bmatrix}\n    &\n    \\pmb{\\Sigma}_2 = \\begin{bmatrix}\n    0.1 & 0 \\\\ 0 & 1\n    \\end{bmatrix}\n    \\\\ \\\\\n    \\pmb{\\Sigma}_1 = \\begin{bmatrix}\n    1 & 0.9 \\\\ 0.9 & 1\n    \\end{bmatrix}\n    &\n    \\pmb{\\Sigma}_2 = \\begin{bmatrix}\n    0.01 & 0 \\\\ 0 & 1\n    \\end{bmatrix}\n\\end{array}\n\\]\nQue dan lugar a las siguientes funciones de densidad:\n\n\n\n\n\n\n\n\n\nParte 1: Metropolis-Hastings\n\nUtilice el algoritmo Metropolis-Hastings para obtener \\(n=10000\\) muestras de cada una de las distribuciones.\nCalcule la probabilidad de aceptaciÃ³n.\nGrafique la funciÃ³n de autocorrelaciÃ³n y calcule la cantidad de muestras efectivas.\nAnalice como varÃ­a la probabilidad de aceptaciÃ³n y la cantidad de muestras efectivas segÃºn las diferentes caracterÃ­sticas de la distribuciÃ³n objetivo.\nÂ¿CuÃ¡les son las ventajas y desventajas del algoritmo de Metropolis-Hastings segÃºn lo que puede concluir a partir de esta aplicaciÃ³n? Comente dificultades con las que se haya encontrado.\n\nParte 2: Hamiltonian Monte Carlo\n\nUtilice el algoritmo HMC para obtener \\(n=10000\\) muestras de cada una de las distribuciones.\nCalcule la probabilidad de aceptaciÃ³n.\nGrafique la funciÃ³n de autocorrelaciÃ³n y calcule la cantidad de muestras efectivas.\nAnalice como varÃ­a la probabilidad de aceptaciÃ³n y la cantidad de muestras efectivas segÃºn las diferentes caracterÃ­sticas de la distribuciÃ³n objetivo.\nÂ¿CuÃ¡les son las ventajas y desventajas del algoritmo de Metropolis-Hastings segÃºn lo que puede concluir a partir de esta aplicaciÃ³n? Comente dificultades con las que se haya encontrado.\n\n\nTorus? To Do\ndef torus_logpdf(scale):\ndef logp(x):\n     return -((1 - x.norm(2)) / scale)**2\nreturn logp\n\n# pdf = np.exp(-((1 - np.linalg.norm(xs, axis=0)) / scale)**2)\n\n\nEjercicios que faltan\n\nBenchmark del mÃ©todo de aproximaciÃ³n mediante grilla de puntos\n\nMedir y comparar uso de memoria y tiempo computacional\n\nUtilizar MH para obtener muestras\n\nNormal univariada\nGamma univariada\nBeta univariada\nUna funciÃ³n muy arbitraria y â€œno genÃ©ricaâ€\nNormal multivariada\n\nIndependiente\nCon correlaciÃ³n moderada\nCon alta correlaciÃ³n\n\n\nCalcular medidas de diagnÃ³stico sobre los casos anteriores\n\nEn algunos casos tenemos que sugerir que corran mÃºltiples cadenas\n\nUtilizar MH para obtener el posterior\n\nUtilizar casos de la prÃ¡ctica 2\n\nIncluir algÃºn caso donde no todos los parÃ¡metros vivan en \\(\\mathbb{R}\\)\n\n\nUtilizar HMC para la normal multivariada con correlaciÃ³n moderada y alta correlaciÃ³n\nUtilizar HMC para los modelos donde se usÃ³ MH\nStan:\n\nEscribir algunos modelos con Stan\nDiferentes priors\nAnalizar posterior de manera grafica (marginales y conjuntas)\nCalcular diagnosticos y analizar\n\nAlgun caso donde los diagnosticos no den bienâ€¦\n\nPuede ser cuando el HMC no esta bien tuneado\nPensar algunos otros (deberia buscar en cosas que he hecho)\n\nAlgo con brms?\n\nNota: Para los que dicen â€œutilizar HMCâ€ estaria bueno que proveamos una funcion que use HMC, sin que tengan que usar Stan."
  },
  {
    "objectID": "practica/practica_02.html",
    "href": "practica/practica_02.html",
    "title": "PrÃ¡ctica - Unidad 2",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "practica/practica_02.html#modelos-de-distribuciones-conjugadas",
    "href": "practica/practica_02.html#modelos-de-distribuciones-conjugadas",
    "title": "PrÃ¡ctica - Unidad 2",
    "section": "Modelos de Distribuciones Conjugadas",
    "text": "Modelos de Distribuciones Conjugadas\n\nEn un campamento de verano para infantes se realizaron actividades que promueven el contacto con la naturaleza. Una de las tareas consistiÃ³ en germinar semillas de tomate. Josefina plantÃ³ 18 semillas en su almaciguera. Al cabo de 5 dÃ­as, germinaron 8 de ellas. Llamaremos con \\(\\theta\\) a la probabilidad de que una semilla de tomate germine y asumimos una distribuciÃ³n \\(\\text{Beta}(1, 1)\\).\n\nCalcular la media y el desvÃ­o estÃ¡ndar a posteriori de \\(\\theta\\) a mano.\nVerifique el cÃ¡lculo utilizando R.\nCalcule un intervalo de credibilidad del 95% para \\(\\theta\\).\n\nA mano\nUsando R\n\n\n\n\n\n\n\nFoto de Markus Spiske en Unsplash\n\n\n\n\nEn la final del 2018 de la Copa del Mundo de la FIFA, Francia le ganÃ³ a Croacia por 4 a 2. En funciÃ³n de este resultado,\n\nÂ¿QuÃ© probabilidad hay de que Francia fuera un mejor equipo que Croacia?\nSi el mismo partido se jugara de nuevo (cosa que los franceses en aquella oportunidad no pidieron), Â¿cuÃ¡l es la probabilidad de que Francia ganara de nuevo? \n\nDurante el desarrollo de las vacunas contra el COVID-19, un medio anunciÃ³ para una determinada vacuna una eficacia del 100%.\n\nEn la fase 3 de un ensayo en adolescentes de entre 12 y 15 aÃ±os, la vacuna BNT162b2 de Pfizer-BioNTech para el COVID-19 demostrÃ³ una eficacia del 100% y una respuesta robusta de anticuerpos. El ensayo clÃ­nico involucrÃ³ 2260 jÃ³venes estadounidenses. En el ensayo, 18 casos de COVID-19 fueron observados en el grupo placebo (\\(n=1129\\)) y ninguno en el grupo vacunado (\\(n=1131\\))\n\nEs de esperar que, en un ensayo mÃ¡s grande, aparezca algÃºn caso de COVID-19 en el grupo que recibiÃ³ el tratamiento. Â¿CÃ³mo se estima la probabilidad de algo que aÃºn no ocurriÃ³? \nLa regla del tres\nUna estudiante de Licenciatura en EstadÃ­stica estÃ¡ releyendo su tesina antes de entregarla. Si en 20 pÃ¡ginas encontrara 5 typos, serÃ­a razonable estimar \\(\\frac{5}{20} = \\frac{1}{4}\\) typos por pÃ¡gina. Â¿Pero quÃ© ocurre si en 20 pÃ¡ginas no encuentra ningÃºn error?\nVerifcar que, partiendo de un prior uniforme, \\(\\frac{3}{N}\\) es una estimaciÃ³n razonable para \\(\\tau\\) (la tasa de typos por pÃ¡gina), siendo \\(N\\) el nÃºmero de pÃ¡ginas. Para ello, hallar la probabilidad de que \\(\\tau > \\frac{3}{N}\\) para diferentes valores de \\(N\\). \nUna colega quiere comprar un producto por Internet. Tres vendedores ofrecen el mismo producto al mismo precio. Un vendedor tiene 100% evaluaciones positivas, con 10 reviews. Otro tiene 96% de evaluaciones positivas, con 50 reviews. El Ãºltimo tiene 90% de comentarios positivos, con 200 evaluaciones. Â¿CuÃ¡l de los tres vendedores le recomendarÃ­as? \nInferencia sobre una distribuciÃ³n de Poisson\nLa distribuciÃ³n de masa de probabilidad Poisson se define como \\[\n\\begin{array}{lcr}\n\\displaystyle p(x | \\lambda) = \\frac{e^{-\\lambda}\\lambda^x}{x!} &\n\\text{con} &\nx \\in \\{0, 1, 2, \\cdots \\}\n\\end{array}\n\\]\ndonde \\(\\lambda > 0\\) es la cantidad promedio de veces que ocurre el evento de interÃ©s en un periodo o espacio determinado.\n\nDerive el estimador de mÃ¡xima verosimilitud del parÃ¡metro \\(\\lambda\\).\nDerive el posterior \\(p(\\lambda|D)\\) suponiendo que el prior sobre \\(\\lambda\\) es \\(p(\\lambda) = \\text{Ga}(\\lambda | a, b) \\propto \\lambda^{\\alpha-1}e^{-\\lambda b}\\). Ayuda: El posterior tambiÃ©n es una distribuciÃ³n Gamma.\nÂ¿A quÃ© valor tiende la media a posteriori cuando \\(a \\to 0\\) y \\(b \\to 0\\)? Recuerde que la media de una distribuciÃ³n \\(\\text{Ga}(a, b)\\) es \\(a/b\\). \n\nInferencia sobre una distribuciÃ³n Uniforme\nConsidere una distribuciÃ³n uniforme crentrada en \\(0\\) y rango \\(2a\\). La funciÃ³n de densidad de probabilidad es\n\\[\np(x) = \\frac{1}{2a}I(x \\in [-a, a])\n\\]\nSea \\(\\mathbf{X} = (X_1,..., X_n)\\) un vector de \\(n\\) variables aleatorias independientes e idÃ©nticamente distribuidas segÃºn \\(p(x)\\)\nInferencia mÃ¡ximo-verosÃ­mil\n\nÂ¿CuÃ¡l es el estimador mÃ¡ximo verosÃ­mil de \\(a\\) (llÃ¡melo \\(\\hat{a}\\))?\nÂ¿QuÃ© probabilidad le asigna el modelo a una nueva observaciÃ³n \\(x_{n + 1}\\) usando \\(\\hat{a}\\)?\nÂ¿Observa algÃºn problema con el resultado anterior? Si es asÃ­, sugiera una alternativa mejor.\n\nInferencia Bayesiana\nEl prior conjugado de la distribuciÃ³n uniforme es la distribuciÃ³n de Pareto.\nSi \\(x \\sim \\text{Pareto}(x | \\alpha, m)\\), luego\n\\[\np(x| \\alpha, m) = \\frac{\\alpha m^\\alpha}{x^{\\alpha+1}} \\mathbb{I}(x \\ge m)\n\\]\nSi el prior es una distribuciÃ³n de Pareto, la distribuciÃ³n conjunta de \\(\\theta\\) y \\(\\mathbf{X} = (X_1,..., X_n)\\) es\n\\[\np(\\theta, \\mathbf{X})\n    = \\frac{\\alpha m^\\alpha}{\\theta^{n + \\alpha + 1}}\n    \\mathbb{I}(\\theta \\ge \\text{max}(\\mathbf{X}))\n\\]\nLlamando \\(M_x = \\text{max}(\\mathbf{X})\\). La evidencia (la probabilidad que las \\(n\\) muestras provengan de la misma distribuciÃ³n uniforme) es\n\\[\n\\begin{aligned}\np(\\mathbf{X}) &= \\int_{M_x}^\\infty\n                 \\frac{\\alpha m^\\alpha}{\\theta^{n + \\alpha + 1}}\n                 d\\theta \\\\\n&=  \\begin{cases}\n    \\frac{\\alpha}{(n+\\alpha)m^n} & \\text{Si } M_x \\le m \\\\\n    \\frac{\\alpha m^\\alpha}{(n+\\alpha)m^{n+\\alpha}} & \\text{Si } M_x > m \\\\\n    \\end{cases}\n\\end{aligned}\n\\]\nDerive el posterior y muestre que puede ser expresado como una distribuciÃ³n de Pareto.  \nInferencia sobre una distribuciÃ³n Exponencial\nEl tiempo de vida de una mÃ¡quina en aÃ±os \\(X\\) es modelado con una distribuciÃ³n exponencial con parÃ¡metro \\(\\theta\\) desconocido. La funciÃ³n de densidad es\n\\[\n\\begin{array}{lcrr}\np(x | \\theta) = \\theta e^{-\\theta x} & \\text{con} & x \\ge 0, & \\theta \\ge 0\n\\end{array}\n\\]\n\nMuestre que el estimador mÃ¡ximo verosÃ­mil es \\(\\hat{\\theta} = 1/\\bar{x}\\)\n\nSuponga que se observan los siguientes tiempos de vida de tres mÃ¡quinas independientes \\(x_1 = 5\\), \\(x_2 = 6\\), \\(x_3 = 4\\). Â¿CuÃ¡l es el valor del estimador MV?\nUna experta del Ã¡rea sugiere que \\(\\theta\\) debe tener una distribuciÃ³n a priori que tambiÃ©n sea exponencial. \\[\n\\begin{aligned}\n\\theta &\\sim \\text{Exp}(\\lambda) \\\\\np(\\theta | \\lambda) &= \\lambda e^{-\\lambda \\theta}\n\\end{aligned}\n\\] Elija un valor para la distribuciÃ³n a priori, llÃ¡melo \\(\\hat{\\lambda}\\), tal que \\(\\mathbb{E}(\\theta) = 1/3\\).\nÂ¿CuÃ¡l es el posterior \\(p(\\theta | \\mathbf{X}, \\hat{\\lambda})\\)?\nÂ¿Es la distribuciÃ³n exponencial conjugada con un likelihood exponencial?\nEncuentre la media del posterior, \\(\\mathbb{E}(\\theta | \\mathbf{X}, \\hat{\\lambda})\\)\nExplique por que difieren el estimador MV de la media a posteriori.\nÂ¿CuÃ¡l es mÃ¡s razonable en este ejemplo? \n\nSea una variable \\(Y\\) tal que \\(Y | \\theta \\sim \\text{Binomial}(n, \\theta)\\) y \\(\\theta \\sim \\text{Beta}(1/2, 1/2)\\). Mediante un estudio de simulaciÃ³n calcule la cobertura empÃ­rica del intervalo de credibilidad del 95% para \\(n \\in \\{1, 5, 10, 25\\}\\) y \\(\\theta \\in \\{0.05, 0.10, \\dots, 0.50 \\}\\). Describa las propiedades frecuentistas del intervalo de credibilidad bayesiano. \nCalculo de conjugada no tradicional\n\nBinomial negativa - Beta\nExponencial - Gamma. Modificar el ejercicio sobre Exponencial-Exponencial?"
  },
  {
    "objectID": "practica/practica_02.html#simulaciones",
    "href": "practica/practica_02.html#simulaciones",
    "title": "PrÃ¡ctica - Unidad 2",
    "section": "Simulaciones",
    "text": "Simulaciones\n\nEl tiempo que un empleado de recursos humanos demora en hacer una entrevista tiene distribuciÃ³n exponencial con media 30 minutos. Los tiempos de duraciÃ³n de cada entrevista se pueden considerar independientes entre sÃ­. Las entrevistas a postulantes para un trabajo estÃ¡n programadas cada 15 minutos, comenzando desde las 8. Es vÃ¡lido considerar que todos los postulantes llegan puntuales a su entrevista. Cuando la persona del turno de las 8:15 llega a la oficina\n\nÂ¿CuÃ¡l es la probabilidad de que tenga que esperar antes de ser entrevistada?\nÂ¿CuÃ¡l es el horario esperado al que terminarÃ¡ su entrevista? \n\nDos personas se conocen en la fila de embarque para un vuelo en un aviÃ³n Airbus A330-300\n\nÂ¿CuÃ¡l es la probabilidad de que tengan asientos en la misma fila?\nÂ¿CuÃ¡l es la probabilidad de que estÃ©n sentados en asientos adyacentes?\n\nEl Problema de Monty Hall es un problema de probabilidad basado en un juego del concurso televisivo estadounidense â€œTrato hechoâ€. En este problema, el concursante debe elegir una puerta entre tres, todas cerradas. El premio consiste en llevarse lo que se encuentra detrÃ¡s de la elegida. Se sabe con certeza que tras una de ellas se oculta un automÃ³vil, y tras las otras dos hay cabras. Una vez que el concursante haya elegido una puerta y comunicado su elecciÃ³n a los presentes, el presentador, que sabe lo que hay detrÃ¡s de cada puerta, abrirÃ¡ una de las otras dos en la que haya una cabra. A continuaciÃ³n, le da la opciÃ³n al concursante de cambiar, si lo desea, de puerta (tiene dos opciones). Â¿Debe el concursante mantener su elecciÃ³n original o escoger la otra puerta? Â¿Hay alguna diferencia? Resuelva este ejercicio utilizando simulaciones. \n\n\n\n\n\nLas 3 puertas del problema de Monty Hall\n\n\n\n\nBasÃ¡ndose en el siguiente tuit y conociendo el problema del cumpleaÃ±os (Â¿cuÃ¡ntas personas debe haber en una habitaciÃ³n para que la probabilidad de que dos de ellas cumplan aÃ±os el mismo dÃ­a sea mayor a X%?) construir un grÃ¡fico similar al del tuit donde se grafique la probabilidad de que haya \\(n\\) personas que cumplan aÃ±os el mismo dÃ­a para \\(K\\) personas presentes en la habitaciÃ³n.\nEl Ã¡lbum oficial del Mundial de FÃºtbol de Qatar 2022 consta de 638 figuritas. Cada paquete trae cinco figuritas.\n\nComprando cinco paquetes, Â¿cuÃ¡l es la probabilidad de tener a Messi?\nComprando cinco paquetes, Â¿cuÃ¡l es la probabilidad de sacar a Messi repetido?\nÂ¿CuÃ¡ntos paquetes se necesitan, en promedio, para completar el Ã¡lbum?\nSi a una persona le faltan diez figuritas para completar el Ã¡lbum, Â¿cuÃ¡ntos paquetes tiene que comprar para asegurarse de lograrlo?\n\nSi se arroja una moneda \\(n\\) veces, Â¿cuÃ¡l es la probabilidad de que no haya secuencias de \\(k\\) caras?\nÂ¿CuÃ¡l es la probabilidad de que tres personas en un ascensor con doce pisos presionen para ir a tres pisos consecutivos?\nPrevio a la final de la Copa AmÃ©rica 2021, los jugadores de la SelecciÃ³n Argentina se reÃºnen en la habitaciÃ³n del hotel como se describe en este tuit.\n\nÂ¿CuÃ¡l es la probabilidad de que un jugador adivine una de diez cartas?\nÂ¿CuÃ¡l es la probabilidad de que tres de ellos adivinen una de diez cartas?\n\nUn cajÃ³n contiene 10 pares de medias. No hay dos pares iguales. Por fiaca, el dueÃ±o de las medias no las agrupa despuÃ©s de lavarlas y simplemente las pone en el cajÃ³n. Al momento de necesitar un par de medias, saca una tras una hasta que se forma un par. En promedio, Â¿cuÃ¡ntas medias sacarÃ¡ hasta encontrar un par? \nDados los resultados de un estudio piloto, la probabilidad a posteriori de que la droga desarrollada por tu compaÃ±Ã­a sea mas efectiva que el tratamiento actual es \\(\\theta \\in [0, 1]\\). Tu compaÃ±Ã­a estÃ¡ considerando realizar un ensayo clÃ­nico a gran escala para confirmar que la droga que desarrollan es de hecho mejor. El costo del estudio es $X. Si la droga es mejor, la probabilidad de que esto se confirme en el ensayo es del 80%. Si la droga no es mejor, hay una probabilidad del 5% de que el estudio confirme que es mejor. Si el ensayo sugiere que tu droga es mejor, ganarÃ¡s $cX. Â¿Para quÃ© valores de \\(\\theta\\) y \\(c\\) tiene sentido realizar el estudio? \nResuelva el problema de concordancia de de Montmort presentado en la Practica 0 utilizando simulaciones. \nResuelva el problema de los dos sobres presentado en la Practica 0 utilizando simulaciones.\nConsidere un problema conocido. Se desean comparar dos muestras independientes de tamaÃ±o 5 utilizando un test t y utilizando el test de Mann-Whitney.\n\nConsidere el caso en que las dos muestras provienen de poblaciones con igual media y desvÃ­o estÃ¡ndar (supongamos normal de media nula y varianza unitaria). Si se repitiera muchas veces el proceso de tomar las muestras y realizar los tests, Â¿quÃ© distribuciÃ³n tendrÃ¡n los p-values obtenidos para cada test?\nConsidere ahora el caso en que las dos muestras provienen de poblaciones con diferente media e igual desvÃ­o estÃ¡ndar (\\(\\mathcal{N}(0,1)\\) y \\(\\mathcal{N}(1,0)\\)). Si se repitiera muchas veces el proceso de tomar las muestras y realizar los tests, Â¿quÃ© distribuciÃ³n tendrÃ¡n los p-values obtenidos para cada test?"
  },
  {
    "objectID": "practica/practica_02.html#elecciÃ³n-de-distribuciones-a-priori",
    "href": "practica/practica_02.html#elecciÃ³n-de-distribuciones-a-priori",
    "title": "PrÃ¡ctica - Unidad 2",
    "section": "ElecciÃ³n de distribuciones a priori?",
    "text": "ElecciÃ³n de distribuciones a priori?\n\nEsbozar la distribuciÃ³n de las siguientes variables\n\nEl nÃºmero de personas que compran cafÃ© en el bar de la facultad asumiendo distribuciÃ³n de Poisson.\nEl peso de perros adultos en kilogramos asumiendo una distribuciÃ³n Uniforme.\nEl peso de elefantes adultos en kilogramos asumiendo una distribuciÃ³n Normal.\nEl peso de humanos adultos en libras asumiendo una distribuciÃ³n asimÃ©trica hacia la derecha.\n\nPara cada uno cada uno de los ejemplos del ejercicio anterior, graficar la distribuciÃ³n usando R. Seleccionar los parÃ¡metros que creas razonable, tomar una muestra aleatoria de tamaÃ±o 1000 y graficar la distribuciÃ³n en base a las muestras. Â¿Se refleja tu conocimiento del problema en la distribuciÃ³n graficada? Si no, ajustar los parÃ¡metros y repetir el proceso hasta que el resultado tenga concuerde con el conocimiento del problema.\nComparar las siguientes distribuciones a priori.\n\n\\(\\text{Beta}(0.5, 0.5)\\)\n\\(\\text{Beta}(1, 1)\\)\n\\(\\text{Beta}(1, 1)\\)\n\\(\\text{Beta}(1, 4)\\)\n\\(\\text{Beta}(5, 1.5)\\)\n\n\nÂ¿En quÃ© se diferencian?\nÂ¿CuÃ¡l de ellas es mÃ¡s informativa?\nÂ¿CÃ³mo lo determinaste?\n\nEn cada una de la situaciones que se describen debajo, ajustar manualmente los parÃ¡metros de una distribuciÃ³n \\(\\text{Beta}\\) para que reflejen la informaciÃ³n brindada. En algunos casos puede haber varias respuestas aceptables en vez de existir â€œla respuesta correctaâ€.\n\nUn amigo se postulÃ³ para un empleo en LinkedIn y te dijo: â€œDirÃ­a que tengo una chance del 40% de que me den el trabajo, pero no estoy seguroâ€. Cuando le preguntamos un poco mas, dijo que estima sus chances entre un 20% y un 60%.\nUn grupo de investigaciÃ³n del CONICET desarrollÃ³ una nueva prueba para una enfermedad bastante rara. El grupo espera que esta prueba arroje resultados correctos el 80% de las veces, con una varianza de 0.05.\nEl primo de un amigo disfruta de salir a pescar, y lo hace muy seguido. En el asado de los Jueves dice que â€œEl 90% de las veces que salgo a pescar, vuelvo con algo. Si te tuviera que dar un rango, te dirÃ­a entre el 85% y el 100% de las vecesâ€.\n\nEfecto de la parametrizaciÃ³n\nSea \\(\\theta\\) la probabilidad de Ã©xito en un experimento binomial y sea \\(\\gamma = \\frac{\\theta}{1-\\theta}\\) la chance de Ã©xito. Utilizar simulaciones para explorar los efectos de las siguientes elecciones de distribuciones a priori\n\nSi \\(\\theta \\sim \\text{Uniforme}(0,1)\\), Â¿cuÃ¡l es el prior inducido para \\(\\gamma\\)?\nSi \\(\\theta \\sim \\text{Beta}(0,1)\\), Â¿cuÃ¡l es el prior inducido para \\(\\gamma\\)?\nSi \\(\\gamma \\sim \\text{Uniforme}(0,100)\\), Â¿cuÃ¡l es el prior inducido para \\(\\theta\\)?\nSi \\(\\gamma \\sim \\text{Gamma}(1,1)\\), Â¿cuÃ¡l es el prior inducido para \\(\\theta\\)?"
  },
  {
    "objectID": "practica/practica_02.html#notas",
    "href": "practica/practica_02.html#notas",
    "title": "PrÃ¡ctica - Unidad 2",
    "section": "Notas",
    "text": "Notas\nEn algÃºn lado podrÃ­amos tener un glosario, o algo del estilo. El objetivo es despejar dudas, por ejemplo, sobre las parametrizaciones de las distribuciones que utilizamos por defecto. AcÃ¡ podriamos mostrar que usamos \\(\\text{Beta}(a, b)\\) con \\(\\text{pdf}(x) = \\frac{\\Gamma(a + b)}{\\Gamma(a) + \\Gamma(b)} x^{a-1}(1-x)^{b-1}\\)"
  },
  {
    "objectID": "complementario/variables.html",
    "href": "complementario/variables.html",
    "title": "Repaso de Variables Aleatorias",
    "section": "",
    "text": "Variables aleatorias\n\nDiscretas\nContinuas\n\nCDF\nPDF\nDistribucion conjunta\nDistribucion marginal\nDistribucion condicional\nIndependencia e independencia condicional\nMomentos de una distribucion\nRegla de Bayes\nDistribuciones de probabilidad frecuentemente utilizadas\nTransformacion de variables aleatorias\n\nPropiedades de transformaciones lineales\n\n\nEste listado esta sacado del capitulo 2 de Murphy (2022)\nTambien hay cosas interesantes en capitulo 3 de Murphy (2022)\n\nUncorrelated does not imply independent\nCorrelation does not imply causation\n\n\nPairwise independence does not imply mutual independence\nWe say that two random variables are pairwise independent if \\(p(X_2|X_1) = p(X_2)\\) and hence \\(p(X_2, X_1) = p(X_1)p(X_2|X_1) = p(X_1)p(X_2)\\)\nWe say that \\(n\\) random variables are mutually independent if \\(p(Xi|XS) = p(Xi)\\) \\(\\forall S \\subseteq \\{1, \\cdots , n\\}\\) and hence \\(\\displaystyle p(X_{1:n}) = \\prod_{i=1}^{n} p(X_i)\\)\nShow that pairwise independence between all pairs of variables does not necessarily imply mutual independence. It suffices to give a counter example.\nExercise 2.5 Murphy (2022)\nExercise 2.6 Murphy (2022)\nExercise 3.5 [Gaussian vs jointly Gaussian ]\n\n\n\n\n\nReferencias\n\nMurphy, Kevin P. 2022. Probabilistic Machine Learning: An Introduction. 1st edition. The MIT Press. https://probml.ai/."
  }
]
[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Licenciatura en EstadÃ­stica\n Â  Facultad de Ciencias EconÃ³micas y EstadÃ­stica (UNR)\n Â  1Â° Cuatrimestre 2023\n Â  Lun â€“ 11:00 a 13:00 Â  | Â  MiÃ© â€“ 7:00 a 9:00 Â  | Â  Vie â€“ 7:00 a 9:00"
  },
  {
    "objectID": "index.html#profesores",
    "href": "index.html#profesores",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Profesores",
    "text": "Profesores\n\n\nNacho Evangelista\n\n Â  evangelistaignacio@gmail.com\n Â  Consultas: Martes 14:00|14:45\n\n\n\nTomÃ¡s Capretto\n\n Â  tomicapretto@gmail.com\n Â  Consultas: Jueves 9:00"
  },
  {
    "objectID": "info/calendario.html",
    "href": "info/calendario.html",
    "title": "Calendario",
    "section": "",
    "text": "Semana\nFecha\nUnidad\nTemas\nLectura sugerida\nOtras actividades\n\n\n\n\n1\n20 de marzo\n1\nâ€¢ PresentaciÃ³n de la materiaâ€¢ Probabilidadâ€¢ Regla de Bayes\nâ€¢ McElreath (2020): CapÃ­tulo 1â€¢ Kruschke (2014): CapÃ­tulo 4\n\n\n\n2\n27 de marzo\n1, 2\nâ€¢ Inferencia bayesianaâ€¢ DistribuciÃ³n a priori, funciÃ³n de verosimilitud y distribuciÃ³n a posterioriâ€¢ Modelos conjugados\nâ€¢ Johnson, Ott, y Dogucu (2022): CapÃ­tulos 1, 3, 4, 5 y 8â€¢ Kruschke (2014): CapÃ­tulos 1, 5 y 6â€¢ McElreath (2020): CapÃ­tulo 2\n\n\n\n3\n3 de abril\n2\nâ€¢ Modelos de varios parÃ¡metros\nâ€¢ Gelman etÂ al. (2013): CapÃ­tulo 3\nPresentaciÃ³n TP1 (5-abr)\n\n\n4\n10 de abril\n2, 3\nâ€¢ Nociones de Teoria de DecisiÃ³n Bayesianaâ€¢ Limitaciones del enfoque analÃ­ticoâ€¢ Simulacionesâ€¢ AproximaciÃ³n grilla\nâ€¢ Johnson, Ott, y Dogucu (2022): CapÃ­tulo 6â€¢ McElreath (2020): CapÃ­tulo 3\n\n\n\n5\n17 de abril\n3\nâ€¢ IntroducciÃ³n al cÃ³mputo bayesianoâ€¢ Markov-chain Montecarloâ€¢ Metropolis-Hastings\nâ€¢ Johnson, Ott, y Dogucu (2022): CapÃ­tulo 7â€¢ Kruschke (2014): CapÃ­tulo 7\nEntrega TP1 (19-abr)  PresentaciÃ³n TP2 (19-abr)\n\n\n6\n24 de abril\n3\nâ€¢ ProgramaciÃ³n probabilÃ­sticaâ€¢ Stanâ€¢ DiagnÃ³sticosâ€¢ Visualizacionesâ€¢ Hamiltonian Montecarlo\nâ€¢ Kruschke (2014): CapÃ­tulo 14\n\n\n\n7\n1 de mayo\n4\nâ€¢ Modelos linealesâ€¢ Paquete brms\nâ€¢ Johnson, Ott, y Dogucu (2022): CapÃ­tulo 9â€¢ McElreath (2020): CapÃ­tulo 4â€¢ Gelman y Hill (2006): CapÃ­tulos 3 y 4â€¢ Gelman, Hill, y Vehtari (2021): CapÃ­tulos 6, 7 y 8\nEntrega TP2 (3-may)\n\n\n8\n8 de mayo\n4\nâ€¢ RegularizaciÃ³n\n\n\n\n\n9\n15 de mayo\n4\nâ€¢ SelecciÃ³n de modelosâ€¢ Criterios de informaciÃ³nâ€¢ ValidaciÃ³n cruzadaâ€¢ Sobreajuste y subajuste\nâ€¢ Gelman, Hill, y Vehtari (2021): CapÃ­tulo 11â€¢ Johnson, Ott, y Dogucu (2022): CapÃ­tulo 10â€¢ McElreath (2020): CapÃ­tulo 7\nParcial (15-may)  PresentaciÃ³n TP3 (17-may)\n\n\n10\n22 de mayo\n5\nâ€¢ RegresiÃ³n logÃ­stica\nâ€¢ Gelman, Hill, y Vehtari (2021): CapÃ­tulo 13â€¢ Gelman y Hill (2006): CapÃ­tulo 5â€¢ Johnson, Ott, y Dogucu (2022): CapÃ­tulo 13\n\n\n\n11\n29 de mayo\n5\nâ€¢ RegresiÃ³n Poisson\nâ€¢ Johnson, Ott, y Dogucu (2022): CapÃ­tulo 12â€¢ Gelman y Hill (2006): CapÃ­tulo 6â€¢ Gelman, Hill, y Vehtari (2021): CapÃ­tulo 15\nEntrega TP3 (31-may)  Recuperatorio (2-jun)\n\n\n12\n5 de junio\n5\nâ€¢ Enfoque multinivelâ€¢ Modelos jerÃ¡rquicosâ€¢ Shrinkage de parÃ¡metros\nâ€¢ Kruschke (2014): CapÃ­tulo 9â€¢ Johnson, Ott, y Dogucu (2022): CapÃ­tulos 15 y 16â€¢ McElreath (2020): CapÃ­tulo 13â€¢ Gelman y Hill (2006): CapÃ­tulo 11\nPresentaciÃ³n TP Final\n\n\n13\n12 de junio\n5\nâ€¢ Modelos lineales jerÃ¡rquicosâ€¢ VariaciÃ³n en el interceptoâ€¢ VariaciÃ³n en la pendienteâ€¢ Problemas de estimaciÃ³n\nâ€¢ Johnson, Ott, y Dogucu (2022): CapÃ­tulo 17â€¢ Gelman y Hill (2006): CapÃ­tulos 12 y 13\n\n\n\n14\n19 de junio\n\n\n\n\n\n\n15\n26 de junio\n\n\n\nEntrega TP Final + Defensa oral\n\n\n\n\n\n\n\n\n\n\nReferencias\n\nGelman, Andrew, John B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, y Donald B. Rubin. 2013. Bayesian Data Analysis. 3rd edition. Chapman; Hall/CRC.\n\n\nGelman, Andrew, y Jennifer Hill. 2006. Data Analysis Using Regression and Multilevel-Hierarchical Models. 1st edition. Cambridge University Press.\n\n\nGelman, Andrew, Jennifer Hill, y Aki Vehtari. 2021. Regression and Other Stories. 1st edition. Cambridge University Press. https://users.aalto.fi/~ave/ROS.pdf.\n\n\nJohnson, Alicia A., Miles Q. Ott, y Mine Dogucu. 2022. Bayes Rules! An Introduction to Bayesian Modeling. 1st edition. Chapman; Hall/CRC. https://www.bayesrulesbook.com/.\n\n\nKruschke, John. 2014. Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan. 2nd edition. Academic Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2nd edition. Chapman; Hall/CRC."
  },
  {
    "objectID": "info/aprobacion.html",
    "href": "info/aprobacion.html",
    "title": "Condiciones de aprobaciÃ³n",
    "section": "",
    "text": "Instancias de evaluaciÃ³n\n\nğŸ“ Parcial â€“ escrito e individual, se aprueba con 6, hay una instancia de recuperaciÃ³n;\nğŸ’»ğŸ’»ğŸ’» Trabajos prÃ¡cticos cortos â€“ grupales (hasta tres personas), se hacen por fuera del horario de clase, se entrega informe;\nğŸ“ˆ Trabajo prÃ¡ctico final â€“ realizaciÃ³n grupal, defensa individual.\n\n\n\nCondiciones de aprobaciÃ³n\n\nPromociÃ³n\n\nLas y los estudiantes que hayan aprobado el parcial o su recuperatorio (con nota \\(P\\)), los tres trabajos prÃ¡cticos cortos (con promedio simple \\(T\\)) y hayan entregado el trabajo prÃ¡ctico final, accederÃ¡n a una instancia de evaluaciÃ³n oral donde se discutirÃ¡ el trabajo prÃ¡ctico final y se evaluarÃ¡n de manera general todos los contenidos conceptuales de la asignatura; esta instancia puede incluir la realizaciÃ³n de algunas actividades en computadora (el trabajo prÃ¡ctico final y la instancia oral tendrÃ¡n nota \\(O\\)).\nLa nota final se obtendrÃ¡ segÃºn \\(0.3\\ T + 0.4\\ P + 0.3\\ O\\)\n\nRegularidad\n\nQuienes no alcancen la condiciÃ³n de promociÃ³n podrÃ¡n quedar en condiciÃ³n de estudiante regular si aprueban el parcial o su recuperatorio y aprueban al menos dos de los trabajos prÃ¡cticos cortos. Para alcanzar la aprobaciÃ³n de la asignatura, los y las estudiantes en condiciÃ³n de regulares deberÃ¡n presentar el trabajo final en una mesa de examen y aprobar una instancia oral de defensa del trabajo y de evaluaciÃ³n integral de los contenidos de la materia. Esta instancia puede incluir la realizaciÃ³n de algunas actividades en computadora.\n\nLibres\n\nAquellas personas que no alcancen la promociÃ³n de la asignatura ni la condiciÃ³n de estudiante regular quedarÃ¡n en condiciÃ³n de estudiante libre. Los y las estudiantes en condiciÃ³n de libre deberÃ¡n presentar un trabajo prÃ¡ctico y rendir un examen teÃ³rico-prÃ¡ctico sobre la totalidad de los temas de la asignatura."
  },
  {
    "objectID": "info/bibliografia.html",
    "href": "info/bibliografia.html",
    "title": "BibliografÃ­a",
    "section": "",
    "text": "BibliografÃ­a principal\n\nJohnson, Ott, y Dogucu (2022) McElreath (2020) Gelman y Hill (2006) Kruschke (2014) Reich y Ghosh (2019)\n\n\n\nGelman, Andrew, y Jennifer Hill. 2006. Data Analysis Using Regression and Multilevel-Hierarchical Models. 1st edition. Cambridge University Press.\n\n\nJohnson, Alicia A., Miles Q. Ott, y Mine Dogucu. 2022. Bayes Rules! An Introduction to Bayesian Modeling. 1st edition. Chapman; Hall/CRC. https://www.bayesrulesbook.com/.\n\n\nKruschke, John. 2014. Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan. 2nd edition. Academic Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2nd edition. Chapman; Hall/CRC.\n\n\nReich, Brian J., y Sujit K. Ghosh. 2019. Bayesian Statistical Methods. 1st edition. Chapman; Hall/CRC.\n\n\n\n\nBibliografÃ­a complementaria\n\nGelman etÂ al. (2013), Gelman, Hill, y Vehtari (2021), Downey (2021), Lee y Wagenmakers (2014), Davidson-Pilon (2015), Nicenboim, Schad, y Vasishth (2022), Barr (2021), Carlin y Louis (2008), Hoff (2009), MacKay (2003), Lambert (2018), Murphy (2022), Murphy (2023), Bishop (2006), Martin, Kumar, y Lao (2021), Theoridis (2020), Clyde etÂ al. (2022), Ma, Kording, y Goldreich (2022)\n\n\n\n\n\nBarr, Dale J. 2021. Learning statistical models through simulation in R: An interactive textbook. 1st edition. https://psyteachr.github.io/stat-models-v1/.\n\n\nBishop, Christopher M. 2006. Pattern Recognition and Machine Learning. 1st edition. Springer.\n\n\nCarlin, Bradley P., y Thomas A. Louis. 2008. Bayesian Methods for Data Analysis. 3rd edition. Chapman; Hall/CRC.\n\n\nClyde, Merlise, Mine Ã‡etinkaya-Rundel, Colin Rundel, David Banks, Christine Chai, y Lizzy Huang. 2022. An Introduction to Bayesian Thinking. 1st edition. https://statswithr.github.io/book/.\n\n\nDavidson-Pilon, Cameron. 2015. Bayesian Methods for Hackers: Probabilistic Programming and Bayesian Inference. 1st edition. Addison-Wesley Data; Analytics Series.\n\n\nDowney, Allen B. 2021. Think Bayes: Bayesian Statistics in Python. 2nd edition. Oâ€™Reilly Media. http://allendowney.github.io/ThinkBayes2/.\n\n\nGelman, Andrew, John B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, y Donald B. Rubin. 2013. Bayesian Data Analysis. 3rd edition. Chapman; Hall/CRC.\n\n\nGelman, Andrew, Jennifer Hill, y Aki Vehtari. 2021. Regression and Other Stories. 1st edition. Cambridge University Press. https://users.aalto.fi/~ave/ROS.pdf.\n\n\nHoff, Peter D. 2009. A First Course in Bayesian Statistical Methods. 1st edition. Springer.\n\n\nLambert, Ben. 2018. A Studentâ€™s Guide to Bayesian Statistics. 1st edition. SAGE Publications Ltd.\n\n\nLee, Michael D., y Eric-Jan Wagenmakers. 2014. Bayesian Cognitive Modeling: A Practical Course. 1st edition. Cambridge University Press.\n\n\nMa, Wei Ji, Konrad P. Kording, y Daniel Goldreich. 2022. Bayesian Models of Perception and Action: An Introduction. 3rd edition. http://www.cns.nyu.edu/malab/bayesianbook.html.\n\n\nMacKay, David J. C. 2003. Information Theory, Inference and Learning Algorithms. 1st edition. Cambridge University Press.\n\n\nMartin, Osvaldo A., Ravin Kumar, y Junpeng Lao. 2021. Bayesian Modeling and Computation in Python. 1st edition. Chapman; Hall/CRC.\n\n\nMurphy, Kevin P. 2022. Probabilistic Machine Learning: An Introduction. 1st edition. The MIT Press. https://probml.ai/.\n\n\nMurphy, Kevin P. 2023. Probabilistic Machine Learning: Advanced Topics. 1st edition. The MIT Press. https://probml.ai/.\n\n\nNicenboim, Bruno, Daniel Schad, y Shravan Vasishth. 2022. An Introduction to Bayesian Data Analysis for Cognitive Science. https://vasishth.github.io/bayescogsci/book/.\n\n\nTheoridis, Sergios. 2020. Machine Learning: A Bayesian and Optimization Perspective. 2nd edition. Academic Press."
  },
  {
    "objectID": "info/programa.html",
    "href": "info/programa.html",
    "title": "Programa",
    "section": "",
    "text": "FundamentaciÃ³n\nLa EstadÃ­stica Bayesiana es un enfoque de la inferencia estadÃ­stica que se basa en utilizar probabilidades para representar el conocimiento disponible sobre el conjunto de parÃ¡metros de un modelo y actualizar esa informaciÃ³n utilizando la Regla de Bayes a partir de la observaciÃ³n de un conjunto de datos. El conocimiento inicial se representa con una distribuciÃ³n de probabilidad a priori, la informaciÃ³n contenida en los datos observados se modeliza con una funciÃ³n de verosimilitud y ambas fuentes de informaciÃ³n se combinan para obtener una distribuciÃ³n de probabilidad a posteriori. La informaciÃ³n a posteriori puede ser utilizada para extraer conclusiones sobre el fenÃ³meno en estudio y realizar predicciones sobre datos no observados o eventos futuros.\nLos mÃ©todos bayesianos requieren, salvo en casos muy simples, una complejidad computacional que resultaba inalcanzable hace algunos aÃ±os. Gracias a desarrollos revolucionarios en el Ã¡mbito de la computaciÃ³n, la principal barrera para la implementaciÃ³n de los modelos bayesianos desapareciÃ³ y la utilizaciÃ³n de estos se ha incrementado masivamente en mÃºltiples campos cientÃ­ficos. Esta creciente popularidad se debe a que la inferencia bayesiana brinda un marco teÃ³rico consistente que permite la incorporaciÃ³n de informaciÃ³n a priori, el desarrollo de un aprendizaje secuencial, la obtenciÃ³n de inferencias y predicciones en forma de distribuciones de probabilidad, el tratamiento de datos faltantes, los anÃ¡lisis con pocos datos, entre otras ventajas.\n\n\nObjetivos\nQue quienes cursen la materia logren:\n\nentender las caracterÃ­sticas y los conceptos fundamentales de la EstadÃ­stica Bayesiana;\ndescribir las caracterÃ­sticas principales de la EstadÃ­stica Bayesiana;\ncomprender la complejidad analÃ­tica de la inferencia bayesiana y la necesidad de la utilizaciÃ³n de un enfoque computacional para superar estas dificultades;\nser capaces de aplicar mÃ©todos bayesianos a problemas reales utilizando software especÃ­fico; e\ninterpretar los resultados del proceso de anÃ¡lisis bayesiano de datos.\n\n\n\nContenidos\n\nUnidad 1: IntroducciÃ³n y Fundamentos de la EstadÃ­stica Bayesiana\n\nProbabilidad para cuantificar la incertidumbre. Modelos de probabilidad. Regla de Bayes. Inferencia bayesiana. DistribuciÃ³n a priori, funciÃ³n de verosimilitud, distribuciÃ³n a posteriori.\n\nUnidad 2: Inferencia Bayesiana\n\nModelos de distribuciones conjugadas. Modelos de un parÃ¡metro. Modelo beta-binomial. Enfoque intuitivo. DistribuciÃ³n a posteriori como compromiso entre la verosimilitud y la distribuciÃ³n a priori. Razonamiento secuencial. Modelo normal-normal. Modelo gammaâ€“Poisson. Modelos de varios parÃ¡metros. Modelo normal â€“ normal-gamma-inversa. Modelo Dirichletâ€“multinomial.\nElecciÃ³n de distribuciones a priori: no informativas (impropias, de Jeffrey) y dÃ©bilmente informativas. Medidas de resumen de la distribuciÃ³n a posteriori. Intervalos de credibilidad. DistribuciÃ³n predictiva a posteriori. Nociones de teorÃ­a de la decisiÃ³n bayesiana. Riesgo bayesiano. Estimador de Bayes.\n\nUnidad 3: MÃ©todos Computacionales\n\nLimitaciones del enfoque analÃ­tico: cÃ¡lculo de probabilidades y determinaciÃ³n de la distribuciÃ³n a posteriori. Soluciones: anÃ¡lisis de datos simulados y aproximaciÃ³n de grilla. IntroducciÃ³n al cÃ³mputo bayesiano. Nociones bÃ¡sicas de mÃ©todos de cadenas de Markov â€“ Montecarlo (MCMC). Algoritmo de Metropolisâ€“Hastings. Montecarlo Hamiltoniano. DiagnÃ³stico de mÃ©todos MCMC.\nProgramaciÃ³n probabilÃ­stica. Alternativas. Sintaxis de modelos. Ejemplos. DiagnÃ³stico. Medidas de resumen a partir de las cadenas obtenidas. Visualizaciones.\n\nUnidad 4: Modelos Lineales\n\nModelos lineales. ElecciÃ³n de distribuciones a priori. RegularizaciÃ³n. DiagnÃ³stico de modelos. Predicciones basadas en distribuciones de probabilidad. Pruebas predictivas a priori y a posteriori. Densidad predictiva a posteriori logarÃ­tmica evaluada punto a punto (lppd). Deviance. Criterios de informaciÃ³n: AIC, BIC, WAIC. Validacion cruzada. Sobreajuste y subajuste. ValidaciÃ³n cruzada utilizando muestreo por importancia mediante suavizado Pareto (PSIS-CV).\n\nUnidad 5: Modelos Avanzados\n\nRegresiÃ³n logÃ­stica. RegresiÃ³n Poisson. ComparaciÃ³n de grupos. Modelos de variable latente. FormulaciÃ³n grÃ¡fica. AnÃ¡lisis de sensibilidad.\nEl enfoque multinivel: modelos jerÃ¡rquicos. Modelo beta-binomial jerÃ¡rquico. Shrinkage de parÃ¡metros. VariaciÃ³n en el intercepto. VariaciÃ³n en la pendiente. Pooling de estimaciones. Problemas de estimaciÃ³n."
  },
  {
    "objectID": "info/enlaces_utiles.html",
    "href": "info/enlaces_utiles.html",
    "title": "Enlaces Ãºtiles",
    "section": "",
    "text": "Awesome Bayesian Statistics. Es un listado de recursos en lÃ­nea (y gratuitos!) relacionados al mundo de la EstadÃ­stica Bayesiana."
  },
  {
    "objectID": "info/faq.html",
    "href": "info/faq.html",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Preguntas frecuentes\n\nPertenezo al plan 2003 de la carrera, Â¿puedo participar de las clases?\nSi, podÃ©s asistir a las clases como oyente y tambiÃ©n realizar los trabajos prÃ¡cticos. Sin embargo, los profesores no se comprometen a realizar devoluciones o correcciones sobre los trabajos de estudiantes que asistan en calidad de oyente."
  },
  {
    "objectID": "practica/practica_04.html",
    "href": "practica/practica_04.html",
    "title": "PrÃ¡ctica - Unidad 4",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "practica/practica_04.html#regresiÃ³n-lineal",
    "href": "practica/practica_04.html#regresiÃ³n-lineal",
    "title": "PrÃ¡ctica - Unidad 4",
    "section": "RegresiÃ³n lineal",
    "text": "RegresiÃ³n lineal\nEl objetivo principal de esta unidad es la aplicaciÃ³n de modelos de regresiÃ³n lineales desde una perspectiva bayesiana, considerando a los parÃ¡metros del modelo como cantidades aleatorias que se corresponden con una distribuciÃ³n de probabilidad a priori. A diferencia del enfoque frecuentista o mÃ¡ximo verosÃ­mil, el resultado de la inferencia bayesiana es una distribuciÃ³n de probabilidad a posteriori, la cual se utiliza como fuente de todas las conclusiones. AdemÃ¡s, se emplean tÃ©cnicas propias de la estadÃ­stica bayesiana para evaluar la adecuaciÃ³n y comparar los modelos utilizados.\n\nMi primer regresiÃ³n bayesiana\nEl conjunto de datos sales contiene los montos semanales de inversiÃ³n en publicidad y de ingresos de una determinada compaÃ±Ã­a. Considere el siguiente modelo de regresiÃ³n lineal simple:\n\\[\n\\begin{aligned}\n\\mu_i &= \\beta_0 + \\beta_1 \\text{publicidad}_i \\\\\n\\text{ventas}_i &\\sim \\text{Normal}(\\mu_i, \\sigma^2)\n\\end{aligned}\n\\]\n\nAjuste el modelo utilizando {brms} y sus priors por defecto.\nConstruya un grÃ¡fico que muestre las ventas en funciÃ³n de la inversiÃ³n en publicidad y superponga la recta de regresiÃ³n estimada.\n\nMejorando mi regresiÃ³n bayesiana\nConsidere la siguiente versiÃ³n del modelo del ejercicio anterior que propone distribuciones a priori para los parÃ¡metros del modelo: \\[\n\\begin{aligned}\n\\mu_i &= \\beta_0 + \\beta_1 \\text{publicidad}_i \\\\\n\\text{ventas}_i &\\sim \\text{Normal}(\\mu_i, \\sigma^2) \\\\\n\\beta_0  &\\sim \\text{Normal}(\\overline{\\text{ventas}}, 10) \\\\\n\\beta_1  &\\sim \\text{Normal}(0, 0.5) \\\\\n\\sigma &\\sim \\text{Normal}^+(5)\n\\end{aligned}\n\\]\n\nAjuste el modelo utilizando {brms} y los priors sugeridos.\nConstruya un grÃ¡fico que muestre las ventas en funciÃ³n de la inversiÃ³n en publicidad, superponga la recta de regresiÃ³n estimada, y el intervalo de credibilidad del 95% para la recta de regresiÃ³n.\n\nComparando de lm() y brm()\nUtilice datos simulados para comparar la estimaciÃ³n por mÃ­nimos cuadrados con la estimaciÃ³n Bayesiana en modelos de regresiÃ³n.\n\nSimule 100 observaciones del modelo \\(Y = 2 + 3X + \\varepsilon\\) donde los valores del predictor \\(X\\) se obtienen de una distribuciÃ³n \\(\\text{Uniforme}(0, 20)\\) y los errores son obtenidos de manera independiente de una distribuciÃ³n \\(\\text{Normal}(0, 5^2)\\).\nAjuste el modelo de regresiÃ³n utilizando lm() y brm() del paquete {brms} utilizando priors por defecto.\nVerifique que ambos mÃ©todos arrojan resultados similares.\nRepresente grÃ¡ficamente los datos y las dos rectas de regresiÃ³n.\nIntente repetir la simulaciÃ³n, pero esta vez cree las condiciones para que ambos enfoques den resultados diferentes. \n\nLa alturaâ€¦ Â¿se hereda?\nEl conjunto de datos de las alturas (heights) contiene las alturas (en pulgadas) de 5524 pares de madres e hijas registradas en un estudio realizado por Karl Pearson y Alice Lee en 1903.\n\nElabore un grÃ¡fico que permita ver la relaciÃ³n entre las alturas de las madres y las hijas. Aplique las tÃ©cnicas que crea necesaria para obtener una visualizaciÃ³n informativa y fidedigna.\nÂ¿Por quÃ© es adecuado utilizar un modelo de regresiÃ³n lineal?\nAjuste el siguiente modelo de regresiÃ³n lineal utilizando {brms} y priors por defecto:\n\n\\[\n\\begin{aligned}\n\\mu_i &= \\beta_0 + \\beta_1 \\text{altura\\_madre}_i \\\\\n\\text{altura\\_hija}_i &\\sim \\text{Normal}(\\mu_i, \\sigma^2)\n\\end{aligned}\n\\]\n\nCalcule la media, el desvÃ­o estÃ¡ndar y el intervalo de credibilidad del 95% para los parÃ¡metros del modelo utilizando el posterior.\nInterprete los coeficientes del modelo.\nSuperponga la recta de regresiÃ³n en el grÃ¡fico donde se visualiza la relaciÃ³n entre las variables.\nObtenga el posterior del peso medio de una hija cuya madre mide 58 pulgadas. \n\nClima en Australia\nEl conjunto de datos weather_WU datos climÃ¡ticos correspondientes a 100 dÃ­as en dos ciudades de Australia: Uluru y Wollongong. Se intentarÃ¡ predecir la temperatura a las 3 de la tarde, utilizando otras variables.\nConsidere los siguientes cuatro modelos:\n\n\\(m_1\\): temp3pm ~ temp9am;\n\\(m_2\\): temp3pm ~ location;\n\\(m_3\\): temp3pm ~ temp9am + location;\n\\(m_4\\): temp3pm ~ ..\n\n\nAjuste cada uno de los modelos y construya grÃ¡ficas para mostrar los parÃ¡metros obtenidos.\nRealice pruebas predictivas a posteriori para comparar los modelos.\nCompare los ELPD de cada modelo utilizando LOO. \n\n\n\n\n\n\nParque Nacional Uluá¹Ÿu-Kata Tjuá¹¯a en Uluru, Australia. Foto de Snowscat en Unsplash\n\n\n\n\nPingÃ¼inos\nConsidere el dataset de pingÃ¼inos de Palmer (penguins) y los siguientes modelos:\n\n\\(m_1\\): body_mass_g ~ flipper_length_mm;\n\\(m_2\\): body_mass_g ~ species;\n\\(m_3\\): body_mass_g ~ flipper_length_mm + species;\n\\(m_4\\): body_mass_g ~ flipper_length_mm + species + flipper_length_mm:species;\n\\(m_5\\): body_mass_g ~ flipper_length_mm + bill_length_mm + bill_depth_mm.\n\n\nAjuste cada uno de los modelos y construya grÃ¡ficas para mostrar los parÃ¡metros obtenidos.\nRealice pruebas predictivas a posteriori para comparar los modelos.\nCompare los ELPD de cada modelo utilizando LOO. \n\nDe tal paloâ€¦\nEl dataset child_iq contiene informaciÃ³n de los resultados de tests de coeficiente intelectual de niÃ±os de 3 aÃ±os, educaciÃ³n de la madre, y edad de la madre cuando dio a luz.\n\nAjuste un modelo de regresiÃ³n del puntaje del bebÃ© a los 3 aÃ±os en funciÃ³n de la edad de la madre.\nAjsute ahora un modelo que incluya la educaciÃ³n de la madre.\nConstruya grÃ¡ficas para mostrar los parÃ¡metros obtenidos.\nRealice pruebas predictivas a posteriori para comparar los modelos.\nCompare los ELPD de cada modelo utilizando LOO.\n\n\nIngresos\nEl dataset earnings contiene los resultados de la encuesta realizada por Ross sobre Trabajo, Familia y Bienestar.\n\nAjuste un modelo que prediga ingreso en funciÃ³n de altura e interprete los parÃ¡metros.\nÂ¿QuÃ© transformaciÃ³n serÃ­a necesaria para interpretar el intercepto como el ingreso promedio de una persona con altura promedio?\nAjuste un nuevo modelo utilizando la transformaciÃ³n propuesta en el punto anterior y compare los posteriors de los coeficientes.\n\n!Kung\nLos !Kung son un pueblo que habita en el desierto de Kalahari entre Botsuana, Namibia y Angola. Hablan la lengua !Kung, que se destaca por su amplio uso de consonantes clic (chasquido consonÃ¡ntico). El !K del nombre ÇƒKung es un sonido como cuando sale un corcho de una botella.\nEl archivo Howell1 contiene datos de un censo parcial realizado por Dobe Howell acerca de la poblaciÃ³n !Kung.\nConsidere un modelo de altura en funciÃ³n del peso.\n\nDetermine e interprete las distribuciones a posteriori de los parÃ¡metros.\nConstruya un grÃ¡fico de altura en funciÃ³n del peso, incluya las observaciones de los individuos, la recta de regresiÃ³n MAP, el intervalo del 80% para la media y y el intervalo del 80% para la altura predicha.\nRealice predicciones para individuos cuyos pesos son: 46.95, 43.72, 64.78, 32.59 y 54.63. Calcule la altura esperada y el intervalo del 89%.\n\nZorros urbanos\nConsidere del conjunto de datos sobre zorros urbanos (foxes). Ajuste tres modelos:\n\n\\(m_1\\): weight ~ area;\n\\(m_2\\): weight ~ groupsize;\n\\(m_3\\): weight ~ area + groupsize.\n\n\nPara los modelos \\(m_1\\) y \\(m_2\\), represente grÃ¡ficamente los resultados, incluyendo la recta de regresiÃ³n MAP, su intervalo del 89% y el intervalo de predicciÃ³n del 89%. Â¿Es alguna de las dos variables importantes para predecir la masa de un zorro?\nRepresentar grÃ¡ficamente las predicciones del modelo para cada predictor, dejando el otro constante en su valor medio. Â¿QuÃ© puede decirse sobre la importancia de las variables para predecir la masa de un zorro?\n\nUn prior informativo marca la diferencia\nConsidere el conjunto de datos sobre belleza y proporciÃ³n de sexos (sexratio) . Estos datos provienen de un estudio de adolescentes estadounidenses cuyo atractivo en una escala de cinco puntos fue evaluado por entrevistadores en una encuesta cara a cara. AÃ±os mÃ¡s tarde, muchos de estos encuestados tuvieron hijos y se registraron ciertos atributos entre los cuales se incluyÃ³ el sexo. El objetivo del anÃ¡lisis es comparar la proporciÃ³n de sexos de los hijos segÃºn la belleza de los padres. Para ello considere el siguiente modelo de regresiÃ³n:\n\\[\n\\begin{aligned}\n\\mu_i &= \\beta_0 + \\beta_1 \\text{belleza}_i \\\\\n\\text{pf}_i &\\sim \\text{Normal}(\\mu_i, \\sigma^2)\n\\end{aligned}\n\\]\nDonde \\(\\text{pf}\\) representa la proporciÃ³n de bebÃ©s de sexo femenino y \\(\\text{belleza}\\) representa el grupo de belleza de los padres.\n\nAjuste el modelo utilizando mÃ­nimos cuadrados.\nAjuste el modelo con brm() y sus priors por defecto.\nCompare el ajuste de ambos modelos.\nExplore los priors utilizados por {brms} y la distribuciÃ³n predictiva a priori. Â¿QuÃ© puede concluir?\nProponga distribuciones a priori informativas.\nAjuste el modelo utilizando brm() y los priors informativos.\nCompare el resultado con los obtenidos anteriormente y concluya.\n\nÂ¡A la pesca de priors!\nEl conjunto de datos fish-market contiene mediciones morfolÃ³gicas realizadas sobre pescados de diferentes especies. El objetivo es construir un modelo de regresiÃ³n lineal que permita predecir el peso de los pescados en base a sus otros atributos.\nUno de los modelos propuestos es el siguiente:\n\\[\n\\begin{aligned}\n\\log(\\text{Weight}_i) &\\sim \\text{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i  &= \\beta_{0, j[i]} + \\beta_{1, j[i]} \\log(\\text{Length1}_i)\n\\end{aligned}\n\\]\n\\(\\text{Weight}_i\\) es el peso del i-Ã©simo pescado en gramos y \\(\\text{Length1}_i\\) es la longitud del i-Ã©simo pescado en centÃ­metros. La letra \\(j\\) indexa las especies de los pescados. Por lo tanto, en este modelo cada especie tiene su propio intercepto y pendiente.\n\nImplemente el modelo utilizando {brms} y los siguientes priors no informativos \\[\n\\begin{aligned}\n\\beta_{0, j[i]} &\\sim \\text{Normal}(0, 10) \\\\\n\\beta_{1, j[i]} &\\sim \\text{Normal}(0, 5)\n\\end{aligned}\n\\]\nObtenga y visualice la distribuciÃ³n predictiva a priori.\nElabore un grÃ¡fico y describa la funciÃ³n de densidad a priori de los parÃ¡metros \\(\\beta_{0, j[i]}\\) y \\(\\beta_{1, j[i]}\\).\nProponga priors mÃ¡s adecuados en base a la interpretaciÃ³n de los parÃ¡metros del modelo y la informaciÃ³n que tenga del problema.\nNuevamente, obtenga y visualice la distribuciÃ³n predictiva a priori y compare con el resultado obtenido anteriormente.\nAjuste el modelo, obtenga la distribuciÃ³n predictiva a posteriori y grafÃ­quela.\n\n\n\n\n\n\nEspecies de peces de todas variedades y tamaÃ±os.\n\n\n\n\nEn bÃºsqueda del modelo adecuado\nContinuando con los datos del ejercicio anterior, El objetivo es construir un modelo de regresiÃ³n lineal que permita predecir el peso de los pescados en base a sus otros atributos.\nConsidere los siguientes modelos\n\n\\(m_1\\): log(Weight) ~ 0 + Species;\n\\(m_2\\): log(Weight) ~ 0 + Species + log(Length1);\n\\(m_3\\): log(Weight) ~ 0 + Species + log(Length1):Species;\n\\(m_4\\): log(Weight) ~ 0 + Species + log(Length1):Species + log(Height);\n\\(m_5\\): log(Weight) ~ 0 + Species + log(Length1):Species + log(Height):Species.\n\n\nAjuste cada uno de los modelos.\nEstime el ELPD de cada modelo utilizando LOO y seleccione el modelo mÃ¡s adecuado de acuerdo a este criterio.\nExplique el resultado.\n\nComparaciÃ³n de modelos\nSe recopilaron datos (mesquite) con el fin de desarrollar un mÃ©todo para estimar la producciÃ³n total (biomasa) de hojas de mesquite utilizando parÃ¡metros fÃ¡cilmente medibles de la planta, antes de que se realice la cosecha real. Se tomaron dos conjuntos separados de mediciones, uno en un grupo de 26 arbustos de mesquite y otro en un grupo diferente de 20 arbustos de mesquite medidos en un momento diferente del aÃ±o. Todos los datos se obtuvieron en la misma ubicaciÃ³n geogrÃ¡fica, pero ninguno constituyÃ³ una muestra estrictamente aleatoria. La variable de resultado es el peso total (en gramos) de material fotosintÃ©tico obtenido de la cosecha real del arbusto. Las variables de entrada son:\n\n\n\n\n\n\n\nNombre\nDescripciÃ³n\n\n\n\n\ndiam1\nDiÃ¡metro de la copa medido a lo largo del eje mÃ¡s largo del arbusto (metros)\n\n\ndiam2\nDiÃ¡metro de la copa medido a lo largo del eje mÃ¡s corto (metros)\n\n\ncanopy_height\nAltura de la copa\n\n\ntotal_height\nAltura total del arbusto\n\n\ndensity\nNÃºmero de tallos primarios por planta\n\n\ngroup\nGrupo de mediciones (0 para el primer grupo, 1 para el segundo)\n\n\n\n\nRealice un anÃ¡lisis exploratorio de los datos.\nAjuste el modelo weight ~ diam1 + diam2 + canopy_height + total_height + density + group.\nExplore y describa el posterior.\nEstime ELPD mediante PSIS-CV con la funciÃ³n loo(), analice los valores de las estimaciones del parÃ¡metro \\(k\\) de la distribuciÃ³n generalizada de Pareto y otros valores de la salida que crea relevant, Â¿quÃ© puede concluir?\nEstime ELPD mediante K-fold cross validation con \\(K=10\\). Compare la estimaciÃ³n con el resultado obtenido mediante PSIS-CV y concluya.\nAjuste el modelo transformando todas las variables numÃ©ricas con la funciÃ³n logarÃ­tmica. Â¿CÃ³mo afecta esta transformaciÃ³n la interpretaciÃ³n de los coeficientes?\nEstime ELPD mediante PSIS-CV con la funciÃ³n loo(). Concluya acerca de la estabilidad del cÃ³mputo. Â¿Es posible comparar la la estimaciÃ³n con la obtenida en el inciso iv? Â¿Por quÃ©?\nCon ambos modelos, obtenga y grafique la distribuciÃ³n predictiva a posteriori comparÃ¡ndola con los datos observados Â¿CuÃ¡l de los modelos representa mejor a los datos?\n\n\n\n\n\n\nUn Ã¡rbol de mesquite.Foto de Sergei Bogomyakov, Alamy Stock Photo.\n\n\n\n\n\n\nSecundarios en Portugal\nSe cuenta con un conjunto de datos sobre 343 estudiantes de secundaria de Portugal (portugal) y se desea predecir la calificaciÃ³n final en matemÃ¡ticas del Ãºltimo aÃ±o en base a un gran nÃºmero de predictores potencialmente relevantes.\nEl listado de variables se compone por: escuela del estudiante, sexo del estudiante, edad del estudiante, tipo de domicilio del estudiante, tamaÃ±o de la familia, estado de convivencia de los padres, educaciÃ³n de la madre, educaciÃ³n del padre, tiempo de viaje del hogar a la escuela, tiempo de estudio semanal, nÃºmero de fracasos escolares pasados, apoyo educativo adicional, clases pagadas adicionales dentro de la materia del curso, actividades extracurriculares, si el estudiante asistiÃ³ a una guarderÃ­a, si el estudiante desea cursar estudios superiores, acceso a Internet en el hogar, si el estudiante tiene una relaciÃ³n romÃ¡ntica, calidad de las relaciones familiares, tiempo libre despuÃ©s de la escuela, si el estudiante sale con amigos, consumo de alcohol entre semana, consumo de alcohol los fines de semana, estado de salud actual y nÃºmero de ausencias escolares.\nPriors dÃ©bilmente informativos\n\nAjuste un modelo de regresiÃ³n lineal utilizando todos los predictores luego de estandarizarlos y con los siguientes priors: \\[\n\\begin{aligned}\n\\beta_k &\\sim \\text{Normal}(0, 2.5) \\\\\n\\sigma  &\\sim \\text{Exponential}(1 / \\text{std}(y))\n\\end{aligned}\n\\]\nElabore un grÃ¡fico para visualizar los posteriors marginales y compÃ¡relos. Â¿QuÃ© puede concluir acerca de su incertidumbre?\nCalcule y compare la mediana del \\(R^2\\) bayesiano y del \\(R^2\\) calculado mediante LOO Â¿QuÃ© conclusiÃ³n puede extraer de esta comparaciÃ³n?\nÂ¿CuÃ¡l es el nÃºmero efectivo de parÃ¡metros segÃºn LOO? Â¿QuÃ© indica?\nObtenga muestras del prior y del posterior del \\(R^2\\) bayesiano, compÃ¡relos utilizando una visualizaciÃ³n y concluya considerando la elecciÃ³n de los priors dÃ©bilmente informativos sobre \\(\\beta_k\\) y \\(\\sigma\\).\n\nPriors alternativos (I)\nSi se asume que muchos predictores pueden tener poca relevancia, se pueden escalar los priors independientes para que la suma de la varianza de los priors se encuentre alrededor de un valor razonable. En este caso, se cuenta con 26 predictores y se podrÃ­a suponer que la proporciÃ³n de la varianza explicada por los predictores estÃ¡ alrededor de 0.3. Entonces, un enfoque simple consiste en asignar priors independientes a los coeficientes de regresiÃ³n con media 0 y desviaciÃ³n estÃ¡ndar \\(\\sqrt{0.3/26}\\text{sd}(y)\\) y un prior exponencial con media \\(\\sqrt{0.7}\\text{sd}(y)\\) para \\(\\sigma\\).\n\nAjuste el modelo nuevamente utilizando los siguientes priors: \\[\n\\begin{aligned}\n\\beta_k &\\sim \\text{Normal}(0, \\sqrt{\\frac{0.3}{26}}\\text{sd}(y)) \\\\\n\\sigma  &\\sim \\text{Exponential}(1 / \\sqrt{0.7}\\text{sd}(y))\n\\end{aligned}\n\\]\nExplore la distribuciÃ³n a priori sobre \\(R^2\\) y compÃ¡rela con la distribuciÃ³n obtenida con los priors dÃ©bilmente informativos.\nCalcule ELPD mediante LOO y compare este modelo con el anterior.\nElabore un grÃ¡fico para visualizar los posteriors marginales. Compare este resultado con el obtenido con los priors dÃ©bilmente informativos.\n\nPriors alternativos (II)\nOtra alternativa es asumir que solo algunos de los predictores tienen alta relevancia y que el resto de los predictores tienen una relevancia insignificante. Una posibilidad para modelar bajo este supuesto es el horseshoe prior regularizado1. Este prior utiliza distribuciones normales independientes con media 0 y varianza \\(\\tau^2\\lambda_k^2\\) para los coeficientes de regresiÃ³n \\(\\beta_k\\) y se describe a continuaciÃ³n:\n\\[\n\\begin{aligned}\n\\beta_k   &\\sim \\text{Normal}(0, \\tau^2\\tilde{\\lambda}_k^2) \\\\\n\\tilde{\\lambda}_k^2 &= \\frac{c^2\\lambda_k^2}{c^2 + \\tau^2\\lambda_k^2} \\\\\nc & = \\sqrt{c'} \\text{SS} \\\\\nc' &\\sim \\text{InvGamma}(0.5 \\cdot SDF, 0.5 \\cdot SDF) \\\\\n\\lambda_k &\\sim \\text{StudentT}^+(\\text{df} = 1, \\mu = 0, \\sigma = 1 ) \\\\\n\\tau      &\\sim \\text{StudentT}^+(\\text{df} = 1, \\mu = 0, \\sigma = \\text{GS})\n\\end{aligned}\n\\]\ncon \\[\n\\begin{aligned}\n\\text{GS} = \\frac{p_0}{p - p_0} \\frac{\\sigma}{\\sqrt{n}} \\\\\n\\text{SS} = \\sqrt{\\frac{0.3}{p_0}} \\text{sd}(y) \\\\\n\\text{SDF} = 4\n\\end{aligned}\n\\]\ndonde \\(\\text{GS}\\), \\(\\text{SS}\\) y \\(\\text{SDF}\\) representan global scale, slab scale y slab degrees of freedom, respectivamente. AdemÃ¡s, \\(p\\) representa la cantidad de predictores, 26, y \\(p_0\\) la cantidad de predictores que se espera que sean relevantes.\nIntuitivamente, el parÃ¡metro global \\(\\tau\\) empuja todos los \\(\\beta_k\\) hacia el 0, mientras que los parÃ¡metros locales \\(\\lambda_k\\) contribuyen a que algunos de los \\(\\beta_k\\) escapen del 0.\n\nUtilice \\(p_0 = 6\\) para ajustar el modelo con todos los predictores y grafique y analice los posteriors marginales.\nCompare este modelo con los ajustados anteriormente en base a sus ELPD estimados con LOO y concluya.\n\nPriors dÃ©bilmente informativos con menos predictores\nAjuste el modelo de regresiÃ³n con un subconjunto de predictores que crea conveniente y los priors dÃ©bilmente informativos que se utilizaron inicialmente.\n\nVisualice los posteriors marginales.\nNuevamente, calcule y compare la mediana del \\(R^2\\) bayesiano y del \\(R^2\\) calculado mediante.\nCompare este modelo con el ajustado anteriormente en base a sus ELPD estimados con LOO y concluya sobre la capacidad predictiva de este modelo."
  },
  {
    "objectID": "practica/practica_00.html",
    "href": "practica/practica_00.html",
    "title": "PrÃ¡ctica - Unidad 0",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "practica/practica_00.html#repaso-de-probabilidad",
    "href": "practica/practica_00.html#repaso-de-probabilidad",
    "title": "PrÃ¡ctica - Unidad 0",
    "section": "Repaso de probabilidad",
    "text": "Repaso de probabilidad\nEl objetivo de los ejercicios de esta unidad es refrescar y consolidar los conocimientos relacionados con el cÃ¡lculo de probabilidades y la manipulaciÃ³n de distribuciones de probabilidad.\n\nÂ¡Argentina campeÃ³n!\nDe las siguientes expresiones cual(es) se corresponde(n) con el enunciado â€œla probabilidad de que Argentina gane la copa del mundo dado que es 18 de Diciembre de 2022â€?\n\n\\(P(\\text{18 de Diciembre de 2022} | \\text{Argentina campeÃ³n})\\).\n\\(P(\\text{Argentina campeÃ³n})\\).\n\\(P(\\text{Argentina campeÃ³n}, \\text{18 de Diciembre de 2022}) / P(\\text{18 de Diciembre de 2022})\\).\n\\(P(\\text{Argentina campeÃ³n} | \\text{Diciembre})\\).\n\\(P(\\text{Argentina campeÃ³n} | \\text{18 de Diciembre de 2022})\\). \n\n\n\n\n\n\nEl festejo de los campeones del mundo\n\n\n\n\nDe formulas al espaÃ±ol\nEnuncie con palabras cada una de las expresiones del punto anterior. \nProbabilidades condicionales\nSegÃºn la definiciÃ³n de probabilidad condicional\n\nÂ¿CuÃ¡l es el valor de \\(P(A | A)\\)?\nÂ¿CuÃ¡l es la probabilidad de \\(P(A, B)\\)?\nÂ¿CuÃ¡l es la probabilidad de \\(P(A, B)\\) en el caso que \\(A\\) y \\(B\\) sean independientes?\nÂ¿CuÃ¡ndo se cumple que \\(P(A | B) = P(A)\\)?\nÂ¿Es posible que \\(P(A | B) > P(A)\\)? Â¿CuÃ¡ndo?\nÂ¿Es posible que \\(P(A | B) < P(A)\\)? Â¿CuÃ¡ndo? \n\nAmigarse con la funciÃ³n de densidad (I)\nSuponga \\(X \\sim \\text{Uniforme}(a, b)\\). Su soporte es \\(\\mathcal{S} = [a, b]\\) y su funciÃ³n de densidad de probabilidad es \\(p(x) = 1 / (b - a)\\) para todo \\(x \\in \\mathcal{S}\\).\n\nPruebe que \\(p(x)\\) es una funciÃ³n de densidad de probabilidad vÃ¡lida.\nEncuentre la media y la varianza de \\(X\\). \n\nAmigarse con la funciÃ³n de densidad (II)\nSea \\(X\\) una variable aleatoria con soporte \\(X \\in \\mathcal{S} = [1, \\infty)\\). Encuentre la constante \\(c\\), en funciÃ³n de \\(\\theta\\), que haga que \\(p(x) = c \\exp(-x / \\theta)\\) sea una funciÃ³n de densidad de probabilidad vÃ¡lida. \nEn bÃºsqueda de la distribuciÃ³n deseada\nSegÃºn personas expertas en un problema determinado, se indica que el valor de un parÃ¡metro debe ser positivo y su distribuciÃ³n a priori debe tener media igual a 5 y varianza igual a 3. Encuentre una distribuciÃ³n que satisfaga estas condiciones. \nDistribuciÃ³n conjunta, marginal y condicional\nSean \\(X_1\\) y \\(X_2\\) dos variables aleatorias con funciÃ³n de probabilidad conjunta dada por la siguiente tabla:\n\n\n\n\n\n\\(X_1\\) / \\(X_2\\)\n\\(X_2=0\\)\n\\(X_2=1\\)\n\n\n\n\n\\(X_1=0\\)\n\\(0.15\\)\n\\(0.15\\)\n\n\n\\(X_1=1\\)\n\\(0.15\\)\n\\(0.20\\)\n\n\n\\(X_1=2\\)\n\\(0.15\\)\n\\(0.20\\)\n\n\n\n\n\ndonde la celda de la primer fila y primer columna se lee \\(P(X_1=0, X_2=0)=0.15\\)\n\nObtenga la distribuciÃ³n marginal de \\(X_1\\).\nObtenga la distribuciÃ³n marginal de \\(X_2\\).\nObtenga la distribuciÃ³n condicional de \\(X_1\\) dado \\(X_2\\).\nObtenga la distribuciÃ³n condicional de \\(X_2\\) dado \\(X_1\\). \n\nDistribuciones marginal y condicional de una normal\nSean \\(X_1\\) y \\(X_2\\) tales que \\((X_1, X_2)\\) siguen una distribuciÃ³n normal bivariada con \\(\\mathbb{E}(X_1) = \\mathbb{E}(X_2) = 0\\), \\(\\text{Var}(X_1) = \\text{Var}(X_2) = 1\\) y \\(\\text{cor}(X_1, X_2) = \\rho\\)\n\nEncuentre la distribuciÃ³n marginal de \\(X_1\\).\nEncuentre la distribuciÃ³n condicional de \\(X_1\\) dado \\(X_2\\). \n\nDe bolas, pesos y distribuciones de probabilidad\nSuponga una urna \\(S\\) contiene un 40% de bolas verdes y un 60% de bolas rojas, y otra urna \\(E\\) contiene un 60% de bolas verdes y un 40% de bolas rojas. Una persona arroja una moneda de un peso argentino y selecciona una bola de una de las dos urnas dependiendo de si la moneda en sol o escudo. Si la moneda cae en sol, saca una bola de la urna \\(S\\) y si la moneda cae en escudo, saca una bola de la urna \\(E\\).\nConsidere las siguientes variables aleatorias:\n\\[\n\\begin{aligned}\nX &=\n    \\begin{cases}\n    1 & \\text{Si la moneda cae en sol} \\\\\n    0 & \\text{Si la moneda cae en escudo}\n    \\end{cases}\n\\\\\n\\\\\nY &=\n    \\begin{cases}\n    1 & \\text{Si la bola es verde} \\\\\n    0 & \\text{Si la bola es roja}\n    \\end{cases}\n\\end{aligned}\n\\]\n\nEncuentre la distribuciÃ³n conjunta de \\(X\\) e \\(Y\\) en una tabla.\nEncuentre \\(\\mathbb{E}(Y)\\). Â¿CuÃ¡l es la probabilidad de que la bola sea verde?\nEncuentre \\(\\text{Var}(Y | X = 0)\\), \\(\\text{Var}(Y | X = 1)\\) Y \\(\\text{Var}(Y)\\). Considerando a la varianza como una medida de incertidumbre, explique de manera intuitiva por que algunas variancias son mas grandes que otras.\nSuponga que observa que la bola es verde. Â¿CuÃ¡l es la probabilidad de que la moneda haya caido en escudo? \n\n\n\n\n\n\nMoneda de un peso argentino acuÃ±ada en 1995\n\n\n\n\nLuces de giro\nLas luces de giro en los automÃ³viles se utilizan para indicar que se va a realizar alguna acciÃ³n determinada. La acciÃ³n depende del escenario donde se conduzca (urbano, ruta, rotonda, etc.) y la luz que se encienda (izquierda o derecha). En el uso urbano, se debe colocar la luz de giro correspondiente para indicar que se va a girar en un sentido determinado. Sin embargo, esto no siempre se realiza. Muchas veces sucede que un vehÃ­culo no muestra luz de giro, y sin embargo, gira. Aunque menos frecuente, tambiÃ©n se da que el vehÃ­culo coloca la luz de giro, pero no gira. Un estudio revelÃ³ un vehÃ­culo gira en una de cada diez intersecciones que cruza, que la probabilidad de colocar la luz de giro cuando se va a doblar es de 0.87 y que la probabilidad de que se coloque la luz de giro cuando no se va a doblar es de 0.04. Si observa que un vehÃ­culo coloca la luz de giro, Â¿cuÃ¡l es la probabilidad de que efectivamente doble?\nProblema del cumpleaÃ±os\nHay \\(k\\) personas en una sala. Suponga que el cumpleaÃ±os de cada persona tiene la misma probabilidad de ocurrir en cualquiera de los 365 dÃ­as del aÃ±o (se excluye el 29 de Febrero) y que los cumpleaÃ±os de las personas son independientes entre si. Â¿CuÃ¡l es la probabilidad de que al menos un par de personas en el grupo cumplan los aÃ±os el mismo dÃ­a? \n\n\n\n\n\nFoto de Adi Goldstein en Unsplash\n\n\n\n\nProblema de concordancia de de Montmort\nConsidere un mazo de \\(n\\) cartas bien mezcladas, etiquetadas con nÃºmeros de 1 a \\(n\\). Se seleccionan las cartas de a una y se la da vuelta, diciendo en voz alta el nÃºmero de cartas dadas vueltas desde 1 a \\(n\\). Para ganar el juego tiene que coincidir el nÃºmero que se dice en voz alta con el nÃºmero de la carta que se estÃ¡ dando vuelta â€“ por ejemplo, si la sÃ©ptima carta dada vuelta contiene el nÃºmero 7. Â¿CuÃ¡l es la probabilidad de ganar? Â¿Depende de \\(n\\)? \nProblema de los dos sobres\nSupongamos que te presentan dos sobres con dinero. Un sobre contiene el doble de dinero que el otro, pero a simple vista son indistinguibles. Se te pide que escojas uno de los sobres. Antes de abrirlo se te ofrece la posibilidad de cambiarlo por el otro. Â¿CambiarÃ­as el sobre? Â¿Por quÃ©?"
  },
  {
    "objectID": "practica/practica_05.html",
    "href": "practica/practica_05.html",
    "title": "PrÃ¡ctica - Unidad 5",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "practica/practica_05.html#modelos-de-regresiÃ³n-avanzados",
    "href": "practica/practica_05.html#modelos-de-regresiÃ³n-avanzados",
    "title": "PrÃ¡ctica - Unidad 5",
    "section": "Modelos de regresiÃ³n avanzados",
    "text": "Modelos de regresiÃ³n avanzados\nEn esta Ãºltima unidad de la prÃ¡ctica se presentan ejercicios que requieren el desarrollo de modelos de regresiÃ³n con un nivdel de complejidad mayor. La distribuciÃ³n condicional de la respuesta ya no es necesariamente normal y la forma del predictor de la media incluye caracterÃ­sticas que lo diferencian de un predictor lineal simple. AdemÃ¡s, esta unidad presenta ejercicios con modelos jerÃ¡rquicos.\n\nRegresiÃ³n Poisson\nConsidere el siguiente modelo para datos de conteo con un predictor \\(X\\) que toma valores entre -3 y 50:\n\\[\n\\begin{aligned}\nY_i   &\\sim \\mathrm{Poisson}(\\lambda_i) \\\\\n\\log(\\lambda_i) &= \\beta X \\\\\n\\end{aligned}\n\\]\n\nGenere 1000 valores de \\(X\\), asuma un valor conocido (y fijo) para \\(\\beta\\), simule los correspondientes valores de \\(\\lambda_i\\) y los de \\(Y_i\\). Â¿CÃ³mo es \\(\\lambda\\) en funciÃ³n de \\(X\\)? Â¿Es lineal la relaciÃ³n entre \\(X\\) e \\(Y\\)? Â¿QuÃ© ocurre con la varianza de \\(Y\\) en funciÃ³n de \\(X\\)? Â¿CÃ³mo es la distribuciÃ³n marginal de \\(Y\\)?\nAhora aÃ±ada incertidumbre al valor de \\(\\beta\\) (Â¿cÃ³mo se hace esto?) y simule nuevamente valores para \\(\\lambda_i\\) y \\(Y_i\\). Compare los resultados.\n\nRegresiÃ³n logÃ­stica\nConsidere el siguiente modelo de clasificaciÃ³n con un predictor \\(X\\) que toma valores entre -30 y 10:\n\\[\n\\begin{aligned}\nY_i   &\\sim \\mathrm{Bernoulli}(\\theta_i) \\\\\n\\log\\left(\\frac{\\theta_i}{1 - \\theta_i}\\right) &= \\beta X \\\\\n\\end{aligned}\n\\]\n\nGenere 1000 valores de \\(X\\), asuma un valor conocido (y fijo) para \\(\\beta\\), simule los correspondientes valores de \\(\\theta_i\\) y los de \\(Y_i\\). Â¿CÃ³mo es \\(\\theta\\) en funciÃ³n de \\(X\\)? Â¿Es lineal la relaciÃ³n entre \\(X\\) e \\(Y\\)?\nAhora aÃ±ada incertidumbre al valor de \\(\\beta\\) (Â¿cÃ³mo se hace esto?) y simule nuevamente valores para \\(\\theta_i\\) y \\(Y_i\\). Compare los resultados.\n\nIntenciÃ³n de voto\nEl conjunto de datos elecciones.csv contiene los resultados de un estudio piloto sobre intenciÃ³n de voto. Contiene las variables voto, edad y partido que indican respectivamente el candidato elegido, la edad y la afinidad partidaria del encuestado.\nUtilice un modelo de regresiÃ³n logÃ­stica para responder a las siguiente preguntas de investigaciÃ³n:\n\nÂ¿CÃ³mo se relaciona la edad de los encuestados con la intenciÃ³n de voto?\nÂ¿Es esta relaciÃ³n diferente para las diferentes afinidades partidarias?\n\nDÃ­as de ausencia\nUn organismo pÃºblico de un Estado de los Estados Unidos estÃ¡ intereaso en estudiar el comportamiento de la asistencia de los estudiantes de secundaria. Para eso se cuenta con datos de 314 estudiantes tercer aÃ±o en students.csv. Los predictores del nÃºmero de dÃ­as de ausencia incluyen el tipo de programa en el que estÃ¡ inscrito el estudiante y una prueba estandarizada de matemÃ¡ticas.\nLas variables de interÃ©s en el conjunto de datos son:\n\ndaysabs: El nÃºmero de dÃ­as de ausencia. Es nuestra variable de respuesta.\nprogr: El tipo de programa. Puede ser uno de los siguientes: \"General\", \"Academic\" o \"Vocational\".\nmath: PuntuaciÃ³n en una prueba de matemÃ¡ticas estandarizada.\n\nInteresa evaluar la asociaciÃ³n entre el tipo de programa y la puntuaciÃ³n en la prueba con los dÃ­as de ausencia. TambiÃ©n se desea ver ver si la asociaciÃ³n entre el puntaje en la prueba y los dÃ­as de ausencia es diferente en cada tipo de programa.\nRealice un anÃ¡lisis exploratorio de los datos y elabore un modelo de regresiÃ³n Poisson que permita explicar la asociaciÃ³n entre las variables predictoras y la cantidad de dÃ­as que se ausentan los estudiantes.\nModelo lineal para elecciones en Estados Unidos\nUtilice el conjunto de datos de las elecciones presidenciales de Estados Unidos del aÃ±o 2016 que se provee en Reich y Ghosh (2019) (rep_2012_2016). Elabore un modelo de regresiÃ³n lineal bayesiano donde la variable respuesta es la diferencia porcentual entre el porcentaje de votos que obtuvo el candidato Republicano en el 2016 versus los que tuvo en el 2012 en cada condado y utilice todas las demÃ¡s variables como predictoras.\n\nUtilice distribuciones a priori normales no informativas. Interprete las distribuciones a posteriori marginales de los coeficientes de regresiÃ³n.\nCalcule los residuos \\(\\mathbf{r} = \\mathbf{y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}\\) donde \\(\\hat{\\boldsymbol{\\beta}}\\) es la media a posteriori del vector de coeficientes de regresiÃ³n Â¿Puede concluir que los residuos siguen una distribuciÃ³n normal? Â¿QuÃ© condados presentan los residuos mÃ¡s grandes y mÃ¡s pequeÃ±os? Â¿QuÃ© puede indicar sobre estos condados? \n\nControl de armas\nUtilice el conjunto de datos sobre el control de armas en Estados Unidos. Estos datos provienen de un estudio transversal. Para el estado \\(i\\), sea \\(Y_i\\) el numero de homicidios y \\(N_i\\) el tamaÃ±o de la poblaciÃ³n.\n\nAjuste el modelo \\(Y_i | \\boldsymbol{\\beta} \\sim \\text{Poisson}(N_i\\lambda_i)\\) donde \\(\\text{log}(\\lambda_i) = \\mathbf{X}_i\\boldsymbol{\\beta}\\). Use distribuciones a priori no informativas y \\(p = 7\\) de las covariables en \\(\\mathbf{X}_i\\): el intercepto, los cinco confounders \\(\\mathbf{Z}_i\\), y el nÃºmero de leyes relacionadas a armas. Justifique que el sampler ha convergido y explorado suficientemente la distribuciÃ³n a posteriori y resuma la distribuciÃ³n a posteriori de \\(\\boldsymbol{\\beta}\\). \n\nÂ¿A cuÃ¡ntas SofÃ­as conoces?\nDescargue el conjunto de datos babynames en R y calcule el log-odds de un bebÃ© llamado â€œSophiaâ€ en cada aÃ±o luego de 1950.\n\nlibrary(babynames)\ndat <- babynames\ndat <- dat[dat$name == \"Sophia\" & dat$sex == \"F\" & dat$year > 1950, ]\nyr <- dat$year\np <- dat$prop\nt <- dat$year - 1950\nY <- log(p / (1 - p))\n\nSea \\(Y_t\\) el log-odds muestral en el aÃ±o \\(t + 1950\\). Ajuste el siguiente modelo auto-regresivo de orden 1:\n\\[\n\\begin{aligned}\nY_t   &= \\mu_t + \\rho(Y_{t - 1} + \\mu_{t - 1}) + \\varepsilon_t \\\\\n\\mu_t &= \\alpha + \\beta t \\\\\n\\varepsilon &\\underset{iid}{\\sim} \\text{Normal}(0, \\sigma^2) \\\\\n\\alpha, \\beta &\\sim \\text{Normal}(0, 100^2) \\\\\n\\rho &\\sim \\text{Uniforme}(-1, 1) \\\\\n\\sigma^2 &\\sim \\text{InvGamma}(0.1, 0.1)\n\\end{aligned}\n\\]\n\nInterprete los parÃ¡metros del modelo (\\(\\alpha\\), \\(\\beta\\), \\(\\rho\\) y \\(\\sigma^2\\))\nAjuste el modelo utilizando {RStan} para \\(t > 1\\). Verifique la convergencia y reporte la media a posteriori e intervalos del 95% para los parÃ¡metros.\nGrafique la distribuciÃ³n predictiva a posteriori para \\(Y_t\\) en el aÃ±o 2020. \n\nMeta-anÃ¡lisis\nEn este ejercicio se llevarÃ¡ a cabo un meta-anÃ¡lisis, es decir, un anÃ¡lisis que combina el resultado de varios estudios. Los datos provienen del paquete {rmeta} en R.\n\nlibrary(rmeta)\ndata(cochrane)\ncochrane\n\n          name ev.trt n.trt ev.ctrl n.ctrl\n1     Auckland     36   532      60    538\n2        Block      1    69       5     61\n3        Doran      4    81      11     63\n4        Gamsu     14   131      20    137\n5     Morrison      3    67       7     59\n6 Papageorgiou      1    71       7     75\n7      Tauesch      8    56      10     71\nLos datos provienen de siete ensayos aleatorizados que evalÃºan el efecto de la terapia con corticosteroides en la muerte neonatal. Para el ensayo \\(i \\in \\{1, \\dots, 7 \\}\\) \\(Y_{i0}\\) representa el nÃºmero de eventos que ocurren en el grupo de control de tamaÃ±o \\(N_{i0}\\) y \\(Y_{i1}\\) representa el nÃºmero de eventos que ocurren en el grupo tratado de tamaÃ±o \\(N_{i1}\\).\n\nAjuste el modelo \\(Y_{ij} | \\theta_j \\underset{indep}{\\sim} \\text{Binomial}(N_{ij}, \\theta_j)\\) con \\(\\theta_0, \\theta_1 \\sim \\text{Uniforme}(0, 1)\\). Â¿Se puede concluir que el tratamiento estÃ¡ asociado a una reducciÃ³n de la tasa de muerte?\nAjuste el modelo \\(Y_{ij} | \\theta_j \\underset{indep}{\\sim} \\text{Binomial}(N_{ij}, \\theta_j)\\) con\n\n\\(\\text{logit}(\\theta_{ij}) = \\alpha_{ij}\\)\n\\(\\boldsymbol{\\alpha}_i = (\\alpha_{i0}, \\alpha_{i1})^T \\underset{iid}{\\sim} \\text{Normal}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})\\)\n\\(\\boldsymbol{\\mu} \\sim \\text{Normal}(0, 10^2I_2)\\)\n\\(\\boldsymbol{\\Sigma} \\sim \\text{InvWishart}(3, I_2)\\)\n\nInterprete los resultados indicando si estos sugieren que el tratamiento estÃ¡ asociado a una reducciÃ³n en la tasa de muerte.\nDibuje un DAG para ambos modelos.\nDiscuta las ventajas y desventajas de ambos modelos.\nÂ¿CuÃ¡l modelo es el preferido para estos datos? \n\nComparando modelos normales\nUtilice el conjuto de datos airquality que viene con el paquete {datasets} que se carga automÃ¡ticamente al crear una sesiÃ³n de R.\n\nhead(airquality)\n\n  Ozone Solar.R Wind Temp Month Day\n1    41     190  7.4   67     5   1\n2    36     118  8.0   72     5   2\n3    12     149 12.6   74     5   3\n4    18     313 11.5   62     5   4\n5    NA      NA 14.3   56     5   5\n6    28      NA 14.9   66     5   6\nCompare los siguientes modelos utilizando 5-fold cross-validation:\n\\[\n\\begin{array}{l}\n\\mathcal{M}_1: \\text{Ozone}_i \\sim \\text{Normal}(\\beta_1 + \\beta_2 \\text{Solar.R}_i, \\sigma^2) \\\\\n\\mathcal{M}_2: \\text{Ozone}_i \\sim \\text{Normal}(\\beta_1 + \\beta_2 \\text{Solar.R}_i + \\beta_3 \\text{Temp}_i + \\beta_4 \\text{Wind}_i, \\sigma^2)\n\\end{array}\n\\]\nElija priors para los parÃ¡metros de ambos modelos explicando su elecciÃ³n. \nAccidente del Challenger\nEl 28 de enero de 1986, el vuelo nÃºmero veinticinco del programa estadounidense de trasbordadores espaciales acabÃ³ en un desastre cuando uno de los propulsores del Challenger explotÃ³ poco despuÃ©s del despegue. En el accidente murieron los siete tripulantes. La comisiÃ³n que investigÃ³ el accidente concluyÃ³ que el accidente fue causado por una falla en un o-ring en una juntura de uno de los propulsores. Esta falla se debiÃ³ a un diseÃ±o defectuoso que volviÃ³ al o-ring excesivamente sensible a factores externos, entre ellos la temperatura. De los veinticuatro vuelos previos, existÃ­a informaciÃ³n de fallas de o-rings para veintitrÃ©s de ellos (el otro se perdiÃ³ en el ocÃ©ano). Estos datos fueron discutidos la noche previa al incidente. No obstante, los datos de los siete vuelos en los que hubo fallas llevaron a la conclusiÃ³n de que no habÃ­a una evidencia clara.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nT\n66\n70\n69\n68\n67\n72\n73\n70\n57\n63\n70\n78\n67\n53\n67\n75\n70\n81\n76\n79\n75\n76\n58\n\n\nF\n0\n1\n0\n0\n0\n0\n0\n0\n1\n1\n1\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n1\n\n\n\n\n\nCurvas de crecimiento de tiranosÃ¡uridos\nSe analizan datos de 20 fÃ³siles de tiranosÃ¡uridos para estimar las curvas de crecimiento de cuatro especies: Albertosaurio, Daspletosaurio, Gorgosaurio y Tiranosaurio. Los datos se toman de la Tabla 1 de Erickson etÂ al. (2004) y se muestran en la FiguraÂ 1. El objetivo es determinar la curva de crecimiento, esto es, determinar el peso esperado por edad para todas las especies.\nEn el panel izquierdo de la FiguraÂ 1 se puede observar que hay una relaciÃ³n no lineal entre la edad y el peso. TambiÃ©n se observan ciertos patrones comunes a las especies. Por ejemplo, la relaciÃ³n positiva entre las variables o el decrecimiento en la tasa de cambio conforme la edad es mayor.\n\n\n\n\n\nFiguraÂ 1: (Izquierda) Edad (aÃ±os) vs Peso (kilogramos). (Derecha) Los mismos datos luego de aplicar la transformaciÃ³n logarÃ­tmica a ambas variables.\n\n\n\n\nSea \\(Y_{ij}\\) el peso y \\(X_{ij}\\) y la edad de la muestra \\(i\\) de la especie \\(j\\), con \\(j = 1, 2, 3, 4\\). Se propone el siguiente modelo:\n\\[\nY_{ij} = f_j(X_{ij}) \\epsilon_{ij}\n\\]\ndonde \\(f_j\\) es la verdadera curva de crecimiento para la especie \\(j\\) y \\(\\epsilon_{ij} > 0\\) es un error multiplicativo.\n\nÂ¿Por quÃ© tiene sentido proponer un error multiplicativo?\nÂ¿CuÃ¡l es un valor sensato para la media de la distribuciÃ³n del error?\nUtilice una distribuciÃ³n log-normal para el error, \\(\\log (\\epsilon_{ij}) \\sim \\text{Normal}\\). Proponga valores para la media y la varianza de forma tal que satisfagan la condiciÃ³n del punto anterior.\n\nEsto da lugar un al siguiente modelo log-normal para \\(Y_{ij}\\):\n\\[\n\\log (Y_{ij}) \\sim \\text{Normal}\n(\\log [f_j(X_{ij})] + \\mu_{\\log \\epsilon}, \\sigma^2_{\\log \\epsilon})\n\\]\ncon \\(\\mathbb{E}(Y_{ij}) = f_j(X_{ij})\\).\nA continuaciÃ³n se proponen cuatro modelos que varÃ­an segÃºn la relaciÃ³n funcional que se propone para \\(f_j\\) y la naturaleza de las distribuciones a priori que se utilizan.\nModelo 1\nObservando el panel derecho de la FiguraÂ 1 se puede concluir que luego de transformar ambas variables con la funciÃ³n logaritmo la relaciÃ³n se ve aproximadamente lineal. Por lo tanto, se propone el siguiente modelo log-lineal:\n\\[\n\\log [f_j(X)] = a_j + b_j \\log(X)\n\\]\ndonde \\(a_j\\) y \\(b_j\\) representan al intercepto y pendiente de la especie \\(j\\). La curva de crecimiento en la escala original resulta \\(f_j(X) = \\exp (a_j)X^{b_j}\\). Considere los siguientes priors:\n\\[\n\\begin{aligned}\na_j &\\sim \\text{Normal}(0, 10) \\\\\nb_j &\\sim \\text{Normal}(0, 10) \\\\\n\\sigma^2_j &\\sim \\text{InvGamma}(0.1, 0.1)\n\\end{aligned}\n\\]\n\nEscriba un programa en Stan que implemente el modelo y obtenga el posterior con {RStan}.\nAnalice los coeficientes del modelo y las curvas de crecimiento. Realice grÃ¡ficos que permitan observar la curva ajustada y su incertidumbre para cada especie.\n\nModelo 2\nEste modelo es el mismo que el Modelo 1, excepto que las especies tienen la misma varianza, \\(\\sigma^2_j = \\sigma^2\\) y los coeficientes de regresiÃ³n son modelados de manera jerÃ¡rquica. Utilice los siguientes priors:\n\\[\n\\begin{aligned}\n\\mu_a    &\\sim \\text{Normal}(0, 10) \\\\\n\\sigma_a &\\sim \\text{InvGamma}(0.1, 0.1) \\\\\n\\mu_b    &\\sim \\text{Normal}(0, 10) \\\\\n\\sigma_b &\\sim \\text{InvGamma}(0.1, 0.1) \\\\\na_j      &\\sim \\text{Normal}(\\mu_a, \\sigma^2_a) \\\\\nb_j      &\\sim \\text{Normal}(\\mu_b, \\sigma^2_b) \\\\\n\\sigma^2 &\\sim \\text{InvGamma}(0.1, 0.1)\n\\end{aligned}\n\\]\n\nEscriba un programa en Stan que implemente el modelo y obtenga el posterior con {RStan}.\nAnalice los coeficientes del modelo y las curvas de crecimiento. Genere grÃ¡ficos similares a los producidos en el punto anterior. Describa similitudes y diferencias respecto del modelo 1. Justifique su respuesta.\nÂ¿QuÃ© problemas detecta los modelos 1 y 2? Considere como evoluciona el peso conforme la edad segÃºn el modelo.\n\nModelo 3\nComo alternativa al componente log-lineal anterior, se propone la siguiente curva de crecimiento logÃ­stico:\n\\[\nf_j(X) = a_j + b_j \\frac{\\exp [d_j (\\log(X) - c_j)]}{1 + \\exp [d_j(\\log(X) - c_j)]}\n\\]\nEste modelo tiene cuatro parÃ¡metros:\n\n\\(a_j\\) es el peso esperado cuando la edad es 0;\n\\(b_j\\) es el peso mÃ¡ximo esperado (o la cota superior del peso);\n\\(\\log (c_j)\\) es la edad a la que la especie \\(j\\) alcanza la mitad del peso mÃ¡ximo;\n\\(d_j > 0\\) determina la tasa de crecimiento del peso conforme aumenta la edad.\n\nPara que la curva sea positiva y creciente para todas las edades, se debe cumplir que \\(a_j > 0\\), \\(b_j > a_j\\) y \\(d_j > 0\\). Se pueden satisfacer estas restricciones expresando los parÃ¡metros en funciÃ³n de parÃ¡metros cuyo dominio es \\(\\mathbb{R}\\):\n\n\\(a_j = \\exp (\\alpha_{j1})\\);\n\\(b_j = \\exp (\\alpha_{j2})\\);\n\\(c_j = \\alpha_{j3}\\);\n\\(d_j = \\exp (\\alpha_{j4})\\).\n\nConsidere las siguientes distribuciones a priori para los parÃ¡metros del modelo:\n\\[\n\\begin{aligned}\n\\alpha_{jk} &\\sim \\text{Normal}(0, 10) \\\\\n\\sigma^2_j  &\\sim \\text{InvGamma}(0.1, 0.1)\n\\end{aligned}\n\\]\n\nEscriba un programa en Stan que implemente el modelo y obtenga el posterior con {RStan}.\nAnalice los diagnÃ³sticos de la inferencia realizada.\nGrafique las curvas estimadas para cada especie junto a sus intervalos de credibilidad e interprete los resultados.\n\nModelo 4\nEste modelo es el mismo que el Modelo 3, excepto que las especies tienen la misma varianza, \\(\\sigma^2_j = \\sigma^2\\) y los coeficientes de regresiÃ³n son modelados de manera jerÃ¡rquica. Utilice los siguientes priors:\n\\[\n\\begin{aligned}\n\\mu_k             &\\sim \\text{Normal}(0, 10) \\\\\n\\sigma^2_k        &\\sim \\text{InvGamma}(0.1, 0.1) \\\\\n\\log(\\alpha_{jk}) &\\sim \\text{Normal}(\\mu_k, \\sigma^2_k) \\\\\n\\sigma^2          &\\sim \\text{InvGamma}(0.1, 0.1)\n\\end{aligned}\n\\]\n\nEscriba un programa en Stan que implemente el modelo y obtenga el posterior con {RStan}.\nAnalice los diagnÃ³sticos de la inferencia y compare con los resultados del modelo 3.\nGrafique las curvas estimadas para cada especie junto a sus intervalos de credibilidad e interprete los resultados. Compare con los resultados del modelo 3. Â¿QuÃ© diferencias observa? Â¿Por quÃ© se dan?\nEscriba una sÃ­ntesis comparando todos los modelos desarrollados. Comente ventajas y desventajas de cada uno de ellos, explicando a que se deben en cada caso Â¿QuÃ© modelo resulta mÃ¡s conveniente para estimar la curva de crecimiento de los tiranosÃ¡uridos? Justifique su respuesta."
  },
  {
    "objectID": "practica/practica_03.html",
    "href": "practica/practica_03.html",
    "title": "PrÃ¡ctica - Unidad 3",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "practica/practica_03.html#mÃ©todos-computacionales",
    "href": "practica/practica_03.html#mÃ©todos-computacionales",
    "title": "PrÃ¡ctica - Unidad 3",
    "section": "MÃ©todos Computacionales",
    "text": "MÃ©todos Computacionales\nEsta secciÃ³n contiene una lista exhaustiva de ejercicios que requieren el uso de herramientas computacionales para resolver problemas que involucran una variedad de cÃ¡lculos, como el cÃ¡lculo de probabilidades y el cÃ¡lculo de integrales. Se vuelve indispensable el uso de R y se promueve el uso de buenas prÃ¡cticas de programaciÃ³n cientÃ­fica, como el uso de funciones compartimentar los componentes de un programa.\n\nÂ¡A calcular probabilidades! (I)\nSea \\(X \\sim \\text{Normal}(\\mu=3, \\sigma=1.2)\\).\n\nElabore un grÃ¡fico que permita visualizar la funciÃ³n de densidad de probabilidad de \\(X\\).\nÂ¿CuÃ¡l es la probabilidad de que \\(X\\) sea menor a 2.5?\nÂ¿CuÃ¡l es la probabilidad de que \\(X\\) sea mayor a 4?\nÂ¿CuÃ¡l es la probabilidad de que \\(X\\) sea mayor 2 y menor 3?\n\nÂ¡A calcular probabilidades! (II)\nSea \\(X \\sim \\text{Beta}(\\alpha=10, \\beta=2)\\).\n\nElabore un grÃ¡fico que permita visualizar la funciÃ³n de densidad de probabilidad de \\(X\\).\nÂ¿CuÃ¡l es la probabilidad de que \\(X\\) sea menor a 0.5?\nÂ¿CuÃ¡l es la probabilidad de que \\(X\\) sea mayor a 0.8?\nÂ¿CuÃ¡l es la probabilidad de que \\(X\\) sea mayor 0.25 y menor 0.75?\n\nMagia blanca: Obtener probabilidades mediante simulaciÃ³n\nResponda los dos puntos anteriores sin evaluar la funciÃ³n de densidad ni la funciÃ³n de distribuciÃ³n de las variables aleatorias mencionadas. Para eso genere muestras que provengan de las correspondientes distribuciones y utilÃ­celas para responder las preguntas mencionadas. Reflexione sobre las ventajas y desventajas de utilizar un enfoque basado en la simulaciÃ³n para resolver problemas.\nMedia y varianza de una variable aleatoria\nUna variable aleatoria \\(X\\) toma valores en el conjunto \\(\\{2, 4, 6, 8, 10\\}\\) con igual probabilidad. Encuentre la media y el desvÃ­o estÃ¡ndar de las variables \\(X\\) e \\(Y = 2X + 1\\). \nProbabilidades a posteriori\nEn un problema determinado la distribuciÃ³n a posteriori de la parÃ¡metro de inteÅ•es \\(\\alpha\\) es \\(\\Gamma(k=3, \\theta=1.5)\\), donde \\(k\\) es el parÃ¡metro de forma y \\(\\theta\\) es el parÃ¡metro de escala. Calcule la probabilidad de que \\(\\alpha^2\\) sea mayor a 10. \nProbabilidades con dos variables aleatorias\nSean \\(X\\) e \\(Y\\) dos variables aleatorias independientes con distribuciÃ³n uniforme en el intervalo \\([0, 1]\\).\n\nÂ¿CuÃ¡l es la probabilidad de que \\(X \\le Y\\)?\nGrafique los puntos muestreados coloreando de acuerdo a si la muestra satisface el evento antes mencionado o no.\n\nTe veo en la fotocopiadora\nDos estudiantes de estadÃ­stica deciden encontrarse en la fotocopiadora de la Facultad entre las 10 y las 11 de la maÃ±ana, eligiendo el tiempo de llegada al azar. La estudiante A esperarÃ¡ 10 minutos luego de llegar. Si el estudiante B no llega en ese intervalo, se irÃ¡. Lo mismo hace el estudiante B, pero este decide esperar 14 minutos. Â¿CuÃ¡l es la probabilidad de que se produzca el encuentro en la fotocopiadora entre la estudiante A y el estudiante B?\nArmando celulares en Tierra del Fuego\nUna mÃ¡quina que se utiliza para ensamblar telÃ©fonos celulares en una fÃ¡brica en Tierra del Fuego cuenta con tres componentes crÃ­ticos para su funcionamiento. Ante una falla en cualquiera de estos componentes, la mÃ¡quina se detiene. Las probabilidades de que estos elementos operen correctamente durante un dÃ­a cualquiera son \\(p_1 = 0.8\\), \\(p_2 = 0.9\\) y \\(p_3 = 0.7\\). Responda las siguientes preguntas utilizando tÃ©cnicas de simulaciÃ³n:\n\nÂ¿CuÃ¡l es la probabilidad de que la mÃ¡quina falle en el primer dÃ­a de uso?\nÂ¿CuÃ¡l es la probabilidad de que la mÃ¡quina siga funcionando luego de 10 dÃ­as?\nÂ¿CuÃ¡l es la probabilidad de que la mÃ¡quina falle en el dÃ­a 7 de uso?\nSea \\(T=\\) Cantidad de dÃ­as que la mÃ¡quina funciona ininterrumpidamente. Grafique la funciÃ³n de densidad de probabilidad de \\(T\\).\n\nBolas infinitas\nEste tuit propone un problema muy interesante. Una urna contiene una bola azul y una amarilla. Se elije una bola al azar y se la vuelve a colocar junto con otra bola adicional del mismo color. Se repite este proceso indefinidamente. Â¿QuÃ© ocurre con la proporciÃ³n de bolas azules en la urna a medida que repetimos mÃ¡s y mÃ¡s veces?\n\nTiende a 1/2.\nTiende a 0 Ã³ a 1.\nNo se estabiliza.\nNinguna de las anteriores.\n\nEscriba un programa en R para responder esta pregunta utilizando simulaciones. Genere grÃ¡ficos que faciliten la comprensiÃ³n del resultado. \nEstimando el valor de \\(\\pi\\)\nImagine un cÃ­rculo de radio \\(r\\) y un cuadrado de lado \\(2r\\), ambos centrados en el mismo punto, que de manera arbitraria puede ser el punto \\((0, 0)\\). Obtenga muestras de una distribuciÃ³n uniforme en el plano \\((x, y)\\), cuyo dominio estÃ¡ acotado por el cuadrado antes mencionado. Para cada muestra extraida, determine si se encuentra dentro del cÃ­rculo o no â€“ todos las muestras se encontrarÃ¡n dentro del cuadrado. Utilice esta informaciÃ³n para estimar el valor de \\(\\pi\\).\n\n\n\n\n\n\n\n\n\nAlgunos datos Ãºtiles\n\nArea de un cÃ­rculo: \\(\\pi \\cdot r^2\\).\nArea de un cuadrado: \\(a^2\\), donde \\(a\\) es la longitud del lado.\n\nLos puntos uniformes\nSe seleccionan dos puntos de manera uniforme e independiente dentro de un cÃ­rculo. Â¿CuÃ¡l es la probabilidad de que la distancia entre dos puntos sea menor al radio?\n\nResuelva el problema utilizando R.\nElabore una visualizaciÃ³n que facilite la comunicaciÃ³n de los resultados.\n\nSobre el histÃ³rico 7 a 1 del 2014\nEn la Copa del Mundo de la FIFA 2014, Alemania jugÃ³ contra Brasil en la semifinal. Los alemanes hicieron el primer gol a los 11 minutos y el segundo a los 23. Asuma que el tiempo entre goles sigue una distribuciÃ³n exponencial. Elija una distribuciÃ³n a priori para el tiempo entre goles (puede ser conjugada o no). En ese momento del partido,\n\nÂ¿CuÃ¡l es la distribuciÃ³n a posteriori del tiempo entre goles de Alemania?\nÂ¿CuÃ¡ntos goles cabrÃ­a esperar que Alemania hiciera al finalizar los 90 minutos?\nÂ¿CuÃ¡l era la probabilidad de que Alemania hiciera mÃ¡s de 5 goles (cosa que ocurriÃ³)? \n\nÂ¿TendrÃ© que esperar mucho?\nEl tiempo que un empleado de recursos humanos demora en hacer una entrevista tiene distribuciÃ³n exponencial con media 30 minutos. Los tiempos de duraciÃ³n de cada entrevista se pueden considerar independientes entre sÃ­. Las entrevistas a postulantes para un trabajo estÃ¡n programadas cada 15 minutos, comenzando desde las 8. Es vÃ¡lido considerar que todos los postulantes llegan puntuales a su entrevista. Cuando la persona del turno de las 8:15 llega a la oficina\n\nÂ¿CuÃ¡l es la probabilidad de que tenga que esperar antes de ser entrevistada?\nÂ¿CuÃ¡l es el horario esperado al que terminarÃ¡ su entrevista? \n\nÂ¡QuÃ© casualidad!\nDos personas se conocen en la fila de embarque para un vuelo en un aviÃ³n Airbus A330-300. Considere que el Airbus A330-300 tiene 30 filas de 2-4-2 asientos.\n\nÂ¿CuÃ¡l es la probabilidad de que tengan asientos en la misma fila?\nÂ¿CuÃ¡l es la probabilidad de que estÃ©n sentados en asientos adyacentes?\n\nEl Problema de Monty Hall\nEl Problema de Monty Hall es un problema de probabilidad basado en un juego del concurso televisivo estadounidense â€œTrato hechoâ€. En este problema, el concursante debe elegir una puerta entre tres, todas cerradas. El premio consiste en llevarse lo que se encuentra detrÃ¡s de la elegida. Se sabe con certeza que tras una de ellas se oculta un automÃ³vil, y tras las otras dos hay cabras. Una vez que el concursante haya elegido una puerta y comunicado su elecciÃ³n a los presentes, el presentador, que sabe lo que hay detrÃ¡s de cada puerta, abrirÃ¡ una de las otras dos en la que haya una cabra. A continuaciÃ³n, le da la opciÃ³n al concursante de cambiar, si lo desea, de puerta (tiene dos opciones). Â¿Debe el concursante mantener su elecciÃ³n original o escoger la otra puerta? Â¿Hay alguna diferencia? Resuelva este ejercicio utilizando simulaciones. \n\n\n\n\n\nLas 3 puertas del problema de Monty Hall\n\n\n\n\nQue los cumplan feliz\nBasÃ¡ndose en el siguiente tuit y conociendo el problema del cumpleaÃ±os (Â¿cuÃ¡ntas personas debe haber en una habitaciÃ³n para que la probabilidad de que dos de ellas cumplan aÃ±os el mismo dÃ­a sea mayor a X%?) construir un grÃ¡fico similar al del tuit donde se grafique la probabilidad de que haya \\(n\\) personas que cumplan aÃ±os el mismo dÃ­a para \\(K\\) personas presentes en la habitaciÃ³n.\nQuÃ© suerte, Â¿no?\nPrevio a la final de la Copa AmÃ©rica 2021, los jugadores de la SelecciÃ³n Argentina se reÃºnen en la habitaciÃ³n del hotel como se describe en este tuit.\n\nÂ¿CuÃ¡l es la probabilidad de que un jugador adivine una de diez cartas?\nÂ¿CuÃ¡l es la probabilidad de que tres de ellos adivinen una de diez cartas?\n\nEl Ã¡lbum del CampeÃ³n\nEl Ã¡lbum oficial del Mundial de FÃºtbol de Qatar 2022 consta de 638 figuritas. Cada paquete trae cinco figuritas.\n\nComprando cinco paquetes, Â¿cuÃ¡l es la probabilidad de tener a Messi?\nComprando cinco paquetes, Â¿cuÃ¡l es la probabilidad de sacar a Messi repetido?\nÂ¿CuÃ¡ntos paquetes se necesitan, en promedio, para completar el Ã¡lbum?\nSi a una persona le faltan diez figuritas para completar el Ã¡lbum, Â¿cuÃ¡ntos paquetes tiene que comprar para asegurarse de lograrlo?\n\nÂ¿Que tÃ¡n raras son estas secuencias raras?\nSi se arroja una moneda \\(n\\) veces, Â¿cuÃ¡l es la probabilidad de que no haya secuencias de \\(k\\) caras?\nUn viaje por el elevador\nÂ¿CuÃ¡l es la probabilidad de que tres personas en un ascensor con doce pisos presionen para ir a tres pisos consecutivos? Â¿QuÃ© supuestos realiza para resolver el problema? EscrÃ­balos en una lista de manera explÃ­cita.\nLa vida es muy corta como para perderla ordenando medias\nUn cajÃ³n contiene 10 pares de medias. No hay dos pares iguales. Por fiaca, el dueÃ±o de las medias no las agrupa despuÃ©s de lavarlas y simplemente las pone en el cajÃ³n. Al momento de necesitar un par de medias, saca una tras una hasta que se forma un par. En promedio, Â¿cuÃ¡ntas medias sacarÃ¡ hasta encontrar un par? \nÂ¿Vale la pena hacer un ensayo clÃ­nico a gran escala?\nDados los resultados de un estudio piloto, la probabilidad a posteriori de que la droga desarrollada por tu compaÃ±Ã­a sea mas efectiva que el tratamiento actual es \\(\\theta \\in [0, 1]\\). Tu compaÃ±Ã­a estÃ¡ considerando realizar un ensayo clÃ­nico a gran escala para confirmar que la droga que desarrollan es de hecho mejor. El costo del estudio es $X. Si la droga es mejor, la probabilidad de que esto se confirme en el ensayo es del 80%. Si la droga no es mejor, hay una probabilidad del 5% de que el estudio confirme que es mejor. Si el ensayo sugiere que tu droga es mejor, ganarÃ¡s $cX. Â¿Para quÃ© valores de \\(\\theta\\) y \\(c\\) tiene sentido realizar el estudio? \nEl problema de concordancia\nResuelva el problema de concordancia de de Montmort presentado en la PrÃ¡ctica 0 utilizando simulaciones. \nEl problema de los sobres\nResuelva el problema de los dos sobres presentado en la PrÃ¡ctica 0 utilizando simulaciones.\nIntegraciÃ³n por muestreo\nCalcule las siguientes integrales utilizando muestras.\n\n\\(\\displaystyle \\int_{-\\infty}^{\\infty}{\\frac{x^2}{\\sqrt{2\\pi}}\\exp \\left(-\\frac{x^2}{2} \\right)dx}\\)\n\\(\\displaystyle \\int_{1}^{\\infty}{\\frac{x^3}{\\sqrt{2\\pi}}\\exp \\left(-\\frac{x^2}{2} \\right)dx}\\)\n\\(\\displaystyle \\int_{1}^{\\infty}{\\frac{x^6}{\\sqrt{2\\pi}}\\exp \\left(-\\frac{x^2 - 4x}{2} \\right)dx}\\)\n\\(\\displaystyle \\int_{1}^{10}{x^6\\frac{e^{-x^4/2}}{\\sqrt{2\\pi}}dx}\\) \n\nÂ¿CuÃ¡l es la distribuciÃ³n de muestreo aproximada al usar muestreo independiente para evaluar integrales?"
  },
  {
    "objectID": "practica/practica_03.html#aproximaciÃ³n-de-una-distribuciÃ³n-mediante-una-grilla",
    "href": "practica/practica_03.html#aproximaciÃ³n-de-una-distribuciÃ³n-mediante-una-grilla",
    "title": "PrÃ¡ctica - Unidad 3",
    "section": "AproximaciÃ³n de una distribuciÃ³n mediante una grilla",
    "text": "AproximaciÃ³n de una distribuciÃ³n mediante una grilla\nEn esta parte de la prÃ¡ctica se comienza a utilizar tÃ©cnicas computacionales que se asocian directamente a la prÃ¡ctica de la estadÃ­stica bayesiana. Los problemas tienen como objetivo la familiarizaciÃ³n con el uso prÃ¡ctico de estas tÃ©cnicas y la comprensiÃ³n de sus caracterÃ­sticas principales.\n\nAproximaciÃ³n de grilla\nSe tiene un experimento binomial donde \\(n=80\\) y se observan \\(y=7\\) Ã©xitos. Considere que el prior de la probabilidad de Ã©xito \\(\\theta\\) es \\(\\text{Beta}(2, 10)\\).\n\nObtenga la distribuciÃ³n a posteriori de \\(\\theta\\) de manera analÃ­tica y grafÃ­quela.\nObtenga la distribuciÃ³n a posteriori de \\(\\theta\\) utilizando el mÃ©todo de la grilla en base a una grilla de 10 puntos y dibuje la curva obtenida en el grÃ¡fico creado anteriormente.\nRepita el proceso del punto anterior utilizando una grilla de 100 puntos.\nConcluya sobre la fidelidad de las aproximaciones. Â¿Considera que es necesario utilizar una grilla mÃ¡s densa? Â¿CuÃ¡les serÃ­an las ventajas y desventajas?\n\nCÃ¡lculo de probabilidades en base a la grilla (I)\nEn base al posterior obtenido en el ejercicio anterior mediante el mÃ©todo de la grilla calcule las siguientes probabilidades\n\n\\(P(\\theta < 0.7)\\).\n\\(P(\\theta > 0.05)\\).\n\\(P(0.05 < \\theta < 0.15)\\).\n\nDe ser necesario, obtenga el posterior mediante una grilla de mayor densidad.\nCÃ¡lculo de probabilidades en base a la grilla (II)\nUtilice los valores de la grilla y sus probabilidades a posteriori para obtener muestras del posterior y calcular las mismas probabilidades que en el ejercicio anterior en base a muestras. Ayuda: Para obtener muestras utilice la funciÃ³n sample().\nAproximaciÃ³n de grilla en 2 dimensiones\nSean dos variables aleatorias continuas \\(X\\) e \\(Y\\) tales que \\((X, Y) \\in \\mathbb{R}^2\\), y sea el siguiente modelo de regresiÃ³n lineal simple:\n\\[\n\\begin{aligned}\n\\alpha &\\sim \\text{Normal}(0, 1.5) \\\\\n\\beta  &\\sim \\text{Normal}(0, 2) \\\\\nY      &\\sim \\text{Normal}(\\alpha + \\beta X, 0.8)\n\\end{aligned}\n\\]\n\nObtenga el posterior conjunto del vector de parÃ¡metros \\([\\alpha, \\beta]^T\\) mediante el mÃ©todo de la grilla. Elabore un grÃ¡fico que permita visualizar esta distribuciÃ³n.\nObtenga el posterior marginal de \\(\\alpha\\) y grafÃ­quelo.\nObtenga el posterior marginal de \\(\\beta\\) y grafÃ­quelo.\nCalcule la probabilidad de que el intercepto sea mayor a 0.95.\nCalcule la probabilidad de que la pendiente sea menor a -2.\n\nPara responder las consignas utilice los datos simulados que se obtienen con el siguiente bloque de cÃ³digo:\n\nset.seed(121195)\nalpha <- 1\nbeta <- -2\nsigma <- 0.8\nn <- 80\nx <- rnorm(n)\ny <- rnorm(n, alpha + beta * x, sigma)\ndf <- data.frame(x = x, y = y)\n\nBonus: Â¿CÃ³mo podrÃ­a responder las consignas (ii)-(v) utilizando muestras del posterior?\n\n\n\n\n\n\nEscalando la aproximaciÃ³n de la grilla\nSuponga que se tiene que estimar un posterior utilizando la aproximaciÃ³n mediante una grilla de 200 puntos en cada dimensiÃ³n. Calcule cÃºantas veces se tiene que evaluar el posterior en cada uno de los siguientes escenarios:\n\n1 dimensiÃ³n.\n2 dimensiones.\n3 dimensiones.\n5 dimensiones.\n10 dimensiones.\n\nConcluya sobre las ventajas y desventajas de la aproximaciÃ³n de la grilla teniendo en cuenta sus caracterÃ­sticas conforme se incrementa el nÃºmero de dimensiones del posterior.\nBenchmark de la aproximaciÃ³n de la grilla\nEl siguiente bloque de cÃ³digo define una funciÃ³n llamada create_and_eval_grid() que evalÃºa la funciÃ³n de densidad normal en una cantidad arbitraria dimensiones. El argumento dimension_n indica la dimensionalidad de la distribuciÃ³n normal, y grid_n indica la cantidad de puntos en la grilla de cada dimensiÃ³n. Debajo, se utiliza la funciÃ³n mark() del paquete {bench} para comparar el desempeÃ±o de la funciÃ³n create_and_eval_grid() con diferentes nÃºmeros de dimensiones.\n\ncreate_and_eval_grid <- function(dimension_n, grid_n = 100) {\n    grid <- seq(-3, 3, length.out = grid_n)\n    grids <- replicate(dimension_n, grid, simplify = FALSE)\n    df <- expand.grid(grids, KEEP.OUT.ATTRS = FALSE)\n    Mu <- rep(0, dimension_n)\n    Sigma <- diag(dimension_n)\n    mvtnorm::dmvnorm(df, mean = Mu, sigma = Sigma)\n}\nbench::mark(\n    create_and_eval_grid(1),\n    create_and_eval_grid(2),\n    check = FALSE,\n    max_iterations = 500\n)\n\nModifique el cÃ³digo brindado para evaluar la funciÃ³n de densidad en hasta un mÃ¡ximo de 10 dimensiones. Concluya sobre el tiempo de ejecuciÃ³n, el consumo de memoria, y otras cantidades que se encuentren en la salida y crea adecuadas para el anÃ¡lisis."
  },
  {
    "objectID": "practica/practica_03.html#sec-mh",
    "href": "practica/practica_03.html#sec-mh",
    "title": "PrÃ¡ctica - Unidad 3",
    "section": "Metropolis-Hastings",
    "text": "Metropolis-Hastings\n\n\nEn esta secciÃ³n, se profundiza en la prÃ¡ctica de uno de los algoritmos fundamentales de la inferencia estadÃ­stica bayesiana: el algoritmo de Metropolis-Hastings.\n\nMuestreo utilizando el algoritmo de Metropolis-Hastings (I)\nUse el algoritmo de Metropolis-Hastings y una distribuciÃ³n de propuesta \\(\\text{Normal}(0, 0.1)\\) para obtener 5000 muestras de las siguientes distribuciones de probabilidad:\n\n\\(\\text{Normal}(\\mu = 3, \\sigma = 6)\\).\n\\(\\text{StudentT}(\\nu = 5)\\).\n\\(\\frac{2}{3}\\text{Normal}(\\mu = 0, \\sigma = 0.5) + \\frac{1}{3}\\text{Normal}(\\mu = 3, \\sigma = 2)\\).\n\nGrafique las distribuciones obtenidas utilizando un histograma o una estimaciÃ³n de densidad y superponga la funciÃ³n de densidad verdadera para realizar una comparaciÃ³n. Concluya sobre la similitud de las mismas y la aptitud de la distribuciÃ³n de propuesta utilizada.\nSimplificando el algoritmo de Metropolis-Hastings\nLa distribuciÃ³n de propuesta utilizada en el ejercicio anterior goza de una propiedad que permite simplificar el algoritmo de Metropolis-Hastings.\n\nÂ¿CuÃ¡l es esta propiedad?\nÂ¿QuÃ© simplificaciÃ³n se puede hacer?\nÂ¿QuÃ© nombre recibe la versiÃ³n simplificada del algoritmo?\nImplemente la versiÃ³n simplificada del algoritmo de Metropolis-Hastings y obtenga nuevamente 5000 muestras para las distribuciones presentadas en el ejercicio anterior utilizando la nueva implementaciÃ³n.\n\nMuestreo utilizando el algoritmo de Metropolis-Hastings (II)\nUse el algoritmo de Metropolis-Hastings y una distribuciÃ³n de propuesta que crea conveniente para obtener 5000 muestras de las siguientes distribuciones de probabilidad:\n\n\\(\\text{Beta}(\\alpha=4, \\beta=8)\\).\n\\(\\text{Gamma}(k = 3, \\theta = 2)\\).\n\\(\\frac{1}{2}\\text{Beta}(\\alpha=10, \\beta=3) + \\frac{1}{2}\\text{Beta}(\\alpha=3, \\beta=10)\\).\n\nRealice un anÃ¡lisis similar al realizado en el Ejercicio 1.\nÂ¡A jugar con la distribuciÃ³n de propuesta!\nSuponga que se desea obtener muestras de una distribuciÃ³n \\(\\text{Normal}(4, 1)\\) utilizando Metropolis-Hastings y la siguiente distribuciÃ³n de propuesta:\n\\[\n\\mu' | \\mu \\sim \\text{Uniforme}(\\mu - w, \\mu + w)\n\\]\nObtenga \\(n=5000\\) muestras con \\(w \\in \\{0.01, 1, 100\\}\\) y compute la probabilidad de aceptaciÃ³n. Luego, para cada \\(w\\), grafique la distribuciÃ³n obtenida y visualice la cadena de Markov utilizando un traceplot.\n\nÂ¿CÃ³mo se relaciona \\(w\\) con el desempeÃ±o del muestreo?\nÂ¿CÃ³mo se relaciona \\(w\\) con la probabilidad de aceptaciÃ³n? Justifique su respuesta utilizando la ecuaciÃ³n del criterio de aceptaciÃ³n.\n\nModelo Normal-Normal\nSe desea estudiar el tiempo promedio que los estudiantes de estadÃ­stica dedican por semana a la materia EstadÃ­stica Bayesiana. Para eso se propone utilizar un modelo Normal-Normal, con \\(\\sigma=1.2\\) conocido.\n\nElija una distribuciÃ³n a priori para el parÃ¡metro \\(\\mu\\).\nDescriba el modelo matemÃ¡ticamente.\nDetermine una distribuciÃ³n de propuesta adecuada para este problema. Explique.\nObtenga 2000 muestras del posterior de \\(\\mu\\). Ajuste los parÃ¡metros de la distribuciÃ³n de propuesta hasta que los resultados se vean adecuados.\nGrafique un histograma de las muestras obtenidas y concluya sobre el desempeÃ±o de la aproximaciÃ³n.\n\nPara resolver este problema utilice los datos que se leen con el siguiente codigo:\n\nurl <- paste0(\n    \"https://raw.githubusercontent.com/estadisticaunr/\",\n    \"estadistica-bayesiana/main/datos/tiempo-estudio-eb.csv\"\n)\ndf_estudio <- readr::read_csv(url)\n\nModelo Beta-Binomial\nSe desea estimar el posterior del parÃ¡metro \\(\\pi\\) en el siguiente modelo Beta-Binomial:\n\\[\n\\begin{aligned}\nY &\\sim \\text{Binomial}(n, \\pi) \\\\\n\\pi &\\sim \\text{Beta}(2, 3)\n\\end{aligned}\n\\]\nSe observan \\(n=10\\) ensayos de Bernoulli y se registran \\(y=3\\) Ã©xitos. Determine una distribuciÃ³n de propuesta adecuada y obtenga muestras de la distribuciÃ³n a posteriori del parÃ¡metro \\(\\pi\\) utilizando el algoritmo de Metropolis-Hastings.\nDe ser necesario, ajuste los parÃ¡metros de la distribuciÃ³n de propuesta.\nModelo Poisson\nEn el ejercicio Â¡Ostras! Â¡Estoy haciendo inferencia bayesiana! de la PrÃ¡ctica 1 se reportÃ³ que la cantidad de especies marinas bivalvas descubiertas cada aÃ±o entre 2010 y 2015 fue 64, 13, 33, 18, 30 y 20.\nSea \\(Y_t\\) la cantidad de especies descubiertas en el aÃ±o \\(2009 + t\\) (e.g.Â \\(Y_1 = 64\\) es el conteo para el aÃ±o 2010) y el siguiente modelo:\n\\[\n\\begin{aligned}\nY_t        &\\sim \\text{Poisson}(\\lambda_t) \\\\\n\\lambda_t  &= \\exp (\\alpha + \\beta t) \\\\\n\\alpha     &\\sim \\text{Normal}(0, 10^2) \\\\\n\\beta      &\\sim \\text{Normal}(0, 10^2)\n\\end{aligned}\n\\]\nAjuste el modelo utilizando Metropolis-Hastings y verifique la convergencia de las cadenas de Markov. \nMetropolis-Hastings multivariado\nUse el algoritmo de Metropolis Hastings para obtener 1000 muestras de la distribuciÃ³n \\(\\text{MVN}(\\pmb{\\mu}, \\pmb{\\Sigma})\\) donde\n\\[\n\\begin{array}{cc}\n    \\pmb{\\mu} = \\begin{bmatrix}1.2 \\\\ 0.8 \\end{bmatrix}, &\n    \\pmb{\\Sigma} = \\begin{bmatrix}3 & 0.2 \\\\ 0.2 & 2 \\end{bmatrix}\n\\end{array}\n\\]\nUtilice una distribuciÃ³n de propuesta \\(\\text{MVN}(\\mathbf{0}_2, \\mathbf{I}_2\\sigma)\\) con \\(\\sigma = 0.2\\).\nMetropolis-Hastings para regresiÃ³n\nRepita el ejercicio AproximaciÃ³n de grilla en 2 dimensiones pero utilice Metropolis-Hastings para obtener muestras del posterior en vez del mÃ©todo de la grilla."
  },
  {
    "objectID": "practica/practica_03.html#diagnÃ³sticos",
    "href": "practica/practica_03.html#diagnÃ³sticos",
    "title": "PrÃ¡ctica - Unidad 3",
    "section": "DiagnÃ³sticos",
    "text": "DiagnÃ³sticos\nEl uso de algoritmos de MCMC provee de un gran poder que conlleva una gran responsabilidad. En los ejercicios de esta secciÃ³n ya se cuenta con un posterior y se busca evaluar la fiabilidad de las muestras utilizando diferentes medidas de diagnÃ³stico anÃ¡liticas y grÃ¡ficas.\n\nDescribir medidas de diagnÃ³stico (I)\nEn sus propias palabras, explique que son \\(\\text{ESS}\\), \\(\\hat{R}\\) y \\(\\text{MCSE}\\). Considere:\n\nÂ¿QuÃ© miden?\nÂ¿QuÃ© potencial problema de MCMC detectan? \n\nDescribir medidas de diagnÃ³stico (II)\nEn sus propias palabras, explique por quÃ© las tÃ©cnicas de estimaciÃ³n del posterior basadas en MCMC necesitan diagnÃ³sticos de convergencia. En particular, contraste estos con los mÃ©todos conjugados descritos en la Unidad 2 que no necesitan esos diagnÃ³sticos. Â¿QuÃ© es diferente entre los dos mÃ©todos de inferencia? \nProblemitas de MCMC\nPara cada escenario de simulaciÃ³n mediante MCMC descrito a continuaciÃ³n, explique cÃ³mo el escenario podrÃ­a afectar la aproximaciÃ³n del posterior.\n\nLa cadena se mezcla muy lentamente.\nLa cadena presenta alta auto-correlaciÃ³n.\nLa cadena tiende a quedarse â€œtrabadaâ€. \n\nVamos de paseo\nElabore traceplots que le permitan visualizar la traza de la cadena de Markov utilizada en el ejercicio Modelo Normal-Normal de la secciÃ³n Metropolis-Hastings.\nLuego, repita el ejercicio utilizando 4 cadenas independientes y grafique sus trazas en un mismo grÃ¡fico. Â¿QuÃ© puede concluir sobre la convergencia y la mezcla de las cadenas?\nPrimeros pasitos con \\(\\hat{R}\\)\nRepita lo realizado en el ejercicio Modelo Beta-Binomial de la secciÃ³n Metropolis-Hastings utilizando 4 cadenas independientes. Luego:\n\nCalcule la varianza intra-cadenas \\(W\\).\nCalcule la varianza entre-cadenas \\(B\\).\nCalcule \\(\\hat{R}\\) y concluya sobre el resultado obtenido.\n\n\n\\(\\hat{R}\\) para un muestreo independiente\nEn un determinado problema se encuentra que el posterior del parÃ¡metro \\(\\pi\\) de un modelo con verosimilitud binomial estÃ¡ dado por\n\\[\n\\pi | \\mathbf{y} \\sim \\text{Beta}(12, 6)\n\\]\n\nObtenga 4 conjuntos independientes de 1000 muestras independientes de esta distribuciÃ³n.\nCalcule \\(W\\), \\(B\\), y \\(\\hat{R}\\) considerando que cada conjunto representa una cadena.\nExplique el resultado de \\(\\hat{R}\\).\n\nBonus\n\nÂ¿Se puede concluir que cada uno de los muestreos realizados representan realizaciones de una cadena de Markov? Â¿Por quÃ©?\nÂ¿Por quÃ© no fue necesario descartar un conjunto de muestras de warm-up?\n\nFunciÃ³n de autocorrelaciÃ³n\nUtilice las 4 cadenas obtenidas en el ejercicio Primeros pasitos con \\(\\hat{R}\\) y grafique la funciÃ³n de autocorrelaciÃ³n y calcule el coeficiente de autocorrelaciÃ³n utilizando un rezago unitario. Concluya sobre la dependencia entre las muestras obtenidas.\nTamaÃ±o de muestra efectivo\nUtilice las muestras obtenidas en el ejercicio anterior para calcular el tamaÃ±o de muestra efectivo.\nExperimentos con el tamaÃ±o de muestra efectivo\nSuponga una distribuciÃ³n \\(\\text{Normal}(0, 1^2)\\). Obtenga \\(n\\) muestras independientes utilizando rnorm() y \\(n\\) muestras dependientes utilizando Metropolis-Hastings con \\(n \\in \\{10, 50, 100, 500, 1000, 10000\\}\\).\n\nCalcule el temaÃ±o de muestra efectivo en todos los escenarios simulados.\nDescriba el comportamiento del tamaÃ±o de muestra efectivo conforme se incrementa el nÃºmero de muestras.\nÂ¿Por quÃ© se observan los comportamientos descritos?\n\nÂ¡Rompan todo! Un caso simulado\nLos siguientes grÃ¡ficos muestran las trazas y las distribuciones que resultan al obtener muestras de un posterior utilizando dos cadenas de Markov independientes. Estos muestreos fueron realizados de manera que presenten algunos problemas. Describa cuales son los problemas que puede observar en los siguientes grÃ¡ficos y explique por quÃ© no utilizarÃ­a estas muestras para obtener conclusiones sobre el posterior.\n\n\n\n\n\n\n\n\nGrÃ¡fico 1\n\n\n\n\n\n\n\n\n\nGrÃ¡fico 2\n\n\n\n\n\n\n\n\n\nGrÃ¡fico 3\n\n\n\n\n\n\n\n\n\nGrÃ¡fico 4\n\n\n\n\nÂ¡Rompan todo! Un caso real\nAl igual que en el ejercicio anterior, se presentan traceplots donde el muestreo del posterior presenta problemas. En este caso, los grÃ¡ficos que se observan fueron obtenidos en el marco de un problema real, y se usan 4 cadenas en vez de 2. Nuevamente, describa cuales son los problemas que puede observar en los siguientes grÃ¡ficos y explique por quÃ© no utilizarÃ­a estas muestras para obtener conclusiones sobre el posterior.\n\n\n\n\n\nGrÃ¡fico 1\n\n\n\n\n\n\n\n\n\nGrÃ¡fico 2\n\n\n\n\nAdemÃ¡s, responda:\n\nÂ¿CuÃ¡l grÃ¡fico se asocia a un mayor tamaÃ±o de muestra efectivo?\nÂ¿QuÃ© grafico muestra peor mezcla entre cadenas?\nÂ¿En quÃ© grÃ¡fico se puede observar que las cadenas convergen a la misma distribuciÃ³n?"
  },
  {
    "objectID": "practica/practica_03.html#programaciÃ³n-probabilÃ­stica---stan-y-rstan",
    "href": "practica/practica_03.html#programaciÃ³n-probabilÃ­stica---stan-y-rstan",
    "title": "PrÃ¡ctica - Unidad 3",
    "section": "ProgramaciÃ³n probabilÃ­stica - Stan y RStan",
    "text": "ProgramaciÃ³n probabilÃ­stica - Stan y RStan\nEn esta secciÃ³n se comienza a utilizar Stan para realizar los cÃ¡lculos relacionados a la inferencia bayesiana. Stan es uno de los lenguajes de programaciÃ³n probabilÃ­stica mas potentes y populares en la actualidad. Los ejercicios contienen modelos estadÃ­sticos que deben ser resueltos con la interface de Stan a R, {RStan}.\n\nMCMC con RStan: Precalentamiento (I)\nUtilice la informaciÃ³n proporcionada para definir la estructura del modelo bayesiano utilizando {RStan}. No es necesario ejecutar nada, solo necesita proporcionar el cÃ³digo correcto.\n\n\\(Y | \\pi \\sim \\text{Binomial}(\\pi, 20)\\) con \\(\\pi \\sim \\text{Beta}(1, 1)\\).\n\\(Y | \\lambda \\sim \\text{Poisson}(\\lambda)\\) con \\(\\lambda \\sim \\text{Gamma}(4, 2)\\).\n\\(Y | \\mu \\sim \\text{Normal}(\\mu, 1^2)\\) con \\(\\mu \\sim \\text{Normal}(0, 10^2)\\). \n\nMCMC con RStan: Precalentamiento (II)\nUtilice la informaciÃ³n proporcionada para (1) definir la estructura del modelo bayesiano y (2) obtener muestras del posterior utilizando {RStan}. No es necesario ejecutar nada, solo necesita proporcionar el cÃ³digo correcto.\n\n\\(Y | \\pi \\sim \\text{Binomial}(\\pi, 20)\\) con \\(\\pi \\sim \\text{Beta}(1, 1)\\) e \\(y = 12\\).\n\\(Y | \\lambda \\sim \\text{Poisson}(\\lambda)\\) con \\(\\lambda \\sim \\text{Gamma}(4, 2)\\) e \\(y = 3\\).\n\\(Y | \\mu \\sim \\text{Normal}(\\mu, 1^2)\\) con \\(\\mu \\sim \\text{Normal}(0, 10^2)\\) e \\(y = 12.2\\). \n\nModelo Beta-Binomial con RStan (I)\nConsidere el modelo Beta-Binomial para \\(\\pi\\) con \\(Y | \\pi \\sim \\text{Binomial}(\\pi, n)\\) y \\(\\pi \\sim \\text{Beta}(3, 8)\\). Suponga que en \\(n = 10\\) ensayos independientes observa \\(y = 2\\) Ã©xitos.\n\nObtenga muestras del posterior de \\(\\pi\\) con {RStan} utilizando 3 cadenas y 12000 iteraciones por cadena.\nGrafique la traza de cada una de las tres cadenas.\nÂ¿CuÃ¡l es el rango de valores en el eje x del traceplot? Â¿Por quÃ© el valor mÃ¡ximo de este rango no es 12000?\nCree un grÃ¡fico que permita visualizar la funciÃ³n de densidad de los valores obtenidos con cada una de las tres cadenas.\nUtilizando lo estudiado en la Unidad 2, especifique el posterior de \\(\\pi\\). Â¿CÃ³mo se compara con la aproximaciÃ³n mediante MCMC?\n\nModelo Beta-Binomial con RStan (II)\nRepita el ejercicio anterior utilizando \\(\\pi \\sim \\text{Beta}(4, 3)\\), donde observa \\(y = 4\\) Ã©xitos en \\(n = 12\\) ensayos independientes.\nModelo Gamma-Poisson con RStan (I)\nConsidere el modelo Gamma-Poisson para \\(\\lambda\\) con \\(Y_i | \\lambda \\sim \\text{Poisson}(\\lambda)\\) y \\(\\lambda \\sim \\text{Gamma}(20, 5)\\). Suponga que cuenta con \\(n = 3\\) observaciones independientes \\((y_1, y_2, y_3) = (0, 1, 0)\\)\n\nObtenga muestras del posterior de \\(\\lambda\\) con {RStan} utilizando 4 cadenas y 10000 iteraciones por cadena.\nGrafique la traza y la funciÃ³n de densidad de cada una de las tres cadenas.\nA partir del grÃ¡fico de la funciÃ³n de densidad, Â¿cuÃ¡les suelen ser, a posteriori, los valores mÃ¡s probables de \\(\\lambda\\)?\nUtilizando lo estudiado en la Unidad 2, especifique el posterior de \\(\\lambda\\). Â¿CÃ³mo se compara con la aproximaciÃ³n mediante MCMC?\n\nModelo Gamma-Poisson con RStan (II)\nRepita el ejercicio anterior utilizando el prior \\(\\lambda \\sim \\text{Gamma}(5, 5)\\).\nModelo Normal-Normal con RStan (I)\nRepita los mismos pasos del ejercicio Modelo Gamma-Poisson con Rstan (I) pero considere el modelo Normal-Normal para \\(\\mu\\) con \\(Y_i | \\mu \\sim \\text{Normal}(\\mu, 1.3^2)\\) y \\(\\mu \\sim \\text{Normal}(10, 1.2^2)\\). Suponga que cuenta con \\(n = 4\\) observaciones independientes \\((y_1, y_2, y_3, y_4) = (7.1, 8.9, 8.4, 8.6)\\)\nModelo Normal-Normal con RStan (II)\nRepita el ejercicio anterior con el modelo Normal-Normal pero ahora considere \\(Y_i | \\mu \\sim \\text{Normal}(\\mu, 8^2)\\) y \\(\\mu \\sim \\text{Normal}(-15, 2^2)\\). Suponga que en \\(n = 5\\) observaciones independientes observa \\((y_1, y_2, y_3, y_4, y_5) = (âˆ’10.1, 5.5, 0.1,âˆ’1.4, 11.5)\\)\nUn modelo que es un poco Â¿complicado?\nConsidere el siguiente modelo\n\\[\n\\begin{aligned}\n\\text{mass}_i &\\sim \\text{Normal}(\\mu_i, \\sigma^2) \\\\\n\\mu_i         &= \\theta_1 + \\theta_2 + \\text{age}_i^{\\theta_3} \\\\\n\\theta_1      &\\sim \\text{Normal}(0, 100^2) \\\\\n\\theta_2      &\\sim \\text{Uniforme}(0, 20000) \\\\\n\\theta_3      &\\sim \\text{Normal}(0, 1) \\\\\n\\sigma^2      &\\sim \\text{InvGamma}(0.01, 0.01)\n\\end{aligned}\n\\]\ny los siguientes datos\n\nedad <- c(2, 15, 14, 16, 18, 22, 28)\npeso <- c(29.9, 1761, 1807, 2984, 3230, 5040, 5654)\nn <- length(edad)\ndata_list <- data.frame(peso = peso, edad = edad, n = n)\n\n\nAjuste el modelo utilizando {RStan}.\nObtenga una visualizaciÃ³n de la edad versus el peso junto con una curva que indique la media a posteriori de \\(\\mu_i\\) para evaluar si el modelo ajusta bien.\nEstudie la convergencia de las cadenas de Markov.\nMencione tres medidas que podrÃ­a tomar para mejorar la convergencia."
  },
  {
    "objectID": "practica/practica_03.html#otros",
    "href": "practica/practica_03.html#otros",
    "title": "PrÃ¡ctica - Unidad 3",
    "section": "Otros",
    "text": "Otros\n\nUna compaÃ±Ã­a pesquera de Comodoro Rivadavia se encuentra probando un nuevo mÃ©todo para estimar el peso de los peces que extrae del Mar Argentino. El objetivo de este mÃ©todo es obtener una estimaciÃ³n lo suficientemente buena del peso de cada pescado sin tener que pesarlos uno por uno, ya que es un proceso costoso en tiempo y labor. Para eso, seleccionaron una muestra de pescados, los pesaron y les midieron ciertos aspectos morfolÃ³gicos (ancho, alto y largo). En el futuro, esperan recolectar estas mismas medidas morfolÃ³gicas mediante una cÃ¡mara especializada y utilizar un modelo para estimar el peso.\nEl modelo propuesto por el equipo de investigaciÃ³n es el siguiente:\n\\[\n\\begin{aligned}\n\\log(\\text{Peso}_i) &\\sim \\text{Normal}(\\mu, \\sigma) \\\\\n\\mu_i               &= \\beta_0 + \\beta_1 \\log(\\text{Largo}_i) \\\\\n\\sigma              &\\sim \\text{Gamma}(k, \\theta)\n\\end{aligned}\n\\]\nEl peso se encuentra medido en gramos y la longitud en centÃ­metros. El equipo provee las muestras que obtuvieron del posterior. Las mismas se pueden leer en R utilizando el siguiente bloque de cÃ³digo.\n\nurl <- paste0(\n    \"https://raw.githubusercontent.com/estadisticaunr/\",\n    \"estadistica-bayesiana/main/datos/fish-market-posterior.csv\"\n)\ndf_posterior <- readr::read_csv(url)\nhead(df_posterior)\n\n# A tibble: 6 Ã— 3\n  intercepto pendiente sigma\n       <dbl>     <dbl> <dbl>\n1      -4.44      3.08 0.408\n2      -4.30      3.05 0.431\n3      -4.49      3.12 0.433\n4      -4.04      2.96 0.341\n5      -4.76      3.18 0.413\n6      -4.65      3.15 0.350\n\nAnalice de manera grÃ¡fica y analÃ­tica los posteriors marginales de los parÃ¡metros del modelo. Realice las transformaciones de parÃ¡metros que crea conveniente para facilitar la comprensiÃ³n del anÃ¡lisis.\nConsidere un pescado cuya longitud es de 30 centÃ­metros.\n\nObtenga y grafique la distribuciÃ³n a posteriori del peso medio.\nObtenga y grafique la distribuciÃ³n predictiva a posteriori del peso.\nInterprete los resultados.\n\nGrafique la curva de regresiÃ³n junto a una banda de credibilidad del 95% en el plano de las variables originales y en el plano de las variables transformadas.\nAgregue a los grÃ¡ficos anteriores una banda de credibilidad del 95% para la distribuciÃ³n predictiva a posteriori. Interprete los resultados."
  },
  {
    "objectID": "practica/practica_01.html",
    "href": "practica/practica_01.html",
    "title": "PrÃ¡ctica - Unidad 1",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "practica/practica_01.html#regla-de-bayes",
    "href": "practica/practica_01.html#regla-de-bayes",
    "title": "PrÃ¡ctica - Unidad 1",
    "section": "Regla de Bayes",
    "text": "Regla de Bayes\nEl propÃ³sito de esta secciÃ³n de la prÃ¡ctica es resolver situaciones que impliquen la aplicaciÃ³n de la Regla de Bayes como se presenta tradicionalmente en un curso de Probabilidad.\n\nDemostraciÃ³n\nDemuestra la validez de la siguiente expresiÃ³n de la Regla de Bayes\n\\[\nP(B_j | A) = \\frac{P(A | B_j) P(B_j)}{\\sum_{k=1}^{K}P(A | B_k) P(B_k)}\n\\]\ndonde \\(A\\) es un evento cualquiera y \\(\\{B_1, \\cdots, B_K\\}\\) forman una particiÃ³n. \n\n\n\n\n\n\nEl test infalible\nEn una poblaciÃ³n dada, una de cada mil personas tiene una enfermedad. Se toma una persona al azar de la poblaciÃ³n, se le aplica un test para detectar dicha enfermedad, y el resultado es positivo. El test se caracteriza por dar positivo el 99% de las veces que una persona tiene la enfermedad. AdemÃ¡s, dicho test tiene una tasa de falsos positivos del 5%.\n\nÂ¿CuÃ¡l es la probabilidad de que la persona tenga efectivamente la enfermedad?\nSi realizamos el mismo anÃ¡lisis una segunda vez sobre el mismo paciente y obtenemos nuevamente positivo,\n\nÂ¿CuÃ¡l seria la probabilidad que el paciente estÃ© enfermo?\nÂ¿Y si diera negativo?\nÂ¿Es el prior el mismo cuando se analiza el resultado del segundo anÃ¡lisis que cuando solo se analiza el primero? \n\n\nÂ¿Es verdad que existen los vampiros? VersiÃ³n CrepÃºsculo\nEdward quiere probarle a Bella que los vampiros existen. SegÃºn Bella, hay una probabilidad del 5% de que los vampiros existan. TambiÃ©n cree que la probabilidad de que exista alguien con la piel brillante dado que los vampiros existen es del 70%, y que la probabilidad de que alguien tenga la piel brillante si los vampiros no existen es del 3%. Edward lleva a Bella al bosque y le muestra que de hecho su piel brilla como un ğŸ’ Â¿CuÃ¡l es la probabilidad que existan los vampiros? \n\n\n\n\n\nRobert Pattinson como Edward en CrepÃºsculo\n\n\n\n\nÃrboles enfermos\nUn vivero de la ciudad se destaca por vender una variedad de Ã¡rboles nativos, incluyendo al jacarandÃ¡, ceibo, ombÃº, entre otros. Lamentablemente, el 18% de los Ã¡rboles del vivero estan infectados con moho. Los Ã¡rboles enfermos se componen en un 15% por jacarandÃ¡s, 80% de ceibos, y 5% de otras especies. Los Ã¡rboles sanos se componen por un 20% de jacarandÃ¡s, 10% de ceibos, y 70% de otras especies. Con el objetivo de monitorear cuanto se propagÃ³ la enfermedad, una de las personas que trabaja en el vivero selecciona al azar uno de los Ã¡rboles para testear.\n\nÂ¿CuÃ¡l es la probabilidad a priori de que el Ã¡rbol tenga moho?\nResulta que el Ã¡rbol seleccionado es un ceibo. Â¿CuÃ¡l es la probabilidad de haber seleccionado un ceibo?\nÂ¿CuÃ¡l es la probabilidad a posteriori de que el ceibo seleccionado tenga moho?\nCompare las probabilidades a priori y a posteriori de que el Ã¡rbol tenga moho. Â¿CÃ³mo afecta el anÃ¡lisis el saber que el Ã¡rbol es un ceibo? \n\n\n\n\n\n\nFlor del Ceibo, la flor nacional\n\n\n\n\nTransporte â€œEl Impuntualâ€\nUna cierta empresa de transporte regional, que decidimos llamar â€œEl Impuntualâ€, tiene servicios que van desde Rosario hasta Wheelwright varias veces al dÃ­a, todos los dÃ­as de la semana. Un 30% de los viajes salen a la maÃ±ana, otro 30% salen a la tarde, y el restante 40% salen a la noche. Los pasajeros suelen estar muy frustrados ya que un 25% de los viajes salen tarde. De estos viajes demorados, el 40% corresponden a la maÃ±ana, un 50% suceden a la tarde, y el 10% restante ocurre a la noche1.\nLucio y Franco son dos amigos del pueblo, y se volvieron a sus casas en colectivos diferentes.\n\nLucio se fue en uno de los colectivos de la maÃ±ana. Â¿CuÃ¡l es la probabilidad que su viaje estÃ© demorado?\nEl colectivo de Franco no estÃ¡ demorado. Â¿CuÃ¡l es la probabilidad de que estÃ© viajando en uno de los colectivos de la maÃ±ana? \n\n\n\n\n\n\nFoto de Markus Winkler en Unsplash\n\n\n\n\nBebÃ© panda\nSupongamos que hay dos especies de osos panda. Ambas especies son igual de frecuentes y viven en la misma regiÃ³n. Es mÃ¡s, lucen de la misma forma y comen la misma comida. AÃºn no existe una prueba genÃ©tica que pueda diferenciarlos. Lo Ãºnico que los diferencia es la cantidad de crÃ­as que suelen tener. Las madres de la especie A dan luz a mellizos el 10% del tiempo. Y las madres de la especie B dan a luz mellizos el 20% del tiempo. En todos los otros casos, estas madres dan a luz un solo bebÃ© panda.\nUsando un poco la imaginaciÃ³n, supongamos que somos la persona encargada de un programa de reproducciÃ³n de pandas. Tenemos una panda femenina que acaba de dar a luz a un par de mellizos, pero no sabemos a que especie pertenece.\n\nÂ¿CuÃ¡l es la probabilidad que la mamÃ¡ panda sea de la especie A?\nÂ¿CuÃ¡l es la probabilidad que vuelva a tener mellizos en la prÃ³xima pariciÃ³n?\nUn tiempo despuÃ©s sos encontramos con que en la segunda pariciÃ³n da a luz a un Ãºnico bebÃ© panda. Â¿CuÃ¡l es la probabilidad de que este panda sea de la especie A? \n\n\n\n\n\n\nFoto de Stone Wang en Unsplash\n\n\n\n\nParaguas\nEstÃ¡s a punto de subir a un aviÃ³n rumbo a Mendoza. QuerÃ©s saber si tenÃ©s que llevar un paraguas o no. LlamÃ¡s a tres amigos que viven en Mendoza y les preguntÃ¡s si estÃ¡ lloviendo. Cada uno de ellos tiene una probabilidad de \\(2/3\\) de decirte la verdad y \\(1/3\\) de mentirte para hacerte una broma. Los tres responden que sÃ­ estÃ¡ lloviendo. Â¿CuÃ¡l es la probabilidad de que realmente estÃ© lloviendo en las Mendoza? Se puede asumir que en Mendoza llueve en 1 de cada 10 dÃ­as. \nSherlock\nDos personas dejaron rastros de sangre en la escena del crimen. La sangre de Guido, un sospechoso, es analizada y resulta ser de tipo â€˜0â€™. Los rastros de sangre de la escena son de tipo â€˜0â€™ (un tipo comÃºn en la poblaciÃ³n, presente en el 60% de las personas) y de tipo â€˜ABâ€™ (un tipo raro, con una frecuencia del 1% en la poblaciÃ³n). Â¿Estos datos representan evidencia de que Guido estaba presente en la escena del crimen? \n\n\n\n\n\nSherlock Holmes, el detective privado\n\n\n\n\nHijos de la probabilidad\nNos encontramos con alguien en la calle y nos dice que tiene dos hijos. Le preguntamos si alguno de ellos es mujer y nos responde que sÃ­. Â¿CuÃ¡l es la probabilidad de que ambos sean niÃ±as? \nLos Reyes del Rock\nElvis Presley tenÃ­a un hermano varÃ³n que naciÃ³ en el mismo parto pero que muriÃ³ al poco tiempo. Â¿CuÃ¡l es la probabilidad de que Elvis tuviera un gemelo? Alguna informaciÃ³n adicional: en 1935, cuando Elvis naciÃ³, 1/3 de los hermanos del mismo parto eran gemelos y 2/3 mellizos; ademÃ¡s, la probabilidad de que dos mellizos sean del mismo sexo biolÃ³gico puede estimarse en 50%, mientras que dos gemelos son siempre del mismo sexo biolÃ³gico. \nÂ¿Alguien ordena las medias?\nDos cajones contienen medias. Uno de ellos tiene igual cantidad de medias blancas y negras. El otro contiene un nÃºmero igual de medias rojas, verdes y azules. Se elige un cajÃ³n al azar, se sacan dos medias sin mirar y resultan ser las dos iguales. Â¿CuÃ¡l es la probabilidad de que las medias sean blancas? SupÃ³ngase que sacar la primera media no altera las proporciones. \nLa Falacia del Fiscal\nSally Clark era una abogada britÃ¡nica que fue errÃ³neamente sentenciada a prisiÃ³n perpetua en 1999 por la muerte de sus dos hijos bebÃ©s. Su hijo mayor, Christopher, muriÃ³ con 11 semanas en diciembre de 1996 y su hijo mÃ¡s joven, Harry, con 8 semanas en enero de 1998. Durante el juicio, la defensa argumentÃ³ que las muertes se debieron al sÃ­ndrome de muerte sÃºbita del lactante (SIDS). Clark fue condenada a partir del testimonio del pediatra Sir Roy Meadow, quien argumentÃ³ en la corte lo siguiente:\n\nEn familias sanas, la chance de muerte por SIDS es de \\(\\frac{1}{8500}\\)\nLa probabilidad de dos muertes por SIDS en la misma familia es aproximadamente \\(\\frac{1}{8500^2} \\approx \\frac{1}{73000000}\\)\nEs, por ende, muy poco probable que Clark sea inocente\n\nLuego de pasar 3 aÃ±os en prisiÃ³n, Clark fue liberada en 2003 luego de que se determinara que el testimonio experto de Meadows era equivocado. Dos mujeres, a las cuales el testimonio de Meadows habÃ­a enviado a prisiÃ³n, tambiÃ©n fueron liberadas.\n\nIdentifica una falla en la probabilidad de \\(\\frac{1}{73000000}\\) dada por Meadows.\nIncluso aceptando el nÃºmero anterior como correcto, Â¿cuÃ¡l es el problema de interpretar esa probabilidad como la probabilidad de inocencia de Clark?"
  },
  {
    "objectID": "practica/practica_01.html#inferencia-bayesiana",
    "href": "practica/practica_01.html#inferencia-bayesiana",
    "title": "PrÃ¡ctica - Unidad 1",
    "section": "Inferencia Bayesiana",
    "text": "Inferencia Bayesiana\nEn esta parte de la prÃ¡ctica, se le otorga un significado a las cantidades que aparecen en la Regla de Bayes modificando conceptualmente el enfoque de las situaciones problemÃ¡ticas. Ahora los problemas se tratan de realizar inferencias sobre posibles causas de ciertos datos observados. Se incrementa el rigor matemÃ¡tico, aparecen distribuciones de probabilidad y la necesidad de dejar ciertos cÃ¡lculos en manos de la computadora.\n\nEl lenguaje de las probabilidades\nEscribir la expresiÃ³n matemÃ¡tica para cada una de las siguientes descripciones verbales:\n\nProbabilidad de un parÃ¡metro dados los datos observados.\nLa distribuciÃ³n de probabilidad de los parÃ¡metros antes de ver los datos.\nLa verosimilitud de los datos para un valor dado de los parÃ¡metros.\nLa probabilidad de una observaciÃ³n nueva luego de observar los datos.\nLa probabilidad de una observaciÃ³n antes de ver los datos. \n\nQuÃ© datazo me tiraste, rey\nLos M&Ms azul fueron introducidos en el aÃ±o 1995 (antes habÃ­a dos tipos de marrÃ³n)\n\nAntes de 1995, la mezcla de colores en una bolsa de M&Ms era: 30% marron, 20% amarillo, 20% rojo, 10% verde, 10% naranja y 10% marrÃ³n bronceado.\nLuego de 1995, la mezcla pasÃ³ a ser: 24% azul, 20% verde, 16% naranja, 14% amarillo, 13% rojo y 13% marrÃ³n.\n\nUn amigo tiene dos bolsas de M&M y nos dice que una bolsa es de 1994 y la otra es de 1996, pero no nos dice cuÃ¡l es cuÃ¡l. Nos da un M&M de cada bolsa: uno es amarillo y el otro es verde (ambos posiblemente estÃ©n vencidos). Â¿CuÃ¡l es la probabilidad de que el amarillo venga de la bolsa de 1994?\nLa Gran Estafa\nHay dos monedas en una caja. Una de ellas es una moneda comÃºn y la otra es una moneda que tiene dos caras.\n\nSe elige una moneda al azar, se arroja, y se obtiene cara. Â¿CuÃ¡l es la probabilidad de que la moneda elegida sea la falsa?\nSe elige una moneda al azar y se arroja al aire tres veces, obteniÃ©ndose tres caras. Â¿CuÃ¡l es la probabilidad de que la moneda elegida sea la falsa?\n\nVocabulario limitado\nSupongamos que existe un idioma con seis palabras:\n\\[\n\\text{\\{perro, parra, farra, carro, corro, tarro\\}}\n\\]\nUn anÃ¡lisis lingÃ¼Ã­stico exhaustivo de esta lengua ha descubierto que todas las palabras son igualmente probables, excepto por â€˜perroâ€™, que es \\(\\alpha\\) veces mÃ¡s probable que las otras.\nAdemÃ¡s:\n\nCuando se tipean, un caracter se introduce errÃ³neamente con probabilidad \\(\\theta\\).\nTodas las letras tienen la misma probabilidad de producir un error de tipeo.\nSi una letra se tipeÃ³ mal, la probabilidad de cometer un error en otro caracter no cambia.\nLos errores son independientes a lo largo de una palabras.\n\n\nÂ¿CuÃ¡l es la probabilidad de escribir correctamente â€˜tarroâ€™?\nÂ¿CuÃ¡l es la probabilidad de tipear â€˜cerroâ€™ o â€˜curroâ€™ al querer escribir â€˜carroâ€™?\nUtilizando la Regla de Bayes, desarrollar un corrector gramatical para esta lengua. Para las palabras tipeadas â€˜farraâ€™, â€˜birraâ€™ y â€˜locosâ€™, hallar la probabilidad de que cada palabra del diccionario sea la palabra que se habÃ­a querido escribir. Utilizar las siguientes combinaciones de parÃ¡metros:\n\n\\(\\alpha = 2\\) y \\(\\theta = 0.1\\)\n\\(\\alpha = 50\\) y \\(\\theta = 0.1\\)\n\\(\\alpha = 2\\) y \\(\\theta = 0.9\\)\n\n\nQue el Ã¡rbol no tape el bosque\nSea \\(X_1 \\sim \\text{Bernoulli}(\\theta)\\) una variable que indica si una especie de Ã¡rboles se halla en un determinado bosque y \\(\\theta \\in [0, 1]\\) representa la probabilidad a priori de que la especie se encuentre en el bosque. Una investigadora selecciona una muestra de \\(n\\) Ã¡rboles del bosque y encuentra que \\(X_2\\) de ellas pertenecen a la especie de interÃ©s.\nEl modelo luego es\n\\[\n\\begin{array}{lc}\nX_2|X_1 \\sim \\text{Binomial}(\\lambda X_1, n) & \\text{con} \\ \\lambda \\in [0, 1]\n\\end{array}\n\\]\n\\(\\lambda\\) representa la probabilidad de detectar la especie, dado que la especie se encuentra en el bosque.\nEncuntre expresiones matemÃ¡ticas en tÃ©rmino de \\(n\\), \\(\\theta\\) y \\(\\lambda\\) para las siguientes probabilidades:\n\n\\(P(X_1 = 0, X_2 = 0)\\).\n\\(P(X_1 = 0)\\).\n\\(P(X_2 = 0)\\).\n\\(P(X_1 = 0 | X_2 = 0)\\).\n\\(P(X_2 = 0 | X_1 = 0)\\).\n\\(P(X_1 = 0 | X_2 = 1)\\).\n\\(P(X_2 = 0 | X_1 = 1)\\).\nExplique de manera intuitiva cÃ³mo es que las probabilidades calculadas en (iv)-(vii) cambian segÃºn \\(n\\), \\(\\theta\\) y \\(\\lambda\\).\nAsuma \\(\\theta=0.5\\), \\(\\lambda=0.1\\) y \\(X_2 = 0\\) Â¿CuÃ¡n grande debe ser \\(n\\) para que se puede concluir con 95% de confianza que la especie no se encuentra en el bosque? \n\n\n\n\n\n\nFoto de Sergei A en Unsplash\n\n\n\n\nÂ¡Ostras! Â¡Estoy haciendo inferencia bayesiana!\nEn un estudio que utiliza mÃ©todos de la EstadÃ­stica Bayesiana para predecir el nÃºmero de especies que serÃ¡n descubiertas en el futuro se reporta que la cantidad de especies marinas bivalvas2 descubiertas cada aÃ±o entre 2010 y 2015 fue 64, 13, 33, 18, 30 y 20.\nSi se representa con \\(Y_t\\) a la cantidad de especies descubierta en el aÃ±o \\(t\\), y asumiendo:\n\\[\n\\begin{aligned}\nY_t | \\lambda &\\underset{iid}{\\sim} \\text{Poisson}(\\lambda) \\\\\n\\lambda       &\\sim \\text{Uniforme}(0, 100)\n\\end{aligned}\n\\]\nGraficar la distribuciÃ³n a posteriori de \\(\\lambda\\). \nEs negocioâ€¦\nSea \\(n\\) la cantidad desconocida de clientes que visitan una tienda en un dia cualquiera. El nÃºmero de clientes que realizan una compra es \\(Y\\) y se cumple que\n\\[\nY | \\theta, n \\sim \\text{Binomial}(\\theta, n)\n\\]\ndonde \\(\\theta\\) es la probabilidad de compra, dado que se produce la visita a la tienda. La distribuciÃ³n a priori de \\(n\\) es \\(n \\sim \\text{Poisson}(5)\\). Bajo el supuesto que \\(\\theta\\) es conocido y que \\(n\\) es desconocido, graficar la distribuciÃ³n a posteriori de \\(n\\) para todas las combinaciones de \\(Y \\in \\{0, 5, 10 \\}\\) y \\(\\theta \\in \\{0.2, 0.5\\}\\). Explique cual es del efecto de cambiar \\(Y\\) y \\(\\theta\\) sobre la distribuciÃ³n a posteriori.  \nCon amigos asÃ­, quiÃ©n necesita enemigos\nUn amigo arroja un dado y anota en secreto el nÃºmero que sale (llamÃ©moslo \\(T\\)). A continuaciÃ³n, nosotros, con los ojos vendados, arrojamos el dado varias veces. No podemos ver el nÃºmero que sale pero nuestro amigo nos dice si el nÃºmero que sacamos es mayor, menor o igual a \\(T\\).\nSupongamos que nos da la secuencia: \\(G,\\ G,\\ C,\\ I,\\ C,\\ C,\\ C, I,\\ G,\\ C\\) (siendo \\(G\\) mÃ¡s grande, \\(C\\) mÃ¡s chico e \\(I\\) igual). Â¿CuÃ¡l es la distribuciÃ³n a posteriori de los valores de \\(T\\)? \nOrden en la sala\nEn las Jornadas Rosarinas de Ciencia de Datos, una expositora estÃ¡ dando una charla en un salÃ³n cuando el personal de seguridad la interrumpe porque cree que puede haber mÃ¡s de 1000 personas en la sala, superando el mÃ¡ximo permitido.\nLa expositora piensa que hay menos de 1000 personas y se ofrece a demostrarlo, aunque piensa que contarlas podrÃ­a llevar mucho tiempo. Decide hacer un experimento:\n\nPregunta cuÃ¡ntas personas nacieron el 11 de mayo. Dos personas levantan la mano.\nPregunta cuÃ¡ntas personas nacieron el 23 de mayo. Una persona levanta la mano.\nPregunta cuÃ¡ntas personas nacieron el 1 de agosto. Nadie levanta la mano.\n\nÂ¿CuÃ¡ntas personas hay en la sala? O, mejor dicho, Â¿cuÃ¡l es la probabilidad de que haya mÃ¡s de 1000 personas en la sala? \nHouse of Cards\nHay 538 miembros en el Congreso de Estados Unidos. Supongamos que se auditan sus inversiones y se encuentra que 312 de ellos obtuvieron rendimientos por encima del mercado. Asumamos que un miembro honesto del Congreso tiene solo una probabilidad del 50% de tener rendimientos por encima del mercado, pero uno deshonesto que opera con informaciÃ³n confidencial tiene una chance del 90% de hacerlo. Â¿CuÃ¡ntos miembros del Congreso son honestos? \n\n\n\n\n\nRobin Wright y Kevin Spacey, protagonistas de House of Cards\n\n\n\n\nPuede fallarâ€¦\nCansada de los experimentos de arrojar una moneda cientos de veces al aire, una estudiante diseÃ±a un sistema de reconocimiento de imÃ¡genes que determina si saliÃ³ cara o ceca y registra el resultado.\nLÃ³gicamente, el sistema diseÃ±ado no es perfecto sino que presenta una tasa de error. En particular, la probabilidad de que clasificar mal es de 0.2 (20% de las veces que sale cara, el sistema dice ceca, y viceversa).\nSe arroja la moneda 250 veces y el sistema detecta 140 caras,\n\nÂ¿CuÃ¡l es la distribuciÃ³n a posteriori de \\(\\theta\\), la probabilidad de obtener cara?\nÂ¿QuÃ© ocurre a medida que la probabilidad de clasificar mal varÃ­a? \n\nÂ¡Saludos a los cubos con puntos! (â€¦) SerÃ¡n dados\nDos dados de seis caras son arrojados. Se sabe que la suma de los dos puntajes obtenidos es 9. Â¿CuÃ¡l es la distribuciÃ³n a posteriori de los puntajes de los dados?"
  },
  {
    "objectID": "practica/practica_01.html#conceptuales",
    "href": "practica/practica_01.html#conceptuales",
    "title": "PrÃ¡ctica - Unidad 1",
    "section": "Conceptuales",
    "text": "Conceptuales\nEn esta secciÃ³n, se nos invita a pensar sobre las caracterÃ­sticas de la EstadÃ­stica Bayesiana. En lugar de encontrar una respuesta Ãºnica mediante cÃ¡lculos matemÃ¡ticos, se necesita comprender en profundidad tanto el enfoque frecuentista como el bayesiano para interpretar estas visiones en diferentes escenarios.\n\nVoy a conseguir esa pasantÃ­a\nLa empresa de tecnologÃ­a en la que todo el mundo quiere trabajar tiene varias vacantes para pasantes en ciencia de datos. Luego de leer la descripciÃ³n de la bÃºsqueda, te das cuenta que sos una persona calificada para el puesto: estos son tus datos. Tu objetivo es averiguar si te van a ofrecer el puesto: esta es tu hipÃ³tesis.\n\nDesde la perspectiva de una persona con un razonamiento frecuentista, Â¿QuÃ© es lo que se responde al evaluar la hipÃ³tesis de que te ofrecen el puesto?\nRepita el punto anterior considerando la perspectiva de una persona con un razonamiento Bayesiano.\nÂ¿QuÃ© pregunta tiene mÃ¡s sentido responder: la frecuentista o la Bayesiana? Justifica tu respuesta. \n\nBeneficios de la EstadÃ­stica Bayesiana\nUna amiga te cuenta que estÃ¡ interesada en aprender mÃ¡s sobre EstadÃ­stica Bayesiana. ExplÃ­cale lo siguiente:\n\nÂ¿Por quÃ© es Ãºtil el enfoque Bayesiano?\nÂ¿CuÃ¡les son las similitudes entre el enfoque frecuentista y el Bayesiano?"
  },
  {
    "objectID": "practica/practica_02.html",
    "href": "practica/practica_02.html",
    "title": "PrÃ¡ctica - Unidad 2",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "practica/practica_02.html#modelos-de-distribuciones-conjugadas",
    "href": "practica/practica_02.html#modelos-de-distribuciones-conjugadas",
    "title": "PrÃ¡ctica - Unidad 2",
    "section": "Modelos de Distribuciones Conjugadas",
    "text": "Modelos de Distribuciones Conjugadas\nEsta secciÃ³n contiene ejercicios para trabajar con modelos basados en distribuciones conjugadas. En general, los ejercicios requieren cÃ¡lculos o derivaciones que se pueden realizar a mano. Sin embargo, se promueve fuertemente el uso de la computadora y el lenguaje R para verificar los resultados, mostrar soluciones alternativas y ejercitar el uso de una herramienta que serÃ¡ de suma utilidad a lo largo de todo el curso y de la vida profesional.\n\nÂ¿QuiÃ©n domina el posterior?\nPara cada una de las situaciones siguientes, se da una distribuciÃ³n a priori Beta para el parÃ¡metro \\(\\pi\\) de un ensayo binomial. Para cada escenario, identificar cuÃ¡l de estos se cumple: el prior tiene mayor influencia en el posterior, los datos tienen mÃ¡s influencia en el posteriori, o la creencia a priori y los datos influyen de manera similar en la creencia a posteriori\n\nPrior: \\(\\pi \\sim \\text{Beta}(1,4)\\), observaciones: \\(y=8\\) Ã©xitos en \\(n=10\\) ensayos.\nPrior: \\(\\pi \\sim \\text{Beta}(20,3)\\), observaciones: \\(y=0\\) Ã©xitos en \\(n=1\\) ensayos.\nPrior: \\(\\pi \\sim \\text{Beta}(4,2)\\), observaciones: \\(y=1\\) Ã©xitos en \\(n=3\\) ensayos.\nPrior: \\(\\pi \\sim \\text{Beta}(3,10)\\), observaciones: \\(y=10\\) Ã©xitos en \\(n=13\\) ensayos.\nPrior: \\(\\pi \\sim \\text{Beta}(20,2)\\), observaciones: \\(y=10\\) Ã©xitos en \\(n=200\\) ensayos.\n\nMÃ¡s o menos certeza\nSea \\(\\theta\\) la proporciÃ³n de personas que prefieren los perros a los gatos. Suponga que se elige una distribuciÃ³n \\(\\text{Beta}(7,2)\\) para representar la creencia a priori\n\nDe acuerdo al prior Â¿cuÃ¡les son valores razonables para \\(\\theta\\)?\nSe observa en una encuesta que \\(y=19\\) de \\(n=20\\) personas prefieren perros, Â¿cÃ³mo cambia eso el conocimiento acerca de \\(\\theta\\)? Comenta en tÃ©rminos de la evoluciÃ³n de la credibilidad media y del grado de certidumbre acerca de \\(\\theta\\).\nSi, en lugar de eso, se determina que \\(y=1\\) de \\(n=20\\) personas prefieren perros, Â¿cÃ³mo cambia ahora el grado de credibilidad de los diferentes valores de \\(\\theta\\)?\nSi, en lugar de eso, se determina que \\(y=10\\) de \\(n=20\\) personas prefieren perros, Â¿cÃ³mo cambia ahora el grado de credibilidad de los diferentes valores de \\(\\theta\\)?\n\nPasito a pasito\nSea \\(\\theta\\) la probabilidad de Ã©xito de un evento de interÃ©s. Sea \\(\\text{Beta}(2,3)\\) la distribuciÃ³n a priori para \\(\\theta\\). Actualiza la distribuciÃ³n a posteriori para \\(\\theta\\) secuencialmente:\n\nPrimera observaciÃ³n: Ã©xito.\nSegunda observaciÃ³n: Ã©xito.\nTercera observaciÃ³n: fracaso.\nCuarta observaciÃ³n: Ã©xito.\n\nPasitos tras pasitos\nSea \\(\\theta\\) la probabilidad de Ã©xito de un evento de interÃ©s. Sea \\(\\text{Beta}(2,3)\\) la distribuciÃ³n a priori para \\(\\theta\\). Actualiza la distribuciÃ³n a posteriori para \\(\\theta\\) secuencialmente dados conjuntos de cinco observaciones:\n\nPrimeras observaciones: tres Ã©xitos.\nSegundas observaciones: un Ã©xito.\nTerceras observaciones: un Ã©xito.\nCuartas observaciÃ³nes: dos Ã©xitos.\n\nDiferentes observaciones, diferentes posteriors\nUna empresa que fabrica zapatillas estÃ¡ diseÃ±ando una publicidad para Instagram. Tres empleados comparten que la creencia a priori para \\(\\pi\\), la probabilidad de que un cliente haga clic en el anuncio cuando lo ve, puede expresarse con una distribuciÃ³n \\(\\text{Beta}(4, 3)\\). No obstante, los tres empleados realizan tres experimentos distintos y por ende tienen acceso a datos diferentes. El primer empleado prueba el anuncio en una persona, que no cliquea el anuncio. El segundo lo prueba en 10 personas, de las cuales 3 cliquean el anuncio. El Ãºltimo lo prueba en 100 personas, 20 de las cuales cliquean el anuncio.\n\nDescriba el entendimiento a priori que los empleados tienen sobre \\(\\pi\\).\nEspecifique la distribuciÃ³n a posteriori de cada uno de los empleados.\nCompare las distribuciones a posteriori de cada empleado.\n\nÂ¿Galletitas o masitas?\nLa UNR reÃºne cada aÃ±o a estudiantes provenientes de diferentes localidades. CuÃ¡ntas cuadras constituyen una distancia â€œcaminableâ€ suele ser motivo de discusiÃ³n, entre otros. Pero la verdadera grieta estÃ¡ entre la denominaciÃ³n galletitas versus masitas. Un rosarino pone un prior \\(\\text{Beta}(20,2)\\) a la proporciÃ³n de personas que dicen galletitas, mientras que un oriundo de una localidad del interior dirÃ¡ que la credibilidad a priori es \\(\\text{Beta}(2,8)\\).\n\nResuma ambas distribuciones a priori y explique con sus palabras lo que implican.\nCon la informaciÃ³n de sus compaÃ±eros de curso, actualice ambas distribuciones a priori. Â¿Es suficiente esa informaciÃ³n para acercar ambas posturas?\n\nMi primera huerta\nEn un campamento de verano para infantes se realizaron actividades que promueven el contacto con la naturaleza. Una de las tareas consistiÃ³ en germinar semillas de tomate. Josefina plantÃ³ 18 semillas en su almaciguera. Al cabo de 5 dÃ­as, 8 de ellas germinaron. Sea \\(\\theta\\) la probabilidad de que una semilla de tomate germine y sea \\(\\text{Beta}(1, 1)\\) su distribuciÃ³n a priori.\n\nÂ¿QuÃ© informaciÃ³n implica el prior sobre la probabilidad de germinaciÃ³n?\nCalcule la media y el desvÃ­o estÃ¡ndar a posteriori de \\(\\theta\\) a mano.\nVerifique el cÃ¡lculo utilizando R.\nObtenga un intervalo de credibilidad del 95% para \\(\\theta\\).\n\n\n\n\n\n\nFoto de Markus Spiske en Unsplash\n\n\n\n\nÂ¿QuiÃ©n dijo que el fÃºtbol siempre da revancha?\nEn la final del 2018 de la Copa del Mundo de la FIFA, Francia le ganÃ³ a Croacia por 4 a 2. Considere que el nÃºmero de goles que un equipo hace en un partido puede modelizarse con una distribuciÃ³n de Poisson. Suponga un parÃ¡metro \\(\\lambda_F\\) para Francia y uno \\(\\lambda_C\\) para Croacia. Elija una distribuciÃ³n Gamma a priori para el nÃºmero medio de goles por partido (es decir, \\(\\lambda_F\\) y \\(\\lambda_C\\) compartirÃ¡n la distribuciÃ³n a priori). \\(\\lambda_F\\) da una idea de la capacidad de Francia de hacer goles (\\(\\lambda_C\\) lo mismo, pero para Croacia).\nEn funciÃ³n del resultado del partido, obtenga las distribuciones a posteriori de \\(\\lambda_F\\) y \\(\\lambda_C\\) y responda utilizando R:\n\nÂ¿QuÃ© probabilidad hay de que Francia fuera un mejor equipo que Croacia?\nSi el mismo partido se jugara de nuevo (cosa que los franceses en aquella oportunidad no pidieron), Â¿cuÃ¡l es la probabilidad de que Francia ganara de nuevo? \n\nMirÃ¡ si me va a pasar a miâ€¦\nDurante el desarrollo de las vacunas contra el COVID-19, un medio anunciÃ³ para una determinada vacuna una eficacia del 100%.\n\nEn la fase 3 de un ensayo en adolescentes de entre 12 y 15 aÃ±os, la vacuna BNT162b2 de Pfizer-BioNTech para el COVID-19 demostrÃ³ una eficacia del 100% y una respuesta robusta de anticuerpos. El ensayo clÃ­nico involucrÃ³ 2260 jÃ³venes estadounidenses. En el ensayo, 18 casos de COVID-19 fueron observados en el grupo placebo (\\(n=1129\\)) y ninguno en el grupo vacunado (\\(n=1131\\))\n\nEs de esperar que, en un ensayo mÃ¡s grande, aparezca algÃºn caso de COVID-19 en el grupo que recibiÃ³ el tratamiento. Â¿CÃ³mo se estima la probabilidad de algo que aÃºn no ocurriÃ³? \nLa regla del tres\nUna estudiante de Licenciatura en EstadÃ­stica estÃ¡ releyendo su tesina antes de entregarla. Si en 20 pÃ¡ginas encontrase 5 de ellas con al menos un typo, serÃ­a razonable estimar que la probabilidad de que una pÃ¡gina contenga un typo es \\(\\frac{5}{20} = \\frac{1}{4}\\). Â¿Pero quÃ© ocurre si en 20 pÃ¡ginas no encuentra ningÃºn error?\nVerifcar que, partiendo de un prior uniforme, \\(\\frac{3}{N}\\) es una estimaciÃ³n razonable para \\(\\tau\\) (la probabilidad de que una pÃ¡gina contenga un typo), siendo \\(N\\) el nÃºmero de pÃ¡ginas. Para ello, grafique la distribuciÃ³n a priori que se obtiene al haber observado 0 typos en 10 pÃ¡ginas y luego halle la probabilidad de que \\(\\tau < \\frac{3}{N}\\) para diferentes valores de \\(N\\) (10, 100, 1000, 10000). \nÂ¿TenÃ©s alguien para recomendar?\nUna colega quiere comprar un producto por Internet. Tres vendedores ofrecen el mismo producto al mismo precio. Un vendedor tiene 100% de evaluaciones positivas, con 10 reviews. Otro tiene 96% de evaluaciones positivas, con 50 reviews. El Ãºltimo tiene 90% de comentarios positivos, con 200 evaluaciones. Â¿CuÃ¡l de los tres vendedores le recomendarÃ­as? \nBichos\nUn biÃ³logo quiere determinar la densidad de un insecto en su regiÃ³n. Su conocimiento a priori del nÃºmero promedio de insectos por unidad de Ã¡rea (\\(\\text{m}^2\\)) se puede representar con una distribuciÃ³n Gamma de media 0.50 y desvÃ­o estÃ¡ndar 0.25. En una investigaciÃ³n en 20 \\(\\text{m}^2\\) de Ã¡rea, se hallan 3, 2, 5, 1 y 2 insectos en los primeros 5 \\(\\text{m}^2\\) y ninguno en la fracciÃ³n de tierra restante.\n\nHalle la distribuciÃ³n a posteriori del nÃºmero medio de insectos por unidad de Ã¡rea.\nHalle la distribuciÃ³n predictiva a posteriori del nÃºmero de insectos que se espera encontrar en una exploraciÃ³n de un Ã¡rea de 10 \\(\\text{m}^2\\)\n\n\n\n\n\n\nUna gran variedad de insectosImÃ¡gen de Freepik\n\n\n\n\nAlter-ego\nEl profesor Caprista y el profesor Evangetto estÃ¡n dando sus primeros cursos de EstadÃ­stica Bayesiana. Sus colegas les dijeron que el puntaje promedio en un examen final, \\(\\mu\\), varÃ­a normalmente aÃ±o a aÃ±o con media 8 y desvÃ­o estÃ¡ndar 0.4. Y ademÃ¡s, que los puntajes individuales de lxs estudiantes \\(Y\\) varÃ­an normalmente alrededor de \\(\\mu\\) con una desviaciÃ³n estÃ¡ndar de 0.4\n\nÂ¿CuÃ¡l es la probabilidad a priori de que un estudiante se saque mÃ¡s de 9 en un examen final?\nEl profesor Caprista toma el examen final y observa que sus 20 estudiantes obtuvieron una nota media de 8.6. Halle la distribuciÃ³n a posteriori de \\(\\mu\\).\nEl profesor Evangetto toma el examen final y observa que sus 20 estudiantes obtuvieron una nota media de 8.2. Halle la distribuciÃ³n a posteriori de \\(\\mu\\).\nCombine las notas de ambos exÃ¡menes para obtener la distribuciÃ³n a posteriori de \\(\\mu\\)\nÂ¿CuÃ¡l es la probabilidad a posteriori de que un estudiante se saque mÃ¡s de 9 en un examen final?\n\nInferencia sobre una distribuciÃ³n de Poisson\nLa distribuciÃ³n de masa de probabilidad Poisson se define como\n\\[\n\\begin{array}{lcr}\n\\displaystyle p(x \\mid \\lambda) = \\frac{e^{-\\lambda}\\lambda^x}{x!} &\n\\text{con} &\nx \\in \\{0, 1, 2, \\cdots \\}\n\\end{array}\n\\]\ndonde \\(\\lambda > 0\\) es la cantidad promedio de veces que ocurre el evento de interÃ©s en un periodo o espacio determinado.\n\nDerive el estimador de mÃ¡xima verosimilitud del parÃ¡metro \\(\\lambda\\).\nDerive el posterior \\(p(\\lambda \\mid \\mathbf{x})\\) suponiendo que el prior sobre \\(\\lambda\\) es \\(\\text{Gamma}(\\lambda \\mid \\alpha, \\beta)\\) con \\(p(\\lambda \\mid \\alpha, \\beta) \\propto \\lambda^{\\alpha - 1}e ^ {-\\lambda \\beta}\\).\nAyuda: El posterior tambiÃ©n es una distribuciÃ³n Gamma.\nÂ¿A quÃ© valor tiende la media a posteriori cuando \\(\\alpha \\to 0\\) y \\(\\beta \\to 0\\)?\nRecuerde que la media de una distribuciÃ³n \\(\\text{Gamma}(\\alpha, \\beta)\\) es \\(\\alpha/\\beta\\). \n\nEl modelo Gamma-Poisson\nSea \\(\\lambda\\) la tasa de mensajes de WhatsApp que una persona recibe en una hora. Suponga inicialmente que se cree que la tasa de mensajes por hora tiene media 5 con desvÃ­o estÃ¡ndar de 0.25 mensajes.\n\nElija una distribuciÃ³n Gamma que represente adecuadamente lo que se cree acerca de \\(\\lambda\\)\nÂ¿CuÃ¡l es la probabilidad a priori de que la tasa de mensajes sea mayor a 10?\nÂ¿CuÃ¡ntos mensajes se espera que reciba una persona en promedio en una hora?\n\nSe sondea a un grupo de seis personas que recibieron 7, 3, 8, 9, 10 y 12 mensajes en la Ãºltima hora.\n\nGraficar la verosimilitud de \\(\\lambda\\).\nDeterminar la distribuciÃ³n a posteriori de \\(\\lambda\\).\nÂ¿CuÃ¡l es la probabilidad a posteriori de que la tasa de mensajes sea mayor a 10?\nÂ¿CuÃ¡ntos mensajes se espera ahora que reciba una persona en promedio en una hora?\n\nInferencia sobre una distribuciÃ³n Uniforme\nConsidere una distribuciÃ³n \\(\\text{Uniforme}(0, \\theta)\\). La funciÃ³n de densidad de probabilidad es\n\\[\np(x) = \\frac{1}{\\theta}I(x \\in [0, \\theta])\n\\]\nSea \\(\\mathbf{X} = (X_1,..., X_n)\\) un vector de \\(n\\) variables aleatorias independientes e idÃ©nticamente distribuidas segÃºn \\(p(x)\\)\nInferencia mÃ¡ximo-verosÃ­mil\n\nÂ¿CuÃ¡l es el estimador mÃ¡ximo verosÃ­mil de \\(\\theta\\) (llÃ¡melo \\(\\hat{\\theta}_{\\text{MV}}\\))?\nÂ¿QuÃ© probabilidad le asigna el modelo a una nueva observaciÃ³n \\(x_{n + 1}\\) usando \\(\\hat{\\theta}_{\\text{MV}}\\)?\nÂ¿Observa algÃºn problema con el resultado anterior? Si es asÃ­, sugiera una alternativa mejor.\n\nInferencia Bayesiana\nEl prior conjugado de la distribuciÃ³n uniforme es la distribuciÃ³n de Pareto.\nSi \\(X \\sim \\text{Pareto}(\\alpha, m)\\), luego\n\\[\np(x| \\alpha, m) = \\frac{\\alpha m^\\alpha}{x^{\\alpha+1}} \\mathbb{I}(x \\ge m)\n\\]\nSi el prior es una distribuciÃ³n de Pareto, la distribuciÃ³n conjunta de \\(\\theta\\) y \\(\\mathbf{X} = (X_1,..., X_n)\\) es\n\\[\np(\\theta, \\mathbf{X})\n    = \\frac{\\alpha m^\\alpha}{\\theta^{n + \\alpha + 1}}\n    \\mathbb{I}(\\theta \\ge \\text{max}(\\mathbf{X}))\n\\]\nLlamando \\(M_x = \\text{max}(\\mathbf{X})\\). La evidencia es\n\\[\n\\begin{aligned}\np(\\mathbf{X}) &= \\int_{M_x}^\\infty\n                 \\frac{\\alpha m^\\alpha}{\\theta^{n + \\alpha + 1}}\n                 d\\theta \\\\\n&=  \\begin{cases}\n    \\frac{\\alpha}{(n+\\alpha)m^n} & \\text{Si } M_x \\le m \\\\\n    \\frac{\\alpha m^\\alpha}{(n+\\alpha)M_x^{n+\\alpha}} & \\text{Si } M_x > m \\\\\n    \\end{cases}\n\\end{aligned}\n\\]\nDerive el posterior y muestre que puede ser expresado como una distribuciÃ³n de Pareto.  \nInferencia sobre una distribuciÃ³n Exponencial\nEl tiempo de vida de una mÃ¡quina en aÃ±os \\(X\\) es modelado con una distribuciÃ³n exponencial con parÃ¡metro \\(\\theta\\) desconocido. La funciÃ³n de densidad es\n\\[\n\\begin{array}{lcrr}\np(x | \\theta) = \\theta e^{-\\theta x} & \\text{con} & x \\ge 0, & \\theta \\ge 0\n\\end{array}\n\\]\n\nMuestre que el estimador mÃ¡ximo verosÃ­mil (MV) es \\(\\hat{\\theta}_\\text{MV} = 1/\\bar{x}\\).\nSuponga que se observan los siguientes tiempos de vida de tres mÃ¡quinas independientes \\(x_1 = 5\\), \\(x_2 = 6\\), \\(x_3 = 4\\). Â¿CuÃ¡l es el valor del estimador MV?\nUna experta del Ã¡rea sugiere que \\(\\theta\\) debe tener una distribuciÃ³n a priori que tambiÃ©n sea exponencial. \\[\n\\begin{aligned}\n\\theta \\mid \\lambda &\\sim \\text{Exp}(\\lambda) \\\\\np(\\theta \\mid \\lambda) &= \\lambda e^{-\\lambda \\theta}\n\\end{aligned}\n\\] Elija un valor para el hiperparÃ¡metro \\(\\lambda\\) de la distribuciÃ³n a priori tal que \\(\\mathbb{E}(\\theta) = 1/3\\). Utilice \\(\\lambda_0\\) para representar al valor.\nÂ¿CuÃ¡l es el posterior \\(p(\\theta \\mid \\mathbf{X}, \\lambda_0)\\)?\nÂ¿Es la distribuciÃ³n exponencial conjugada con un likelihood exponencial?\nEncuentre la media del posterior, \\(\\mathbb{E}(\\theta \\mid \\mathbf{X}, \\lambda_0)\\)\nExplique por que difieren el estimador MV de la media a posteriori. Â¿CuÃ¡l es mÃ¡s razonable en este ejemplo? \n\nOtras distribuciones conjugadas (I)\nConsidere el siguiente modelo:\n\\[\n\\begin{array}{l}\nY\\mid\\theta \\sim \\text{Geom}(\\theta) \\\\\n\\theta \\sim \\text{Beta}(\\alpha,\\beta)\n\\end{array}\n\\] donde la funciÃ³n de densidad de la distribuciÃ³n geomÃ©trica es \\(p(y\\mid\\theta) = \\theta(1-\\theta)^{y-1}\\) para \\(y \\in {1,2,\\dots}\\)\n\nÂ¿QuÃ© deberÃ­a ocurrir con la distribuciÃ³n a posteriori de \\(\\theta\\) para poder afirmar que la distribuciÃ³n geomÃ©trica es conjugada de la beta?\nDerive la distribuciÃ³n a posteriori de \\(\\theta\\) y concluya.\n\nOtras distribuciones conjugadas (II)\nConsidere el siguiente modelo:\n\\[\n\\begin{aligned}\nY\\mid\\theta &\\sim \\text{BinomialNeg}(\\theta, m) \\\\\n\\theta &\\sim \\text{Beta}(\\alpha,\\beta)\n\\end{aligned}\n\\]\ndonde la funciÃ³n de densidad de la distribuciÃ³n binomial negativa es\n\\[p(y\\mid \\theta, m) = {y+m-1 \\choose y} \\theta^{m} (1-\\theta)^y\\]\nObtenga la distribuciÃ³n a posteriori de \\(\\theta\\).\nOtras distribuciones conjugadas (III)\nConsidere el siguiente modelo:\n\\[\n\\begin{array}{l}\nY\\mid\\theta \\sim \\text{Exp}(\\theta) = \\text{Gamma}(1,\\theta)\n\\end{array}\n\\]\ndonde la funciÃ³n de densidad exponencial es \\(p(y\\mid\\theta) = \\theta e^{-\\theta y}\\).\nElija una distribuciÃ³n a priori conjugada de la verosimilitud propuesta y obtenga la expresiÃ³n para la distribuciÃ³n de probabilidad a posteriori"
  },
  {
    "objectID": "practica/practica_02.html#simulaciones",
    "href": "practica/practica_02.html#simulaciones",
    "title": "PrÃ¡ctica - Unidad 2",
    "section": "Simulaciones",
    "text": "Simulaciones\nA diferencia de la secciÃ³n anterior, que requiere resolver los ejercicios a mano y promueve el uso de la computadora y R de manera complementaria, esta secciÃ³n contiene ejercicios que deben ser resueltos mediante tÃ©cnicas de simulaciÃ³n implementadas en R. Es posible que en algunos casos tambiÃ©n se pueda obtener una soluciÃ³n analÃ­tica. En estos casos, puede resultar de utilidad obtener tambiÃ©n una soluciÃ³n a mano para validar el resultado, evaluar el nivel de dificultad y ver que tan intuitivo resultan ambos enfoques.\n\nEntrada en calor\nPara cada una de las siguientes situaciones, hallar los intervalos centrales de credibilidad\n\nIntervalo del 95% para \\(\\pi\\) siendo \\(\\pi\\mid \\mathbf{y} \\sim \\text{Beta}(4,5)\\).\nIntervalo del 60% para \\(\\pi\\) siendo \\(\\pi\\mid \\mathbf{y} \\sim \\text{Beta}(4,5)\\).\nIntervalo del 89% para \\(\\lambda\\) siendo \\(\\lambda\\mid \\mathbf{y} \\sim \\text{Gamma}(1,8)\\).\nIntervalo del 95% para \\(\\lambda\\) siendo \\(\\lambda\\mid \\mathbf{y} \\sim \\text{Gamma}(2,5)\\).\nIntervalo del 81% para \\(\\mu\\) siendo \\(\\mu\\mid \\mathbf{y} \\sim \\mathcal{N}(10,2^2)\\).\nIntervalo del 99% para \\(\\pi\\) siendo \\(\\mu\\mid \\mathbf{y} \\sim \\mathcal{N}(-3,1^2)\\).\n\nPropiedades frecuentistas de inferencias bayesianas (!!)\nSea una variable \\(Y\\) tal que \\(Y \\mid \\theta \\sim \\text{Binomial}(n, \\theta)\\) y \\(\\theta \\sim \\text{Beta}(1/2, 1/2)\\). Mediante un estudio de simulaciÃ³n calcule la cobertura empÃ­rica del intervalo de credibilidad del 95% con \\(n \\in \\{1, 5, 10, 25\\}\\) y \\(\\theta \\in \\{0.05, 0.10, \\dots, 0.50 \\}\\). Describa las propiedades frecuentistas del intervalo de credibilidad bayesiano. \nÂ¿Te preguntaste alguna vez cuÃ¡l es la distribuciÃ³n de un p-value?\nConsidere un problema conocido. Se desean comparar dos muestras independientes de tamaÃ±o 5 utilizando un test t y utilizando el test de Mann-Whitney.\n\nConsidere el caso en que las dos muestras provienen de poblaciones con igual media y desvÃ­o estÃ¡ndar (supongamos normal de media nula y varianza unitaria). Si se repitiera muchas veces el proceso de tomar las muestras y realizar los tests, Â¿quÃ© distribuciÃ³n tendrÃ¡n los p-values obtenidos para cada test?\nConsidere ahora el caso en que las dos muestras provienen de poblaciones con diferente media e igual desvÃ­o estÃ¡ndar (\\(\\mathcal{N}(0,1)\\) y \\(\\mathcal{N}(1,1)\\)). Si se repitiera muchas veces el proceso de tomar las muestras y realizar los tests, Â¿quÃ© distribuciÃ³n tendrÃ¡n los p-values obtenidos para cada test?"
  },
  {
    "objectID": "practica/practica_02.html#elecciÃ³n-de-distribuciones-a-priori",
    "href": "practica/practica_02.html#elecciÃ³n-de-distribuciones-a-priori",
    "title": "PrÃ¡ctica - Unidad 2",
    "section": "ElecciÃ³n de distribuciones a priori",
    "text": "ElecciÃ³n de distribuciones a priori\nEsta Ãºtima secciÃ³n de la prÃ¡ctica tiene como propÃ³sito ejercitar el uso de distribuciones de probabilidad como herramienta para reflejar informaciÃ³n de un problema determinado.\n\nEsbozar la distribuciÃ³n de las siguientes variables\n\nEl nÃºmero de personas que compran cafÃ© en el bar de la facultad asumiendo distribuciÃ³n de Poisson.\nEl peso de perros adultos en kilogramos asumiendo una distribuciÃ³n Uniforme.\nEl peso de elefantes adultos en kilogramos asumiendo una distribuciÃ³n Normal.\nEl peso de humanos adultos en libras asumiendo una distribuciÃ³n asimÃ©trica hacia la derecha.\n\nVerificar los resultados de manera computacional\nPara cada uno cada uno de los ejemplos del ejercicio anterior, graficar la distribuciÃ³n usando R. Seleccionar los parÃ¡metros que creas razonable, tomar una muestra aleatoria de tamaÃ±o 1000 y graficar la distribuciÃ³n en base a las muestras. Â¿Se refleja tu conocimiento del problema en la distribuciÃ³n graficada? Si no, ajustar los parÃ¡metros y repetir el proceso hasta que el resultado tenga concuerde con el conocimiento del problema.\nHay que amigarse con de la distribuciÃ³n Beta\nComparar las siguientes distribuciones a priori.\n\n\\(\\text{Beta}(0.5, 0.5)\\).\n\\(\\text{Beta}(1, 1)\\).\n\\(\\text{Beta}(1, 4)\\).\n\\(\\text{Beta}(5, 1.5)\\).\n\n\nÂ¿En quÃ© se diferencian?\nÂ¿CuÃ¡l de ellas es mÃ¡s informativa?\nÂ¿CÃ³mo lo determinaste?\n\nElicitaciÃ³n de priors\nEn cada una de la situaciones que se describen debajo, ajustar manualmente los parÃ¡metros de una distribuciÃ³n \\(\\text{Beta}\\) para que reflejen la informaciÃ³n brindada. No siempre existe una Ãºnica respuesta correcta.\n\nUn amigo se postulÃ³ para un empleo en LinkedIn y te dijo: â€œDirÃ­a que tengo una chance del 40% de que me den el trabajo, pero no estoy seguroâ€. Cuando le preguntamos un poco mas, dijo que estima sus chances entre un 20% y un 60%.\nUn grupo de investigaciÃ³n del CONICET desarrollÃ³ una nueva prueba para una enfermedad bastante rara. El grupo espera que esta prueba arroje resultados correctos el 80% de las veces, con una varianza de 0.05.\nEl primo de un amigo es un apasionado de la pesca, lo practica muy seguido, y se dice ser muy bueno. SegÃºn comenta tu amigo, en el asado de los Jueves el pescador dijo lo siguiente:\n\n\nSi tengo que hacer un promedio, 9 de cada 10 veces que salgo, vuelvo con algo. Pero Ãºltimamente te dirÃ­a que siempre es 10 de 10. Estoy infalible. La verdad es que soy un crack de la pesca.\n\nAnte el descreimiento de algunos de los comensales supo reconocer que no siempre le fue tan bien:\n\nTuve mis malas rachas, pero nunca menos de 8 pescas de cada 10 salidas.\n\nEfecto de la parametrizaciÃ³n\nSea \\(\\theta\\) la probabilidad de Ã©xito en un experimento binomial y sea \\(\\gamma = \\frac{\\theta}{1-\\theta}\\) la chance de Ã©xito. Utilizar simulaciones para explorar los efectos de las siguientes elecciones de distribuciones a priori\n\nSi \\(\\theta \\sim \\text{Uniforme}(0, 1)\\), Â¿cuÃ¡l es el prior inducido para \\(\\gamma\\)?\nSi \\(\\theta \\sim \\text{Beta}(5, 5)\\), Â¿cuÃ¡l es el prior inducido para \\(\\gamma\\)?\nSi \\(\\gamma \\sim \\text{Uniforme}(0, 100)\\), Â¿cuÃ¡l es el prior inducido para \\(\\theta\\)?\nSi \\(\\gamma \\sim \\text{Gamma}(1, 1)\\), Â¿cuÃ¡l es el prior inducido para \\(\\theta\\)?"
  },
  {
    "objectID": "practica/practica_02.html#teorÃ­a-de-la-decisiÃ³n",
    "href": "practica/practica_02.html#teorÃ­a-de-la-decisiÃ³n",
    "title": "PrÃ¡ctica - Unidad 2",
    "section": "TeorÃ­a de la DecisiÃ³n",
    "text": "TeorÃ­a de la DecisiÃ³n\n\nDada la distribuciÃ³n a posteriori \\(p(\\theta \\mid y)\\), probar que el estimador de Bayes que minimiza la funciÃ³n de pÃ©rdida \\(L_1\\) es la mediana de \\(p(\\theta \\mid y)\\). \nSuponga que la distribuciÃ³n a posteriori de \\(\\pi\\), \\(p(\\pi \\mid y)\\), es \\(\\text{Beta}(12,4)\\). Determine mediante simulaciÃ³n el estimador que minimiza la pÃ©rdida de Huber: \\[\n\\mathcal{L}(\\delta,\\pi) =\n\\begin{cases}\n\\frac{1}{2} (\\pi - \\delta)^2 \\text{ si } |\\pi - \\delta| \\leq \\alpha \\\\\n\\alpha \\cdot (|\\pi - \\delta|-\\frac{1}{2}\\alpha) \\text{ en cualquier otro caso}\n\\end{cases}\n\\]"
  },
  {
    "objectID": "practica/practica_02.html#otros",
    "href": "practica/practica_02.html#otros",
    "title": "PrÃ¡ctica - Unidad 2",
    "section": "Otros",
    "text": "Otros\n\nDistribuciÃ³n predictiva a posteriori (a mano)\nConsidere un modelo \\(y\\mid \\theta \\sim \\mathrm{Bin}(\\theta,n)\\), donde \\(\\theta\\) puede tomar valores discretos \\(0,\\ 0.1,\\ 0.2,\\ \\dots,\\ 1\\). Se realizaron inferencias sobre \\(\\theta\\) y se obtuvo la distribuciÃ³n a posteriori que se muestra en la parte superior de la FiguraÂ 1.\nSe desea obtener la distribuciÃ³n predictiva a posteriori para el nÃºmero de Ã©xitos \\(\\tilde{y}\\) en \\(n=5\\) nuevas realizaciones del experimento. Cada valor de \\(\\theta\\) da lugar a una posible distribuciÃ³n de \\(\\tilde{y}\\) de acuerdo a la verosimilitud binomial, como se observa en la parte inferior de la FiguraÂ 1.\n\n\n\n\n\n\nFiguraÂ 1: DistribuciÃ³n a posteriori y distribuciÃ³n predictiva a posteriori\n\n\n\n\n\nCalcule \\(p(\\tilde{y}\\mid\\theta)\\) para cada valor posible de \\(\\theta\\) y compruebe que los grÃ¡ficos de la parte inferior de la FiguraÂ 1 son correctos.\nCombine los \\(p(\\tilde{y}\\mid\\theta)\\) ponderando por las probabilidades a posteriori de \\(\\theta\\), \\(p(\\theta\\mid y)\\) para obtener la distribuciÃ³n predictiva a posteriori\nCompare la varianza de una de las \\(p(\\tilde{y}\\mid\\theta)\\) (por ejemplo, la de \\(\\theta=0.5\\)) con la varianza de la distribuciÃ³n predictiva a posteriori Â¿quÃ© observa?\nA partir de \\(p(\\theta\\mid y)\\) y de la verosimilitud binomial, obtenga muestras de \\(p(\\tilde{y}\\mid y)\\) y grafique su distribuciÃ³n."
  },
  {
    "objectID": "trabajos_practicos/03_tp3.html",
    "href": "trabajos_practicos/03_tp3.html",
    "title": "TP3: Estudio de modelos lineales",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "trabajos_practicos/03_tp3.html#simulaciones",
    "href": "trabajos_practicos/03_tp3.html#simulaciones",
    "title": "TP3: Estudio de modelos lineales",
    "section": "Simulaciones",
    "text": "Simulaciones\nEl archivo tp3_train.csv contiene 100 observaciones que se usarÃ¡n para identificar los parÃ¡metros de un modelo, mientras que el archivo tp3_test.csv tiene 20 observaciones que se usarÃ¡n para evaluar los resultados del proceso de inferencia.\nSe sabe que los datos fueron generados utilizando un modelo de la forma:\n\\[\ny_i \\sim \\mathcal{N}(\\theta_3 x_i^3 + \\theta_2 x_i^2 + \\theta_1 x_i + \\theta_0, \\sigma^2)\n\\]\naunque no se conocen los valores de los \\(\\theta_i\\) ni de \\(\\sigma\\)\nEn primer lugar, se estudiarÃ¡ el efecto de la cantidad de datos utilizados para el ajuste del modelo.\n\nRealice un anÃ¡lisis exploratorio de los datos de ajuste del modelo (train) y proponga priors vagos de acuerdo a la escala de los datos. Realice simulaciones predictivas a priori.\nUtilice los priors propuestos en el punto anterior para ajustar el modelo utilizando 10, 20, 50 o 100 observaciones de los datos de entrenamiento. Compare las distribuciones a posteriori de los parÃ¡metros, la media condicional y las predicciones sobre el conjunto de datos de evaluaciÃ³n.\n\nEn segundo lugar, se investigarÃ¡ quÃ© efecto tiene la elecciÃ³n de distribuciones a priori centradas en valores errÃ³neos de los parÃ¡metros de la regresiÃ³n.\n\nConsidere las siguientes distribuciones a priori:\n\\[\n\\begin{aligned}\n\\theta_0 &\\sim \\mathcal{N}(0.6,0.2) \\\\\n\\theta_1 &\\sim \\mathcal{N}(-0.2,0.2) \\\\\n\\theta_2 &\\sim \\mathcal{N}(2.1,0.2) \\\\\n\\theta_3 &\\sim \\mathcal{N}(1,0.2)\n\\end{aligned}\n\\]\nCompare, como hizo en el caso anterior, los resultados en las estimaciones utilizando 10, 20, 50 y 100 observaciones.\n\nFinalmente, se considera el caso donde se propone un modelo errÃ³neo.\n\nUtilizando priors vagos, ajuste polinomios de grado 3, 4, 5 y 6 utilizando 20 observaciones. Compare grÃ¡ficamente el ajuste en los datos de entrenamiento con el ajuste en los datos de evaluaciÃ³n. Â¿QuÃ© ocurre si se utilizan todos los datos del conjunto de entrenamiento?\nUtilice ahora priors de regularizaciÃ³n (centrados en 0 y con diferentes varianzas: \\(0.01\\), \\(0.1\\), \\(1\\) y \\(10\\)) para polinomios de grado 3, 4, 5 y 6 utilizando 20 observaciones. Compare grÃ¡ficamente el ajuste en los datos de entrenamiento con el ajuste en los datos de evaluaciÃ³n. Como hizo en el punto anterior, analice que ocurre cuando utiliza todos los datos del conjunto de entrenamiento."
  },
  {
    "objectID": "trabajos_practicos/03_tp3.html#enfriamiento-de-agua-en-un-termo",
    "href": "trabajos_practicos/03_tp3.html#enfriamiento-de-agua-en-un-termo",
    "title": "TP3: Estudio de modelos lineales",
    "section": "Enfriamiento de agua en un termo",
    "text": "Enfriamiento de agua en un termo\nEn un paÃ­s matero como Argentina, era de esperarse que aparecieran casi tantos termos como personas. Es difÃ­cil decir si la cantidad de variantes de termos en el mercado nacional cambiÃ³, pero es indudable que, tras el furor del termo color verde militar, la elecciÃ³n de un termo adquiriÃ³ un papel relevante en el ritual del mate.\nDe acero, de vidrio, con capa aisladora. Diferentes configuraciones dan lugar a distintas capacidades de mantener la temperatura y, obviamente, a distintos rangos de precios. Dejando de lado la cuestiÃ³n monetaria, centrÃ©monos en estudiar cÃ³mo varÃ­a la temperatura de un lÃ­quido en el interior de un termo en funciÃ³n del tiempo transcurrido.\nLa temperatura es una medida del grado de agitaciÃ³n de las partÃ­culas de una sustancia. Un lÃ­quido (o sÃ³lido, o gas) estÃ¡ mÃ¡s caliente que otro si sus partÃ­culas tienen (en promedio) mayor grado de agitaciÃ³n. Sabemos por evidencia empÃ­rica que si un cuerpo se pone en contacto con otro que tiene una temperatura menor, hay una transferencia de energÃ­a que hace que el primero se enfrÃ­e y el segundo se caliente, hasta que alcanzan el denominado equilibrio tÃ©rmico.\nDe manera similar, esto es lo que ocurre con el agua que dejamos dentro del termo: en algÃºn momento, llega al equilibrio tÃ©rmico con el ambiente. La salvedad necesaria acÃ¡ es que, como el ambiente es grande, no aumenta su temperatura con la energÃ­a que pierde el agua del recipiente.\nAhora bien, el ritmo con el cual el agua caliente pierde energÃ­a no es constante. FÃ­sicamente, mientras mayor sea la diferencia de temperatura entre dos cuerpos, mÃ¡s rÃ¡pido fluirÃ¡ la energÃ­a (y mÃ¡s rÃ¡pido cambiarÃ¡ la temperatura). Si estudiamos la temperatura del agua en el termo en funciÃ³n del tiempo, notaremos que el ritmo con el que cambia decrece a medida con el que transcurre el tiempo.\nLa lectura del pÃ¡rrafo anterior deberÃ­a permitir asociar el concepto de ritmo de cambio con la nociÃ³n matemÃ¡tica de derivada. En efecto, la derivada de la temperatura respecto al tiempo varÃ­a con el tiempo. En otras palabras, la pendiente no es constante.\nLas leyes que rigen el universo pueden muchas veces formularse en tÃ©rminos de lo que en matemÃ¡tica se conoce como ecuaciÃ³n diferencial. En este caso, la temperatura del agua en el termo satisface la siguiente ley:\n\\[\n\\frac{\\mathrm{d}T(t)}{\\mathrm{d}t} = r [T_{\\text{amb}}-T(t)]\n\\]\ndonde \\(T_{\\text{amb}}\\) es la temperatura ambiente (un valor fijo y conocido), \\(r\\) es una constante y \\(T(t)\\) es la funciÃ³n (en principio desconocida) que describe la temperatura del agua del termo en funciÃ³n del tiempo.\nNo se trata de una ecuaciÃ³n algebraica donde la soluciÃ³n es un valor numÃ©rico sino de una ecuaciÃ³n donde la soluciÃ³n es una funciÃ³n. Buscamos una funciÃ³n \\(T(t)\\) que satisfaga la ecuaciÃ³n: su derivada debe cambiar con el valor que toma la funciÃ³n.\nUna funciÃ³n que satisface esa ecuaciÃ³n es:\n\\[\nT(t) = T_{\\text{amb}} + (T_i - T_{\\text{amb}})e^{-rt}\n\\]\nsiendo \\(T_i\\) la temperatura a la que estÃ¡ inicialmente el agua en el termo (un valor fijo y conocido).\n\nVerificar que la funciÃ³n anterior satisface la ecuaciÃ³n diferencial\nGrafique \\(T(t)\\) para \\(T_{\\text{amb}} = 20 \\text{ CÂ°}\\) y \\(T_i = 90 \\text{ CÂ°}\\), para dos valores de \\(r\\), \\(r_1=0.1\\) y \\(r_2 = 0.3\\). Â¿QuÃ© representa \\(r\\)?\nSegÃºn su experiencia con termos, Â¿cuÃ¡l es un valor realista de \\(r\\)?\n\nEstudiaremos a continuaciÃ³n un conjunto de mediciones de temperatura de agua en un termo en funciÃ³n del tiempo transcurrido.\nLeonel tiene un termo Estanliâ„¢ que comprÃ³ por Amason y se dispone a despejar la duda de cualquier usuario de termos Estanliâ„¢: Â¿cuÃ¡nto dura el agua caliente? Pone agua en la pava elÃ©ctrica, la vierte en el termo y registra la temperatura en algunos momentos posteriores. Ese dÃ­a, el reporte meteorolÃ³gico indica una temperatura de \\(T_{\\text{amb}} = 23\\text{ CÂ°}\\). Las temperaturas que registrÃ³ Leonel son las siguientes:\n\n\n\n\n \n  \n    t (h:mm) \n    T (Â°C) \n  \n \n\n  \n    1:20 \n    92.0 \n  \n  \n    2:30 \n    90.5 \n  \n  \n    4:00 \n    81.4 \n  \n  \n    5:15 \n    80.8 \n  \n  \n    8:30 \n    74.2 \n  \n\n\n\n\n\nPara simplificar la construcciÃ³n de un modelo, en lugar de considerar la temperatura del agua en el termo, se considerarÃ¡ la diferencia entre la temperatura del agua y la temperatura ambiente \\(T-T_{\\text{amb}}\\). AdemÃ¡s, se llamarÃ¡ \\(T_{\\text{diff}}\\) a la diferencia de temperatura entre la temperatura inicial del agua y la temperatura ambiente \\(T_i - T_{\\text{amb}}\\).\n\\[\nT(t) - T_{\\text{amb}} = T_{\\text{diff}} e^{-rt}\n\\]\n\nVerifique que el logaritmo natural de la nueva variable (\\(T(t) - T_{\\text{amb}}\\)) es una funciÃ³n lineal de \\(t\\). Â¿QuÃ© representan el intercepto y la pendiente? LlÃ¡melos \\(\\beta_0\\) y \\(\\beta_1\\).\n\nSe propone ajustar un modelo lineal normal utilizando los datos transformados.\n\nEn funciÃ³n del enunciado del problema y de su conocimiento de termos, elija una distribuciÃ³n a priori para \\(\\beta_0\\), \\(\\beta_1\\) y \\(\\sigma\\). Â¿CuÃ¡les son las implicancias de sus distribuciones a priori? Realice pruebas predictivas a priori.\nAjuste el modelo lineal utilizando R.\nEncontrar el posterior de \\(r\\), de \\(T_{\\text{diff}}\\) y de la temperatura inicial del agua \\(T_i\\).\nPredecir la temperatura a la que estarÃ¡ el agua transcurridas 12:00 h del inicio de la experiencia."
  },
  {
    "objectID": "trabajos_practicos/descripcion.html",
    "href": "trabajos_practicos/descripcion.html",
    "title": "Generalidades",
    "section": "",
    "text": "Para aprobar la materia es necesario completar tres trabajos prÃ¡cticos cortos. La denominaciÃ³n cortos hace referencia a que los trabajos son guiados y las tareas a realizar estÃ¡n delimitadas.\nLos trabajos prÃ¡cticos tienen como objetivo repasar y afianzar los conocimientos adquiridos durante las clases, adquirir prÃ¡ctica en la aplicaciÃ³n de conceptos trabajados, mejorar las habilidades de programaciÃ³n y el uso de R, e incorporar algunos conceptos complementarios.\nCada trabajo prÃ¡ctico serÃ¡ presentado y discutido en clase. Se destinarÃ¡ una fracciÃ³n de la clase a comenzar a pensar algunas de las actividades.\nLa fecha de entrega de cada trabajo prÃ¡ctico serÃ¡ de dos semanas luego de la fecha de presentaciÃ³n. Se podrÃ¡ entregar el trabajo prÃ¡ctico una semana despuÃ©s de la fecha de entrega con una penalizaciÃ³n del 25% de la nota final.\nPara cada trabajo prÃ¡ctico, cada grupo deberÃ¡ entregar un informe en formato pdf donde se resuelvan las actividades propuestas. El informe debe estar obligatoriamente elaborado utilizando \\(\\mathrm{\\LaTeX{}}\\) (a travÃ©s de Quarto, RMarkdown o alguna otra variante). Tener en cuenta que los apartados presentados en el enunciado del trabajo prÃ¡ctico constituyen una guÃ­a de actividades a resolver y no deben responderse uno a uno como si se tratara de un cuestionario. El informe deberÃ¡ permitir una lectura fluida de los resultados y anÃ¡lisis presentados. Cuando la resoluciÃ³n de una problemÃ¡tica consista en una funciÃ³n o porciÃ³n de cÃ³digo en R, el cÃ³digo deberÃ¡ mostrarse en el informe.\nSe evaluarÃ¡n los siguientes aspectos del informe: presentaciÃ³n, redacciÃ³n (claridad, coherencia y cohesiÃ³n), estÃ©tica, resultados obtenidos, profundidad del anÃ¡lisis."
  },
  {
    "objectID": "trabajos_practicos/00_tp0.html",
    "href": "trabajos_practicos/00_tp0.html",
    "title": "TP0: DistribuciÃ³n de Rocklets azules",
    "section": "",
    "text": "Descargar PDF\n\n\nDistribuciÃ³n de Rocklets azules"
  },
  {
    "objectID": "trabajos_practicos/04_tp_final.html",
    "href": "trabajos_practicos/04_tp_final.html",
    "title": "TP Final: El otro Fisher",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "trabajos_practicos/04_tp_final.html#introducciÃ³n",
    "href": "trabajos_practicos/04_tp_final.html#introducciÃ³n",
    "title": "TP Final: El otro Fisher",
    "section": "IntroducciÃ³n",
    "text": "IntroducciÃ³n\nEn este Ãºltimo trabajo prÃ¡ctico nos sitÃºa como parte del equipo de ciencia de datos en una empresa de comercio electrÃ³nico que se especializa en vender pescado fresco de alta calidad a una clientela muy selectiva que consiste principalmente en restaurantes de lujo.\nCuando enviamos nuestros productos hay un dato que no puede faltar: el peso del pescado. Esta informaciÃ³n es relevante por dos razones. En primer lugar, el monto de dinero que se le factura a nuestros clientes es funciÃ³n del peso del pescado que reciben. En segundo lugar, la empresa de transporte con la que trabajamos tiene diferentes bandas tarifarias segÃºn el peso de la mercaderÃ­a transportada, y algunas de estas bandas pueden resultar bastante caras.\n\nEl problema es que nuestra empresa compra pescados al por mayor, por lo que se sabe el peso total del pedido, pero no el de los pescados individualmente. La soluciÃ³n mas obvia consiste en pesar a cada uno de los pescados de manera manual. Pero no es una gran soluciÃ³n: pesar cada pescado manualmente es costoso, requiere mucho tiempo y mano de obra. Entonces, Â¿quÃ© podemos hacer?, Â¿ideas?\nResulta que hablando con algunos colegas descubrimos que nuestro proveedor mayorista conoce el tamaÃ±o (es decir, largo, alto y ancho) de cada pescado de manera individual. Es imposible pesar los peces en el bote, porque el bote siempre estÃ¡ en movimiento, pero tienen una cÃ¡mara que registra el tamaÃ±o de cada pez ğŸ¤¯.\nÂ¡QuÃ© noticiÃ³n! Pero eso no es todo. Nuestra empresa solÃ­a pesar cada pez manualmente antes de detenerse por razones de costo, lo que significa que tenemos un conjunto de datos de entrenamiento de diferentes tipos de peces, con su peso medido de manera precisa.\n\n\n\n\n\nEspecies de peces de todas variedades y tamaÃ±os."
  },
  {
    "objectID": "trabajos_practicos/04_tp_final.html#el-desafÃ­o",
    "href": "trabajos_practicos/04_tp_final.html#el-desafÃ­o",
    "title": "TP Final: El otro Fisher",
    "section": "El desafÃ­o",
    "text": "El desafÃ­o\nEl conjunto de datos fish-market.csv contiene la informaciÃ³n de los pescados mencionados en la introducciÃ³n e incluye mediciones sobre las siguientes variables:\n\nSpecies: Nombre de la especie del pescado\nWeight: Peso del pescado en gramos\nLength1: Longitud vertical en centÃ­metros\nLength2: Longitud diagonal en centÃ­metros\nLength3: Longitud transversal en centÃ­metros\nHeight: Altura en centÃ­metros\nWidth: Ancho diagonal en centÃ­metros\n\nEl objetivo final de este trabajo es construir un modelo regresiÃ³n bayesiano que en base a la informaciÃ³n de los pescados prediga su peso. Para ello, se recomienda que se tengan en consideraciÃ³n las siguientes pautas generales que hacen a un anÃ¡lisis bayesiano:\n\nIntroducciÃ³n\nAnÃ¡lisis exploratorio de datos\nPropuesta y ajuste de modelos\n\nDescripciÃ³n matemÃ¡tica\nElicitaciÃ³n de los priors\nPruebas predictivas a priori\nAjuste del modelo\nEvaluaciÃ³n de la convergencia de las cadenas de Markov\nExploraciÃ³n de la distribuciÃ³n a posteriori de los parÃ¡metros\nPruebas predictivas a posteriori\nEvaluaciÃ³n del ajuste del modelo\nInterpretaciÃ³n de parÃ¡metros\n\nComparaciÃ³n de modelos\nAjuste del modelo final en un conjunto de entrenamiento y predicciÃ³n sobre un conjunto de datos de evaluaciÃ³n\nAnÃ¡lisis final y conclusiÃ³n\n\nSe recomienda fuertemente que se haga uso de diferentes visualizaciones para comunicar los resultados de las diferentes etapas del anÃ¡lisis y que se propongan y evalÃºen un mÃ­nimo de tres modelos. En particular, considere que sucede a medida que se incorporan mas predictores e interacciones entre los mismos."
  },
  {
    "objectID": "trabajos_practicos/01_tp1.html",
    "href": "trabajos_practicos/01_tp1.html",
    "title": "TP1: AplicaciÃ³n de modelos conjugados a reviews de Google Maps",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "trabajos_practicos/01_tp1.html#descubriendo-la-distribuciÃ³n-de-dirichlet",
    "href": "trabajos_practicos/01_tp1.html#descubriendo-la-distribuciÃ³n-de-dirichlet",
    "title": "TP1: AplicaciÃ³n de modelos conjugados a reviews de Google Maps",
    "section": "Descubriendo la distribuciÃ³n de Dirichlet",
    "text": "Descubriendo la distribuciÃ³n de Dirichlet\nLa distribuciÃ³n Dirichlet es en realidad una familia de distribuciones. Se trata de una familia de distribuciones de probabilidad continuas y multivariadas. La distribuciÃ³n de Dirichlet en \\(K \\geq 2\\) es la distribuciÃ³n de probabilidad del vector aleatorio \\(X=[X_1, X_2 \\dots, X_K]\\) dimensiones tiene como parÃ¡metro al vector \\(\\mathbf{\\alpha} = [\\alpha_1, \\alpha_2, \\dots,\\alpha_K]\\).\n\\[\nf(x_1,x_2,\\dots,x_k \\mid \\alpha_1, \\alpha_2,\\dots,\\alpha_K) =\n    \\frac{1}{B(\\pmb{\\alpha})} \\prod_{i=1}^K x_i^{\\alpha_i-1}\n\\]\ndonde los \\(\\alpha_i \\in \\mathbb{R}^+\\) y \\(B(\\pmb{\\alpha})\\) es la constante que hace que la integral sea unitaria.\nEl soporte de la distribuciÃ³n Dirichlet es tal que \\(\\sum_{i=1}^{K} x_i = 1\\) y \\(x_i \\in [0,1]\\). Es decir, los \\(x_i\\) suman 1. Si consideramos, por ejemplo, \\(K=3\\), el vector \\([x_1, x_2, x_3]\\) pertenece al triÃ¡ngulo en \\(\\mathbb{R}^3\\) que tiene por vÃ©rtices a los puntos \\((1,0,0)\\), \\((0,1,0)\\) y \\((0,0,1)\\). AsÃ­, si \\(x_1=1\\) entonces \\(x_2=x_3=0\\).\nMÃ¡s simple aÃºn, cuando \\(K=2\\), el vector \\([x_1,x_2]\\) pertenece al segmento en \\(\\mathbb{R}^2\\) que tiene por extremos a los puntos \\((1,0)\\) y \\((0,1)\\).\nNotar que esta caracterÃ­stica hace que los \\(x_1, x_2, \\dots, x_K\\) puedan representar las probabilidades de un experimento con \\(K\\) resultados posibles.\nA tÃ­tulo informativo, el soporte de la distribuciÃ³n Dirichlet en \\(K\\) dimensiones es lo que se conoce como simplex (estÃ¡ndar) de \\(K-1\\) dimensiones. El \\(3\\)-simplex es un triÃ¡ngulo y el \\(2\\)-simplex es un segmento. En general, un \\(K-1\\)-simplex es la envolvente convexa de \\(K\\) vÃ©rtices y, a su vez, es la colecciÃ³n de todas las combinaciones convexas de puntos en el conjunto (Teorema de CarathÃ©odory).\nLos pÃ¡rrafos anteriores, delirantemente matemÃ¡ticos, muestran una virtud particular de la distribuciÃ³n Dirichlet de \\(K=3\\) dimensiones. Esta distribuciÃ³n, a pesar de ser de una variable aleatoria en \\(\\mathbb{R}^3\\), puede representarse perfectamente de manera grÃ¡fica en dos dimensiones (aunque utilizando un sistema de coordenadas peculiar: las coordenadas baricÃ©ntricas), como si se tratara de una distribuciÃ³n bivariada.\n\n\n\n\n\nComo los valores posibles del vector aleatorio tridimensional yacen en un plano, la distribuciÃ³n de probabilidad puede representarse grÃ¡ficamente con facilidad\n\n\n\n\n\n\nMostrar que, cuando \\(K=2\\), la distribuciÃ³n de Dirichlet es la distribuciÃ³n beta de parÃ¡metros \\(a=\\alpha_1\\) y \\(b=\\alpha_2\\)"
  },
  {
    "objectID": "trabajos_practicos/01_tp1.html#relaciÃ³n-entre-la-distribuciÃ³n-dirichlet-y-la-multinomial",
    "href": "trabajos_practicos/01_tp1.html#relaciÃ³n-entre-la-distribuciÃ³n-dirichlet-y-la-multinomial",
    "title": "TP1: AplicaciÃ³n de modelos conjugados a reviews de Google Maps",
    "section": "RelaciÃ³n entre la distribuciÃ³n Dirichlet y la multinomial",
    "text": "RelaciÃ³n entre la distribuciÃ³n Dirichlet y la multinomial\nCuando un experimento puede tener dos resultados posibles, uno de ellos tiene probabilidad \\(p\\) y el otro probabilidad \\(1-p\\). Si coleccionamos \\(N\\) realizaciones independientes del experimento, el nÃºmero de Ã©xitos es una variable aleatoria con distribuciÃ³n binomial. Estudiamos que era natural utilizar la distribuciÃ³n beta como distribuciÃ³n a priori para \\(p\\), dado que la distribuciÃ³n a posterioriÂ tambiÃ©n era beta.\nAnÃ¡logamente, cuando un experimento puede tener tres resultados posibles, el primero tiene probabilidad \\(p_1\\), el segundo tiene probabilidad \\(p_2\\) y el tercero, probabilidad \\(p_3 = p_1 - p_2\\). Necesariamente debe ser \\(p_1 + p_2 + p_3 = 1\\). Si coleccionamos \\(N\\) realizaciones independientes del experimento, el nÃºmero de ocurrencias de cada resultado posible es un vector aleatorio con distribuciÃ³n multinomial. Por lo visto hasta aquÃ­, todo parece indicar que, si queremos realizar inferencias sobre \\(p_1\\), \\(p_2\\) y \\(p_3\\), serÃ­a natural utilizar la distribuciÃ³n Dirichlet de tres dimensiones como distribuciÃ³n a priori para las probabilidadesâ€¦\nEn efecto, cuando la distribuciÃ³n a priori es Dirichlet y la verosimilitud es multinomial, la distribuciÃ³n a posteriori tambiÃ©n es Dirichlet.\n\nSabemos que para una verosimilitud binomial, si la distribuciÃ³n a priori de la probabilidad de Ã©xito \\(p\\) es beta de parÃ¡metros \\(a\\) y \\(b\\) y se observan \\(s\\) Ã©xitos en \\(N\\) intentos independientes, la distribuciÃ³n a posteriori es beta de parÃ¡metros \\(a' = a + s\\) y \\(b' = b + (N - s)\\).\nHallar, por analogÃ­a con el caso anterior, los parÃ¡metros de la distribuciÃ³n a posteriori que se obtiene si la verosimilitud es multinomial con tres resultados posibles, la distribuciÃ³n a prioriÂ es Dirichlet de parÃ¡metros \\([\\alpha_1, \\alpha_2, \\alpha_3]\\) y se obtuvieron \\(s_1\\) veces el primer resultado y \\(s_2\\) veces el segundo resultado, sobre un total de \\(N\\) intentos."
  },
  {
    "objectID": "trabajos_practicos/01_tp1.html#aplicaciÃ³n",
    "href": "trabajos_practicos/01_tp1.html#aplicaciÃ³n",
    "title": "TP1: AplicaciÃ³n de modelos conjugados a reviews de Google Maps",
    "section": "AplicaciÃ³n",
    "text": "AplicaciÃ³n\nAsumiremos ahora que las reviews de un local tienen distribuciÃ³n multinomial de parÃ¡metros \\([p_1, p_2, \\dots, p_5]\\). Es decir, la probabilidad de que un usuario asigne 1â­ es \\(p_1\\), de que asigne 2â­ es \\(p_2\\), y asÃ­ sucesivamente. Llamaremos \\(n_1\\) al nÃºmero de calificaciones de 1â­, \\(n_2\\) al nÃºmero de calificaciones de 2â­, y asÃ­ sucesivamente. \\(n_1 + n_2 + n_3 + n_4 + n_5 = N\\) serÃ¡ el nÃºmero total de reviews.\nSe puede verificar que el nÃºmero esperado de reviews de \\(i\\)â­ serÃ¡ \\(N p_i\\). Por lo tanto, la puntuaciÃ³n esperada serÃ¡:\n\\[\n\\frac{1}{N} (1\\cdot N p_1 + 2\\cdot N p_2 + 3\\cdot N p_3 + 4\\cdot N p_4 +5\\cdot N p_5) =\n    \\sum_{i=1}^5 i \\cdot p_i\n\\]\n\nElija dos combinaciones de posibles valores de \\(p_i\\) que den un valor esperado de 4.1â­. Piense en una combinaciÃ³n que represente acuerdo entre los clientes y otra que indique la presencia de opiniones dispares.\nEscriba una funciÃ³n que, dada una combinaciÃ³n de valores de \\(p_i\\), simule el proceso de calificaciÃ³n de un cliente.\nConstruya una funciÃ³n que simule la calificaciÃ³n de \\(U\\) clientes.\nSimule 1000 veces el proceso de 15 clientes que evalÃºan una cafeterÃ­a de 4.1â­ y el proceso de 100 clientes que evalÃºan la misma cafeterÃ­a. Â¿QuÃ© se observa?\n\nUtilizaremos este nuevo modelo para realizar inferencias sobre las puntuaciones de Arto y Orlan.\nPara obtener muestras de una distribuciÃ³n Dirichlet, puede utilizar la funciÃ³n rdirichlet de alguno de los siguientes paquetes: {LaplacesDemon}, {rBeta2009}, {gtools}.\n\nLos datos se generan siguiendo una distribuciÃ³n multinomial. Â¿CuÃ¡les son los parÃ¡metros de esa distribuciÃ³n multinomial? Â¿QuÃ© distribuciÃ³n a priori serÃ­a conveniente utilizar? Â¿CÃ³mo estÃ¡ parametrizada esa distribuciÃ³n a priori?\nElija los parÃ¡metros de la distribuciÃ³n a priori de modo tal que la creencia inicial sea uniforme sobre los posibles valores de los \\(p_i\\). Â¿QuÃ© implicancias tiene para la puntuaciÃ³n en â­ la distribuciÃ³n a priori elegida?\nCon los datos de la introducciÃ³n, obtenga la distribuciÃ³n a posteriori de los \\(p_i\\) para cada cafeterÃ­a.\nÂ¿CuÃ¡l es la probabilidad de que Orlan sea mejor que Arto?\nÂ¿CÃ³mo cambiarÃ­a el resultado si cada cafeterÃ­a tuviera diez veces menos reviews?"
  },
  {
    "objectID": "trabajos_practicos/02_tp2.html",
    "href": "trabajos_practicos/02_tp2.html",
    "title": "TP2: ImplementaciÃ³n del algoritmo de Metropolis-Hastings",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "trabajos_practicos/02_tp2.html#metropolis-hastings-en-2d",
    "href": "trabajos_practicos/02_tp2.html#metropolis-hastings-en-2d",
    "title": "TP2: ImplementaciÃ³n del algoritmo de Metropolis-Hastings",
    "section": "Metropolis-Hastings en 2D",
    "text": "Metropolis-Hastings en 2D\nSe desean tomar muestras de una normal bivariada asimÃ©trica cuya funciÃ³n de densidad viene dada por\n\\[\nf(\\mathbf{x}) =\n    2\\ \\phi_2(\\mathbf{x} \\mid \\mathbf{0}, \\pmb{\\Omega})\n    \\ \\Phi(\\pmb{\\alpha}^T\\mathbf{x})\n    \\qquad \\mathbf{x} \\in \\mathbb{R}^2\n\\]\nsiendo \\(\\phi_2(\\mathbf{x}\\mid\\mathbf{0},\\mathbf{\\Omega})\\) la funciÃ³n de densidad de la normal bivariada de media \\(\\mathbf{0}\\) y matriz de covarianza \\(\\mathbf{\\Omega}\\), \\(\\Phi(\\pmb{\\alpha}^T\\mathbf{x})\\) es la funciÃ³n de probabilidad acumulada de la normal estÃ¡ndar \\(\\mathcal{N}(0,1)\\) y \\(\\pmb{\\alpha} \\in \\mathbb{R}^2\\) es un vector de parÃ¡metros.\n\nEn este caso, se tiene:\n\\[\n\\mathbf{\\Omega} = \\begin{bmatrix}1.5 & 0.6 \\\\ 0.6 & 1.5 \\end{bmatrix}\n\\]\ny\n\\[\n\\pmb{\\alpha} = [2 \\quad 0]\n\\]\n\n\n\n\n\nFunciÃ³n de densidad de la que se desean obtener muestras\n\n\n\n\n\nEscriba una funciÃ³n que implemente el algoritmo de Metropolis-Hastings para tomar muestras de una funciÃ³n de probabilidad bivariada dada. Separe en funciones cada una de los pasos del algoritmo. La probabilidad de salto serÃ¡ normal bivariada de matriz de covarianza variable. Otorgue flexibilidad al algoritmo haciendo que reciba como argumento la matriz de covarianza de la probabilidad de transiciÃ³n.\n\nSe utilizarÃ¡ una normal bivariada para proponer un salto en el algoritmo de Metropolis-Hastings (utilizar para ello la funciÃ³n rmvnorm del paquete {mvtnorm}. Se explorarÃ¡ el efecto de diferentes distribuciones de probabilidad para el salto, en funciÃ³n de diferentes matrices de covarianza \\(\\mathbf{\\Sigma}\\). Si se representa a \\(\\mathbf{\\Sigma}\\) de la siguiente manera\n\\[\n\\mathbf{\\Sigma} =\n    \\begin{bmatrix} \\sigma_1 & 0 \\\\ 0 & \\sigma_2 \\end{bmatrix}\n    \\begin{bmatrix} 1 & \\rho \\\\ \\rho & 1\\end{bmatrix}  \n    \\begin{bmatrix} \\sigma_1 & 0 \\\\ 0 & \\sigma_2 \\end{bmatrix}\n\\]\ndonde \\(\\sigma_i\\) representa el desvÃ­o estÃ¡ndar de la componente \\(i\\) y \\(\\rho\\) la correlaciÃ³n entre las variables \\(X_1\\) y \\(X_2\\), entonces se deberÃ¡n ensayar los siguientes casos:\n\n\\(\\sigma_1 = \\sigma_2\\) y \\(\\rho = 0\\)\n\\(\\sigma_1 > \\sigma_2\\) y \\(\\rho = 0\\)\n\\(\\sigma_1 < \\sigma_2\\) y \\(\\rho = 0\\)\n\\(\\sigma_1 = \\sigma_2\\) y \\(\\rho > 0\\)\n\\(\\sigma_1 = \\sigma_2\\) y \\(\\rho < 0\\)\n\n\nPara al menos dos de los cinco casos anteriores, comparar las trayectorias seguidas por las cadenas al obtener muestras de \\(f(x)\\)."
  },
  {
    "objectID": "teoria/u3_teoria_05.html",
    "href": "teoria/u3_teoria_05.html",
    "title": "Unidad 3 - MÃ©todos Computacionales",
    "section": "",
    "text": "Instrucciones para guardar como PDF\n\nHacer clic acÃ¡\nAbrir la ventana de impresiÃ³n del navegador con CTRL+P\nSi es necesario, cambiar el â€œDestinoâ€ a â€œGuardar como PDFâ€\nCliquear en â€œGuardarâ€\nElegir el nombre del archivo de destino\nÂ¡Listo! ğŸ‰"
  },
  {
    "objectID": "teoria/u4_teoria_06.html",
    "href": "teoria/u4_teoria_06.html",
    "title": "Unidad 4 - Modelos Lineales",
    "section": "",
    "text": "Instrucciones para guardar como PDF\n\nHacer clic acÃ¡\nAbrir la ventana de impresiÃ³n del navegador con CTRL+P\nSi es necesario, cambiar el â€œDestinoâ€ a â€œGuardar como PDFâ€\nCliquear en â€œGuardarâ€\nElegir el nombre del archivo de destino\nÂ¡Listo! ğŸ‰"
  },
  {
    "objectID": "teoria/u1_teoria_02.html",
    "href": "teoria/u1_teoria_02.html",
    "title": "Unidad 1 - Inferencia Bayesiana",
    "section": "",
    "text": "Instrucciones para guardar como PDF\n\nHacer clic acÃ¡\nAbrir la ventana de impresiÃ³n del navegador con CTRL+P\nSi es necesario, cambiar el â€œDestinoâ€ a â€œGuardar como PDFâ€\nCliquear en â€œGuardarâ€\nElegir el nombre del archivo de destino\nÂ¡Listo! ğŸ‰"
  },
  {
    "objectID": "teoria/u2_teoria_04.html",
    "href": "teoria/u2_teoria_04.html",
    "title": "Unidad 2 - TeorÃ­a de la DecisiÃ³n",
    "section": "",
    "text": "Instrucciones para guardar como PDF\n\nHacer clic acÃ¡\nAbrir la ventana de impresiÃ³n del navegador con CTRL+P\nSi es necesario, cambiar el â€œDestinoâ€ a â€œGuardar como PDFâ€\nCliquear en â€œGuardarâ€\nElegir el nombre del archivo de destino\nÂ¡Listo! ğŸ‰"
  },
  {
    "objectID": "teoria/u5_teoria_07.html",
    "href": "teoria/u5_teoria_07.html",
    "title": "Unidad 5 - Modelos Avanzados",
    "section": "",
    "text": "Instrucciones para guardar como PDF\n\nHacer clic acÃ¡\nAbrir la ventana de impresiÃ³n del navegador con CTRL+P\nSi es necesario, cambiar el â€œDestinoâ€ a â€œGuardar como PDFâ€\nCliquear en â€œGuardarâ€\nElegir el nombre del archivo de destino\nÂ¡Listo! ğŸ‰"
  },
  {
    "objectID": "teoria/u5_teoria_08.html",
    "href": "teoria/u5_teoria_08.html",
    "title": "Unidad 5 - Modelos JerÃ¡rquicos",
    "section": "",
    "text": "Instrucciones para guardar como PDF\n\nHacer clic acÃ¡\nAbrir la ventana de impresiÃ³n del navegador con CTRL+P\nSi es necesario, cambiar el â€œDestinoâ€ a â€œGuardar como PDFâ€\nCliquear en â€œGuardarâ€\nElegir el nombre del archivo de destino\nÂ¡Listo! ğŸ‰"
  },
  {
    "objectID": "teoria/u1_teoria_01.html",
    "href": "teoria/u1_teoria_01.html",
    "title": "Unidad 1 - IntroducciÃ³n",
    "section": "",
    "text": "Instrucciones para guardar como PDF\n\nHacer clic acÃ¡\nAbrir la ventana de impresiÃ³n del navegador con CTRL+P\nSi es necesario, cambiar el â€œDestinoâ€ a â€œGuardar como PDFâ€\nCliquear en â€œGuardarâ€\nElegir el nombre del archivo de destino\nÂ¡Listo! ğŸ‰"
  },
  {
    "objectID": "teoria/u2_teoria_03.html",
    "href": "teoria/u2_teoria_03.html",
    "title": "Unidad 2 - Distribuciones Conjugadas",
    "section": "",
    "text": "Instrucciones para guardar como PDF\n\nHacer clic acÃ¡\nAbrir la ventana de impresiÃ³n del navegador con CTRL+P\nSi es necesario, cambiar el â€œDestinoâ€ a â€œGuardar como PDFâ€\nCliquear en â€œGuardarâ€\nElegir el nombre del archivo de destino\nÂ¡Listo! ğŸ‰"
  },
  {
    "objectID": "complementario/variables.html",
    "href": "complementario/variables.html",
    "title": "Repaso de Variables Aleatorias",
    "section": "",
    "text": "Variables aleatorias\n\nDiscretas\nContinuas\n\nCDF\nPDF\nDistribucion conjunta\nDistribucion marginal\nDistribucion condicional\nIndependencia e independencia condicional\nMomentos de una distribucion\nRegla de Bayes\nDistribuciones de probabilidad frecuentemente utilizadas\nTransformacion de variables aleatorias\n\nPropiedades de transformaciones lineales\n\n\nEste listado esta sacado del capitulo 2 de Murphy (2022)\nTambien hay cosas interesantes en capitulo 3 de Murphy (2022)\n\nUncorrelated does not imply independent\nCorrelation does not imply causation\n\n\nPairwise independence does not imply mutual independence\nWe say that two random variables are pairwise independent if \\(p(X_2|X_1) = p(X_2)\\) and hence \\(p(X_2, X_1) = p(X_1)p(X_2|X_1) = p(X_1)p(X_2)\\)\nWe say that \\(n\\) random variables are mutually independent if \\(p(Xi|XS) = p(Xi)\\) \\(\\forall S \\subseteq \\{1, \\cdots , n\\}\\) and hence \\(\\displaystyle p(X_{1:n}) = \\prod_{i=1}^{n} p(X_i)\\)\nShow that pairwise independence between all pairs of variables does not necessarily imply mutual independence. It suffices to give a counter example.\nExercise 2.5 Murphy (2022)\nExercise 2.6 Murphy (2022)\nExercise 3.5 [Gaussian vs jointly Gaussian ]\n\n\n\n\n\nReferencias\n\nMurphy, Kevin P. 2022. Probabilistic Machine Learning: An Introduction. 1st edition. The MIT Press. https://probml.ai/."
  },
  {
    "objectID": "recursos/codigo/index.html",
    "href": "recursos/codigo/index.html",
    "title": "CÃ³digo",
    "section": "",
    "text": "Esta secciÃ³n contiene scripts de R que son de utilidad para el curso.\n\n\n\n01 - Rocklets discretos02 - Diferentes observaciones, diferentes posteriors03 - FunciÃ³n de verosimilitud Poisson04 - DistribuciÃ³n de Dirichlet05 - Propiedades frecuentistas de inferencias bayesianas06 - Te veo en la fotocopiadora07 - Bolas infinitas08 - AproximaciÃ³n de grilla en 2 dimensiones09 - Hamiltonian Monte Carlo para normal bivariada10 - Random-Walk Metropolis-Hastings en 2 dimensiones11 - RegresiÃ³n lineal simple con {brms}12 - Guardar y leer modelos de {brms}13 - RegresiÃ³n logÃ­stica con {brms}"
  },
  {
    "objectID": "recursos/codigo/10_rwmh_2d.html",
    "href": "recursos/codigo/10_rwmh_2d.html",
    "title": "10 - Random-Walk Metropolis-Hastings en 2 dimensiones",
    "section": "",
    "text": "El siguiente cÃ³digo es de utilidad para resolver con R el ejercicio Metropolis-Hastings multivariado de la PrÃ¡ctica 3.\n\nlibrary(ggplot2)\nlibrary(mvtnorm)\n\n# Cantidad de muestras a obtener\nn <- 5000\n\n# ParÃ¡metros de la distribuciÃ³n a muestrear\nMu_objetivo <- c(1.2, 0.8)\nSigma_objetivo <- matrix(c(3, 0.2, 0.2, 2), ncol = 2)\n\n# Matriz de dimensiÃ³n (n, 2) que va a contener las muestras\nmuestras <- matrix(NA, nrow = n, ncol = 2)\n\n# El punto inicial es el (0, 0)\nmuestras[1, ] <- c(0, 0)\n\n# Matriz de varianza de la distribuciÃ³n de propuesta\nSigma_propuesta <- diag(2) * 0.2\n\nfor (i in 2:n) {\n    # Proponer un nuevo valor\n    propuesta <- rmvnorm(1, mean = muestras[i - 1, ], sigma = Sigma_propuesta)\n    \n    # Evaluar la funciÃ³n de densidad en el valor actual y en el propuesto\n    f_propuesta <- dmvnorm(propuesta, Mu_objetivo, Sigma_objetivo)\n    f_actual <- dmvnorm(muestras[i - 1, ], Mu_objetivo, Sigma_objetivo)\n    \n    # Calcular probabilidad de aceptaciÃ³n\n    alpha <- min(c(1, f_propuesta / f_actual))\n    \n    # Determinar aceptaciÃ³n de propuesta\n    aceptar <- rbinom(1, 1, alpha)\n\n    # Seleccionar nueva muestras \n    if (aceptar) {\n        muestras[i, ] <- propuesta\n    } else {\n        muestras[i, ] <- muestras[i - 1, ]\n    }\n}\n\n# Obtener las muestras como data.frame\ndf <- as.data.frame(muestras)\ncolnames(df) <- c(\"y1\", \"y2\")\ndf$x <- 1:n\n\n# Graficar muestras en el plano\nggplot(df) +\n    geom_point(aes(x = y1, y = y2), alpha = 0.6)\n\n\n\n\n\n\n\n# Obtener una visualizaciÃ³n de la densidad empÃ­rica\nggplot(df, aes(x = y1, y = y2)) + \n    stat_density2d(\n        geom = \"raster\",\n        aes(fill = after_stat(density)),\n        contour = FALSE\n    ) + \n    scale_fill_viridis_c()\n\n\n\n\n\n\n\n# Graficar las trazas de ambas variables\ntidyr::pivot_longer(df, c(\"y1\", \"y2\"), names_to = \"variable\") |>\n    ggplot() + \n        geom_line(aes(x = x, y = value, color = variable)) + \n        facet_wrap(~ variable, ncol = 1)"
  },
  {
    "objectID": "recursos/codigo/08_grid_2d.html",
    "href": "recursos/codigo/08_grid_2d.html",
    "title": "08 - AproximaciÃ³n de grilla en 2 dimensiones",
    "section": "",
    "text": "El siguiente programa muestra como se puede resolver en R el ejercicio AproximaciÃ³n de grilla en 2 dimensiones de la PrÃ¡ctica 3.\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\nset.seed(121195)\n\n# GeneraciÃ³n de datos\nalpha <- 1\nbeta <- -2\nsigma <- 0.8\nn <- 80\nx <- rnorm(n)\ny <- rnorm(n, alpha + beta * x, sigma)\ndf <- data.frame(x = x, y = y)\n\n# Crear grilla para alfa y beta\ngrid_a <- seq(0.5, 1.5, length.out = 50)\ngrid_b <- seq(-2.5, -1.5, length.out = 50)\n\n# Crear todas las combinaciones entre los valores de las dos grillas\ngrid_df <- expand.grid(grid_a, grid_b)\n\n# Utilizar nombres indicativos\nnames(grid_df) <- c(\"a\", \"b\")\n\n# Crear vectores que van a contener los valores de la\n# funciÃ³n de verosimilitud y del posterior\nlikelihood <- numeric(nrow(grid_df))\nposterior <- numeric(nrow(grid_df))\n\n# Calcular la funciÃ³n de verosimilitud en cada punto\nfor (i in seq_along(likelihood)) {\n    likelihood[i] <- prod(dnorm(y, grid_df$a[i] + grid_df$b[i] * x, sigma))\n}\n# Calcular el posterior en cada punto\nposterior <- (\n    likelihood \n    * dnorm(grid_df$a, mean = 0, sd = 1.5) # alpha ~ Normal(0, 1.5)\n    * dnorm(grid_df$b, mean = 0, sd = 2)   # beta ~ Normal(0, 2)\n)\n\n# Escalar el posterior para que sea propio\nposterior <- posterior / sum(posterior)\n\n# Incorporar likelihood y posterior al data frame\ngrid_df$likelihood <- likelihood\ngrid_df$posterior <- posterior\n\n# Graficar con ggplot\nggplot(grid_df, aes(x = a, y = b)) +\n    geom_raster(aes(fill = posterior)) +\n    stat_contour(aes(z = posterior), col = \"white\", bins = 5) +\n    geom_point(x = alpha, y = beta, color = \"black\", fill = \"red\", size = 3, pch = 21) +\n    labs(x = expression(alpha), y = expression(beta)) +\n    viridis::scale_fill_viridis() +\n    theme(legend.position = \"none\") +\n    scale_x_continuous(expand = c(0, 0)) +\n    scale_y_continuous(expand = c(0, 0))\n\n\n\n\nDistribuciÃ³n a posteriori evaluada en una grilla de 50Ã—50 puntos. El punto indica los valores de \\(\\alpha\\) y \\(\\beta\\) utilizados para generar los datos.\n\n\n\nposterior_a_df <- grid_df |>\n    group_by(a) |>\n    summarise(p = sum(posterior))\n\nggplot(posterior_a_df) +\n    geom_segment(aes(x = a, xend = a, y = 0, yend = p)) +\n    geom_point(aes(x = a, y = p)) +\n    labs(x = expression(alpha), y = \"p(Î± | y)\")\n\n\n\n\nDistribuciÃ³n marginal de \\(\\alpha\\).\n\n\n\nposterior_b_df <- grid_df |>\n    group_by(b) |>\n    summarise(p = sum(posterior))\n\nggplot(posterior_b_df) +\n    geom_segment(aes(x = b, xend = b, y = 0, yend = p)) +\n    geom_point(aes(x = b, y = p)) +\n    labs(x = expression(beta), y = \"p(Î² | y)\")\n\n\n\n\nDistribuciÃ³n marginal de \\(\\beta\\).\n\n\n\n# P(alpha > 0.95)\nsum(posterior_a_df$p[posterior_a_df$a > 0.95])\n\n[1] 0.7292537\n\n# P(beta < -2)\nsum(posterior_b_df$p[posterior_b_df$b < -2])\n\n[1] 0.1204088"
  },
  {
    "objectID": "recursos/codigo/03_likelihood_poisson.html",
    "href": "recursos/codigo/03_likelihood_poisson.html",
    "title": "03 - FunciÃ³n de verosimilitud Poisson",
    "section": "",
    "text": "Este programa grafica la funciÃ³n de verosimilitud cuando se obtiene una muestra de \\(n\\) realizaciones independientes de una distribuciÃ³n Poisson. Se utiliza en el ejercicio El modelo Gamma-Poisson de la PrÃ¡ctica 2.\n\\[\n\\begin{array}{lcc}\nX \\sim \\text{Poisson}(\\lambda), & \\lambda > 0, & X \\in \\{0, 1, 2, \\cdots \\}\n\\end{array}\n\\]\n\\[\np(x \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^x}{x!}\n\\]\n\\[\n\\ell(\\theta \\mid x_1, x_2, \\cdots, x_n) = p(\\mathbf{x} \\mid \\theta)\n    = \\prod_{i=1}^{n} p(x_i \\mid \\lambda)\n    = \\prod_{i=1}^{n} \\frac{e^{-\\lambda} \\lambda^{x_i}}{x_i!}\n    = \\frac{e^{- n \\lambda} \\lambda^{\\sum_i x_i}}{\\prod_i x_i!}\n\\]\n\n# Cantidad de mensajes observados\nmensajes <- c(7, 3, 8, 9, 10, 12)\n\n# OpciÃ³n 1: Escribiendo la funciÃ³n de verosimilitud analÃ­ticamente\nn <- length(mensajes)\ntotal <- sum(mensajes)\nproducto_factoriales <- prod(factorial(mensajes))\n\n# Grilla de valores para 'lambda'\n# TeorÃ©ticamente, el soporte del parÃ¡metro es (0, infty). Lo acotamos en 20.\nlambda <- seq(0, 20, length.out = 200)\n\n# CÃ¡lculo de la verosimilitud\nverosimilitud <- exp(-n * lambda) * lambda ^ total / producto_factoriales\n\n# VisualizaciÃ³n de la verosimilitud para los valores de lambda en la grilla\nplot(lambda, verosimilitud, type = \"l\")\n\n# OpciÃ³n 2: Utilizando 'dpois'.\n# Para cada valor observado, se evalÃºa la pmf de la Poisson en una grilla\n# de valores de lambda.\n# Luego se multiplican los resultados de la pmf en los valores observados,\n# para cada valor de lambda.\n# Nota: Hay que verificar bien que R estÃ¡ reciclando los argumentos de\n# la manera esperada\nmensajes_matriz <- matrix(rep(mensajes, 200), nrow = 200, byrow = TRUE)\npmf <- dpois(mensajes_matriz, lambda)\nverosimilitud <- apply(pmf, 1, prod)\nplot(lambda, verosimilitud, type = \"l\")"
  },
  {
    "objectID": "recursos/codigo/11_regresion_lineal_brms.html",
    "href": "recursos/codigo/11_regresion_lineal_brms.html",
    "title": "11 - RegresiÃ³n lineal simple con {brms}",
    "section": "",
    "text": "El siguiente programa muestra el cÃ³digo necesario para con R los ejercicios Mi primer regresiÃ³n bayesiana y Mejorando mi regresiÃ³n bayesiana de la PrÃ¡ctica 4.\n\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# Cargar librerÃ­as necesarias\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \nlibrary(brms)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(readr)\n\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# Ejercicio 1\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n# Leer los datos desde el repositorio\ndf_sales <- read_csv(\n    \"https://raw.githubusercontent.com/estadisticaunr/estadistica-bayesiana/main/datos/sales.csv\"\n)\n\n# Explorar los datos\nggplot(df_sales) +\n  geom_point(aes(x = x, y = y), alpha = 0.6, size = 2) +\n  labs(x = \"publicidad\", y = \"ventas\")\n\n\n\n\n\n\n\n# Crear modelo con brms\n# refresh = 0 es para que no muestre los mensajes del sampler\nmodelo_1 <- brm(y ~ x, df_sales, refresh = 0)\n\n# Mostrar salida por defecto\nmodelo_1\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: y ~ x \n   Data: df_sales (Number of observations: 52) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     5.42      0.47     4.52     6.32 1.00     3613     2582\nx             0.29      0.04     0.21     0.36 1.00     3667     2519\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     1.20      0.12     0.99     1.46 1.00     3085     2673\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n# Obtener las muestras del posterior como un data frame\ndf_draws_1 <- as_draws_df(modelo_1)\n\n# Calcular la media a posteriori del intercepto y la pendiente\nintercept_mean <- mean(df_draws_1$b_Intercept)\nslope_mean <- mean(df_draws_1$b_x)\n\n# Utilizar estos dos valores para graficar la media de la recta de regresiÃ³n\nggplot(df_sales) + \n  geom_point(aes(x = x, y = y), alpha = 0.6, size = 2) +\n  geom_abline(\n    intercept = intercept_mean, \n    slope = slope_mean, \n    linewidth = 1, \n    color = \"red\"\n  ) +\n  labs(x = \"publicidad\", y = \"ventas\")\n\n\n\n\n\n\n\n# Graficar rectas utilizando algunas muestras del posterior\n# Da una idea de la variabilidad en la estimaciÃ³n\nggplot(df_sales) +\n  geom_point(aes(x = x, y = y), alpha = 0.6, size = 2) +\n  geom_abline(\n    aes(intercept = b_Intercept, slope = b_x),\n    alpha = 0.3,\n    color = \"gray30\",\n    data = df_draws_1[sample(nrow(df_draws_1), 40), ]\n  ) +\n  geom_abline(\n    intercept = intercept_mean, \n    slope = slope_mean, \n    linewidth = 1, \n    color = \"red\"\n  ) +\n  labs(x = \"publicidad\", y = \"ventas\")\n\n\n\n\n\n\n\n# Lo siguiente es un enfoque posible, y bastante manual, para graficar\n# los posteriors marginales del intercepto y la pendiente\ndf_draws_long_1 <- df_draws_1 |>\n  select(b_Intercept, b_x) |>\n  tidyr::pivot_longer(c(\"b_Intercept\", \"b_x\"), names_to = \"parametro\")\n\nggplot(df_draws_long_1) +\n  geom_histogram(aes(x = value, y = after_stat(density)), bins = 40) +\n  facet_wrap(~ parametro, scales = \"free\")\n\n\n\n\n\n\n\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# Ejercicio 2\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nmean_y <- mean(df_sales$y) # ~ 8.75\n\n# Especificar los priors\npriors <- c(\n  prior(normal(8.75, 10), class = \"Intercept\"),\n  prior(normal(0, 0.5), class = \"b\", coef = \"x\"),\n  prior(normal(0, 5), class = \"sigma\") # Opcional: lb = 0\n)\n\n# Especificar y ajustar el modelo\nmodelo_2 <- brm(y ~ x, df_sales, prior = priors, refresh = 0)\nmodelo_2\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: y ~ x \n   Data: df_sales (Number of observations: 52) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     5.46      0.47     4.51     6.39 1.00     3518     3090\nx             0.29      0.04     0.21     0.36 1.00     3407     3014\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     1.20      0.12     0.99     1.46 1.00     3419     2934\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n# Lo siguiente permite obtener un resumen de los priors utilizados\nprior_summary(modelo_2)\n\n            prior     class coef group resp dpar nlpar lb ub  source\n           (flat)         b                                  default\n   normal(0, 0.5)         b    x                                user\n normal(8.75, 10) Intercept                                     user\n     normal(0, 5)     sigma                             0       user\n\n# {brms} provee funciones para generar visualizaciones frecuentemente utilizadas\n# Muestra los posteriors marginales y las trazas de las cadenas\nplot(modelo_2)\n\n\n\n\n\n\n\n# Muestra los posteriors marginales y graficos de dispersiÃ³n\n# para evaluar la relaciÃ³n entre los parÃ¡metros\npairs(modelo_2, off_diag_args = list(size = 1/3, alpha = 1/3))\n\n\n\n\n\n\n\n# Crear nuevo conjunto de datos para obtener predicciones (y visualizaciones)\nx_min <- min(df_sales$x)\nx_max <- max(df_sales$x)\ndf_new <- data.frame(x = seq(x_min, x_max, length.out = 100))\n\n# Predecir la media (obtener posterior de mu)\ndf_new_mean <- fitted(modelo_2, newdata = df_new) |>\n  as.data.frame() |>\n  bind_cols(df_new) |>\n  select(estimate = Estimate, lower = Q2.5, upper = Q97.5, x)\n\n# Mostrar el intervalo de credibilidad para la recta de regresiÃ³n\nggplot(df_new_mean) + \n  geom_ribbon(\n    aes(x = x, ymin = lower, ymax = upper), \n    fill = \"grey80\", \n    alpha = 0.8\n  ) +\n  geom_line(aes(x = x, y = estimate), linewidth = 1, color = \"red\") + \n  geom_point(aes(x = x, y = y), alpha = 0.6, size = 2, data = df_sales) +\n  labs(x = \"publicidad\", y = \"ventas\")\n\n\n\n\n\n\n\n# Predecir nuevas observaciones (obtener predictiva a posteriori)\ndf_new_predict <- predict(modelo_2, newdata = df_new) |>\n  as.data.frame() |>\n  bind_cols(df_new) |>\n  select(estimate = Estimate, lower = Q2.5, upper = Q97.5, x)\n\n# Mostrar el intervalo de credibilidad para la recta de regresiÃ³n \n# y para nuevas observaciones\nggplot(df_new_mean) + \n  geom_ribbon(\n    aes(x = x, ymin = lower, ymax = upper),\n    fill = \"grey80\",\n    data = df_new_predict\n  ) +\n  geom_ribbon(\n    aes(x = x, ymin = lower, ymax = upper), \n    fill = \"grey50\", \n    alpha = 0.8\n  ) +\n  geom_line(aes(x = x, y = estimate), linewidth = 1, color = \"red\") + \n  geom_point(aes(x = x, y = y), alpha = 0.6, size = 2, data = df_sales) +\n  labs(x = \"publicidad\", y = \"ventas\")\n\n\n\n\n\n\n\n\nAlgunas otras visualizaciones que se pueden generar\n\nmcmc_plot(modelo_2, type = \"hist\")\nmcmc_plot(modelo_2, type = \"neff\")\nmcmc_plot(modelo_2, type = \"rhat\")\nmcmc_plot(modelo_2, type = \"trace\")\nmcmc_plot(modelo_2, type = \"dens_overlay\")\nmcmc_plot(modelo_2, type = \"acf_bar\")"
  },
  {
    "objectID": "recursos/codigo/13_regresion_logistica_brms.html",
    "href": "recursos/codigo/13_regresion_logistica_brms.html",
    "title": "13 - RegresiÃ³n logÃ­stica con {brms}",
    "section": "",
    "text": "En este programa se muestra cÃ³digo de R utilizar con el ejercicio IntenciÃ³n de voto de la PrÃ¡ctica 5.\nLa variable respuesta \\(Y\\) se define:\n\\[\n\\begin{split}Y_i =\n\\left\\{\n    \\begin{array}{ll}\n        1 & \\text{si la persona } i \\text{ vota al candidato A} \\\\\n        0 & \\text{si la persona } i \\text{ vota al candidato B}\n    \\end{array}\n\\right.\\end{split}\n\\]\nSe trabaja con los siguientes tres modelos:\n\\[\n\\begin{array}{lc}\n    \\mathcal{M}_1 &\n    \\begin{aligned}\n    \\text{logit}(p_i) &= \\beta_0 + \\beta_1 \\text{edad}_i \\\\\n    Y_i &\\sim \\text{Bernoulli}(p_i)\n    \\end{aligned} \\\\\n    \\\\\n    \\mathcal{M}_2 &\n    \\begin{aligned}\n    \\text{logit}(p_i) &= \\beta_{0, j[i]} + \\beta_1 \\text{edad}_i \\\\\n    Y_i &\\sim \\text{Bernoulli}(p_i)\n    \\end{aligned} \\\\\n    \\\\\n    \\mathcal{M}_3 &\n    \\begin{aligned}\n    \\text{logit}(p_i) &= \\beta_{0, j[i]} + \\beta_{1, j[i]} \\text{edad}_i \\\\\n    Y_i &\\sim \\text{Bernoulli}(p_i)\n    \\end{aligned}\n\\end{array}\n\\]\ndonde \\(j = 1, 2, 3\\) indexa a los diferentes partidos.\n\nlibrary(brms)\nlibrary(ggplot2)\nlibrary(dplyr)\n\nurl <- \"https://raw.githubusercontent.com/estadisticaunr/estadistica-bayesiana/main/datos/elecciones.csv\"\ndatos <- readr::read_csv(url)\n\ntabla <- table(datos$voto, datos$partido)\n\n# Distribucion conjunta\nprop.table(tabla)\n\n             \n                    azul       rojo      verde\n  candidato A 0.42627346 0.01340483 0.13672922\n  candidato B 0.04557641 0.20375335 0.17426273\n\n# Distribucion marginal 1\n# Como se componen los votos de cada candidato en terminos de las afinidades partidarias\nprop.table(tabla, margin = 1) |> round(2)\n\n             \n              azul rojo verde\n  candidato A 0.74 0.02  0.24\n  candidato B 0.11 0.48  0.41\n\n# Distribucion marginal 2\n# Como se distribuyen los votos de cada partido a los candidatos\nprop.table(tabla, margin = 2) |> round(2)\n\n             \n              azul rojo verde\n  candidato A 0.90 0.06  0.44\n  candidato B 0.10 0.94  0.56\n\n# Creamos una variable indicadora para estar seguros que 'candidato A' es el Ã©xito\ndatos$y <- ifelse(datos$voto == \"candidato A\", 1, 0)\nmodelo_1 <- brm(y ~ 1 + edad, datos, family = \"bernoulli\", refresh = 0)\nmodelo_2 <- brm(y ~ 0 + partido + edad, datos, family = \"bernoulli\", refresh = 0)\nmodelo_3 <- brm(y ~ 0 + partido + edad:partido, datos, family = \"bernoulli\", refresh = 0)\n\n\ndf_draws_1 <- as.data.frame(modelo_1$fit) |> select(-lprior, -lp__)\ndf_draws_2 <- as.data.frame(modelo_2$fit) |> select(-lprior, -lp__)\ndf_draws_3 <- as.data.frame(modelo_3$fit) |> select(-lprior, -lp__)\n\n\nedad_min <- min(datos$edad)\nedad_max <- max(datos$edad)\nedad_grid <- seq(edad_min, edad_max, length.out = 100)\npartidos <- unique(datos$partido)\n\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# Modelo 1\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsummary(modelo_1)\n\n Family: bernoulli \n  Links: mu = logit \nFormula: y ~ 1 + edad \n   Data: datos (Number of observations: 373) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     1.19      0.32     0.54     1.81 1.00     4173     2697\nedad         -0.02      0.01    -0.03    -0.01 1.00     4280     2682\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\ndf_draws_1 |>\n  tidyr::pivot_longer(\n    everything(), \n    names_to = \"coeficiente\",\n    values_to = \"valor\"\n  ) |>\n  ggplot() +\n  geom_density(aes(x = valor, color = coeficiente, fill = coeficiente)) +\n  scale_color_manual(values = c(\"#3498db\", \"#e74c3c\")) +\n  scale_fill_manual(values = c(\"#3498db\", \"#e74c3c\")) +\n  facet_wrap(~ coeficiente, scales = \"free\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\ndf_new <- data.frame(edad = edad_grid)\ndf_mean_1 <- data.frame(\n  p = as.vector(posterior_epred(modelo_1, newdata = df_new)),\n  edad = rep(edad_grid, each = 4000),\n  draw = rep(1:4000, times = length(edad_grid))\n)\n\nggplot(df_mean_1[df_mean_1$draw %in% sample(4000, 100), ]) +\n  geom_line(\n    aes(x = edad, y = p, group = draw), \n    alpha = 0.6, \n    color = \"#3498db\"\n  ) + \n  geom_line(\n    aes(x = edad, y = p),\n    color = \"grey20\",\n    linewidth = 1,\n    data = df_mean_1 |> group_by(edad) |> summarise(p = mean(p))\n  )\n\n\n\n\n\n\n\n  labs(y = \"P(voto = Candidato A)\")\n\n$y\n[1] \"P(voto = Candidato A)\"\n\nattr(,\"class\")\n[1] \"labels\"\n\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# Modelo 2\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsummary(modelo_2)\n\n Family: bernoulli \n  Links: mu = logit \nFormula: y ~ 0 + partido + edad \n   Data: datos (Number of observations: 373) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\npartidoazul      3.32      0.54     2.33     4.42 1.00      936     1007\npartidorojo     -1.80      0.64    -3.10    -0.59 1.00     1167     1646\npartidoverde     0.79      0.48    -0.12     1.75 1.00      915     1065\nedad            -0.02      0.01    -0.04    -0.00 1.00      844     1055\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\ndf_draws_2_long <- df_draws_2 |>\n  tidyr::pivot_longer(\n    everything(), \n    names_to = \"coeficiente\",\n    values_to = \"valor\"\n  ) |>\n  mutate(\n    grupo = case_when(\n      coeficiente == \"b_partidoazul\" ~ \"intercepto\",\n      coeficiente == \"b_partidorojo\" ~ \"intercepto\",\n      coeficiente == \"b_partidoverde\" ~ \"intercepto\",\n      coeficiente == \"b_edad\" ~ \"pendiente\"\n    ),\n    partido = case_when(\n      coeficiente == \"b_partidoazul\" ~ \"azul\",\n      coeficiente == \"b_partidorojo\" ~ \"rojo\",\n      coeficiente == \"b_partidoverde\" ~ \"verde\",\n      coeficiente == \"b_edad\" ~ \"global\"\n    )\n  ) |>\n  mutate(\n    partido = factor(\n      partido, levels = c(\"azul\", \"rojo\", \"verde\", \"global\"), ordered = TRUE\n    )\n  )\n\nhead(df_draws_2_long)\n\n# A tibble: 6 Ã— 4\n  coeficiente      valor grupo      partido\n  <chr>            <dbl> <chr>      <ord>  \n1 b_partidoazul   3.01   intercepto azul   \n2 b_partidorojo  -1.38   intercepto rojo   \n3 b_partidoverde  0.554  intercepto verde  \n4 b_edad         -0.0172 pendiente  global \n5 b_partidoazul   3.12   intercepto azul   \n6 b_partidorojo  -2.57   intercepto rojo   \n\nggplot(df_draws_2_long) +\n  geom_density(aes(x = valor, color = partido, fill = partido), alpha = 0.5) +\n  scale_color_manual(\n    values = c(\"#3498db\", \"#e74c3c\",\"#2ecc71\", \"#535c68\"), \n    name = \"Partido\"\n  ) +\n  scale_fill_manual(\n    values = c(\"#3498db\", \"#e74c3c\",\"#2ecc71\", \"#535c68\"),\n    name = \"Partido\"\n  ) +\n  facet_wrap(~ grupo, scales = \"free\") +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\ndf_new <- data.frame(\n  edad = rep(edad_grid, 3), \n  partido = rep(partidos, each = length(edad_grid))\n)\n\ndf_mean_2 <- data.frame(\n  p = as.vector(posterior_epred(modelo_2, newdata = df_new)),\n  edad = rep(rep(edad_grid, each = 4000), times = 3),\n  partido = rep(partidos, each = 4000 * length(edad_grid)),\n  draw = rep(1:4000, times = length(edad_grid) * length(partidos))\n)\n\nggplot(df_mean_2[df_mean_2$draw %in% sample(4000, 100), ]) +\n  geom_line(\n    aes(\n      x = edad, \n      y = p, \n      group = interaction(draw, partido), \n      color = partido\n    ), \n    alpha = 0.5\n  ) + \n  geom_line(\n    aes(x = edad, y = p, group = partido),\n    linewidth = 0.7,\n    color = \"grey20\",\n    data = df_mean_2 |> group_by(edad, partido) |> summarise(p = mean(p))\n  ) + \n  scale_color_manual(\n    values = c(\"#3498db\", \"#e74c3c\",\"#2ecc71\", \"#535c68\"), \n    name = \"Partido\"\n  ) +\n  labs(y = \"P(voto = Candidato A)\") +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# Modelo 3\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsummary(modelo_3)\n\n Family: bernoulli \n  Links: mu = logit \nFormula: y ~ 0 + partido + edad:partido \n   Data: datos (Number of observations: 373) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\npartidoazul           1.68      0.72     0.30     3.13 1.00     2121     2325\npartidorojo           0.89      1.64    -2.25     4.26 1.00     2039     1729\npartidoverde          1.40      0.62     0.22     2.58 1.00     2129     1988\npartidoazul:edad      0.01      0.02    -0.02     0.04 1.00     2137     2129\npartidorojo:edad     -0.09      0.04    -0.19    -0.02 1.00     2033     1537\npartidoverde:edad    -0.03      0.01    -0.06    -0.01 1.00     2151     1902\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\ndf_draws_3_long <- df_draws_3 |>\n  tidyr::pivot_longer(\n    everything(), \n    names_to = \"coeficiente\",\n    values_to = \"valor\"\n  ) |>\n  mutate(\n    grupo = case_when(\n      coeficiente == \"b_partidoazul\" ~ \"intercepto\",\n      coeficiente == \"b_partidorojo\" ~ \"intercepto\",\n      coeficiente == \"b_partidoverde\" ~ \"intercepto\",\n      coeficiente == \"b_partidoazul:edad\" ~ \"pendiente\",\n      coeficiente == \"b_partidorojo:edad\" ~ \"pendiente\",\n      coeficiente == \"b_partidoverde:edad\" ~ \"pendiente\"\n    ),\n    partido = case_when(\n      coeficiente %in% c(\"b_partidoazul\", \"b_partidoazul:edad\")~ \"azul\",\n      coeficiente %in% c(\"b_partidorojo\", \"b_partidorojo:edad\") ~ \"rojo\",\n      coeficiente %in% c(\"b_partidoverde\", \"b_partidoverde:edad\") ~ \"verde\",\n    )\n  ) |>\n  mutate(\n    partido = factor(\n      partido, levels = c(\"azul\", \"rojo\", \"verde\", \"global\"), ordered = TRUE\n    )\n  )\n\nhead(df_draws_3_long)\n\n# A tibble: 6 Ã— 4\n  coeficiente           valor grupo      partido\n  <chr>                 <dbl> <chr>      <ord>  \n1 b_partidoazul        1.43   intercepto azul   \n2 b_partidorojo        3.32   intercepto rojo   \n3 b_partidoverde       3.24   intercepto verde  \n4 b_partidoazul:edad   0.0130 pendiente  azul   \n5 b_partidorojo:edad  -0.156  pendiente  rojo   \n6 b_partidoverde:edad -0.0684 pendiente  verde  \n\nggplot(df_draws_3_long) +\n  geom_density(aes(x = valor, color = partido, fill = partido), alpha = 0.5) +\n  scale_color_manual(\n    values = c(\"#3498db\", \"#e74c3c\",\"#2ecc71\"), \n    name = \"Partido\"\n  ) +\n  scale_fill_manual(\n    values = c(\"#3498db\", \"#e74c3c\", \"#2ecc71\"),\n    name = \"Partido\"\n  ) +\n  facet_wrap(~ grupo, scales = \"free\") +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\ndf_new <- data.frame(\n  edad = rep(edad_grid, 3), \n  partido = rep(partidos, each = length(edad_grid))\n)\n\ndf_mean_3 <- data.frame(\n  p = as.vector(posterior_epred(modelo_3, newdata = df_new)),\n  edad = rep(rep(edad_grid, each = 4000), times = 3),\n  partido = rep(partidos, each = 4000 * length(edad_grid)),\n  draw = rep(1:4000, times = length(edad_grid) * length(partidos))\n)\n\nggplot(df_mean_3[df_mean_3$draw %in% sample(4000, 100), ]) +\n  geom_line(\n    aes(\n      x = edad, \n      y = p, \n      group = interaction(draw, partido), \n      color = partido\n    ), \n    alpha = 0.5\n  ) + \n  geom_line(\n    aes(x = edad, y = p, group = partido),\n    linewidth = 0.7,\n    color = \"grey20\",\n    data = df_mean_3 |> group_by(edad, partido) |> summarise(p = mean(p))\n  ) + \n  scale_color_manual(\n    values = c(\"#3498db\", \"#e74c3c\",\"#2ecc71\", \"#535c68\"), \n    name = \"Partido\"\n  ) +\n  labs(y = \"P(voto = Candidato A)\") +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# Algunos calculos de probabilidades...\n\nmean(df_draws_3[\"b_partidoazul:edad\"] > df_draws_3[\"b_partidorojo:edad\"])\n\n[1] 0.994\n\nmean(df_draws_3[\"b_partidoazul:edad\"] > df_draws_3[\"b_partidoverde:edad\"])\n\n[1] 0.9945\n\nmean(df_draws_3[\"b_partidoverde:edad\"] > df_draws_3[\"b_partidorojo:edad\"])\n\n[1] 0.91025\n\nmean(df_draws_3[\"b_partidoazul:edad\"] > 0)\n\n[1] 0.80575\n\nmean(df_draws_3[\"b_partidorojo:edad\"] < 0)\n\n[1] 0.99175\n\nmean(df_draws_3[\"b_partidoverde:edad\"] < 0)\n\n[1] 0.99775\n\n# Comparando los modelos con LOO... Â¿quÃ© significa?\nloo_1 <- loo(modelo_1)\nloo_2 <- loo(modelo_2)\nloo_3 <- loo(modelo_3)\n\nloo_compare(loo_1, loo_2, loo_3)\n\n         elpd_diff se_diff\nmodelo_3   0.0       0.0  \nmodelo_2  -1.9       3.3  \nmodelo_1 -98.3      11.8"
  },
  {
    "objectID": "recursos/codigo/05_cobertura_ic.html",
    "href": "recursos/codigo/05_cobertura_ic.html",
    "title": "05 - Propiedades frecuentistas de inferencias bayesianas",
    "section": "",
    "text": "El siguiente programa sirve para responder al ejercicio Propiedades frecuentistas de inferencias bayesianas de la PrÃ¡ctica 2.\n\nlibrary(ggplot2)\n\nset.seed(1234)\n\n# Definir cantidad de repeticiones\nreps_n <- 10000\n\n# Definir valores de 'n'\nn_vector <- c(1, 5, 10, 25)\n\n# Definir valores de 'theta'\ntheta_vector <- seq(0.05, 0.5, by = 0.05)\n\n# Definir hiperparÃ¡metros del prior\na_prior <- 0.5\nb_prior <- 0.5\n\n# Crear matriz para almacenar las coberturas empÃ­ricas\ncoberturas <- matrix(\n    nrow = length(n_vector),\n    ncol = length(theta_vector)\n)\n\nfor (i in seq_along(n_vector)) {\n    for (j in seq_along(theta_vector)) {\n        n <- n_vector[i]\n        theta <- theta_vector[j]\n        y_rvs <- rbinom(reps_n, n, theta)\n        a_posterior <- a_prior + y_rvs\n        b_posterior <- b_prior + (n - y_rvs)\n        ic_lower <- qbeta(0.025, a_posterior, b_posterior)\n        ic_upper <- qbeta(0.975, a_posterior, b_posterior)\n        cobertura <- mean(theta > ic_lower & theta < ic_upper)\n        cat(\"n=\", n, \"theta=\", theta, \"cobertura=\", cobertura, \"\\n\")\n        coberturas[i, j] <- cobertura\n    }\n}\n\n# Crear combinaciones entre los valores de 'n' y 'theta'\ndatos <- as.data.frame(expand.grid(n_vector, theta_vector))\n\n# Asignar nombres de columnas mas claros\ncolnames(datos) <- c(\"n\", \"theta\")\n\n# Transformar matriz en vector y guardar como columna del data frame\ndatos$cobertura <- as.vector(coberturas)\n\n# Graficar con ggplot2\nggplot(datos, aes(x = theta, y = cobertura)) +\n    geom_line() +\n    geom_point() +\n    geom_hline(yintercept = 0.95, linetype = \"dashed\") +\n    facet_wrap(~ as.factor(n))"
  },
  {
    "objectID": "recursos/codigo/02_diferentes_posteriors.html",
    "href": "recursos/codigo/02_diferentes_posteriors.html",
    "title": "02 - Diferentes observaciones, diferentes posteriors",
    "section": "",
    "text": "Este programa obtiene la distribuciÃ³n a posteriori para los diferentes trabajadores del ejercicio Diferentes observaciones, diferentes posteriors de la PrÃ¡ctica 2.\n\nlibrary(ggplot2)\n\n# Crear grilla para los valores de \"pi\"\ngrid_n <- 200\npi_grid <- seq(0, 1, length.out = grid_n)\n\n# Evaluar la funcion de densidad del posterior de cada trabajador\n# en cada uno de los puntos de \"pi_grid\"\nposterior1 <- dbeta(pi_grid, 4, 4)\nposterior2 <- dbeta(pi_grid, 7, 10)\nposterior3 <- dbeta(pi_grid, 24, 83)\n\n# Crear un data.frame, necesario para trabajar con ggplot2\ndatos <- data.frame(\n  pi = rep(pi_grid, times = 3),\n  posterior = c(posterior1, posterior2, posterior3),\n  trabajador = rep(c(\"T1\", \"T2\", \"T3\"), each = grid_n)\n)\n\n# Crear el grafico con ggplot2 con los siguientes mapeos\n# * Los valores del eje horizontal \"x\" salen de \"pi\"\n# * Los valores de la altura en el eje vertical \"y\" salen de \"posterior\"\n# * Los colores se mapean a cada uno de los valores de \"trabajador\"\n# * Las areas tienen un color de relleno distinto para cada valor en \"trabajador\"\nggplot(datos, aes(x = pi, y = posterior, color = trabajador)) +\n  geom_line() + \n  geom_area(aes(fill = trabajador), alpha = 0.5, position = \"identity\")"
  },
  {
    "objectID": "recursos/codigo/07_bolas_infinitas.html",
    "href": "recursos/codigo/07_bolas_infinitas.html",
    "title": "07 - Bolas infinitas",
    "section": "",
    "text": "El siguiente programa sirve para responder al ejercicio Bolas infinitas de la PrÃ¡ctica 3.\n\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# Parte 1\n# Se ejecutan 10000 pasos de este proceso una sola vez\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# Inicializar urna con una bola azul y otra amarilla\nurna <- c(\"azul\", \"amarillo\")\n\n# Realizar 10000 pasos del proceso\nfor (i in seq_len(10000)) {\n    # Seleccionar uno de los elementos de la urna\n    muestra <- sample(urna, 1)\n    # Agregar otro elemento igual al extraido\n    urna <- c(urna, muestra)\n\n    # Cada 500 iteraciones imprimir la proporciÃ³n de bolas azules\n    if (i %% 500 == 0) {\n        cat(\"Proporcion de bolas azules\", round(mean(urna == \"azul\"), 4), \"\\n\")\n    }\n}\n\n# Mostrar la proporciÃ³n de bolas azules\nmean(urna == \"azul\")\n\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# Parte 2\n# Se ejecutan 10000 pasos de este proceso diez veces\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n# Crear vector vacÃ­o que contendrÃ¡ las proporciones de azules a medida que\n# se realizan pasos del experimento. \nproporciones <- numeric(0)\n\n# Realizar 10 iteraciones independientes (utilizando 10 bolsas independientes)\nfor (j in 1:10) {\n    urna <- c(\"azul\", \"amarillo\")\n    for (i in 1:1000) {\n        muestra <- sample(urna, 1)\n        urna <- c(urna, muestra)\n    }\n    # Calcular la proporciÃ³n de azules conforme se avanza en el experimento\n    proporcion <- cumsum(urna == \"azul\") / seq_along(urna)\n    # Descartar el primer valor, que siempre es 0.5\n    proporcion <- proporcion[2:length(proporcion)]\n    # Guardar el vector producido en el vector 'proporciones'\n    proporciones <- c(proporciones, proporcion)\n}\n\n# Generar un data.frame para graficar con ggplot2\n# x: Los pasos del experimento\n# y: Las proporciones conforme se realizan pasos del experimento\n# prueba: Indica la prueba. Sirve para graficar una lÃ­nea para cada prueba\ndatos <- data.frame(\n    x = rep(seq_along(proporcion), 10),\n    y = proporciones,\n    prueba = as.factor(rep(1:10, each = length(proporcion)))\n)\n\nlibrary(ggplot2)\n\nggplot(datos) +\n    geom_line(aes(x = x, y = y, color = prueba))"
  },
  {
    "objectID": "recursos/codigo/09_hmc_gaussian_2d.html",
    "href": "recursos/codigo/09_hmc_gaussian_2d.html",
    "title": "09 - Hamiltonian Monte Carlo para normal bivariada",
    "section": "",
    "text": "Esta secciÃ³n muestra una implementaciÃ³n de Hamiltonian Monte Carlo para obtener muestras de una distribuciÃ³n \\(\\mathcal{N}(\\mathbf{0}, \\pmb{\\Sigma})\\) con\n\\[\n\\pmb{\\Sigma} =\n    \\begin{bmatrix}\n    1 & \\rho \\\\\n    \\rho & 1\n    \\end{bmatrix}\n\\]\n\nlibrary(ggplot2)\nlibrary(ggquiver)\nlibrary(mvtnorm)\n\nset.seed(12345)\n\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# Funciones auxiliares\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\ndlogpdx <- function(x, y, rho) {\n  - (x - rho * y) / (1 - rho ^ 2)\n}\n\ndlogpdy <- function(x, y, rho) {\n  - (y - rho * x) / (1 - rho ^ 2)\n}\n\ndlogp <- function(q, rho) {\n  x <- q[1]\n  y <- q[2]\n  c(dlogpdx(x, y, rho), dlogpdy(x, y, rho))\n}\n\nmake_neg_dlogp <- function(rho) {\n  function(q) -dlogp(q, rho)\n}\n\nmake_neg_logp <- function(rho) {\n  Mu <- rep(0, 2)\n  Sigma <- diag(2)\n  Sigma[Sigma == 0] <- rho\n  function(q) -dmvnorm(q, Mu, Sigma, log = TRUE)\n}\n\nleapfrog <- function(p, q, neg_dlogp, path_length, step_size) {\n  leap_q <- list()\n  leap_p <- list()\n  p <- p - step_size * neg_dlogp(q) / 2\n  for (i in seq_len(round(path_length / step_size) - 1)) {\n    q <- q + step_size * p\n    p <- p - step_size * neg_dlogp(q)\n    leap_q[[i]] <- q\n    leap_p[[i]] <- p\n  }\n  q <- q + step_size * p\n  p <- p - step_size * neg_dlogp(q) / 2\n  \n  # Flip del momentum \n  return(list(q = q, p = -p, leap_q = leap_q, leap_p = leap_p))\n}\n\nlappend <- function(l, object) {\n  l[[length(l) + 1]] <- object\n  l\n}\n\nltail <- function(l) {\n  l[[length(l)]]\n}\n\nhmc <- function(\n    neg_logp, \n    neg_dlogp, \n    n_samples, \n    initial_position, \n    path_length = 1, \n    step_size = 0.01\n) {\n  \n  leap_p <- list()\n  leap_q <- list()\n  samples <- list(initial_position)\n  n_dimensions <- length(initial_position)\n  \n  # Se generan momentums a partir de una MVN(0, 1)\n  # Es de dimension (n_samples, n_dimensions)\n  momentum <- rmvnorm(n_samples, rep(0, n_dimensions), diag(n_dimensions))\n  \n  for (i in seq_len(n_samples)) {\n    # Obtener posicion y momentum\n    p_current <- momentum[i, ]\n    q_current <- ltail(samples)\n    \n    # Integrar para obtener una nueva posiciÃ³n y momentum\n    integration <- leapfrog(\n      p_current, q_current, neg_dlogp, path_length, step_size\n    )\n    \n    p_new <- integration$p\n    q_new <- integration$q\n    leap_p <- lappend(leap_p, integration$leap_p)\n    leap_q <- lappend(leap_q, integration$leap_q)\n    \n    # Criterio de aceptacion de Metropolis\n    current_logp <- neg_logp(q_current) - dmvnorm(p_current, log = TRUE)\n    new_logp <- neg_logp(q_new) - dmvnorm(p_new, log = TRUE)\n    \n    sample_new <- if(log(runif(1)) < current_logp - new_logp) {\n      q_new\n    } else {\n      sample_current\n    }\n    samples <- lappend(samples, sample_new)\n  }\n  samples <- as.data.frame(do.call(rbind, samples))\n  leap_p <- as.data.frame(do.call(rbind, lapply(leap_p, function(x) do.call(rbind, x))))\n  leap_q <- as.data.frame(do.call(rbind, lapply(leap_q, function(x) do.call(rbind, x))))\n  \n  colnames(samples) <- c(\"x\", \"y\")\n  colnames(leap_p) <- c(\"p0\", \"p1\")\n  colnames(leap_q) <- c(\"q0\", \"q1\")\n  list(samples = samples, leap_p = leap_p, leap_q = leap_q)\n}\n\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# Primer caso: Graficar trayectorias\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nneg_logp <- make_neg_logp(0)\nneg_dlogp <- make_neg_dlogp(0)\n\ninitial_position <- c(1.6, -0.6)\nhmc_output <- hmc(neg_logp, neg_dlogp, 10, initial_position, 1.5, 0.01)\n\ndf_samples <- hmc_output$samples\ndf_leap_p <- hmc_output$leap_p\ndf_leap_q <- hmc_output$leap_q\ndf_leap <- cbind(df_leap_p, df_leap_q)\n\ndf_basis <- tidyr::crossing(x1 = seq(-3, 3, 0.1), x2 = seq(-3, 3, 0.1))\nplt <- df_basis |>\n  dplyr::mutate(f = mvtnorm::dmvnorm(df_basis, c(0, 0), diag(2))) |>\n  ggplot() +\n  geom_raster(aes(x = x1, y = x2, fill = f)) +\n  stat_contour(aes(x = x1, y = x2, z = f), col = \"white\", bins = 5) +\n  viridis::scale_fill_viridis() +\n  theme(\n    legend.position = \"none\", \n    plot.title = element_text(hjust = 0.5, size = 18)\n  )\n\nplt + \n  geom_path(aes(x = q0, y = q1), size = 1, data = df_leap) + \n  geom_quiver(\n    aes(x = q0, y = q1, u = p0, v = p1), \n    size = 1,\n    vecsize = 600,\n    data = df_leap[seq(1, nrow(df_leap), by = 30), ]\n  ) +\n  geom_point(\n    aes(x = x, y = y), \n    color = \"red\",\n    size = 2,\n    data = df_samples\n  ) +\n  labs(x = \"x\", y = \"y\") +\n  scale_x_continuous(expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0))\n\n\n\n\nTrayectorias realizadas junto a las 10 muestras obtenidas.\n\n\n\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# Segundo caso: Obtencion de muestras\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nneg_logp <- make_neg_logp(0)\nneg_dlogp <- make_neg_dlogp(0)\n\ninitial_position <- c(1.6, -0.6)\nhmc_output <- hmc(neg_logp, neg_dlogp, 1000, initial_position, 1.5, 0.01)\n\ndf_samples <- hmc_output$samples\ndf_leap_p <- hmc_output$leap_p\ndf_leap_q <- hmc_output$leap_q\n\ndf_basis <- tidyr::crossing(x1 = seq(-3.5, 3.5, 0.1), x2 = seq(-3.5, 3.5, 0.1))\nplt <- df_basis |>\n  dplyr::mutate(f = mvtnorm::dmvnorm(df_basis, c(0, 0), diag(2))) |>\n  ggplot() +\n  geom_raster(aes(x = x1, y = x2, fill = f)) +\n  stat_contour(aes(x = x1, y = x2, z = f), col = \"white\", bins = 5) +\n  viridis::scale_fill_viridis() +\n  theme(\n    legend.position = \"none\", \n    plot.title = element_text(hjust = 0.5, size = 18)\n  )\n\nplt +\n  geom_point(\n    aes(x = x, y = y), \n    size = 2, \n    alpha = 0.7, \n    color = \"red\", \n    data = df_samples\n  ) +\n  labs(x = \"x\", y = \"y\") +\n  scale_x_continuous(expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0))\n\n\n\n\n1000 muestras de una distribuciÃ³n \\(\\mathcal{N}(\\mathbf{0}, \\mathbf{I})\\).\n\n\n\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# Tercer caso: rho = 0.6\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nneg_logp <- make_neg_logp(0.7)\nneg_dlogp <- make_neg_dlogp(0.7)\n\ninitial_position <- c(1.6, -0.6)\nhmc_output <- hmc(neg_logp, neg_dlogp, 1000, initial_position, 1.5, 0.01)\n\ndf_samples <- hmc_output$samples\ndf_leap_p <- hmc_output$leap_p\ndf_leap_q <- hmc_output$leap_q\n\nSigma <- matrix(c(1, 0.7, 0.7, 1), ncol = 2)\n\ndf_basis <- tidyr::crossing(x1 = seq(-3.5, 3.5, 0.1), x2 = seq(-3.5, 3.5, 0.1))\nplt <- df_basis |>\n  dplyr::mutate(f = mvtnorm::dmvnorm(df_basis, c(0, 0), Sigma)) |>\n  ggplot() +\n  geom_raster(aes(x = x1, y = x2, fill = f)) +\n  stat_contour(aes(x = x1, y = x2, z = f), col = \"white\", bins = 5) +\n  viridis::scale_fill_viridis() +\n  theme(\n    legend.position = \"none\", \n    plot.title = element_text(hjust = 0.5, size = 18)\n  )\n\nplt +\n  geom_point(\n    aes(x = x, y = y), \n    size = 2, \n    alpha = 0.7, \n    color = \"red\", \n    data = df_samples\n  ) +\n  labs(x = \"x\", y = \"y\") +\n  scale_x_continuous(expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0))\n\n\n\n\n1000 muestras de una distribuciÃ³n \\(\\mathcal{N}(\\mathbf{0}, 0.7 \\mathbf{I})\\).\n\n\n\ncor(df_samples$x, df_samples$y)\n\n[1] 0.6584974"
  },
  {
    "objectID": "recursos/codigo/04_dirichlet.html",
    "href": "recursos/codigo/04_dirichlet.html",
    "title": "04 - DistribuciÃ³n de Dirichlet",
    "section": "",
    "text": "Este programa muestra como utilizar obtener muestras de la distribuciÃ³n de Dirichlet en 3 dimensiones utilizando rdirichlet del paquete {gtools} y como graficar estos puntos en el simplex mediante el paquete {ggsimplex}.\n\n# Instalar la libreria ggsimplex\n# devtools::install_github('marvinschmitt/ggsimplex')\nlibrary(ggplot2)\nlibrary(ggsimplex)\nlibrary(gtools)\n\n# Determinar vector de concentracion\nalpha <- c(1.5, 1.5, 1.5)\n\n# Generar valores aleatorios\nrvs <- rdirichlet(200, alpha = alpha)\n\n# Guardar valores aleatorios en un data frame\ndatos <- data.frame(rvs)\ncolnames(datos) <- c(\"x1\", \"x2\", \"x3\")\n\n# Por como funciona {ggsimplex} es necesario crear este tipo de columna especial\ndatos$pmp <- make_list_column(datos$x1, datos$x2, datos$x3)\n\n# Graficar muestras\nggplot(datos) +\n  coord_fixed(ratio = 1, xlim = c(0, 1), ylim = c(0, 1)) +\n  theme_void() +\n  geom_simplex_canvas() +\n  geom_simplex_point(aes(pmp = pmp), size = 0.7, alpha = 0.8)\n\n\n# Crear un data frame con los valores del vector de concentracion\n# para luego graficar la funcion de densidad\ndf_dirichlet <- data.frame(dummy = 1)\ndf_dirichlet$Alpha <- list(alpha)\n\nggplot() +\n  coord_fixed(ratio = 1, xlim = c(0, 1), ylim = c(0, 1))\n  theme_void() +\n  geom_simplex_canvas() +\n  stat_simplex_density(\n    data = df_dirichlet,\n    fun = ddirichlet,\n    args = alist(Alpha = Alpha)\n  )\n\n\nggplot() +\n  coord_fixed(ratio = 1, xlim = c(0, 1), ylim = c(0, 1)) +\n  theme_void() +\n  geom_simplex_canvas() +\n  stat_simplex_density(\n    data = df_dirichlet,\n    fun = ddirichlet,\n    args = alist(Alpha = Alpha)\n  ) +\n  geom_simplex_point(\n    data = datos,\n    aes(pmp = pmp),\n    size = 0.7,\n    alpha = 0.8\n  )"
  },
  {
    "objectID": "recursos/codigo/12_brms_rds.html",
    "href": "recursos/codigo/12_brms_rds.html",
    "title": "12 - Guardar y leer modelos de {brms}",
    "section": "",
    "text": "Este breve ejemplo muestra como guardar un modelo ajustado con {brms} utilizando saveRDS() para luego cargarlo con readRDS() y realizar operaciones tales como una predicciÃ³n sobre un conjunto nuevo de observaciones.\n\nlibrary(brms)\n\n# Simular datos para el ejemplo\na <- 2.2\nb <- 1.33\ns <- 0.5\nx <- runif(50)\ny <- rnorm(50, mean = a + b * x, sd = s)\ndata <- data.frame(x = x, y = y)\n\n# Ajustar modelo\nmodel_fit <- brm(y ~ x, data)\n\n# Guardar el modelo ajustado como \"model_fit.rds\"\nsaveRDS(model_fit, \"model_fit.rds\")\n\n\n# Leer el archivo .rds guardado anteriormente \nmodel_fit_loaded <- readRDS(\"model_fit.rds\")\n\n# Crear un nuevo data frame de ejemplo\nnew_data <- data.frame(x = c(0.1, 0.2, 0.3))\n\n# Calcular la media condicional para las observaciones del data frame de ejemplo    \nfitted(model_fit_loaded, newdata = new_data)\n\n     Estimate Est.Error     Q2.5    Q97.5\n[1,] 2.356671 0.1518292 2.052827 2.654910\n[2,] 2.476600 0.1275577 2.225724 2.727059\n[3,] 2.596528 0.1064967 2.391033 2.805158"
  },
  {
    "objectID": "recursos/codigo/06_encuentro_fotocopiadora.html",
    "href": "recursos/codigo/06_encuentro_fotocopiadora.html",
    "title": "06 - Te veo en la fotocopiadora",
    "section": "",
    "text": "El siguiente programa sirve para responder al ejercicio Te veo en la fotocopiadora de la PrÃ¡ctica 3.\n\nlibrary(ggplot2)\n\n# Tiempo que espera cada estudiante\nespera_a <- 10 \nespera_b <- 14\n\n# Dos tiempos de llegada posible para cada estudiante\nllegada_a <- runif(1, min = 0, max = 60)\nllegada_b <- runif(1, min = 0, max = 60)\n\n# El intervalo en el que cada estudiante estÃ¡ en la fotocopiadora\nintervalo_a <- c(llegada_a, llegada_a + espera_a)\nintervalo_b <- c(llegada_b, llegada_b + espera_b)\n\n# Lo convertimos a data frame para graficar con ggplot2\ndatos <- data.frame(\n  intervalo = c(intervalo_a, intervalo_b),\n  persona = rep(c(\"A\", \"B\"), each = 2)\n)\n\n# Graficamos con ggplot2\nggplot(datos) +\n  geom_line(\n    aes(x = intervalo, y = persona, color = persona), \n    linewidth = 2\n  ) +\n  xlim(c(0, 75))\n\n# Si los intervalos se solapan, significa que hay una linea vertical que\n# cruza a ambos. Esto es lo mismo que decir que hay una C que cumple:\n# a1 <= C <= a2\n# b1 <= C <= b2\n\n# Y ambas se cumplen cuando...\n# a1 <= b2 y b1 <= a2 \n# Es lo mismo que decir que...\n# A llega antes de que B se vaya, y B llega antes de que A se vaya\n(intervalo_a[1] <= intervalo_b[2]) & (intervalo_b[1] <= intervalo_a[2])\n\n# Lo extendemos a muchas iteraciones...\nllegada_a <- runif(10000, min = 0, max = 60)\nllegada_b <- runif(10000, min = 0, max = 60)\n\ncomparaciones <- (\n  (llegada_a <= llegada_b + espera_b)   # A llega antes que B se vaya\n  & (llegada_b <= llegada_a + espera_a) # B llega antes que A se vaya\n)\nmean(comparaciones)"
  },
  {
    "objectID": "recursos/codigo/01_rocklets_grilla.html",
    "href": "recursos/codigo/01_rocklets_grilla.html",
    "title": "01 - Rocklets discretos",
    "section": "",
    "text": "Este script fue utilizado en la primer clase de prÃ¡ctica en el laboratorio para mostrar como resolver el ejercicio de los Rocklets utilizando cÃ³digo.\n\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# Utilizando un prior elicitado grupalmente\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n# Determinar grilla de puntos\npi_grid <- seq(0, 1, length.out = 11)\nprint(pi_grid)\n\n# Obtener prior\nprior_ <- c(0, 1, 2, 2, 1, 0.5, 0.25, 0.125, 0.05, 0.005, 0)\nprior <- prior_ / sum(prior_)\n\n# Graficar prior\nplot(\n  pi_grid,\n  prior,\n  xlab = \"pi\",\n  ylab = \"probabilidad\",\n  main = \"prior\"\n)\nlines(pi_grid, prior)\naxis(1, at = pi_grid)\n\n# Recolectar datos\ncantidad_de_rocklets <- 43 # n\ncantidad_de_rocklets_azules <- 11 # y\n\n# Calcular verosimilitud para cada valor de \"pi\" en la grilla\nlikelihood <- dbinom(\n  cantidad_de_rocklets_azules, \n  cantidad_de_rocklets, \n  pi_grid\n)\n\n# Obtener posterior\nposterior_ <- prior * likelihood\nposterior <- posterior_ / sum(posterior_)\n\n# Graficar posterior\nplot(\n  pi_grid, \n  posterior, \n  xlab = \"pi\", \n  ylab = \"probabilidad\",\n  main = \"posterior\"\n)\nlines(pi_grid, posterior)\naxis(1, at = pi_grid)\n\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# Utilizando un prior Beta\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n# Determinar grilla de puntos\npi_grid <- seq(0, 1, length.out = 50)\n\n# Obtener prior\nprior_ <- dbeta(pi_grid, 2.5, 10)\nprior <- prior_ / sum(prior_)\n\n# Graficar prior\nplot(\n  pi_grid, \n  prior, \n  xlab = \"pi\", \n  ylab = \"probabilidad\",\n  main = \"prior\"\n)\nlines(pi_grid, prior)\naxis(1, at = pi_grid)\n\n# Calcular verosimilitud para cada valor de \"pi\"\nlikelihood <- dbinom(\n  cantidad_de_rocklets_azules, \n  cantidad_de_rocklets, \n  pi_grid\n)\n\n# Obtener posterior \nposterior_ <- prior * likelihood\nposterior <- posterior_ / sum(posterior_)\n\n# Graficar posterior\nplot(\n  pi_grid, \n  posterior, \n  xlab = \"pi\", \n  ylab = \"probabilidad\",\n  main = \"posterior\"\n)\nlines(pi_grid, posterior)\naxis(1, at = pi_grid)\n\n# Q: Que pasa con el prior si incrementamos el 'n'?\n# Q: Que pasa con el posterior si incrementamos el 'n'?"
  },
  {
    "objectID": "recursos/distribuciones/distribuciones.html",
    "href": "recursos/distribuciones/distribuciones.html",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "\\[\nX \\sim \\text{Normal}(\\mu, \\sigma)\n\\]\n\\[\np(x \\mid \\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi} \\sigma}e^{-\\frac{(x - \\mu) ^ 2}{2\\sigma^2}}\n\\]\n\\[\nP(X \\le x) = \\int_{-\\infty}^{x}{p(x | \\mu, \\sigma) dx}\n\\]\no tambiÃ©n\n\\[\nP(X \\le x) = \\frac{1}{2} \\left[1 + \\text{erf}\\left(\\frac{x - \\mu}{\\sigma\\sqrt{2}} \\right) \\right]\n\\]\ncon\n\\[\n\\text{erf}(x) = \\frac{2}{\\sqrt{\\pi}}\\int_0^{x} {e^{-t^2}dt}\n\\]\n\n\\(X \\in \\mathbb{R}\\)\n\\(\\mu \\in \\mathbb{R}\\)\n\\(\\sigma > 0\\)\n\\(\\mathbb{E}(X) = \\mu\\)\n\\(\\mathbb{V}(X) = \\sigma^2\\)\n\n\n\n\n\\[\nX \\sim \\text{StudentT}(\\nu)\n\\]\n\\[\np(x \\mid \\nu) =\n    \\frac{\\Gamma(\\frac{\\nu + 1}{2})}{\\Gamma(\\frac{\\nu}{2})}\n    \\left(\\frac{1}{\\pi\\nu}\\right) ^ {\\frac{1}{2}}\n    \\left[1 + \\frac{x^2}{\\nu}\\right]^{-\\frac{\\nu + 1}{2}}\n\\]\n\\[\nP(X \\le x) = \\frac{1}{2} + x \\Gamma\\left(\\frac{\\nu + 1}{2}\\right)\n             \\frac{{}_2F_1\\left(\\frac{1}{2}, \\frac{v + 1}{2}, \\frac{3}{2}, \\frac{-x^2}{\\nu} \\right)}\n             {\\sqrt{\\pi \\nu} \\Gamma(\\frac{\\nu}{2})}\n\\]\ndonde \\({}_2F_1\\) es la funciÃ³n hipergeomÃ©trica.\n\n\\(X \\in \\mathbb{R}\\)\n\\(\\nu > 0\\)\n\\(\\mathbb{E}(X) = 0\\) si \\(\\nu > 1\\)\n\\(\\mathbb{V}(X) = \\nu / (\\nu - 2)\\) si \\(\\nu > 2\\)\n\n\n\n\n\n\n\\[\nX \\sim \\text{Gamma}(k, \\theta)\n\\]\n\\[\np(x \\mid k, \\theta) = \\frac{1}{\\Gamma(k)\\theta^k}x^{k-1}e^{-\\frac{x}{\\theta}}\n\\]\n\\[\nP(X \\le x) = \\frac{1}{\\Gamma(k)} \\gamma \\left(k, \\frac{x}{\\theta}\\right)\n\\]\n\n\\(X > 0\\)\n\\(k > 0\\)\n\\(\\theta > 0\\)\n\\(\\mathbb{E}(X) = k\\theta\\)\n\\(\\mathbb{V}(X) = k\\theta^2\\)\n\n\n\n\n\\[\nX \\sim \\text{Gamma}(\\alpha, \\beta)\n\\]\n\\[\np(x | \\alpha, \\beta) = \\frac{1}{\\Gamma(\\alpha)}x^{\\alpha-1}e^{-\\beta x}\\beta^\\alpha\n\\]\n\\[\nP(X \\le x) = \\frac{1}{\\Gamma(\\alpha)} \\gamma(\\alpha, \\beta x)\n\\]\n\n\\(X > 0\\)\n\\(\\alpha > 0\\)\n\\(\\beta > 0\\)\n\\(\\mathbb{E}(X) = \\alpha/\\beta\\)\n\\(\\mathbb{V}(X) = \\alpha/\\beta^2\\)\n\n\n\n\n\n\\[\nX \\sim \\text{Exponencial}(\\lambda)\n\\]\n\\[\np(x \\mid \\lambda) = \\lambda e^{-\\lambda x}\n\\]\n\\[\nP(X \\le x) = 1 - e^{-\\lambda x}\n\\]\n\n\\(X > 0\\)\n\\(\\lambda > 0\\)\n\\(\\mathbb{E}(X) = 1 / \\lambda\\)\n\\(\\mathbb{V}(X) = 1 / \\lambda ^ 2\\)\n\nEs un caso particular de \\(\\text{Gamma}(\\alpha, \\beta)\\) con \\(\\alpha = 1\\) y \\(\\beta = \\lambda\\)\n\n\n\n\\[\nX \\sim \\text{Beta}(a, b)\n\\]\n\\[\np(x \\mid a, b) = \\frac{x^{a-1} (1-x)^{b-1}}{B(a, b)}\n\\]\n\\[\nB(a, b) = \\int_0^1 x^{a-1} (1-x)^{b-1} dx = \\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}\n\\]\n\\[\n\\Gamma(x) = \\int_0^\\infty u^{x-1} e^{-u} du\n\\]\n\n\\(X \\in (0, 1)\\)\n\\(\\displaystyle \\mathbb{E}(X) = \\frac{a}{a + b}\\)\n\\(\\displaystyle \\mathbb{V}(X) = \\frac{ab}{(a + b) ^ 2 (a + b + 1)}\\)\n\n\n\n\n\\[\nX \\sim \\text{Binomial}(\\theta, n)\n\\]\n\\[\np(x \\mid \\theta, n) = {n \\choose x} \\theta^x (1 - \\theta)^{(n - x)}\n\\]\n\\[\nP(X \\le x) = \\sum_{i = 0} ^ {x} {n \\choose i} \\theta^i (1 - \\theta)^{(n - i)}\n\\]\n\n\\(X \\in \\{0, 1, 2, \\cdots, n\\}\\)\n\\(\\theta \\in [0, 1]\\)\n\\(n \\in \\{0, 1, 2, \\cdots \\}\\)\n\\(\\mathbb{E}(X) = n \\theta\\)\n\\(\\mathbb{V}(X) = n \\theta (1 - \\theta)\\)\n\n\n\n\n\\[\nX \\sim \\text{Poisson}(\\lambda)\n\\]\n\\[\np(x \\mid \\lambda) = \\frac{\\lambda^x e^{-\\lambda}}{x!}\n\\]\n\\[\nP(X \\le x) = e^{-\\lambda} \\sum_{i = 0} ^ {x} \\frac{\\lambda^i}{i!}\n\\]\n\n\\(X \\in \\{0, 1, 2, \\cdots\\}\\)\n\\(\\lambda > 0\\)\n\\(\\mathbb{E}(X) = \\lambda\\)\n\\(\\mathbb{V}(X) = \\lambda\\)\n\n\n\n\n\\[\nX \\sim \\text{BinomialNegativa}(r, p)\n\\]\n\\[\np(x \\mid k, p)= \\binom{x + r - 1}{x}(1 - p)^x p^r\n\\]\n\n\\(X \\in \\{0, 1, 2, \\cdots \\}\\)\n\\(r \\in \\{1, 2, 3, \\cdots \\}\\)\n\\(p \\in [0, 1]\\)\n\\(\\mathbb{E}(X) = r(1 - p) / p\\)\n\\(\\mathbb{V}(X) = r(1 - p) / p^2\\)"
  },
  {
    "objectID": "recursos/computo/instalacion.html#instalar-rstudio",
    "href": "recursos/computo/instalacion.html#instalar-rstudio",
    "title": "InstalaciÃ³n de herramientas computacionales",
    "section": "Instalar RStudio",
    "text": "Instalar RStudio\n\nWindows\n\n\nUbuntu\n\n\nMac OS"
  },
  {
    "objectID": "recursos/computo/instalacion.html#instalar-quarto",
    "href": "recursos/computo/instalacion.html#instalar-quarto",
    "title": "InstalaciÃ³n de herramientas computacionales",
    "section": "Instalar Quarto",
    "text": "Instalar Quarto\n\nWindows\n\n\nUbuntu\n\n\nMac OS"
  },
  {
    "objectID": "recursos/computo/instalacion.html#instalar-rstan-y-brms",
    "href": "recursos/computo/instalacion.html#instalar-rstan-y-brms",
    "title": "InstalaciÃ³n de herramientas computacionales",
    "section": "Instalar RStan y brms",
    "text": "Instalar RStan y brms\n\nWindows\n\n\nUbuntu\n\n\nMac OS"
  },
  {
    "objectID": "recursos/computo/instalacion.html#instalar-otras-librerÃ­as",
    "href": "recursos/computo/instalacion.html#instalar-otras-librerÃ­as",
    "title": "InstalaciÃ³n de herramientas computacionales",
    "section": "Instalar otras librerÃ­as",
    "text": "Instalar otras librerÃ­as\n\nWindows\n\n\nUbuntu\n\n\nMac OS"
  },
  {
    "objectID": "notas/planificacion.html",
    "href": "notas/planificacion.html",
    "title": "Contenidos detallados",
    "section": "",
    "text": "Actividad Rocklets\n\n\nRepaso\n\nRepaso de probabilidad, distribuciones conjuntas, distribuciones marginales\nPrÃ¡ctica 0 (ver quÃ© ejercicios)\n\n\n\nIntroducciÃ³n\n\nProbabilidad para cuantificar la incertidumbre\n\nDefiniciones de probabilidad\n\nClasica\nFrecuentista\nBayesiana (subjetiva)\n\nProbabilidades subjetivas\nLÃ³gica y razonamiento plausible (ver Jaynes)\nDutch book\n\nRegla de Bayes\n\nHistoria: Bayes, Price, Laplace\nPresentaciÃ³n tradicional de la Regla de Bayes\n\nLey de la probabilidad total\n\nPrÃ¡ctica 1 (ver quÃ© ejercicios)\n\nInferencia bayesiana: problema original de Bayes, problema de la percepciÃ³n del suelo mojado, problema de las bolas (Â¿hecho en vivo con Sugus?), problema del globo terrÃ¡queo (Â¿hecho en vivo?), problema de detecciÃ³n de gluten (ver Downey), problema de detecciÃ³n de una explosiÃ³n (ver Barber).\n\nDiscutir modelos generativos (probabilidad hacia adelante e inversa).\nPrÃ¡ctica 1 (ver quÃ© ejercicios)\nIdea intuitiva: Â¿quÃ© es el prior? Â¿quÃ© es la funciÃ³n de verosimilitud? Â¿quÃ© es el posterior?\n\n\n\n\nModelos de distribuciones conjugadas\n\nModelo beta-binomial\n\nDemostraciÃ³n\n\nBeta(a,b) siendo a y b â€œpseudocuentasâ€\n\nDefiniciÃ³n de â€œdistribuciones conjugadasâ€ (ver BDA 2.4)\nEnfoque intuitivo\nDistribuciÃ³n a posteriori como compromiso entre likelihood y prior\n\nver caso particular y luego generalidad 2.2 de BDA\n\nRazonamiento secuencial\nResumen de la distribuciÃ³n a posteriori: media, moda, intervalos de credibilidad. CÃ¡lculos a mano, cÃ¡lculos exacto con funciones de R. Simulaciones (vamos a introducir la idea de utilizar simulaciones para resolver problemas)\n\nPodemos resolver algunos ejercicios de SimulaciÃ³n de la PrÃ¡ctica 2\n\nPredicciones: simulaciones. Problema del amanecer.\nEstimaciÃ³n por mÃ¡xima verosimilitud\nPrÃ¡ctica 2\n\nElecciÃ³n de la distribuciÃ³n a priori\n\nPrÃ¡ctica 2\n\nModelo normal-normal\n\nDemostraciÃ³n\nEnfoque intuitivo\nDistribuciÃ³n a posteriori como compromiso entre likelihood y prior\nRazonamiento secuencial\nPredicciones: distribuciÃ³n predictiva. Incertidumbre propia del sampleo + incertidumbre (ver BDA 2.5 y posterior predictive distribution). Plugin approximation vs posterior predictive distribution (3.1.5.2 de Murphy)\nModelo normal con prior uniforme (ver Devinderjit y Skilling, SecciÃ³n 2.3 â€“ Example 2)\n(Â¿) Modelo normal con media conocida y varianza desconocida (?) (ver BDA 2.6)\n\nModelo Gamma-Poisson\nOtros modelos de distribuciones conjugadas para una variable (ver PrÃ¡ctica 2)\nPresentaciÃ³n TP1 â€“ ConjugaciÃ³n Dirichlet-Multinomial\nModelos de varias variables\n\nNormal con media y desvÃ­o desconocido: modelo normal â€“ normal-gamma-inversa (ver Ejemplo 2.8 de Carlin y Louis, BDA SecciÃ³n 3.3 y 3.2.3.3 de Murphy)\nNormal con con media y desvÃ­o desconocido: prior uniforme (ver Devinderjit y Skilling, SecciÃ³n 3.3 â€“ Example 5 y ver BDA SecciÃ³n 3.2). RelaciÃ³n con mÃ¡xima verosimilitud (ver Devinderjit y Skilling, SecciÃ³n 3.5 â€“ Approximations)\n(Â¿) Distribuciones marginales de los parÃ¡metros (?)\n\n\n\n\nNociones de TeorÃ­a de la DecisiÃ³n\n\nEl resultado de la inferencia bayesiana es la distribuciÃ³n a posterioriâ€¦ aÃºn asÃ­, a veces podemos querer resumirla\nÂ¿Por quÃ© tiene sentido resumir la distribuciÃ³n a posteriori usando la media?\nFunciones de pÃ©rdida (ver Davidson-Pilon, CapÃ­tulo 5)\nPosterior expected loss (ver Robert, SecciÃ³n 2.3: Utility and loss)\n\nEjemplo de COVID-19 de Murphy (3.8.2)\n\nDemostraciÃ³n de que la media minimiza la pÃ©rdida cuadrÃ¡tica (ver Robert, ProposiciÃ³n 2.5.1)\nEjercicios (PrÃ¡ctica 2)\n\n\n\nMÃ©todos Computacionales\n\nProblemas: determinaciÃ³n de probabilidades, cÃ¡lculo de integrales, determinaciÃ³n de la distribuciÃ³n a posteriori (dos problemas: integrales analÃ­ticas y dimensiones de esa integral)\nMe gustarÃ­a hablar algo mÃ¡s de la maldiciÃ³n de dimensionalidad (ver Theoridis o MacKay)\nDeterminaciÃ³n de probabilidades (ya lo hemos trabajado en la PrÃ¡ctica 2)\nEjercicios SimulaciÃ³n (PrÃ¡ctica 3)\nIntegraciÃ³n por Montecarlo\nGrid approximation\n\nUn parÃ¡metro\nDos parÃ¡metros\nCaso discreto ((Â¿)grid approximation de un problema para estimar N y theta(?)) y caso continuo\n\nEjercitaciÃ³n grid approximation (PrÃ¡ctica 3)\nDeterminaciÃ³n de la distribuciÃ³n a posteriori (aka sampling) por mÃ©todos de MCMC\n\nPresentar rejection sampling\n(Â¿) Importance sampling (?)\nMetropolis-Hastings\n\nPresentaciÃ³n TP2 â€“ Metropolis-Hastings (trabajo en clase)\nDiagnÃ³stico de mÃ©todos de MCMC\nHamiltonian Montecarlo\nPrÃ¡ctica HMC\nProgramaciÃ³n probabilÃ­stica: Stan\nComponentes de un modelo en Stan\nImplementaciÃ³n de un modelo ya trabajado.\n\nDiagnÃ³sticos\nManipulaciÃ³n de muestras de MCMC.\nVisualizaciones de resultados (estimaciones de parÃ¡metros y predicciones). Uso del paquete ggdist.\n\n\n\n\nModelos lineales\n\nEstimaciÃ³n por mÃ­nimos cuadrados. EstimaciÃ³n por mÃ¡xima verosimilitud.\n\nVer ROS 8.1\n\nEstimaciÃ³n bayesiana. Priors conjugados para varianza conocida y varianza desconocida.\n\nCentrado de variables (ver Murphy y 12.3 de ROS)\n\nDistribuciÃ³n predictiva.\nImplementaciÃ³n en Stan y brms (comparaciÃ³n de brms con lm en R, Â¿cÃ³mo obtenemos los mismos resultados? ver ROS 8.4).\nManipulaciÃ³n de resultados.\nPredicciones probabilÃ­sitas (predicciones basadas en distribuciones de probabilidad). PropagaciÃ³n de incertidumbre. InterpretaciÃ³n.\n\nPredicciÃ³n puntual vs predicciÃ³n de la media (predictor lineal) vs distribuciÃ³n predictiva\nWe have a set of posterior simulations rather than a single point estimate because we have uncertainty about these parameters. (ROS 9.1)\nAs sample size approaches infinity, the coefficients a and b are estimated more and more precisely, and the uncertainty in the linear predictor approaches zero, but the uncertainty in the predictive distribution for a new observation does not approach zero; it approaches the residual standard deviation Ïƒ. (ROS 9.2)\n\nParameter recovery\n\n(ver ROS 7.2 Checking the model-fitting procedure using fake-data simulation)\n\nPruebas predictivas a posteriori. ComparaciÃ³n de los datos disponibles con rÃ©plicas generadas por el modelo ajustado (lo que en ROS llaman validaciÃ³n interna)\n\nVer ROS 11.4\n\nElecciÃ³n de una distribuciÃ³n a priori. Pruebas predictivas a priori.\nProblemas con la estimaciÃ³n de mÃ­nimos cuadrados. RegularizaciÃ³n ridge (\\(L_2\\)) y lasso (\\(L_1\\)). Distribuciones a priori para regularizar.\n\nSelecciÃ³n de variables con horseshoe prior (ver ROS 12.7)\nValidaciÃ³n externa y criterios de informaciÃ³n (ver 3.7.4 de Murphy Advanced, McElreath y BDA aunque estÃ¡ medio confuso)\n\nlppd (log pointwise predictive density): promedio del scoreÂ predictivo a travÃ©s de los posibles valores de \\(\\theta\\)\n\\[\nlppd = \\sum_{i=1}^{N} \\log \\left( \\int p\\left(y_i\\mid\\theta\\right) p_{post}(\\theta) d\\theta \\right)\n\\]\n\\[\nlppd = \\sum_{i=1}^{N} \\log \\left( \\frac{1}{S} \\sum_{i=1}^{S} p\\left(y_i\\mid\\theta^{(s)}\\right) \\right)\n\\]\nPSIS\n\n\n\n\nRegresiÃ³n LogÃ­stica\n\nModelo para clasificaciÃ³n (creo que podemos trabajarlo bien siguiendo Bayes Rules!)\nSimulaciÃ³n\nInterpretaciÃ³n de coeficientes\nExceso de ceros (ver ejemplo de Bayes Rules! y Negative Binomial)\n\n\n\nRegresiÃ³n Poisson\n\nModelo para datos de conteo (creo que podemos trabajarlo bien siguiendo Bayes Rules!)\nSimulaciÃ³n\n\n\n\nEnfoque multinivel\n\nModelo beta-binomial jerÃ¡rquico (ver Kruschke)\nShrinkage de parÃ¡metros\nEjemplo de uranio de Gelman: no pooling vs complete pooling vs partial pooling\nEjemplo de las ranas de McElreath:\nEjemplo de las canciones (Bayes Rules!)\nEjemplo de la carrera de Washington (Bayes Rules!)\nModelos jerÃ¡rquicos con predictores (CapÃ­tulo 17 de Bayes Rules)\n\nVariaciÃ³n en el intercepto\nVariaciÃ³n en la pendiente\n\nProblemas de estimaciÃ³n\nOpcional: regresiÃ³n logÃ­stica jerÃ¡rquica y regresiÃ³n Poisson jerÃ¡rquica (ver ejemplo de Bayes Rules! y de un paper de Paul Burkner sobre pesca (?))"
  },
  {
    "objectID": "presentaciones/presentacion_03.html",
    "href": "presentaciones/presentacion_03.html",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Sea una muestra \\(\\mathbf{y} = (y_1,y_2,\\dots,y_n)\\) obtenida de un modelo Poisson, es decir:\n\\[y_i \\sim \\mathrm{Poisson}(\\lambda)\\]\nInteresa realizar una inferencia sobre el valor de \\(\\lambda\\)\n\nÂ¿CÃ³mo asignamos una credibilidad a priori para \\(\\lambda\\)?\n\n\n\n\n\\[\n\\lambda \\sim \\mathrm{Gamma}(r,s)\n\\]\n\\[\np(\\lambda \\mid r,s) = p(\\lambda) = \\frac{r^s}{\\Gamma(s)} \\lambda^{s-1}e^{-r\\lambda}\n\\]\n\n\n\n\n\n\nCuidado\n\n\n\n\\(\\mathrm{Gamma}(r,s)\\) en R es dgamma(x, shape = s, scale = 1/r)\n\n\n\n\n\nEl modelo propuesto es \\[\n\\begin{align*}\n    y_i \\mid \\lambda & \\sim  Po(\\lambda)\\\\\n    \\lambda & \\sim  \\mathrm{Gamma}(s, r)\n\\end{align*}\n\\]\nEl likelihood es Poisson: \\[p(y_i\\mid \\lambda) = \\frac{\\lambda^{y_i}e^{-\\lambda}}{y_i!} \\rightarrow p(\\mathbf{y}\\mid \\lambda) = \\prod_i \\frac{\\lambda^{y_i}e^{-\\lambda}}{y_i!} = \\frac{\\lambda^{\\sum_i y_i}e^{-n\\lambda}}{\\prod_{i}y_i!}\\]\nEl prior es Gamma: \\[p(\\lambda) = \\frac{r^s}{\\Gamma(s)} \\lambda^{s-1}e^{-r\\lambda}\\]\nInteresa hallar \\(p(\\lambda\\mid \\mathbf{y})\\)\n\n\n\n\\[p(\\lambda\\mid \\mathbf{y}) \\propto p(\\mathbf{y}\\mid\\lambda) p(\\lambda)\\]\n\n\\[p(\\lambda \\mid \\mathbf{y}) \\propto \\frac{\\lambda^{\\sum_i y_i}e^{-n\\lambda}}{\\prod_{i}y_i!} \\frac{r^s}{\\Gamma(s)} \\lambda^{s-1}e^{-r\\lambda}\\] \\[p(\\lambda \\mid \\mathbf{y}) \\propto \\frac{r^s}{\\Gamma(s)\\prod_i y_i!} \\lambda^{\\sum_iy_i+s-1} e^{-n\\lambda - r \\lambda}\\]\n\n\n\\[p(\\lambda \\mid \\mathbf{y}) = K C \\lambda^{\\sum_iy_i+s-1} e^{-n\\lambda - r \\lambda}\\]\n\n\n\\[p(\\lambda \\mid \\mathbf{y}) = K^* \\lambda^{\\sum_iy_i+s-1} e^{-(n + r)\\lambda}\\]\n\n\n\n\nPara que \\(\\int_0^\\infty p(\\lambda\\mid \\mathbf{y})d \\lambda = 1\\), debe ser\n\n\\[K^* = \\frac{(n + r )^{\\sum_i y_i + s}}{\\Gamma(\\sum_i y_i + s)}\\]\n\n\nPor lo tanto, resulta que la distribuciÃ³n a posteriori es Gamma de parÃ¡metros \\(n+r\\) y \\(\\sum_i y_i + s\\)\n\n\n\\[\np(\\lambda\\mid \\mathbf{y}) = \\frac{(n + r )^{\\sum_i y_i + s}}{\\Gamma(\\sum_i y_i + s)} \\lambda^{\\sum_iy_i+s-1} e^{-(n + r)\\lambda}\n\\]\n\\[\n\\lambda\\mid \\mathbf{y} \\sim  \\mathrm{Gamma}(n+r,\\sum_i y_i + s)\n\\]\n\n\n\n\nSea una muestra \\(\\mathbf{y} = (y_1,y_2,\\dots,y_n)\\) obtenida de un modelo normal con varianza conocida \\(\\sigma^2\\), es decir:\n\\[y_i \\sim \\mathcal{N}(\\mu,\\sigma^2)\\]\nInteresa realizar una inferencia sobre el valor de \\(\\mu\\)\n\nÂ¿CÃ³mo asignamos una credibilidad a priori para \\(\\mu\\)?\n\n\n\n\nEl modelo propuesto es \\[\n\\begin{align*}\n    y_i\\mid\\mu & \\sim  \\mathcal{N}(\\mu,\\sigma^2)\\\\\n    \\mu & \\sim \\mathcal{N}(\\theta,\\tau^2)\n\\end{align*}\n\\]\nEl likelihood es normal: \\[p(y_i\\mid \\mu) = \\frac{1}{\\sqrt{2\\pi\\sigma}} e^{-\\frac{(y_i-\\mu)^2}{2\\sigma^2}} \\rightarrow \\\\ p(\\mathbf{y}\\mid \\mu) = \\left(\\frac{1}{2\\pi\\sigma}\\right)^{n/2}  e^{-\\frac{\\sum_i(y_i-\\mu)^2}{2\\sigma^2}} \\propto e^{-\\frac{(\\bar{y}-\\mu)^2}{2\\sigma^2/n}}\\]\nEl prior es normal: \\[p(\\mu) = \\frac{1}{\\sqrt{2\\pi\\tau}} e^{-\\frac{(\\mu-\\theta)^2}{2\\tau^2}}\\]\nInteresa hallar \\(p(\\lambda\\mid \\mathbf{y})\\)\n\n\n\n\\[p(\\mu\\mid \\mathbf{y}) \\propto p(\\mathbf{y}\\mid\\mu) p(\\mu)\\] \\[p(\\mu \\mid \\mathbf{y}) \\propto   e^{-\\frac{(\\bar{y}-\\mu)^2}{2\\sigma^2/n}} \\frac{1}{\\sqrt{2\\pi\\tau}} e^{-\\frac{(\\mu-\\theta)^2}{2\\tau^2}}\\]\n\\[\n\\begin{align*}\np(\\mu \\mid \\mathbf{y}) & \\propto  e^{-\\frac{(\\bar{y}-\\mu)^2}{2\\sigma^2/n}} e^{-\\frac{(\\mu-\\theta)^2}{2\\tau^2}} \\\\\n&  \\propto  e^{-\\left[\\frac{(\\bar{y}-\\mu)^2}{2\\sigma^2/n}+\\frac{(\\mu-\\theta)^2}{2\\tau^2}\\right]} \\\\\n& \\propto e^{-\\left[ \\frac{\\bar{y}^2 - 2\\bar{y} \\mu + \\mu^2}{2\\sigma^2/n} + \\frac{\\mu^2 - 2\\mu\\theta^2 + \\theta^2}{2\\tau^2} \\right]} \\\\\n& \\propto e^{\\left[ \\frac{ 2\\bar{y} \\mu - \\mu^2}{2\\sigma^2/n} + \\frac{-\\mu^2 + 2\\mu\\theta^2}{2\\tau^2} \\right]} \\\\\n& \\propto e^{\\left[ \\frac{(2\\bar{y} \\mu - \\mu^2)n\\tau^2 + (-\\mu^2 + 2\\mu\\theta^2)\\sigma^2}{2\\sigma^2\\tau^2} \\right]}\n\\end{align*}\n\\]\n\n\n\n\\[\n    \\begin{align*}\nP(\\mu \\mid \\mathbf{y}) & \\propto e^{\\frac{2\\mu(\\theta\\sigma^2+ \\bar{y}n\\tau^2)-\\mu^2(n\\tau^2+\\sigma^2)}{2\\tau^2\\sigma^2}} \\\\\n& \\propto e^{\\frac{-\\mu^2 + 2\\mu \\left( \\frac{\\theta\\sigma^2 + \\bar{y}n\\tau^2}{n\\tau^2 + \\sigma^2} \\right)}{2\\tau^2\\sigma^2/(n\\tau^2 + \\sigma^2)}} e^{-\\left(\\frac{\\theta\\sigma^2 + \\bar{y}n\\tau^2}{n\\tau^2 + \\sigma^2}\\right)^2} \\\\\n& \\propto e^{-\\frac{\\left(\\mu -  \\frac{\\theta\\sigma^2 + \\bar{y}n\\tau^2}{n\\tau^2 + \\sigma^2} \\right)^2}{2\\tau^2\\sigma^2/(n\\tau^2+\\sigma^2)}}\n    \\end{align*}\n\\] \\[p(\\mu\\mid\\mathbf{y}) = K^* e^{-\\frac{\\left(\\mu -  \\frac{\\theta\\sigma^2 + \\bar{y}n\\tau^2}{n\\tau^2 + \\sigma^2} \\right)^2}{2\\tau^2\\sigma^2/(n\\tau^2+\\sigma^2)}}\\]\n\n\n\nPor lo tanto, resulta que la distribuciÃ³n a posteriori es normal de parÃ¡metros \\(\\theta_n\\) y \\(\\tau_n^2\\)\n\n\\[\n\\begin{align*}\n\\mu\\mid \\mathbf{y} & \\sim  \\mathcal{N}\\left( \\frac{\\theta\\sigma^2 + \\bar{y}n\\tau^2}{n\\tau^2 + \\sigma^2},\\frac{\\tau^2\\sigma^2}{n\\tau^2+\\sigma^2} \\right) \\\\\n& \\sim \\mathcal{N}\\left( \\theta_n,\\tau_n^2 \\right)\n\\end{align*}\n\\]\n\n\n\n\nReflexionemosâ€¦\n\\[\n\\begin{align*}\n    y_i\\mid\\mu & \\sim  \\mathcal{N}(\\mu,\\sigma^2) \\\\\n    \\mu & \\sim  \\mathcal{N}(\\theta,\\tau^2) \\\\\n    \\mu \\mid \\mathbf{y} & \\sim \\mathcal{N}(\\theta_n,\\tau_n^2)\n\\end{align*}\n\\]\nÂ¿ParÃ¡metros desconocidos en la verosimilitud? Â¿DimensiÃ³n y caracterÃ­stica del espacio de parÃ¡metros? Â¿Constantes de ajuste del prior? Â¿Forma del posterior? Â¿QuÃ© son \\(\\theta_n\\) y \\(\\tau_n^2\\)?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nÂ¿Puedo representar los datos en el grÃ¡fico de la izquierda?\n\nNo, es el mundo de los parÃ¡metros\n\n\nÂ¿QuÃ© representan los valores marcados con \\(\\mathbf{\\times}\\)?\n\nPosibles valores de \\(\\mu\\) que podrÃ­an esperarse a priori.\n\n\n\nÂ¿Media y varianza de la normal de la izquierda?\n\n\\(\\theta\\) y \\(\\tau^2\\)\n\n\n\nÂ¿Media y varianza de las normales de la derecha?\n\n\\(\\mu\\) y \\(\\sigma^2\\)\n\n\n\n\n\nÂ¿QuÃ© estamos viendo?\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 7\n  #| fig-height: 6\n  #| fig-align: center\n  #| cache: true\n\np3\n\n\n\n\n\n\n\nA posteriori (luego de observar los datos)â€¦ Â¿quÃ© ocurre con la plausibilidad de los valores de \\(\\mu\\)?\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 18\n  #| fig-height: 6\n  #| fig-align: center\n  #| cache: true\n\np5 + p4\n\n\n\n\n\n\n\nÂ¿Media y varianza de la normal de la izquierda?\n\n\\(\\theta_n\\) y \\(\\tau_n^2\\)\n\nÂ¿Media y varianza de las normales de la derecha?\n\n\\(\\mu\\) y \\(\\sigma^2\\)\n\n\n\n\n\n\n\\[\\mathbb{E}[p(\\mu\\mid \\mathbf{y})] = \\theta_n = \\frac{\\theta\\sigma^2 + \\bar{y}n\\tau^2}{n\\tau^2 + \\sigma^2}\\] \\[\\mathbb{E}[p(\\mu\\mid \\mathbf{y})] =  \\theta\\frac{\\sigma^2}{n\\tau^2 + \\sigma^2} + \\bar{y}\\frac{n\\tau^2}{n\\tau^2 + \\sigma^2}\\]\n\nRepresenta un balance (promedio ponderado o ) entre la media muestral y la media esperada .\n\n\n\\[\\mathbb{V}[p(\\mu\\mid \\mathbf{y})] = \\tau_n^2 = \\frac{\\tau^2\\sigma^2}{n\\tau^2+\\sigma^2}\\]\n\\[\\mathbb{V}[p(\\mu\\mid \\mathbf{y})] = \\frac{1}{\\frac{n}{\\sigma^2}+\\frac{1}{\\tau^2}}\\] \\[\\frac{1}{\\mathbb{V}[p(\\mu\\mid \\mathbf{y})]} =  \\frac{n}{\\sigma^2} + \\frac{1}{\\tau^2}\\]\nLa precisiÃ³n a posteriori es la suma de las precisiones del prior y la muestra.\n\n\n\n\n\n\n\n\\[p(\\tilde{y}\\mid \\mathbf{y}) = \\int p(\\tilde{y}\\mid \\mu) p(\\mu\\mid \\mathbf{y})d\\mu\\] El integrando es el producto de dos normales: una normal bivariada. Por lo tanto toda la integral es una distribuciÃ³n marginal de una normal: otra normal.\n\n\n\n\nDemostraciÃ³n poco formalâ€¦\nA posteriori vale \\[\n\\begin{array}{ccc}\ny & = & (y-\\mu) + \\mu \\\\\ny-\\mu \\mid \\mu & \\sim & \\mathcal{N}(0,\\sigma^2) \\\\\n\\mu \\mid \\mathbf{y} & \\sim & \\mathcal{N}(\\theta_n,\\tau_n^2)\n\\end{array}\n\\]\nResulta\n\\[p(\\tilde{y}\\mid \\mathbf{y}) = \\mathcal{N}(\\mu_n,\\sigma^2 + \\tau_n^2)\\]\n\n\n\nLa varianza predictiva \\(\\sigma^2 + \\tau_n^2\\) es una medida de la incertidumbre a posteriori respecto a una observaciÃ³n nueva \\(\\tilde{y}\\).\n\nLa incertidumbre en \\(\\tilde{y}\\) proviene de la variabilidad debida al azar (\\(\\sigma\\)) y de la variabilidad debida al desconocimiento de \\(\\mu\\) (\\(\\tau_n\\))\n\n\nEn otras palabras, si supiÃ©ramos que \\(\\mu = 2\\), toda la variabilidad provendrÃ­a de \\(\\sigma\\), Â¡pero no sabemos cuÃ¡nto vale \\(\\mu\\)! Puede ser \\(2\\) o \\(1,98\\) o \\(1.43\\)â€¦ Por lo que hay una componente adicional de varianza.\n\n\n\n\nNo se entendiÃ³ nada. Simular para creer.\n\nÂ¿CÃ³mo obtenemos una observaciÃ³n nueva si sabemos que \\(\\mu = 2\\) (sabiendo que \\(\\sigma = 1,2\\))? . . . Directamente tomamos una muestra \\(\\tilde{y}\\) de \\(\\mathcal{N}\\left(\\mu=2,\\sigma^2= 1.2^2\\right)\\)\n\ny_new <- rnorm(1, mean = 2, sd = 1.2)\n\n\n\nPero en estadÃ­stica bayesiana \\(\\mu\\) tiene una distribuciÃ³n de probabilidad (por ejemplo \\(\\mathcal{N}\\left(\\theta_n=2,\\tau_n^2=1.8^2\\right)\\)), Â¿cÃ³mo hacemos la simulaciÃ³n?\n\n\n\nTomamos una muestra \\(\\mu^{(s)}\\) de la distribuciÃ³n de \\(\\mu\\)\nObtenemos \\(\\tilde{y}\\) a partir de \\(\\mathcal{N}(\\mu=\\mu^{(s)},\\sigma^2=1.2^2)\\)\n\n\n\n\nmu_s <- rnorm(1, mean = 2, sd = 1.8)\ny_new <- rnorm(1, mean = mu_s, sd = 1.2)\n\n\n\nÂ¿QuÃ© va a pasar en cada caso si construimos la distribuciÃ³n de \\(\\tilde{y}\\)?\n\n\n\n\n\n\n\n\n\n\n\n\n\nLa distribuciÃ³n predictiva contiene la variabilidad inherente al fenÃ³meno en estudio (\\(\\sigma\\)) y la incertidumbre en el parÃ¡metro \\(\\mu\\).\n\n\n\nSea una muestra \\(\\mathbf{y} = (y_1,y_2,\\dots,y_n)\\) obtenida de un modelo normal con varianza desconocida \\(\\sigma^2\\), es decir:\n\\[y_i \\sim \\mathcal{N}(\\mu,\\sigma^2)\\]\nE interesa realizar una inferencia sobre el valor de \\(\\mu\\) y el valor de \\(\\sigma\\)\n\nÂ¿CÃ³mo asignamos una credibilidad a priori para \\(\\mu\\) y \\(\\sigma\\)? Â¡Con una distribuciÃ³n en dos dimensiones!\n\n\n\n\nEl modelo es\n\\[\n\\begin{align*}\n    X_i\\mid\\mu,\\sigma^2 & \\sim  \\mathcal{N}(\\mu,\\sigma^2) \\\\\n    \\mu,\\sigma^2 & \\sim  \\mathcal{N}GI(\\theta,\\tau,\\alpha,\\beta)\n\\end{align*}\n\\]\n\\(\\mu\\) y \\(\\sigma^2\\) tienen distribuciÃ³n conjunta normal-gamma-inversa:\n\\[(\\mu,\\sigma^2) = \\frac{\\sqrt{\\tau}}{\\sqrt{2\\pi\\sigma^2}} \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} \\left( \\frac{1}{\\sigma^2} \\right)^{\\alpha+1} e^{-\\frac{2\\beta + \\tau(\\mu-\\theta)^2}{2\\sigma^2}}\\]\nSi anticipamos que la normal-gamma-inversa es conjugada de la normal (para los parÃ¡metros \\(\\mu\\) y \\(\\sigma^2\\)), Â¿quÃ© podemos decir de la distribuciÃ³n a posteriori (conjunta) de \\(\\mu\\) y \\(\\sigma^2\\)\n\n\n\nEfectivamente, se puede probar que:\n\\[\n\\begin{align*}\n\\mu,\\sigma^2 \\mid \\mathbf{y} & \\sim  \\mathcal{N}GI(\\theta_n,\\tau_n,\\alpha_n,\\beta_n)\n\\end{align*}\n\\] con\n\\[\n\\begin{cases}\n\\theta_n = \\frac{\\tau\\theta + n \\bar{y}}{\\tau+n}\\\\\n\\tau_n = \\tau + n\\\\\n\\alpha_n = \\alpha + \\frac{n}{2}\\\\\n\\beta_n = \\beta + \\frac{1}{2} \\sum_i (y_i - \\bar{y})^2 + \\frac{n\\tau}{\\tau + n} \\frac{(\\bar{y}-\\theta)^2}{2}\n\\end{cases}\n\\]\nÂ¿ParÃ¡metros desconocidos en la verosimilitud? Â¿DimensiÃ³n del espacio de parÃ¡metros? Â¿Constantes de ajuste del prior? Â¿Forma del posterior?\n\n\n\nReflexionemosâ€¦\n\\[\n\\begin{align*}\n    y_i\\mid\\mu & \\sim  \\mathcal{N}(\\mu,\\sigma^2) \\\\\n    \\mu & \\sim  \\mathcal{N}(\\theta,\\tau^2) \\\\\n    \\mu \\mid \\mathbf{y} & \\sim \\mathcal{N}(\\theta_n,\\tau_n^2)\n\\end{align*}\n\\]\nÂ¿ParÃ¡metros desconocidos en la verosimilitud? Â¿DimensiÃ³n y caracterÃ­stica del espacio de parÃ¡metros? Â¿Constantes de ajuste del prior? Â¿Forma del posterior? Â¿QuÃ© son \\(\\theta_n\\) y \\(\\tau_n^2\\)?\n\n\n\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 18\n  #| fig-height: 6\n  #| fig-align: center\n  #| cache: true\n\np1 + p2 \n\n\n\n\n\n\n\nÂ¿Puedo representar los datos en el grÃ¡fico de la izquierda?\n\nNo, es el mundo de los parÃ¡metros\n\n\nÂ¿QuÃ© representan los valores marcados con \\(\\mathbf{\\times}\\)?\n\nPosibles valores de \\(\\mu\\) y \\(\\sigma^2\\) que podrÃ­an esperarse a priori.\n\n\n\nÂ¿QuÃ© le da forma a la distribuciÃ³n de la izquierda?\n\n\\(\\theta\\), \\(\\tau\\), \\(\\alpha\\) y \\(\\beta\\)\n\n\n\nÂ¿Media y varianza de las normales de la derecha?\n\n\\(\\mu\\) y \\(\\sigma^2\\)\n\n\n\n\n\nÂ¿QuÃ© estamos viendo?\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 9\n  #| fig-height: 6\n  #| fig-align: center\n  #| cache: true\n\np3\n\n\n\n\n\n\n\nA posteriori (luego de observar los datos)â€¦ Â¿quÃ© ocurre con la plausibilidad de los valores de \\(\\mu\\) y \\(\\sigma^2\\)?\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 18\n  #| fig-height: 6\n  #| fig-align: center\n  #| cache: true\n\np4 + p5\n\n\n\n\n\n\n\nÂ¿ParÃ¡metros de la distribuciÃ³n de la izquierda?\n\n\\(\\theta_n\\), \\(\\tau_n\\), \\(\\alpha_n\\) y \\(\\beta_n\\)\n\n\nÂ¿Media y varianza de las normales de la derecha?\n\n\\(\\mu\\) y \\(\\sigma^2\\)"
  },
  {
    "objectID": "presentaciones/presentacion_04.html",
    "href": "presentaciones/presentacion_04.html",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Un meteorÃ³logo estima, con un 95% de confianza, que la probabilidad de que el huracÃ¡n no llegue a la ciudad estÃ¡ entre 99% y 100%. Muy feliz con su precisiÃ³n y su modelo, aconseja que la evacuaciÃ³n de la ciudad no es necesaria. Desafortunadamente, el huracÃ¡n llega a la ciudad produciendo una grave inundaciÃ³n.\n\n\nâ€œI would rather be vaguely right than very wrong.â€\n\n\n\n\n\nCon el clima, las personas tienden a notar un error mÃ¡s que otro. Cuando llueve sin estar anunciado, se tiende a insultar al servicio meteorolÃ³gico mientras que la ausencia de lluvia a pesar del pronÃ³stico se toma con buena cara.\n\n\n\nEl Weather Channel exagera ligeramente la probabilidad de lluvia cuando es poco probable que ocurra: dicen que es de 20% cuando en realidad es de 5% o 10%\n\n\n\n\n\nEn la estadÃ­stica bayesiana, la distribuciÃ³n a posteriori es la base de todas inferencia: combina el conocimiento a priori con la informaciÃ³n provista por los datos. Contiene todo lo que se sabe y no se sabe sobre un parÃ¡metro desconocido.\n\nLa respuesta a los problemas es toda la distribuciÃ³n a posteriori de los parÃ¡metros (y de otras cantidades de interÃ©s).\n\n\n\n\nNo obstante, puede ser de utilidad (o incluso necesario) tomar decisiones concretas o resumir la distribuciÃ³n a posteriori.\n\n\\(a\\) es la acciÃ³n que tomamos (intervenir o no intervenir quirÃºrgicamente a una persona) o la respuesta que damos (ganancia de una campaÃ±a de marketing).\n\n\nPuede ser una estimaciÃ³n puntual \\(\\hat{\\theta}\\): dada una inferencia sobre la ganancia de una campaÃ±a de marketing, es necesario informar un valor puntual (quizÃ¡s con un intervalo)\n\n\n\n\nTratamos a los parÃ¡metros sobre los que realizamos inferencias como variables aleatorias. Una muestra de la distribuciÃ³n a posteriori es una posible realizaciÃ³n del verdadero valor del parÃ¡metro.\n\nAl dar una respuesta (o resumir la informaciÃ³n a posteriori), podemos incurrir en un error (grande o chico) segÃºn se den los eventos posibles.\n\n\nÂ¿QuÃ© es un error? Â¿CÃ³mo definimos si el error es grande o chico? Â¿CÃ³mo definimos si el error es relevante o no?\n\n\n\n\n\\[L(\\theta,\\hat{\\theta}) = f(\\theta,\\hat{\\theta})\\] es una funciÃ³n de pÃ©rdida, quÃ© tanto pierdo por usar \\(\\hat{\\theta}\\) para estimar \\(\\theta\\).\n\n\n\nPor ejemplo:\n\\[L_2 = (\\theta - \\hat{\\theta})^2\\]\n\\[L_1 = |\\theta - \\hat{\\theta}|\\]\n\\[L_{0/1} =\n\\begin{cases}\n0 \\text{ si } \\hat{\\theta} = \\theta  \\\\\n1 \\text{ si } \\hat{\\theta} \\neq \\theta\n\\end{cases}\\]\n\\[L( \\theta, \\hat{\\theta} ) = \\begin{cases} ( \\theta -  \\hat{\\theta} )^2 & \\hat{\\theta} \\lt \\theta \\\\\\\\ c( \\theta -  \\hat{\\theta} )^2 & \\hat{\\theta} \\ge \\theta, \\;\\; 0\\lt c \\lt 1 \\end{cases}\\]\n\n\n\nBuscamos elegir \\(\\hat{\\theta}\\) de manera tal que minimice \\(L\\). El problema es que no conocemos \\(\\theta\\) y por lo tanto no podemos calcular \\(L(\\theta,\\hat{\\theta})\\).\n\nÂ¿Sabemos algo sobre \\(\\theta\\) que nos pueda ayudar? Conocemos su distribuciÃ³n a posteriori\n\n\nPodemos promediar \\(L\\) para los valores posibles de \\(\\theta\\) (ponderando segÃºn la distribuciÃ³n a posteriori)\n\n\n\n\nEl riesgo a posteriori (posterior risk o posterior expected loss) es la pÃ©rdida esperada ponderada por los valores de \\(\\theta\\) (y su distribuciÃ³n a posteriori).\n\n\\[R(\\hat{\\theta}) = \\mathbb{E}_{\\theta\\mid y}[L(\\theta,\\hat\\theta)] = \\int L(\\theta,\\hat\\theta) p(\\theta\\mid y) d\\theta\\]\n\n\nEs una funciÃ³n de los posibles valores que puede tomar \\(\\hat\\theta\\).\n\n\nPodemos obtener el \\(\\hat\\theta\\) que minimice \\(R(\\hat\\theta)\\). Es decir, buscamos un valor (un estimador) que minimice la pÃ©rdida esperada al usarlo para resumir \\(p(\\theta\\mid y)\\): \\[\\hat{\\theta} = \\underset{\\hat\\theta}{\\mathrm{arg\\,min}}\\left[ R(\\hat\\theta) \\right]\\]\n\n\n\n\nSimulemosâ€¦\n\nSupongamos que \\(\\theta\\mid y \\sim \\mathrm{Beta}(2,9)\\)\n\n\n\n\\(R\\) es una funciÃ³n de \\(\\hat\\theta\\) (los distintos valores que podemos usar para resumir \\(p(\\theta\\mid y)\\))\nPara distintos valores de \\(\\hat\\theta\\) voy a tomar muestras de \\(p(\\theta\\mid y)\\) y calcular la pÃ©rdida \\(L\\)\nPara cada valor de \\(\\hat\\theta\\) voy a calcular la pÃ©rdida promedio (ya va a estar ponderada por la probabilidad a posteriori de \\(\\theta\\))\n\n\n\n\n\n\nL_2 <- function(theta,theta_hat) (theta-theta_hat)^2\n\nloss <- data.frame(theta_hat = double(),\n                   theta = double(),\n                   L = double())\n\nfor(theta_hat in seq(0,1,0.008)){\n  theta <- rbeta(2000, shape1 = 2, shape2 = 9)\n  L <- L_2(theta,theta_hat)\n  loss <- bind_rows(loss,data.frame(theta_hat,theta,L))\n}\n\nexpected.loss <- loss |>\n  group_by(theta_hat) |>\n  summarise(loss.mean = mean(L))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSi deseamos resumir la distribuciÃ³n a posteriori con un Ãºnico valor (Â¡perdiendo informaciÃ³n!), puede usarse:\n\n\nLa media: minimiza la pÃ©rdida cuadrÃ¡tica esperada a posteriori\nLa mediana: minimiza la pÃ©rdida absoluta esperada a posteriori\nLa moda (tambiÃ©n llamado MAP por maximum a posteriori o estimador generalizado de mÃ¡xima verosimilitud): minimiza la pÃ©rdida \\(0/1\\) esperada a posteriori\n\n\n\n\n\nUna prueba mÃ¡s formal para el caso de la mediaâ€¦\n\nSea la pÃ©rdida cuadrÃ¡tica \\(L(\\theta,\\hat\\theta)=(\\theta-\\hat\\theta)^2\\), el riesgo (posterior expected loss) es:\n\n\n\\[\n\\mathbb{E}_{\\theta\\mid y}[L(\\theta,\\hat\\theta)] = \\mathbb{E}_{\\theta\\mid y}[\\theta^2] - 2 \\hat{\\theta}\\mathbb{E}_{\\theta\\mid y}[\\theta] + {\\hat{\\theta}}^2\n\\]\n\n\nderivando respecto a \\(\\hat{\\theta}\\) e igualando a cero se obtiene que \\(\\underset{\\hat\\theta}{\\mathrm{arg\\,min}}\\left[ R(\\hat\\theta) \\right] = \\mathbb{E}_{\\theta\\mid y}[\\theta] = \\mathbb{E}[p(\\theta\\mid y)]\\)\n\n\n\n\nUna prueba mÃ¡s formal para el caso de la medianaâ€¦\n\nSea la pÃ©rdida absoluta \\(L(\\theta,\\hat\\theta)=|\\theta-\\hat\\theta|\\), el riesgo (posterior expected loss) es:\n\n\n\\[\n\\mathbb{E}_{\\theta\\mid y}[L(\\theta,\\hat\\theta)] = \\int_{-\\infty}^\\infty |\\theta-\\hat\\theta| p(\\theta\\mid y)d\\theta\n\\]\n\n\n\\[\n\\int_{-\\infty}^\\hat{\\theta} (\\hat\\theta-\\theta) p(\\theta\\mid y)d\\theta + \\int_{\\hat{\\theta}}^\\hat{\\infty} (\\theta-\\hat\\theta) p(\\theta\\mid y)d\\theta\n\\]\n\n\nPara derivar, se utiliza la regla integral de Leibniz:\n\n\n\\[\\frac{d}{d\\hat\\theta}\\int_{-\\infty}^{\\hat\\theta} g(\\hat\\theta,\\theta)d\\theta = g(\\hat\\theta,\\hat\\theta) + \\int_{-\\infty}^\\hat\\theta \\frac{\\partial}{\\partial\\hat\\theta}g(\\hat\\theta,\\theta)d\\theta\\]\n\n\nSe puede probar que \\(\\int_{-\\infty}^\\hat\\theta p(\\theta\\mid y)d\\theta = \\frac{1}{2}\\), por lo que el \\(\\hat\\theta\\) que minimiza la expresiÃ³n es la mediana.\n\n\n\n\nTambiÃ©n llamados: intervalos de probabilidad, intervalo de confianza bayesiano, regiÃ³n de credibilidad. Es una regiÃ³n del dominio del parÃ¡metro que tiene alta probabilidad de contenerlo. Se utiliza para resumir el posterior.\n\nUn intervalo de credibilidad es una regiÃ³n \\(C\\) tal que la probabilidad de que contenga al parÃ¡metro sea al menos \\(1 - \\alpha\\):\n\n\n\\[p(\\theta \\in C \\mid y) = \\int_C p(\\theta\\mid y) d\\theta = 1-\\alpha\\] en el caso discreto es (\\(\\geq 1-\\alpha\\))\n\n\nDecimos: la probabilidad de que \\(\\theta\\) estÃ© contenido en \\(C\\), dados los datos (y el modelo) es de \\(1-\\alpha\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEn el anÃ¡lisis de datos bayesiano, es habitual resumir los hallazgos reportando:\n\n\nUn grÃ¡fico de la distribuciÃ³n a posteriori\nAlgÃºn medida de centralidad de la distribuciÃ³n a posteriori\nPercentiles relevantes de la distribuciÃ³n a posteriori\nProbabilidades a posteriori de interÃ©s \\(p(\\theta>c\\mid y)\\) para algÃºn \\(c\\) interesante, por ejemplo \\(c=0\\)\n\n\n\n\n\nPara interpretar los resultados de la inferencia bayesiana podemos simplemente realizar simulaciones a partir del posterior y estimar probabilidades contando.\n\n\nlos parÃ¡metros\nfunciones de los parÃ¡metros\nla variable respuesta (predicciones)\n\n\n\n\n\nUn nuevo ejemplo del modelo betaâ€“Binomial: partimos de \\(\\mathrm{Beta}(2,2)\\), observamos \\(4\\) caras en \\(6\\) tiradas y nuestra creencia a posteriori pasa a ser \\(Beta(6,4)\\).\n\n\n\n\n\nÂ¿CuÃ¡l es la probabilidad a posteriori de que \\(\\pi\\) sea mayor a \\(0.50\\)? Â¿y de que sea mayor a ?\n\nmuestras_pi <- rbeta(2000,6,4)\nmean(muestras_pi > 0.5)\nmean(muestras_pi > 0.8)\n\n\n\n\n\n\n\nÂ¿CuÃ¡l es la distribuciÃ³n a posteriori de la chance de obtener cara \\(\\frac{\\pi}{1-\\pi}\\)?\n\nmuestras_pi <- rbeta(2000,6,4)\nmuestras_odds <- muestras_pi/(1-muestras_pi)\n\n\n\n\n\n\n\nSi se arroja la moneda 11 veces mÃ¡s Â¿cuÃ¡l es la distribuciÃ³n de probabilidad de la cantidad de caras? (es la distribuciÃ³n predictiva a posteriori)\n\nmuestras_pi <- rbeta(2000,6,4)\ny_new <- rbinom(2000,11,muestras_pi)\n\n\n\n\n\nToda cantidad que dependa de los parÃ¡metros tiene una distribuciÃ³n a posteriori: una incertidumbre asociada."
  },
  {
    "objectID": "presentaciones/presentacion_01.html",
    "href": "presentaciones/presentacion_01.html",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "\\[A \\Rightarrow B\\] \\(A\\) es verdadero, por lo tanto \\(B\\) es verdadero\n\\(B\\) es falso, por lo tanto \\(A\\) falso\n\n\\(A\\): Tom es un gato\n\\(B\\): Tom es un animal\n\n\\(B\\) es verdadero, por lo tantoâ€¦\n\n\n\nPero este no es el tipo de razonamiento que utilizamos en la vida cotidiana:\n\n\\(A\\): va a llover a las 10 de la maÃ±ana\n\\(B\\): se nubla antes de las 10 de la maÃ±ana\n\n\\(B\\) es verdadero, por lo tanto \\(A\\) se vuelve mÃ¡s plausible\n\n\n\n\nEn una noche oscura, un policÃ­a camina por una calle aparentemente desierta. De repente, se escucha la alarma de un local. Se da vuelta y ve, en la vereda de enfrente, una joyerÃ­a con la vidriera rota. Un hombre con una mÃ¡scara sale agachado a travÃ©s del vidrio roto, con una bolsa llena de joyas caras. El policÃ­a no duda en concluir que el hombre no tiene buenas intenciones.\n\nEl razonamiento del policÃ­a no fue una deducciÃ³n lÃ³gica, ya que podrÃ­a existir una explicaciÃ³n alternativa para lo ocurrido.\n\nDada la evidencia, no podemos decir con seguridad que las intenciones del hombre no son buenas, pero sÃ­ que es extremadamente plausible que no lo sean.\n\n\n\n\nEl cerebro humano permanentemente determina si algo se vuelve mÃ¡s o menos plausible. MÃ¡s aÃºn, de alguna manera, evalÃºa el grado de plausibilidad de una proposiciÃ³n.\n\n\nLa plausibilidad de que llueva a las 10 de la maÃ±ana depende fuertemente de la oscuridad de las nubes a las 9:45.\n\n\n\nEste razonamiento hace uso de nuestra experiencia previa. Combina informaciÃ³n a priori con evidencia disponible. Esto da lugar a un proceso secuencial.\n\n\n\n\n\n\n\n\n\n\nPÃ¡guese $1000 al portador de esta tarjeta si en este grupo hay alguien que tiene un loro como mascota\n\n\n\n\n\n\n\n\n\nPÃ¡guese $1000 al portador de esta tarjeta si en este grupo nadie tiene un loro como mascota\n\n\n\n\nTienen a su disposiciÃ³n estas tarjetas. Podemos comprarlas o venderlas. Al final de la clase develamos el misterio y, quien tenga la tarjeta, cobra.\n\n\nÂ¿Por cuÃ¡l pagarÃ­an mÃ¡s? Â¿CuÃ¡nto estarÃ­an dispuestos a pagar como mÃ¡ximo?\n\n\nNotar que el precio mÃ¡ximo que estarÃ­an dispuestos a pagar para comprarla es el precio mÃ­nimo por el que estarÃ­an dispuestos a venderla.\n\n\n\n\nTodos pagarÃ­amos \\(p\\cdot\\$ 1000\\) con \\(0 \\leq p \\leq 1\\).\n\nDecidimos cuÃ¡nto apostar en funciÃ³n de nuestra incertidumbre en la ocurrencia de un evento (de lo plausible que lo consideremos). Decidimos apostar \\(p\\cdot\\$ 1000\\) en favor de un evento, porque le asignamos una plausibilidad o credibilidad de grado \\(p\\).\n\n\n\n\n\n\n\n\n\n\nPÃ¡guese $1000 al portador de esta tarjeta si el profe tiene una remera negra\n\n\n\nÂ¿CuÃ¡nto estÃ¡n dispuestos a pagar para tener esta tarjeta? Â¿Por cuÃ¡nto venderÃ­an la tarjeta si la tuvieran?\n\n\n\n\n\n\n\n\n\nPÃ¡guese $1000 al portador de esta tarjeta si esta materia es la mejor del cuatrimestre\n\n\n\n\n\n\n\n\n\nPÃ¡guese $1000 al portador de esta tarjeta si esta materia no es la mejor del cuatrimestre\n\n\n\n\nPor la primera pagarÃ­an como mÃ¡ximo \\(p\\cdot\\$ 1000\\) y por la segunda, \\(q\\cdot\\$ 1000\\). Es necesario que \\(p+q=1\\). Â¿Por quÃ©?\n\n\n\n\nSupongamos que \\(p=0.7\\) y \\(q=0.5\\). Eso significa que:\n\nSi no tienen las tarjetas, estarÃ­an dispuestos a comprar ambas por \\(\\$1200\\).\n\nSupongamos que \\(p=0.3\\) y \\(q=0.2\\). Eso significa que:\n\nSi tienen las tarjetas, estarÃ­an dispuestos a vender ambas por \\(\\$500\\).\n\n\nSabemos que a fin de cuatrimestre, quien tenga las dos tarjetas ganarÃ¡ \\(\\$1000\\)â€¦\n\nThe canonical way to measure degrees of belief appeals to the notion of fair odds.\nThe degree of belief that a given epistemic agentâ€”letâ€™s say itâ€™s youâ€”has in this proposition A can be determined by what you deem to be the fair price of this lottery. Here the â€œfair priceâ€ is the price at which you are willing to either buy or sell the lottery ticket.\n\n\n\n\n\n\n\n\n\n\n\nDutch book\n\n\n\nUn Dutch book es un conjunto de apuestas que aseguran una pÃ©rdida. El argumento del Dutch book dice que una persona que tiene creencias inconsistentes actÃºa irracionalmente y puede ser llevado a una pÃ©rdida segura en un juego de apuestas\n\n\n\nLos grados de plausibilidad o grados de creencia que una persona le asigna a un conjunto de eventos deben respetar los axiomas de probabilidad.\n\n\nSe puede asignar un valor de probabilidad a cualquier proposiciÃ³n.\n\n\n\n\nLas probabilidades son la mejor herramienta disponible para cuantificar la incertidumbre y las leyes de la probabilidad, la mejor herramienta para operar con ella.\n\n\n\nTres ideas de probabilidad\n\nClÃ¡sica: si \\(n\\) eventos son equiprobables, la probabilidad de uno de ellos es \\(1/n\\). AdemÃ¡s, la probabilidad de un evento se puede calcular como el nÃºmero de casos favorables dividido el nÃºmero de casos posibles.\nFrecuentista: la probabilidad de un evento se puede estimar observando su frecuencia relativa sobre un gran nÃºmero de realizaciones o ensayos.\nSubjetiva: las probabilidades reflejan el grado de creencia o plausibilidad que una persona le asigna a un evento.\n\n\n\n\n\nEs la forma mÃ¡s general de interpretar la probabilidad (eventos no equiprobables y eventos que no pueden repetirse)\nSe utiliza para cuantificar la incertidumbre o ignorancia (o certidumbre o conocimiento) acerca de un evento o proposiciÃ³n\nEs personal\nDepende del estado actual de conocimiento del mundo\n\n\nTodos los mÃ©todos estadÃ­sticos son subjetivos en el sentido que se basan en idealizaciones matemÃ¡ticas de la realidad (modelos).\n\n\n\n\nDistinguimos dos tipos de incertidumbre:\n\n\nIncertidumbre epistÃ©mica\nIncertidumbre aleatoria\n\n\n\nLo retomaremos a lo largo del curso.\n\n\n\n\nConsideremos la siguiente proposiciÃ³n:\n\nVoy a aprobar todas las materias de este cuatrimestre (\\(W\\))\n\n\nUna caja con 5 bolas azules y 5 bolas rojas. Se extrae una bola al azar. \\(A\\) es el evento extraer una bola azul\n\n\n\n\\(A_1\\): $1000 si \\(W\\)\n\\(A_2\\): $1000 si \\(A\\)\n\n\n\nSi prefieren \\(A_1\\) entoncesâ€¦ 8 bolas azules y 2 bolas rojas. Se extrae una bola al azar. \\(A\\) es el evento extraer una bola azul.\n\n\n\n\\(A_3\\): $1000 si \\(W\\)\n\\(A_4\\): $1000 si \\(A\\)\n\n\n\n\n\nInterludioâ€¦\n\nÂ¿QuÃ© es mÃ¡s probable?\n\nQue el PSG le gane al Lyon\nQue el PSG le gane al Lyon y Messi haga un gol\n\n\n\n\n\nLos seres humanos no estamos optimizados para operar con probabilidades (al menos no intuitivamente)."
  },
  {
    "objectID": "presentaciones/presentacion_01.html#section-7",
    "href": "presentaciones/presentacion_01.html#section-7",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Probabilidad de un evento \\[\\mathrm{Pr}(A)\\] \\[\\mathrm{Pr}(\\bar{A}) = 1-\\mathrm{Pr}(A)\\]"
  },
  {
    "objectID": "presentaciones/presentacion_01.html#section-8",
    "href": "presentaciones/presentacion_01.html#section-8",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Probabilidad de la conjunciÃ³n:\n\\[\\mathrm{Pr}(A\\wedge B) = \\mathrm{Pr}(A,B)\\] Si \\(A\\) y \\(B\\) son independientes, entonces\n\\[\\mathrm{Pr}(A\\wedge B) = \\mathrm{Pr}(A)\\mathrm{Pr}(B)\\] Probabilidad de la uniÃ³n: \\[\\mathrm{Pr}(A \\vee B) = \\mathrm{Pr}(A) + \\mathrm{Pr}(B) - \\mathrm{Pr}(A,B)\\] Donde, si \\(A\\) y \\(B\\) son mutuamente excluyentes,\n\\[\\mathrm{Pr}(A \\vee B) = \\mathrm{Pr}(A) + \\mathrm{Pr}(B)\\]"
  },
  {
    "objectID": "presentaciones/presentacion_01.html#section-9",
    "href": "presentaciones/presentacion_01.html#section-9",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "\\[\\mathrm{Pr}(B\\mid A) = \\frac{\\mathrm{Pr}(A,B)}{\\mathrm{Pr}(A)} \\] siempre que \\(\\mathrm{Pr}(A)>0\\) (no se puede condicionar a eventos imposibles)"
  },
  {
    "objectID": "presentaciones/presentacion_01.html#variables-aleatorias",
    "href": "presentaciones/presentacion_01.html#variables-aleatorias",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Variables aleatorias",
    "text": "Variables aleatorias\nUna variable aleatoria (univariada) \\(X\\) es una funciÃ³n que mapea elementos del espacio muestral \\(\\mathcal{X}\\) a la recta real \\(\\mathbb{R}\\)\n\nSi \\(\\mathcal{X}\\) es finito o infinito numerable entonces \\(X\\) es una variable aleatoria discreta\nSi \\(\\mathcal{X}\\) es cualquier valor en \\(\\mathbb{R}\\) entonces \\(X\\) es una variable aleatoria continua"
  },
  {
    "objectID": "presentaciones/presentacion_01.html#section-10",
    "href": "presentaciones/presentacion_01.html#section-10",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Para el caso discreto: \\[p(x) = \\mathrm{Pr}(X=x) \\quad \\text{(pmf)}\\]\nPara el caso continuo: \\[P(x) = \\mathrm{Pr}(X\\leq x) \\quad \\text{(cdf)}\\] \\[ p(x) = \\frac{d}{dx}P(x) \\quad \\text{(pdf)}\\]\n\\[\\mathrm{Pr}(x\\leq X\\leq x+dx) = p(x)dx\\]"
  },
  {
    "objectID": "presentaciones/presentacion_01.html#distribuciones-conjuntas",
    "href": "presentaciones/presentacion_01.html#distribuciones-conjuntas",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Distribuciones conjuntas",
    "text": "Distribuciones conjuntas\nCaso discreto\n\\[\n\\begin{array}{c|cc}\np(X,Y) & Y=0 & Y=1 \\\\\n\\hline\nX=0 & 0.2 & 0.3 \\\\\nX=1 & 0.3 & 0.2 \\\\\n\\end{array}\n\\]"
  },
  {
    "objectID": "presentaciones/presentacion_01.html#section-11",
    "href": "presentaciones/presentacion_01.html#section-11",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "DistribuciÃ³n marginal\n\\[p(x)=\\sum_y p(x,y)\\]\n\\[p(y)=\\sum_x p(x,y)\\]\nSe conoce como marginalizar (en inglÃ©s tambiÃ©n integrate out)"
  },
  {
    "objectID": "presentaciones/presentacion_01.html#section-12",
    "href": "presentaciones/presentacion_01.html#section-12",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Caso continuo\n\\[p(x,y)\\]"
  },
  {
    "objectID": "presentaciones/presentacion_01.html#section-13",
    "href": "presentaciones/presentacion_01.html#section-13",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "DistribuciÃ³n marginal\n\\[p(x)=\\int p(x,y) dy\\]\n\\[p(y)=\\int p(x,y) dx\\]"
  },
  {
    "objectID": "presentaciones/presentacion_01.html#distribuciÃ³n-condicional",
    "href": "presentaciones/presentacion_01.html#distribuciÃ³n-condicional",
    "title": "EstadÃ­stica Bayesiana",
    "section": "DistribuciÃ³n condicional",
    "text": "DistribuciÃ³n condicional\n\\[p(x \\mid y) = \\frac{p(x,y)}{p(y)}\\]\n\\[p(y \\mid x) = \\frac{p(x,y)}{p(x)}\\]\n\\(p(x)\\) normaliza a \\(p(x,y)\\) (una funciÃ³n de \\(y\\) ya que \\(x\\) tomÃ³ un valor fijo).\n\nimagine a circular dart board, split into 20 equal sections, labelled from 1 to 20. Randy, a dart thrower, hits any one of the 20 sections uniformly at random. Hence the probability that a dart thrown by Randy occurs in any one of the 20 regions is p(region i) = 1=20. A friend of Randy tells him that he hasnâ€™t hit the 20 region. What is the probability that Randy has hit the 5 region?"
  },
  {
    "objectID": "presentaciones/presentacion_01.html#regla-del-producto",
    "href": "presentaciones/presentacion_01.html#regla-del-producto",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Regla del producto",
    "text": "Regla del producto\nTambiÃ©n conocida como regla de la cadena. Recobramos la distribuciÃ³n conjunta haciendo\n\\[p(x,y) = p(x\\mid y) p(y)\\]\n\\[p(x,y) = p(y\\mid x) p(x)\\]\n\\[p(x,y,z) = p(z) p(y\\mid z) p(x\\mid y,z)\\]"
  },
  {
    "objectID": "presentaciones/presentacion_01.html#regla-de-la-probabilidad-total",
    "href": "presentaciones/presentacion_01.html#regla-de-la-probabilidad-total",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Regla de la probabilidad total",
    "text": "Regla de la probabilidad total\n\\[p(x) = \\int p(x\\mid y) p(y) dy\\] \\[p(y) = \\int p(y\\mid x) p(x) dy\\]\n\nLa probabilidad marginal de \\(x\\) (una funciÃ³n de \\(x\\)) se obtiene ponderando todos los posibles \\(p(x\\mid y)\\) (una funciÃ³n de \\(x\\) para cada valor de \\(y\\)) segÃºn la probabilidad de \\(p(y)\\). Y viceversa."
  },
  {
    "objectID": "presentaciones/presentacion_01.html#regla-de-bayes",
    "href": "presentaciones/presentacion_01.html#regla-de-bayes",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Regla de Bayes",
    "text": "Regla de Bayes\n\\[p(x\\mid y) = \\frac{p(y\\mid x) p(x)}{p(y)}\\]\n\nAsÃ­ expresada no nos dice mucho.\n\n\nRecordemos que utilizamos las probabilidades para expresar nuestra incertidumbre. La mejor forma de actualizar nuestro grado de creencia sobre alguna hipÃ³tesis \\(\\mathcal{H}\\) frente a nueva informaciÃ³n \\(E\\) es utilizar la Regla de Bayes.\n\\[p(\\mathcal{H}\\mid E) = \\frac{p(E\\mid\\mathcal{H}) p(\\mathcal{H})}{p(E)}\\]"
  },
  {
    "objectID": "presentaciones/presentacion_01.html#orÃ­genes-de-la-regla-de-bayes",
    "href": "presentaciones/presentacion_01.html#orÃ­genes-de-la-regla-de-bayes",
    "title": "EstadÃ­stica Bayesiana",
    "section": "OrÃ­genes de la Regla de Bayes",
    "text": "OrÃ­genes de la Regla de Bayes\n\n\n\nAlrededor de 1740, Thomas Bayes propone una versiÃ³n de la regla pero no la publica (Â¿su descubrimiento era inÃºtil? Â¿era muy modesto?). Propuso el experimento imaginario de un juego con bolitas. AsignÃ³ iguales probabilidades a priori\n\n\n\nRichard Price publicÃ³ el resultado del Teorema de la Probabilidad Inversa de Bayes en An Essay Towards Solving a Problem in the Doctrine of Chances (1763)\n\n\n\nPierre-Simon Laplace llegÃ³ al mismo resultado que Bayes (algo que llamÃ³ la probabilidad de las causas) y lo publicÃ³ en Memoire sur la ProbabilitÃ© des Causes par les Ã‰venements (1774). Se asemeja mÃ¡s a lo que hoy conocemos. ReconociÃ³ que Bayes habÃ­a descubierto algo similar."
  },
  {
    "objectID": "presentaciones/presentacion_01.html#section-14",
    "href": "presentaciones/presentacion_01.html#section-14",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Bayesâ€™s rule is a mistake, perhaps the only mistake to which the mathematical world has so deeply committed itself (Fisher, ~1920)\n\n\n\nBayesâ€™s theorem is to the theory of probability what Pythagorasâ€™s theorem is to geometry (Savage, ~1950)"
  },
  {
    "objectID": "presentaciones/presentacion_01.html#ejemplos",
    "href": "presentaciones/presentacion_01.html#ejemplos",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Ejemplos",
    "text": "Ejemplos\nVamos a trabajar con un conjunto de ejemplos que consisten en la aplicaciÃ³n de la regla de Bayes, acercÃ¡ndonos de a poco a forma en la que se usa en la estadÃ­stica bayesiana."
  },
  {
    "objectID": "presentaciones/presentacion_01.html#ejemplo-1",
    "href": "presentaciones/presentacion_01.html#ejemplo-1",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Ejemplo 1",
    "text": "Ejemplo 1\nNos encontramos con alguien en la calle y nos dice que tiene dos hijos. Le preguntamos si alguno de ellos es mujer y nos responde que sÃ­. Â¿CuÃ¡l es la probabilidad de que tenga dos niÃ±as?"
  },
  {
    "objectID": "presentaciones/presentacion_01.html#section-15",
    "href": "presentaciones/presentacion_01.html#section-15",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Â¿CÃ³mo lo escribimos con sÃ­mbolos?"
  },
  {
    "objectID": "presentaciones/presentacion_01.html#ejemplo-2",
    "href": "presentaciones/presentacion_01.html#ejemplo-2",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Ejemplo 2",
    "text": "Ejemplo 2\nUn taxi se vio involucrado en una accidente nocturno y se dio a la fuga. En la ciudad hay dos empresas de taxis, la Verde y la Azul. Sobre el accidente se tienen los siguientes datos:\n\n85% de los taxis de la ciudad son de la empresa Verde y 15% de la Azul\nUn testigo identificÃ³ el taxi como azul. La corte evaluÃ³ la confiabilidad del testigo en las circunstancias del accidente y concluyÃ³ que es capaz de identificar correctamente el color en un 80% de los casos.\n\n\nÂ¿CuÃ¡l es la probabilidad de que el taxi haya sido azul, de acuerdo a la declaraciÃ³n del testigo?"
  },
  {
    "objectID": "presentaciones/presentacion_01.html#section-16",
    "href": "presentaciones/presentacion_01.html#section-16",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "\\[p(A\\mid T_A) = \\frac{p(T_A\\mid A) p(A)}{p(T_A)}\\]\n\n\\[p(A\\mid T_A) = \\frac{p(T_A\\mid A) p(A)}{p(T_A\\mid A)p(A) + p(T_A\\mid V)p(V)}\\]\n\n\n\\[P(A\\mid T_A) = \\frac{0.80\\cdot 0.15}{0.80\\cdot 0.15 + 0.2\\cdot 0.85}\\]\n\\[p(A\\mid T_A) = 0.414\\]"
  },
  {
    "objectID": "presentaciones/presentacion_01.html#ejemplo-3",
    "href": "presentaciones/presentacion_01.html#ejemplo-3",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Ejemplo 3",
    "text": "Ejemplo 3\nSe realiza un test de hipÃ³tesis que tiene una potencia \\(1-\\beta = 80\\%\\). Se fija el nivel de significaciÃ³n en \\(\\alpha = 5\\%\\). Se testea \\(H_0\\) versus una hipÃ³tesis alternativa \\(H_1:\\text{ no }H_0\\).\n\nSi se supone que la probabilidad de que \\(H_0\\) sea cierta es de \\(50\\%\\), Â¿cuÃ¡l es la probabilidad de que \\(H_1\\) sea cierta luego de observar un resultado estadÃ­sticamente significativo?\nSi la hipÃ³tesis alternativa es muy rara (digamos \\(10\\%\\)), Â¿cuÃ¡l es la probabilidad de que \\(H_1\\) sea cierta luego de observar un resultado estadÃ­sticamente significativo?"
  },
  {
    "objectID": "presentaciones/presentacion_01.html#section-18",
    "href": "presentaciones/presentacion_01.html#section-18",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "\\[p(H_1 \\mid \\text{rechazo }H_0) = \\frac{p(\\text{rechazo }H_0 \\mid H_1)p(H_1)}{p(\\text{rechazo }H_0)}\\]\n\nSi en el denominador enumeramos exhaustivamente las formas de rechazar \\(H_0\\):\n\n\n\\[p(H_1 \\mid \\text{rechazo }H_0) = \\frac{(1-\\beta)p(H_1)}{\\alpha p(H_0) + (1-\\beta) p(H_1)}\\]\nPara el primer caso: \\(p(H_1 \\mid \\text{rechazo }H_0) = \\frac{{0.80}\\ {0.50}}{{0.05}\\ {0.50} + {0.80}\\ {0.50}} = {0.94}\\)\nPara el segundo caso: \\(p(H_1 \\mid \\text{rechazo }H_0) = \\frac{{0.80}\\ {0.10}}{{0.05}\\ {0.90} + {0.80}\\ {0.10}} = {0.64}\\)"
  },
  {
    "objectID": "presentaciones/presentacion_01.html#el-problema-de-las-urnas",
    "href": "presentaciones/presentacion_01.html#el-problema-de-las-urnas",
    "title": "EstadÃ­stica Bayesiana",
    "section": "El problema de las urnas",
    "text": "El problema de las urnas\n\nSe cuenta con 11 urnas etiquetadas segÃºn \\(u = 0,1,\\dots,10\\), que contienen diez bolas cada una. La urna \\(u\\) contiene \\(u\\) bolas azules y \\(10-u\\) bolas blancas. Fede elige una urna \\(u\\) al azar y extrae con reposiciÃ³n \\(N\\) bolas, obteniendo \\(n_A\\) azules y \\(N-n_A\\) blancas. Nico, el amigo de Fede, observa atentamente. Si despuÃ©s de \\(N=10\\) extracciones resulta \\(n_A = 3\\), Â¿cuÃ¡l es la probabilidad de que la urna que Fede estÃ¡ usando sea la \\(u\\)?"
  },
  {
    "objectID": "presentaciones/presentacion_01.html#section-19",
    "href": "presentaciones/presentacion_01.html#section-19",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "La teorÃ­a de las probabilidades permite predecir una distribuciÃ³n sobre posibles valores de un resultado dado cierto conocimiento (o estado) del universo: probabilidad hacia adelante\n\nPor el contrario, muchas veces estamos interesados en realizar inferencias sobre el estado del universo a partir de observaciones: probabilidad inversa.\n\n\n\\[p(\\mathcal{H}\\mid E) = \\frac{p(E\\mid\\mathcal{H}) p(\\mathcal{H})}{p(E)}\\]\n\\[p(\\mathcal{H}\\mid E) \\propto p(E\\mid\\mathcal{H}) p(\\mathcal{H})\\]\n\n\n\nEstadÃ­stica Bayesiana â€“ 2023"
  },
  {
    "objectID": "presentaciones/presentacion_05.html",
    "href": "presentaciones/presentacion_05.html",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "TÃ­picamente interesa resolver los siguientes problemas:\n\n\nCalcular integrales de la forma \\(\\mathbb{E}[\\phi(x)] = \\int \\phi(x) p(x) d x\\) (law of the unconscious statistician)\nGenerar \\(S\\) muestras independientes \\(x^{(s)}\\) de una distribuciÃ³n de probabilidad \\(p(x)\\)\n\n\n\nEn la estadÃ­stica bayesiana, \\(x\\) es \\(\\theta\\), el parÃ¡metro desconocido de alguna distribuciÃ³n de probabilidad y \\(p(x)\\) es el posterior\n\n\n\n\n\n\n\n\n\n\n\n\nPara el primer problema, sabemos que si \\(X_i \\sim p(x)\\), bajo ciertas condiciones podemos aproximar\n\n\\[\\mathbb{E}[X] \\approx \\frac{1}{N} \\sum_{i=1}^N x_i\\]\n\n\nSi \\(X\\) es una variable aleatoria, entonces para funciones continuas \\(\\phi\\) tenemos que \\(\\phi(X)\\) tambiÃ©n es una variable aleatoria y por lo tanto\n\n\n\\[\\mathbb{E}[\\phi(X)] = \\int\\phi(x)p(x)dx \\approx \\frac{1}{N} \\sum_{i=1}^N \\phi(x_i)\\]\n\n\nEs decir, si los \\(x_i\\) son muestras de \\(p(x)\\), entonces la integral \\(\\int\\phi(x)p(x)dx\\) puede aproximarse por \\(\\frac{1}{N} \\sum_{i=1}^N \\phi(x_i)\\).\n\n\n\n\nEsto ya lo hemos hecho\n\n\nLa distribuciÃ³n predictiva a posteriori es \\(\\int p(y\\mid \\theta) p(\\theta\\mid y) d\\theta\\) y puede aproximarse por \\(\\frac{1}{N} \\sum_{i=1}^N p(y\\mid \\theta_i)\\)\nEl riesgo bayesiano es \\(\\int L(\\theta,\\hat\\theta) p(\\theta\\mid y) d\\theta\\) y puede aproximarse por \\(\\frac{1}{N} \\sum_{i=1}^N L(\\theta_i,\\hat\\theta)\\)\nSi consideramos la integral \\(\\int \\mathbb{I}_{\\theta \\in A} p(\\theta\\mid y) d\\theta = \\int_A p(\\theta\\mid y)d\\theta\\) es la probabilidad de que \\(\\theta\\) estÃ© en \\(A\\) y puede aproximarse por \\(\\frac{1}{N} \\sum_{i=1}^N \\mathbb{I}_{\\theta_i \\in A}\\)\n\n\n\n\n\nTeniendo muestras de \\(p(x)\\) es fÃ¡cil estimar las integrales \\(\\mathbb{E}[\\phi(x)] = \\int \\phi(x) p(x) d x\\) por lo que nos centraremos en el problema de cÃ³mo obtener muestras de \\(p(x)\\).\n\nPara algunas distribuciones de probabilidad es fÃ¡cil obtener muestras. Pero no siempre existe una funciÃ³n rbinom, rbeta, rnorm, rpoiss, etc.\n\n\n\n\nTomar muestras de una distribuciÃ³n de probabilidad \\(p(x)\\) implica obtener valores que provienen, con mayor frecuencia, de regiones donde \\(p(x)\\) es grande. Â¿Por quÃ© es difÃ­cil tomar muestras de una distribuciÃ³n de probabilidad?\n\nEn estadÃ­stica bayesiana tenemos \\(p(\\theta \\mid y ) \\propto p(y\\mid\\theta) p(\\theta)\\) por lo que en general llegamos a \\(p^*(\\theta \\mid y) = \\frac{1}{Z} p(\\theta\\mid y)\\)\n\n\n\nLa determinaciÃ³n de \\(Z\\) implica resolver una integral (potencialmente multivariada) que puede no tener soluciÃ³n analÃ­tica (intractability of the integral)\nAÃºn conociendo \\(Z\\), no hay una manera determinada de obtener muestras de \\(p(\\theta\\mid y)\\)\nTomar muestras de distribuciones discretas es mÃ¡s fÃ¡cil que hacerlo de distribuciones continuas\n\n\n\n\n\nÂ¿CÃ³mo tomamos muestras de una distribuciÃ³n discreta?\n\n\n\n\n\n\n\n\n\n\n\n\nUna soluciÃ³n puede ser discretizar la variable. Esta soluciÃ³n vale incluso si no conocemos \\(Z\\). Conocemos \\(p^*(x) = \\frac{1}{Z} p(x)\\) (izquierda) y pasamos a una discreta \\(\\tilde{p}^*(x) = \\frac{1}{\\tilde{Z}} \\tilde{p}(x)\\) (centro).\n\nEvaluando \\(\\tilde{p}\\) en todos los posibles \\(x_i\\) de la grilla podemos calcular \\(Z=\\sum_{i} \\tilde{p}^*(x_i)\\). Luego tomamos muestras de \\(\\tilde{p}(x)\\) (derecha).\n\n\n\n\n\n\n\n\n\n\n\n\n\nEn cÃ³digo:\n\nprob <- function(x) return(exp(0.4*(x-0.4)^2 - 0.08*x^4)) # sabemos evaluar p\nx <- seq(-4.5, 4.5, 0.5)\np_ <- prob(x) # ~p*\nZ <- sum(p_)\np_rulito <- p_/Z # ~p\nsample(x, replace = TRUE, prob = p_rulito)\n\n\n\n\nÂ¿CÃ³mo se aplica esto en estadÃ­stica bayesiana?\n\nEl posterior es \\(\\frac{1}{Z} p(\\theta\\mid y) p(\\theta)\\). Sabemos calcular el valor del posterior (sin normalizar) para cualquier valor de \\(\\theta\\): haciendo el producto del prior por el likelihood.\n\n\nPodemos considerar una grilla de valores del parÃ¡metro (o los parÃ¡metros), computar el posterior sin normalizar para cada valor de la grilla, normalizarlo y tomar muestras de Ã©l.\n\n\nEscala muy mal con el nÃºmero de parÃ¡metrosâ€¦\n\n\n\n\n\n\n\n\n\nQueremos realizar inferencias sobre la media y la varianza de una normal. Para eso proponemos el siguiente modelo: \\[    \n\\begin{align*}\n    y_i\\mid\\mu,\\sigma^2 & \\sim  \\mathcal{N}(\\mu,\\sigma^2) \\\\\n    \\mu,\\sigma^2 & \\sim  \\frac{1}{K} \\frac{e^{-\\sigma^2}}{\\eta} e^{-\\frac{(\\mu - \\xi)^2}{2\\psi^2}}\n\\end{align*}\n\\] (Â¿CuÃ¡les son las constantes que ajustan el prior)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDeberÃ­amos tomar valores de \\(\\mu\\) en el intervalo \\((-4,4)\\) y valores de \\(\\sigma\\) en el intervalo \\((0,3)\\) y construir una grilla de valores.\nPara cada valor de la grilla podrÃ­amos calular el posterior sin normalizar haciendo el producto del prior por el likelihood (necesitamos la muestra).\n\n\n\n\nSe basa en buscar una distribuciÃ³n de probabilidad candidata \\(q(x)\\) tal que \\(Cq(x)\\geq p^*(x)\\). Se toma una muestra de \\(q(x)\\). Luego se toma una muestra \\(u\\) de \\(\\mathrm{Unif}(0,Cq(x))\\). La muestra de \\(q(x)\\) se retiene si \\(u<p^*(x)\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNecesitamos elegir con cuidado \\(q(x)\\)\n\n\n\nQueremos obtener muestras de \\(p(x)\\). Vamos a hacer un viaje por los distintos valores de \\(x\\) tratando de pasar mÃ¡s tiempo (mÃ¡s iteraciones) en los puntos donde \\(p(x)\\) es grande.\n\nIdea general:\n\nVisitar los distintos valores posibles de \\(x\\)\nGenerar una secuencia de iteraciones: \\(\\{x^{(1)},x^{(2)},\\dots,x^{(S)}\\}\\)\nEn general, para obtener \\(x^{(i+1)}\\) usamos \\(x^{(i)}\\)\n\n\nEn nuestro caso tenemos \\(p(\\theta) \\propto p(y\\mid\\theta)p(\\theta) = p^*(\\theta\\mid y)\\) (unnormalized posterior)\nÂ¿QuÃ© necesitamos? Poder evaluar el prior y poder evaluar el likelihood para cualquier valor de \\(\\theta\\)\n\n\n\n\n\nEl algoritmo de Metropolisâ€“Hastings (1953)\n\nEstamos la iteraciÃ³n \\(i\\) estamos en el valor del parÃ¡metro \\(\\theta^{(i)}\\)\nEn funciÃ³n del valor de parÃ¡metro actual \\(\\theta^{(i)}=\\theta\\), proponemos un nuevo valor \\(\\theta'\\) en funciÃ³n de \\(q(\\theta'\\mid\\theta)\\)\nDecidimos si vamos a la nueva ubicaciÃ³n \\(\\theta^{(i+1)} = \\theta'\\) o si nos quedamos \\(\\theta^{(i+1)} = \\theta\\):\n\nCalcular la probabilidad de salto: \\[\\alpha = \\min\\left\\{ 1,\\frac{f(\\theta')}{f(\\theta)} \\right\\}\\]\nPasar a \\(\\theta'\\) con probabilidad \\(\\alpha\\): \\[\\theta^{(i+1)} =\n\\begin{cases}\n\\theta' \\text{ con probabilidad } \\alpha \\\\\n\\theta \\text{ con probabilidad } (1-\\alpha)\n\\end{cases}\\]\n\n\n\n\n\n\\(q(\\theta'\\mid\\theta)\\) se llama distribuciÃ³n de proposiciÃ³n o de salto propuesto. Todo lo que necesitamos saber es dÃ³nde estamos \\(f(\\theta)\\) y hacia donde queremos ir \\(f(\\theta')\\).\n\nPuede probarse que para cualquier \\(q(\\theta'\\mid\\theta)\\), cuando \\(s\\to \\infty\\) la distribuciÃ³n de probabilidad de la secuencia \\(\\left\\{\\theta^{(s)} \\right\\}_{s=1}^S\\) tiende a \\(p(\\theta)\\). No sabemos nada sobre la rapidez con la que lo hace.\n\n\nEn infinitos pasos, cualquier cadena darÃ¡ muestras de la distribuciÃ³n \\(p(\\theta)\\), en la prÃ¡ctica hay que tener algunos cuidados.\n\n\n\n\n\nx <- seq(-4,4,0.01)\nf <- exp(0.4*(x-0.4)^2-0.08*x^4)\n\np1 <- ggplot(tibble(x,f)) +\n  geom_line(aes(x=x,y=f),size=1,col=\"#FFD400\") +\n  geom_ribbon(aes(x=x,ymin=0,ymax=f),alpha=0.6,fill=\"#FFD400\") +\n  xlab(expression(theta)) +\n  theme(axis.title.y = element_blank())\n\np2 <- p1 +\n  geom_point(aes(x=-1,y=0),shape=\"square\",size=2) \n\np3 <- p2 +\n  geom_line(data=tibble(x=seq(-4,2,0.01),y=dnorm(x,-1,0.8)),\n            aes(x=x,y=y), col=\"#0C7C59\") +\n  geom_ribbon(data=tibble(x=seq(-4,2,0.01),y=dnorm(x,-1,0.8)),\n              aes(x=x,ymin=0,ymax=y), fill=\"#0C7C59\",alpha=0.6)\n\np4 <- p3 +\n  geom_curve(aes(x=-1,xend=0.4,y=0,yend=0),\n             curvature = -0.5,\n             arrow = arrow(length = unit(0.02, \"npc\"),type=\"closed\"),\n             col=\"#215097\")\n\np5 <- p4 +\n  geom_segment(aes(x=0.4,xend=0.4,y=0,yend=exp(0.4*(0.4-0.4)^2-0.08*(0.4)^4)),linetype=\"dashed\") +\n  geom_segment(aes(x=-1,xend=-1,y=0,yend=exp(0.4*(-1-0.4)^2-0.08*(-1)^4)),linetype=\"dashed\") +\n  geom_segment(aes(x=-1,xend=-4,y=exp(0.4*(-1-0.4)^2-0.08*(-1)^4),yend=exp(0.4*(-1-0.4)^2-0.08*(-1)^4)),linetype=\"dotted\") +\n  geom_segment(aes(x=0.4,xend=-4,y=exp(0.4*(0.4-0.4)^2-0.08*(0.4)^4),yend=exp(0.4*(0.4-0.4)^2-0.08*(0.4)^4)),linetype=\"dotted\")\n\n\n\n\np1\n\n\n\n\n\n\n\np2\n\n\n\n\n\n\n\np3\n\n\n\n\n\n\n\np4\n\n\n\n\n\n\n\np5\n\n\n\n\n\n\n\n\n\n\nNecesitamos muestras de \\(p(\\theta)\\)\nTomamos un punto inicial\nElegimos una distribuciÃ³n de saltos posibles \\(q(\\theta'\\mid\\theta)\\)\nProponemos un salto\nÂ¿Saltamos?\n\n\n\n\n\ntheta <- double()\ntheta[1] <- -1    \ni <- 1\n\npropuesta <- rnorm(1, mean = theta[i], sd = 0.8)\n\nf_actual <- fx(theta[i])\nf_propuesta <- fx(propuesta)\n\nalpha <- min(c(1,f_propuesta/f_actual))\n\nquehacemos <- sample(c(\"salto\",\"no salto\"), \n                    size = 1, \n                    prob = c(alpha,1-alpha))\n\nif(quehacemos==\"salto\") {\n  theta[i+1] <- propuesta \n} else {\n  theta[i+1] <- theta[i]\n  }\n\nDebe repetirse el proceso en un for\n\n\n\n\n\n \\[\\sigma = 0.8\\]\n\n\n \\[\\sigma = 0.1\\]\n\n\n \\[\\sigma = 0.6\\]\n\n\n \\[\\sigma = 4.8\\]\n\n\n\n\n\nÂ¿QuÃ© esperamos de nuestra cadena?\n\nRepresentatividad: haber explorado el rango completo de la distribuciÃ³n a posteriori, independientemente de las condiciones iniciales\nPrecisiÃ³n y estabilidad: a lo largo de diferentes cadenas (distintas condiciones iniciales)\nEficiencia: esperamos requerir la menor cantidad posible de muestras\n\nNingÃºn objetivo se alcanza absolutamente, existen chequeos grÃ¡ficos y numÃ©ricos para saber si las cadenas de MCMC estÃ¡n sanas.\n\n\n\nGraficar los valores que toma el algoritmo como funciÃ³n del tiempo (lo que tÃ­picamente llamamos la cadena). Se tiene que ver como un fuzzy caterpillar (buen mixing). Para los impresionables: ruido blanco sin ningÃºn patrÃ³n particular.\n\n\n\n\n\n\n\n\nLas muestras tienen que ser independientes. La dependencia de valores anteriores tiene que desaparecer rÃ¡pido . Podemos medirlo con la autocorrelaciÃ³n.\nPara cada valor de lag \\(k\\) se calcula la correlaciÃ³n de la serie consigo misma originando la funciÃ³n de autocorrelaciÃ³n (\\(ACF(k)\\))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLas muestras no son independientes. Â¿A cuÃ¡ntas muestras independientes equivalen nuestras \\(S\\) muestras? \\(N_{eff}\\) es el nÃºmero de muestras independientes que tienen el mismo poder de estimaciÃ³n que \\(S\\) muestras correlacionadas (el error de estimaciÃ³n es proporcional a \\(\\frac{1}{\\sqrt{N_{eff}}}\\))\n\\[N_{eff} = \\frac{S}{1 + 2 \\sum_{k=1}^\\infty ACF(k)}\\]\n\n\n\nEl estadÃ­stico de Rubinâ€“Gelman \\(\\hat{R}\\) es un indicador de convergencia. Si mÃºltiples cadenas se establizaron en un muestreo representativo del posterior, la diferencia promedio entre cadenas debe ser similar a la diferencia promedio en la cadena.\n\\[\\hat{R} = \\sqrt{\\frac{\\frac{S-1}{S} W  +  \\frac{1}{S}  B}{W}}\\]\nEl valor 1 indica convergencia. Si una cadena se perdiÃ³/divergiÃ³, el \\(\\hat{R}\\) serÃ¡ mucho mayor a 1.\n\n\n\nSi tenemos \\(M\\) cadenas, \\(\\theta_m\\), cada una de las cuales tiene \\(S\\) muestras \\(\\theta_m^{(s)}\\). La varianza entre cadenas (\\(B\\)) es:\n\\[B = \\frac{S}{M-1} \\sum_{m=1}^M (\\bar{\\theta}^{(\\bullet)}_{m} - \\bar{\\theta}^{(\\bullet)}_{\\bullet})^2\\]\n\\[\\bar{\\theta}_m^{(\\bullet)} = \\frac{1}{S} \\sum_{s = 1}^S \\theta_m^{(s)}\\]\n\\[\\bar{\\theta}^{(\\bullet)}_{\\bullet} = \\frac{1}{M} \\, \\sum_{m=1}^M \\bar{\\theta}_m^{(\\bullet)}\\]\nLa varianza intra cadena (\\(W\\)) es:\n\\[W = \\frac{1}{M} \\, \\sum_{m=1}^M s_m^2\\]\n\\[ s_m^2 = \\frac{1}{S-1} \\, \\sum_{s=1}^S (\\theta^{(s)}_m - \\bar{\\theta}^{(\\bullet)}_m)^2\\]\n\n\n\nEl estimador de la varianza total\n\\[\\widehat{\\mbox{var}}^{+}\\!(\\theta|y) = \\frac{N-1}{N}\\, W \\, + \\, \\frac{1}{N} \\, B\\]\n\\[\\hat{R} \\, = \\, \\sqrt{\\frac{\\widehat{\\mbox{var}}^{+}\\!(\\theta|y)}{W}}\\]\n\n\n\n\n\n\n\n\n\n\n\n\nMetropolis-Hastings (MG) es una exploraciÃ³n a ciegas del espacio de parÃ¡metros\nLa distribuciÃ³n de propuesta de salto es fija\nEn las colas de la distribuciÃ³n, se proponen tanto saltos que se acercan al grueso (bulk) de la distribuciÃ³n como saltos que se alejan. Se rechazan muchos saltos propuestos.\nHamiltonian-Montecarlo (HMC) es una variante mÃ¡s eficiente de MCMC. Para lograr la eficiencia, los saltos propuestos se adaptan a la forma del posterior.\nLa forma del posterior estÃ¡ en su gradiente\n\n\n\n\n\nHMC trata de aprovechar la geometrÃ­a local del posterior para decidir dÃ³nde ir en la prÃ³xima iteraciÃ³n.\nSi bien MH no ignora por completo la forma del posterior, HMC utiliza mÃ¡s informaciÃ³n (el gradiente)\nPara entender conceptualmente HMC se necesita un poco de imaginaciÃ³n y entender algo de FÃ­sica\n\n\n\n\n\n\\(p^*(\\theta\\mid y)\\) es el posterior sin normalizar. Consideraremos \\(-\\log[p^*(\\theta\\mid y)]\\).\nLos puntos de alta densidad de probabilidad (mÃ¡ximos locales de \\(p^*(\\theta\\mid y)\\)) se convierten en mÃ­nimos locales de \\(-\\log[p^*(\\theta\\mid y)]\\)\nLa lÃ³gica es la misma que en MH (despuÃ©s de todo, se trata de un algoritmo de MCMC): estamos en algÃºn punto del espacio de parÃ¡metros y decidimos movernos a otroâ€¦ AquÃ­ cambia cÃ³mo proponemos un salto.\nPara ello, imaginamos un trineo (o culipatÃ­n, o bolita) que puede deslizarse por la superficie determinada por \\(-\\log[p^*(\\theta\\mid y)]\\)\n\n\n\n\n\nSi soltamos el trineo en algÃºn punto de la superficie, tenderÃ¡ a deslizar hacia abajo de \\(-\\log[p^*(\\theta\\mid y)]\\) por efecto de la gravedad. E irÃ¡ cada vez mÃ¡s rÃ¡pido.\nEstÃ¡ bueno que el trineo deslice hacia los mÃ­nimos de \\(-\\log[p^*(\\theta\\mid y)]\\) pues son zonas de alta densidad de probabilidad\nQuisiÃ©ramos que nuestro trineo explore otras zonas del posterior, para eso en lugar de soltar el trineo le damos un impulso inicial (velocidad inicial o momento).\nEste impulso inicial serÃ¡ aleatorio\n\n\n\n\n\nConociendo la posiciÃ³n inicial del trineo y el impulso que se le da (la velocidad inicial), la FÃ­sica permite calcular cuÃ¡l serÃ¡ su trayectoria (y por ende su posiciÃ³n despuÃ©s de un tiempo)\nLa posiciÃ³n final despuÃ©s de un tiempo serÃ¡ el nuevo \\(\\theta\\) propuesto. Es decir: mientras que en MH proponÃ­amos un salto con la distribuciÃ³n \\(q(\\theta'\\mid\\theta)\\), aquÃ­ lo hacemos con un momento inicial y estudiando la posiciÃ³n del trineo.\nLuego se acepta o se rechaza el salto propuesto\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHMC propone nuevos saltos de manera mÃ¡s sofisticada que MH\nBusca que los saltos propuestos sean hacia valores del parÃ¡metro mÃ¡s prometedores\n\n\n\n\nCÃ³mo calcular la trayectoria del trineo es una de las cuestiones claves del algoritmo. Planteamos la conservaciÃ³n de la energÃ­a:\n\\[\\mathcal{H}(\\theta,v) = U(\\theta) + K(v)\\]\n\\(\\mathcal{H}\\) se conoce como hamiltoniano y representa la energÃ­a total del sistema que es la suma de la energÃ­a potencial \\(U(\\theta)\\) (funciÃ³n de la posiciÃ³n \\(\\theta\\)) y la energÃ­a cinÃ©tica \\(K(v)\\) (funciÃ³n de la velocidad \\(v\\)).\nSe toma \\(U(\\theta) = -\\log[p^*(\\theta\\mid y)]\\) y \\(K(v) = \\frac{1}{2} m v^2\\)\n\n\n\nLas ecuaciones de Hamilton describen el cambio de \\(\\theta\\) y de \\(v\\) en funciÃ³n del tiempo\n\\[\\frac{d\\theta}{dt} = \\frac{\\partial \\mathcal{H}}{\\partial v}\\] \\[\\frac{dv}{dt} = -\\frac{\\partial \\mathcal{H}}{\\partial \\theta}\\]\n\n\n\nEs necesario resolver estas ecuacionesâ€¦ Queremos hallar la posiciÃ³n (\\(\\theta\\)) del trineo tras un tiempo. No se pueden resolver analÃ­ticamente. Discretizamos el tiempo estudiando \\(L\\) pequeÃ±os intervalitos de duraciÃ³n \\(\\varepsilon\\)\n\n\n\nSe tiene:\n\\[\\frac{dv}{dt} \\approx \\frac{v_{t+\\varepsilon} - v_{t}}{\\varepsilon} = \\frac{v_{t_2} - v_{t_1}}{\\varepsilon}\\]\n\\[\\frac{d\\theta}{dt} \\approx \\frac{\\theta_{t+\\varepsilon} - \\theta_{t}}{\\varepsilon} = \\frac{\\theta_{t_2} - \\theta_{t_1}}{\\varepsilon}\\]\ncon lo cual\n\\[v_{t_2} = v_{t_1} + \\varepsilon \\frac{dv}{dt} = v_{t_1}-\\varepsilon \\frac{\\partial \\mathcal{H}}{\\partial \\theta}\\]\n\\[\\theta_{t_2} = \\theta_{t_1} + \\varepsilon \\frac{d\\theta}{dt} = \\theta_{t_1}-\\varepsilon \\frac{\\partial \\mathcal{H}}{\\partial \\theta}\\]\nEstas aproximaciones no son buenasâ€¦\n\n\n\nSe parte de \\(t\\) y se busca \\(v\\) en \\(t+\\frac{\\varepsilon}{2}\\). Luego se busca \\(\\theta\\) en \\(t+\\varepsilon\\) usando el resultado anterior \\(v\\) en \\(\\frac{\\varepsilon}{2}\\).\n\\[v(t+\\frac{\\varepsilon}{2}) = v(t) - \\frac{\\varepsilon}{2} \\frac{\\partial \\mathcal{H}}{\\partial \\theta}\\rvert_t\\]\n\\[\\theta(t+\\varepsilon) = \\theta(t) + \\varepsilon \\frac{\\partial \\mathcal{H}}{\\partial v}\\rvert_{t+\\frac{\\varepsilon}{2}}\\]\n\\[v(t+\\varepsilon) = v(t+\\frac{\\varepsilon}{2}) - \\frac{\\varepsilon}{2} \\frac{\\partial \\mathcal{H}}{\\partial \\theta}\\rvert_{t+\\varepsilon}\\]\n\n\n\n\n\n\n\n\n\n\n\nLa elecciÃ³n de \\(\\varepsilon\\) es clave para el algoritmo. Si \\(L\\cdot\\varepsilon\\) es pequeÃ±o, tomarÃ¡ mucho tiempo explorar el posterior. Con un valor muy grande, ocurrirÃ¡n giros en U.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPropuesta: A partir de \\(\\theta^{(i)}\\) disparar una bolita en alguna direcciÃ³n aleatoria, con una velocidad (momento lineal) aleatoria\nLeapfrog integration: Calcular una serie de \\(L\\) pasos (leapfrog steps) de duraciÃ³n fija \\(\\varepsilon\\) (step size): instantes dÃ³nde vamos a sacar una foto de la posiciÃ³n de la partÃ­cula\nAceptaciÃ³n: Obtener la posiciÃ³n final \\(\\theta^{(i+1)}\\) como la posiciÃ³n final luego de \\(L\\) steps siempre y cuando la aproximaciÃ³n haya sido buena (la energÃ­a se haya conservado)\n\n\nUn \\(\\varepsilon\\) pequeÃ±o da mÃ¡s resoluciÃ³n sobre la trayectoria, permitiendo que la bolita gire Ã¡ngulos pronunciados (Â¿pero?).\n\n\nUn \\(\\varepsilon\\) grande harÃ¡ que los saltos sean largos y podemos saltear el punto donde la partÃ­cula iba a girar (divergent transition)."
  },
  {
    "objectID": "presentaciones/presentacion_07.html",
    "href": "presentaciones/presentacion_07.html",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "En un problema de regresiÃ³n, no siempre la respuesta (condicionada) es normal\nA veces, la respuesta ni siquiera es cuantitativa\n\n\n\n\nSupongamos que nos interesa modelizar las siguientes variables:\n\nSi una persona vota o no por un determinado candidato\nSi un estudiante aprueba o no un examen\nSi maÃ±ana lloverÃ¡ o no\n\nEs decir, nos interesa modelizar una variable \\(Y\\), una variable respuesta categÃ³rica binaria:\n\\[Y = \\begin{cases}\n1 \\text{ si maÃ±ana llueve} \\\\\n0 \\text{ en caso contrario}\n\\end{cases}\\]\nen funciÃ³n de ciertas variables explicativas potencialesâ€¦\nEn otros contextos se habla de un problema de clasificaciÃ³n\n\n\n\nSegÃºn los valores que puede tomar \\(Y\\), Â¿quÃ© modelo de probabilidad podemos asumir?\n\\[Y_i \\mid \\pi_i \\sim \\mathrm{Bern}(\\pi_i)\\]\n\\[\\mathbb{E}(Y_i) = \\pi_i\\]\n\n\n\nEn la regresiÃ³n normal que conocÃ­amos, tenÃ­amos\n\\[Y_i \\mid \\mu_i \\sim \\mathcal{N}(\\mu_i,\\sigma^2)\\]\n\\[\\mathbb{E}(Y_i) = \\mu_i\\]\nPor analogÃ­a, Â¿podemos hacer \\(\\pi_i = \\beta_0 + \\beta_1 x_{1_i} + \\beta_2 x_{2_i} + \\dots\\)?\nÂ¿QuÃ© problemas identificamos?\n\n\n\nTendremos que hacer\n\\[g(\\pi_i) = \\beta_0 + \\beta_1 x_{1_i} + \\beta_2 x_{2_i} + \\dots\\]\n\\(g(\\cdot)\\) se conoce como funciÃ³n de enlace (link function). Â¿CuÃ¡l es una \\(g\\) apropiada en este caso?\n\n\n\nSi \\(\\pi_i\\) es la probabilidad del evento de interÃ©s, \\(\\frac{\\pi_i}{1-\\pi_i}\\) es la chance (odds) del evento de interÃ©s.\nMientras que \\(\\pi_i \\in [0,1]\\), \\(\\frac{\\pi_i}{1-\\pi_i} \\in [0,+\\infty)\\)\n\n\n\nEstablecemos un modelo lineal para el log-odds del evento de interÃ©s\n\\[\\log(\\mathrm{odds}_i)=\\log\\left( \\frac{\\pi_i}{1-\\pi_i} \\right) = \\beta_0 + \\beta_1 x_{1_i} + \\beta_2 x_{2_i} + \\dots\\]\nLa funciÃ³n \\(g(x) = \\log\\left(\\frac{x}{1-x}\\right)\\) se conoce como funciÃ³n logit. Es una funciÃ³n no lineal.\n\n\n\nAnalicemos lo que vimos hasta ahora:\n\nÂ¿CuÃ¡l es el dominio de la funciÃ³n logit?\nÂ¿Para quÃ© necesitamos la funciÃ³n \\(g(\\cdot)\\)?\nÂ¿CuÃ¡l es la relaciÃ³n entre el predictor lineal y la variable respuesta?\nÂ¿CuÃ¡l es la distribuciÃ³n de la variable respuesta?\n\n\n\n\nConsideremos el caso con una sola variable explicativa\n\\[\\log\\left(\\frac{\\pi_i}{1-\\pi_i}\\right) = \\beta_0 + \\beta_1 x_{1_i}\\]\nSe cumple:\n\\[\n\\frac{\\pi_i}{1-\\pi_i} = e^{\\beta_0 + \\beta_1 x_{1_i}} \\qquad\n\\pi_i = \\frac{e^{\\beta_0 + \\beta_1 x_{1_i}}}{1 + e^{\\beta_0 + \\beta_1 x_{1_i}}}\n\\]\nÂ¡La esperanza de la variable respuesta se relaciona de manera no lineal con las variables explicativas!\n\n\n\nConsideremos la siguiente relaciÃ³n\n\\[\\log\\left(\\frac{\\pi_i}{1-\\pi_i}\\right) = -4 + 0.1\\ x_{1_i}\\]\ne imaginemos que \\(\\pi_i\\) es la probabilidad de que llueva el dÃ­a \\(i\\) y \\(x_{1_i}\\) la humedad a las 9 de la maÃ±ana del dÃ­a anterior al dÃ­a \\(i\\).\n\n\n\n\nx1 <- seq(0, 100, length.out = 100)\nbeta0 <- -4\nbeta1 <- 0.1\n\ndata <- tibble(x1 = x1,\n               log_odds = beta0 + beta1*x1,\n               odds = exp(log_odds),\n               pi = odds/(1+odds))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\beta_0\\) es la log-chance (log-odds) del evento de interÃ©s cuando todas las variables explicativas valen 0. \\(e^{\\beta_0}\\) es la chance. En tÃ©rminos del problema: \\(e^{\\beta_0}\\) es la chance de que llueva maÃ±ana si la humedad de hoy a las 9 de la maÃ±ana es 0.\n\n\n\n\n\n\n\\(\\beta_1\\) no es el incremento en la probabilidad del evento de interÃ©s cuando \\(x_1\\) aumenta en una unidadâ€¦\n\n\\(\\mathrm{odds}_x\\) es la chance del evento de interÃ©s cuando \\(x_1=x\\)\n\\(\\mathrm{odds}_{x+\\Delta x}\\) es la chance del evento de interÃ©s cuando \\(x_1 = x + \\Delta x\\)\n\n\\[\\log (\\mathrm{odds}_x) =\\log\\left( \\frac{\\pi_x}{1-\\pi_x} \\right) = \\beta_0 + \\beta_1 x\\]\n\\[\\log (\\mathrm{odds}_{x+\\Delta x}) =\\log\\left( \\frac{\\pi_{x+\\Delta x}}{1-\\pi_{x+\\Delta x}} \\right) = \\beta_0 + \\beta_1 (x+\\Delta x)\\]\n\n\n\n\nEntonces\n\\[\\log (\\mathrm{odds}_{x+\\Delta x}) - \\log (\\mathrm{odds}_{x}) = \\beta_1 \\Delta x\\]\n\\[ e^{\\beta_1 \\Delta x} = \\frac{\\mathrm{odds}_{x+\\Delta x}}{\\mathrm{odds}_{x}}\\]\nLa chance del evento de interÃ©s aumenta \\(e^{\\beta_1 \\Delta x}\\) veces cuando \\(x_1\\) aumenta en \\(\\Delta x\\) (y el resto de las variables se mantienen constantes). En tÃ©rminos del problema: La chance de que llueva maÃ±ana aumenta \\(e^{\\beta_1}\\) veces si la humedad aumenta en 1.\n\n\n\nMÃ¡s en tÃ©rminos del problema:\n\\[e^{\\beta_1} = \\frac{\\mathrm{odds}_{x+1}}{\\mathrm{odds}_{x}} \\Rightarrow \\mathrm{odds}_{x+1} = e^{\\beta_1} \\mathrm{odds}_{x}\\]\n\\[e^{\\beta_1} = 1.11\\]\n\nLa chance de que llueva maÃ±ana aumenta \\(1.11\\) veces cuando la humedad a las 9 de la maÃ±ana de hoy aumenta en una unidad\nLa chance de que llueva maÃ±ana aumenta en un \\(11\\%\\) cuando la humedad a las 9 de la maÃ±ana de hoy aumenta en una unidad\n\n\n\n\nAnalicemos juntos el siguiente caso:\n\\[\\log\\left(\\frac{\\pi_i}{1-\\pi_i}\\right) = 1.1 - 0.2\\ \\mathrm{despierto}_{i}\\]\ne imaginemos que \\(\\pi_i\\) es la probabilidad de que un estudiante \\(i\\) apruebe el parcial de AnÃ¡lisis de Datos de DuraciÃ³n \\(i\\) y \\(\\mathrm{despierto}_i\\) la cantidad de horas que el estudiante \\(i\\) estuvo despierto la noche anterior al parcial.\n\n\n\nÂ¿Y Bayes?\nLa especificaciÃ³n del modelo se completa con la elecciÃ³n de distribuciones a priori para \\(\\beta_0,\\ \\beta_1,\\ \\dots\\)â€¦\nCada cantidad que dependa de los \\(\\beta_0,\\ \\beta_1,\\ \\dots\\) tendrÃ¡ una distribuciÃ³n de probabilidad.\nLas predicciones tambiÃ©n son probabilÃ­sticas.\n\n\n\nÂ¿CÃ³mo se estiman \\(\\beta_0,\\ \\beta_1,\\ \\dots\\)? Como siempre. Aplicando la Regla de Bayes. Solo que la verosimilitud ahora es Bernoulli."
  },
  {
    "objectID": "presentaciones/presentacion_06.html",
    "href": "presentaciones/presentacion_06.html",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Para modelizar la relaciÃ³n entre una variable dependiente \\(Y\\) y ciertos predictores \\(X_l\\) asumimos un modelo de la forma\n\\[Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p + \\eta\\]\nEn realidad tenemos \\(N\\) observaciones y por lo tanto para cada observaciÃ³n \\((y_i,\\mathbf{x}_i)\\) tenemos\n\\[y_i = \\beta_0 + \\beta_1 x_{1_i} + \\beta_2 x_{2_i} + \\dots + \\beta_p x_{p_i} + \\eta\\]\nO bien, matricialmente\n\\[y_i = \\boldsymbol{\\beta}^T \\mathbf{x}_i + \\eta\\]\nEl error \\(\\eta\\) es desconocido y, en principio, no es necesario asumir nada sobre este.\n\n\n\nPara predecir valores de \\(y_i\\) es necesario estimar \\(\\boldsymbol{\\beta}\\) por \\(\\hat{\\boldsymbol{\\beta}}\\) dando lugar al siguiente modelo predictivo:\n\\[\\hat{y}_i = \\hat\\beta_0 + \\hat\\beta_1 x_{1_i} + \\hat\\beta_2 x_{2_i} + \\dots + \\hat\\beta_p x_{p_i} = \\hat{\\boldsymbol{\\beta}}^T \\mathbf{x}_i\\]\nUna forma de estimar \\(\\boldsymbol{\\beta}\\) es minimizar alguna funciÃ³n del error de aproximar \\(y\\) por \\(\\hat{y}_i\\):\n\\[\\hat{\\boldsymbol{\\beta}} = \\underset{\\boldsymbol\\beta}{\\mathrm{arg\\,min}}\\left[ J(\\boldsymbol\\beta) \\right] = \\underset{\\boldsymbol\\beta}{\\mathrm{arg\\,min}}\\left[ \\sum_{i=1}^N \\left(y_i - \\boldsymbol\\beta^T \\mathbf{x}_i\\right)^2 \\right]\\]\nEl \\(\\boldsymbol{\\beta}\\) que minimiza el error cuadrÃ¡tico se conoce como estimador de mÃ­nimos cuadrados. Esto es lo que se conoce como enfoque de optimizaciÃ³n.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAsumiendo un modelo probabilÃ­stico para el error, \\(\\eta \\sim \\mathcal{N}(0,\\sigma^2)\\) se puede obtener el estimador de mÃ¡xima verosimilitud de \\(\\boldsymbol\\beta\\).\nLa funciÃ³n de verosimilitud viene dada por el producto de las funciones de densidad normales:\n\\[\\ell(\\boldsymbol\\beta,\\sigma|\\mathbf{y}) = \\prod_{i=1}^N p(y_i|\\mathbf{x_i},\\boldsymbol\\beta^T,\\sigma^2) = \\prod_{i=1}^N \\frac{1}{\\sqrt{2\\pi\\sigma}} e^{-\\frac{(y_i - \\boldsymbol\\beta^T\\mathbf{x}_i)^2}{2\\sigma^2}}\\]\n\n\n\nMaximizar la verosimilitud equivale a minimizar el opuesto de la log-verosimilitud \\(\\mathcal{L}(\\boldsymbol\\beta,\\sigma|\\mathbf{y}) = \\log(\\ell(\\boldsymbol\\beta,\\sigma|\\mathbf{y}))\\)\n\\[\\hat{\\boldsymbol{\\beta}}_{ML} = \\underset{\\boldsymbol\\beta}{\\mathrm{arg\\,min}}\\left[ - \\sum_{i=1}^N \\log \\left( \\left( \\frac{1}{2\\pi\\sigma^2} \\right)^{1/2} e^{-\\frac{(y_i - \\boldsymbol\\beta^T\\mathbf{x}_i)^2}{2\\sigma^2}} \\right) \\right]\\]\nLa expresiÃ³n anterior puede minimizarse primero respecto de \\(\\boldsymbol\\beta\\) y luego respecto de \\(\\sigma\\). Resulta que maximizar la verosimilitud respecto de \\(\\boldsymbol\\beta\\) equivale a minimizar el error cuadrÃ¡tico.\n\n\n\nEn estadÃ­stica bayesiana, consideramos a los parÃ¡metros como variables aleatorias y les asignamos una distribuciÃ³n a priori.\nAdemÃ¡s, contamos con un modelo generativo (probabilÃ­stico) para las observaciones: Â¿cÃ³mo obtendrÃ­amos observaciones si conociÃ©ramos los parÃ¡metros? Es una decisiÃ³n de la modelizaciÃ³n.\n\n\n\nAquÃ­ asumimos:\n\\[Y_i \\mid \\boldsymbol\\beta,\\sigma \\sim \\mathcal{N}(\\boldsymbol\\beta^T \\mathbf{x}_i, \\sigma^2)\\]\no bien decimos\n\\[\n\\begin{align*}\n    Y_i & \\sim  \\mathcal{N}(\\mu_i, \\sigma^2) \\\\\n    \\mu_i & = \\beta_0 + \\beta_1 x_{1_i} + \\beta_2 x_{2_i} + \\dots + \\beta_p x_{p_i}\n\\end{align*}\n\\]\nY completamos el modelo especificando una distribuciÃ³n a priori \\(p(\\boldsymbol\\beta,\\sigma)\\)\n\n\n\nLa estimaciÃ³n se hace siempre de la misma manera\n\\(p(\\boldsymbol\\beta,\\sigma\\mid\\mathbf{y}) \\propto p(\\mathbf{y}|\\boldsymbol\\beta,\\sigma)p(\\boldsymbol\\beta,\\sigma)\\)\n\n\n\nObservando un datoâ€¦\n\n\n\n\n\n\n\n\n\n\n\n\nObservando el dato que sigueâ€¦\n\n\n\n\n\n\n\n\n\n\n\n\nObservando dos puntos juntosâ€¦\n\n\n\n\n\n\n\n\n\n\n\n\nComparemos con un prior mÃ¡s fuerteâ€¦\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\mu\\) depende de los parÃ¡metros (y por supuesto del valor de \\(x\\)), por lo que tiene una distribuciÃ³n de probabilidad asociada\n\n\n\n\n\n\n\n\n\n\n\n\nPor supuesto, las predicciones para \\(y\\) tambiÃ©n son probabilÃ­sticasâ€¦\n\n\n\n\n\n\n\n\n\n\n\n\n\nTenemos una distribuciÃ³n de probabilidad para los parÃ¡metros. Es decir, tenemos incertidumbre en los valores de los parÃ¡metros\nTenemos que trabajar con todo el posterior (a travÃ©s de muestras) y no con estimaciones puntuales\nNo confundir predicciÃ³n de la media (tambiÃ©n llamado predictor lineal) con distribuciÃ³n predictiva (para las observaciones)\nA medida que aumenta el tamaÃ±o de muestra, los coeficientes de la regresiÃ³n se estiman cada vez con mayor precisiÃ³n y la incertidumbre del predictor lineal desaparece. No obstante, la incertidumbre en la distribuciÃ³n predictiva no desaparece (siempre quedarÃ¡ \\(\\sigma\\))\n\n\n\n\n\nEl modo fundamental de validar el ajuste de un modelo bayesiano es generar rÃ©plicas del conjunto de datos (utilizando el modelo ajustado) y compararlas con los datos reales. Esto es lo que se conoce como validaciÃ³n interna.\nPara cada muestra de parÃ¡metros del posterior podemos generar un dataset \\[\n\\left[\n\\begin{array}{l|l|l|l}\nY_1^{(1)} & Y_2^{(1)} & \\cdots & Y_{N}^{(1)} \\\\\nY_1^{(2)} & Y_2^{(2)} & \\cdots & Y_{N}^{(2)} \\\\\n\\vdots & \\vdots &  & \\vdots \\\\\nY_1^{(S)} & Y_2^{(S)} & \\cdots & Y_{N}^{(S)} \\\\\n\\end{array}\n\\right]\n\\]\nEsta prÃ¡ctica da lugar a los posterior predictive checks (PPC)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdealmente quisiÃ©ramos ver si nuestro modelo tiene capacidad predictiva para datos nuevos (no usados para ajustarlo)\nAntes de preocuparnos por los datos nuevos, pensemos en las prediccionesâ€¦ Las predicciones son probabilÃ­sticas\nNo podemos simplemente comparar \\(y\\) con \\(\\hat{y}\\)\nDebemos utilizar toda la distribuciÃ³n a posteriori para evaluar el ajuste y (la capacidad predictiva) del modelo\n\n\n\n\nUn posible score predictivo para un determinado valor \\(y_i\\) es la probabilidad que el modelo le asociaba, \\(\\int p\\left(y_i\\mid\\theta\\right) p(\\theta\\mid y) d\\theta \\approx \\frac{1}{S}\\sum_{s=1}^S p(y_i\\mid \\theta^{(s)})\\). El score predictivo total (para todas las posibles observaciones) es la log-posterior pointwise predictive density\n\\[\n\\mathrm{lppd} = \\sum_{i=1}^{N} \\log \\left( \\int p\\left(y_i\\mid\\theta\\right) p(\\theta\\mid y) d\\theta \\right)\n\\]\n\\[\n\\mathrm{lppd} = \\sum_{i=1}^{N} \\log \\left( \\frac{1}{S} \\sum_{s=1}^{S} p\\left(y_i\\mid\\theta^{(s)}\\right) \\right)\n\\]\nA mayor \\(\\mathrm{lppd}\\), mejor es el modelo para realizar predicciones\n\n\n\nLa deviance de un modelo es\n\\[D = -2 \\mathrm{lppd}\\]\n\nLa deviance (o la \\(\\mathrm{lppd}\\)) evalÃºa las predicciones de un modelo (el ajuste), no nos dice quÃ© tan correcto esâ€¦\nSon medidas que siempre mejoran con mÃ¡s parÃ¡metros y en realidad nos importa cÃ³mo se desempeÃ±a el modelo con datos nuevos.\n\n\n\n\nLa \\(\\mathrm{lppd}\\) predice el \\(i\\)-Ã©simo valor con un posterior que usa todos los datos, incluido el \\(i\\). MÃ¡s que la \\(\\mathrm{lppd}\\) nos interesa su valor esperado en datos nuevos (\\(\\mathrm{elpd}\\)). Por supuesto, no conocemos datos nuevos. Podemos aproximar o estimar \\(\\mathrm{elpd}\\) haciendo cross-validation (CV) o, en particular, leave-one-out cross-validation (LOO-CV).\n\\[\\mathrm{elpd} \\approx \\mathrm{lppd}_{LOO} = \\sum_{i=1}^{N} \\log \\left( \\frac{1}{S} \\sum_{s=1}^{S} p\\left(y_i\\mid\\theta_{-i}^{(s)}\\right) \\right)\\]\ndonde los \\(\\theta_{-i}^{(s)}\\) son muestras del posterior de \\(\\theta\\) obtenido sin considerar la \\(i\\)-Ã©sima observaciÃ³n.\nEl problema de hacer LOO-CV es que, si tenemos 1000 observaciones, hay que calcular 1000 distribuciones a posteriori.\n\n\n\nNo contamos con muestras de \\(P(\\theta\\mid \\mathbf{Y}_{-i})\\) sino simplemente de \\(P(\\theta\\mid \\mathbf{Y})\\). No sabemos la distribuciÃ³n a posteriori de \\(\\theta\\) sin considerar la observaciÃ³n \\(i\\). Hay formas de aproximar el desempeÃ±o en LOO-CV sin necesidad de reajustar el modelo. Una forma de hacerlo es usar la â€œimportanciaâ€ de cada observaciÃ³n en el posterior. Esto da lugar a una tÃ©cnica que se conoce como Pareto-smoothed importance sampling cross-validation (PSIS)\n\n\n\nHistÃ³ricamente se han desarrollado los llamados criterios de informaciÃ³n que penalizan la verosimilitud con un tÃ©rmino adicional para compensar la capacidad de sobreajuste de un modelo que tiene mÃ¡s parÃ¡metros.\n\n\n\nEl AIC (Akaike information criterion) es \\[AIC = D + 2p = -2\\ lppd + 2p\\] donde \\(p\\) es el nÃºmero de parÃ¡metros del modelo y \\(D=-2\\ \\mathrm{lppd}\\) se conoce como deviance. Penalizamos el \\(\\mathrm{lppd}\\) con la tendencia (o capacidad) del modelo de sobreajustar. ##\nEl WAIC (widely applicable information criterion) es un criterio mÃ¡s general que el AIC (y un poquitito mÃ¡s difÃ­cil de calcular):\n\\[WAIC = - 2\\left(\\mathrm{lppd} - \\sum_{i=1}^N \\mathbb{V}_\\theta\\left[\\log\\left(p(y_i\\mid\\theta\\right)\\right]\\right)\\]\n\\(\\sum_{i=1}^N \\mathrm{V}_\\theta\\left[\\log\\left(p(y_i\\mid\\theta\\right)\\right]\\) es un tÃ©rmino de penalizaciÃ³n que se suele llamar â€œnÃºmero efectivo de parÃ¡metrosâ€. Es la suma de las varianzas en la log-probabilidad de cada observaciÃ³n \\(i\\) (o sea, la varianza total). Si, para un determinado dato \\(i\\), las diferentes muestras del posterior \\(\\theta_{(s)}\\) dan como resultado predicciones muy diferentes, es porque el modelo tiene mucha incertidumbre (y es posiblemente muy flexible)."
  },
  {
    "objectID": "presentaciones/presentacion_02.html",
    "href": "presentaciones/presentacion_02.html",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Se cuenta con 11 urnas etiquetadas segÃºn \\(u = 0,1,\\dots,10\\), que contienen diez bolas cada una. La urna \\(u\\) contiene \\(u\\) bolas azules y \\(10-u\\) bolas blancas. Fede elige una urna \\(u\\) al azar y extrae con reposiciÃ³n \\(N\\) bolas, obteniendo \\(n_A\\) azules y \\(N-n_A\\) blancas. Nico, el amigo de Fede, observa atentamente. Si despuÃ©s de \\(N=10\\) extracciones resulta \\(n_A = 3\\), Â¿cuÃ¡l es la probabilidad de que la urna que Fede estÃ¡ usando sea la \\(u\\)?\n\n\n\n\nLa teorÃ­a de las probabilidades permite predecir una distribuciÃ³n sobre posibles valores de un resultado dado cierto conocimiento (o estado) del universo: probabilidad hacia adelante\n\nPor el contrario, muchas veces estamos interesados en realizar inferencias sobre el estado del universo a partir de observaciones: probabilidad inversa.\n\n\n\\[p(\\mathcal{H}\\mid E) = \\frac{p(E\\mid\\mathcal{H}) p(\\mathcal{H})}{p(E)}\\]\n\\[p(\\mathcal{H}\\mid E) \\propto p(E\\mid\\mathcal{H}) p(\\mathcal{H})\\]\n\n\n\n\nConociendo \\(N\\), si conociÃ©ramos \\(u\\) podrÃ­amos calcular las probabilidades de los diferentes \\(n_A\\): probabilidad hacia adelante.\n\nAquÃ­ observamos un \\(n_A\\) y queremos calcular las probabilidades de los posibles valores de \\(u\\): probabilidad inversa.\n\n\n\\[p(u\\mid n_A, N) = \\frac{p(n_A\\mid u, N)p(u)}{p(n_A\\mid N)}\\]\n\n\\(N\\) es una cantidad fija\n\\(n_A\\) es otra cantidad fija: lo que observamos al realizar el experimento\n\\(u\\) es la cantidad desconocida\n\n\n\n\n\nProbabilidad conjunta de las cantidades observables (datos) y cantidades no observables (parÃ¡metros):\n\n\\[\np(u,n_A\\mid N) = p(n_A\\mid u, N) p(u)\n\\]\n\n\nPodemos escribir la probabilidad de \\(u\\) condicionada a \\(n_A\\):\n\\[\n\\begin{array}{ccl}\np(u\\mid n_A,N) & = & \\frac{p(u,n_A\\mid N)}{p(n_A\\mid N)} \\\\\n& = & \\frac{p(n_A\\mid u, N) p(u)}{p(n_A\\mid N)}\n\\end{array}\n\\]\n\n\nEs la probabilidad de cada valor de \\(u\\) luego de haber observado \\(n_A = 3\\) bolas azules\n\n\n\n\nLa probabilidad marginal de \\(u\\) es\n\n\\[p(u) = \\frac{1}{11}\\]\nEs la probabilidad inicial de haber tomado la urna \\(u\\)\n\n\n\n\nLa probabilidad de \\(n_A\\) dado \\(u\\) (y \\(N\\)) es:\n\n\\[p(n_A\\mid u,N) = {N \\choose n_A} \\left( \\frac{u}{10} \\right)^{n_A} \\left( 1 - \\frac{u}{10} \\right)^{N-n_A}\\]\n\n\nComo \\(n_A=3\\) es fijo (Â¡son los datos observados!), \\(p(n_A\\mid u,N)\\) es una funciÃ³n de \\(u\\). Indica quÃ© tan compatibles son los datos observados con los distintos valores de \\(u\\)\n\n\n\n\nEl denominador, \\(p(n_A\\mid N) = p(n_A)\\), es\n\n\\[\n\\begin{array}{ccl}\np(n_A\\mid N) & = & \\sum_u p(u,n_A\\mid N) \\\\\n& = & \\sum_u p(n_A\\mid u, N) p(u) \\\\\n& = & \\frac{1}{11} \\sum_u p(n_A\\mid u, N)\n\\end{array}\n\\]\n\n\n\n\nFinalmente, la probabilidad de interÃ©s \\(p(u\\mid n_A,N)\\) es\n\n\\[\np(u\\mid n_A,N) = \\frac{p(n_A\\mid u,N)p(u)}{p(n_A\\mid N)}\n\\]\n\n\n\\[\np(u\\mid n_A,N) = {N \\choose n_A} \\left( \\frac{u}{10} \\right)^{n_A} \\left( 1 - \\frac{u}{10} \\right)^{N-n_A} \\frac{1}{11} \\frac{1}{p(n_A\\mid N)}\n\\]\n\n\n\n\\(N\\) es una cantidad fija\n\\(n_N\\) es 3, otra cantidad fija: lo que observamos al realizar el experimento\n\\(u\\) es la cantidad desconocida\n\n\n\n\\(p(u\\mid n_A,N)\\) es una funciÃ³n de \\(u\\): es la credibilidad de los valores de \\(u\\) luego de observar los datos (es decir, condicionada a \\(n_A=3\\)).\n\n\n\n\nGrÃ¡ficamenteâ€¦\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 8\n  #| fig-height: 8\n  #| fig-align: center\ndata %>% \n  filter(joint>0) %>%\n  ggplot() +\n  geom_point(aes(x=nN,y=u,size=joint),shape='square') +\n  scale_size(range=c(0,10)) +\n  scale_x_continuous(name = expression(n[A]),breaks=c(0:10)) +\n  scale_y_continuous(breaks=c(0:10)) +\n  coord_fixed()\n\n\n\n\n\n\n\nGrÃ¡ficamenteâ€¦\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 8\n  #| fig-height: 8\n  #| fig-align: center\ndata %>% \n  filter(joint>0) %>%\n  ggplot() +\n  geom_point(aes(x=nN,y=u,size=joint),shape='square') +\n  scale_size(range=c(0,10)) +\n  scale_x_continuous(name = expression(n[A]),breaks=c(0:10)) +\n  scale_y_continuous(breaks=c(0:10)) +\n  geom_point(data = filter(data,joint>0,nN==3),aes(x=nN,y=u,size=joint),shape='square',col=\"#21dbbc\") +\n  coord_fixed()\n\n\n\n\n\n\n\nPasamos de una credibilidad a priori antes de observar los datos, a una a posteriori luego de observar \\(n_A = 3\\)\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 12\n  #| fig-height: 8\n  #| fig-align: center\n\nposterior <- data %>%\n  filter(nN == 3) %>%\n  mutate(posterior = joint/sum(joint)) %>%\n  select(u,prior,posterior)\n\np1 <- posterior %>%\n  ggplot() +\n  geom_segment(aes(x=u,xend=u,y=0,yend=prior),size=1,col=\"#56CBF9\") +\n  scale_y_continuous(limits = c(0,0.3),name = \"P(u)\") +\n  scale_x_continuous(\"u\",breaks=0:10)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nâ„¹ Please use `linewidth` instead.\n\np2 <- posterior %>%\n  ggplot() +\n  geom_segment(aes(x=u,xend=u,y=0,yend=posterior),size=1,col=\"#FF729F\") +\n  scale_y_continuous(limits = c(0,0.3),name = expression(\"P(u|\"*n[A]*\",N)\")) +\n  scale_x_continuous(\"u\",breaks=0:10)\n\np1+p2\n\n\n\n\n\n\n\n\nÂ¿Pueden las personas alÃ©rgicas al gluten distinguir harina comÃºn de harina sin gluten en un ensayo ciego? En un experimento, de 35 sujetos, 12 identificaron correctamente la harina comÃºn y 23 se equivocaron o no supieron decir de quÃ© harina se trataba.\nIncluso si no hubiera alÃ©rgicos al gluten en el experimento, esperarÃ­amos encontrar algunas identificaciones correctasâ€¦ BasÃ¡ndonos en el nÃºmero de identificaciones correctas, Â¿cuÃ¡ntos de los sujetos son alÃ©rgicos al gluten y cuÃ¡ntos estaban adivinando?\n\n\nSupongamos que una persona alÃ©rgica al gluten tiene una probabilidad de \\(0.90\\) de detectar la harina comÃºn mientras que una persona sin alergia detecta harina comÃºn con una probabilidad de \\(0.40\\) (y con una probabilidad de \\(0.6\\) se equivoca o no sabe decir).\n\n\n\n\nLlamemos:\n\n\n\\(N\\) a la cantidad total de personas en el ensayo\n\\(N_a\\) al nÃºmero de personas alÃ©rgicas al gluten\n\\(\\pi_a\\) a la probabilidad de que un alÃ©rgico identifique correctamente\n\\(\\pi_f\\) a la probabilidad de que un no alÃ©rgico identifique correctamente\n\\(n_i\\) al nÃºmero de identificaciones correctas\n\n\n\nÂ¿CuÃ¡les son las cantidades conocidas? Â¿CuÃ¡les son las cantidades desconocidas? Â¿CÃ³mo es el modelo de probabilidad hacia adelante? Â¿CÃ³mo es el problema inverso?\n\n\n\n\nConociendo \\(N\\), \\(\\pi_a\\) y \\(\\pi_f\\), si conociÃ©ramos \\(N_a\\) podrÃ­amos calcular las probabilidades de los diferentes \\(n_i\\): probabilidad hacia adelante\n\nAquÃ­ observamos \\(n_i\\) y queremos realizar inferencias sobre \\(N_a\\): probabilidad inversa\n\n\n\n\nDigamos que a priori cualquier nÃºmero de \\(N_a\\) es igualmente probable o esperable:\n\n\\[p(N_a) = \\frac{1}{36}\\]\n\n\n\n\nÂ¿CÃ³mo construimos la verosimilitud de los diferentes valores de \\(N_a\\) \\(p(n_i\\mid N_a)\\)?\n\nPensemos de forma generativa (con el modelo de probabilidad hacia adelante). Imaginemos que conocemos \\(N_a\\) (ademÃ¡s de \\(N\\), \\(\\pi_a\\) y \\(\\pi_f\\)), Â¿podrÃ­amos escribir un programa que simule diferentes valores de \\(n_i\\)?\n\n\n\n\nEl nÃºmero de identificaciones correctas \\(n_i\\) es la suma de las identificaciones correctas entre los \\(N_a\\) alÃ©rgicos (\\(n_{ia}\\)) y los \\(N-N_a\\) no alÃ©rgicos (\\(n_{if}\\)). Â¿CuÃ¡ntas identificaciones habrÃ¡ en cada grupo?\n\n\\[n_{ia} \\sim Bi(N_a,\\pi_a)\\] \\[n_{if} \\sim Bi(N-N_a,\\pi_f)\\] \\[n_i = n_{ia} + n_{if}\\]\n\n\n\nN <- 35\npi_a <- 0.9\npi_f <- 0.4\nN_a <- 10 # lo suponemos conocido para simular\n\nn_ia <- rbinom(1, N_a, pi_a)\nn_if <- rbinom(1, N-N_a, pi_f)\n\nn_i <- n_ia + n_if\n\n\n\nSabrÃ­amos calcular las probabilidades de los diferentes valores de \\(n_{ia}\\) y \\(n_{if}\\), Â¿no?.\n\n\n\n\nRecordemos que no conocemos \\(N_a\\). En nuestro caso, la verosimilitud de cada valor de \\(N_a\\) es la probabilidad de observar \\(n_i=12\\) para ese valor de \\(N_a\\).\n\n\\[\n\\begin{array}{lll}\np(n_i=12\\mid N_a) & = & p(n_{ia}=0\\mid N_a)p(n_{if}=12\\mid N_a) \\\\\n& & \\quad + p(n_{ia}=1\\mid N_a)p(n_{if}=11\\mid N_a) + \\dots\n\\end{array}\n\\]\n\n\nQueda como ejercicio calcular a mano \\(p(n_i\\mid N_a)\\) o, mejor aÃºn, escribir un programita que calcule \\(p(n_i\\mid N_a)\\)\n\n\n\n\nFinalmente,\n\\[p(N_a\\mid n_i) = \\frac{p(n_i\\mid N_a) p(N_a)}{p(n_i)}\\]\n\n\n\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 12\n  #| fig-height: 8\n  #| fig-align: center\n\nposterior <- \nexpand.grid(N_a = 0:35,\n            n_ia = 0:35,\n            n_if = 0:35) |>\n  mutate(n_i = n_ia + n_if,\n         prob_ia = dbinom(n_ia,N_a,0.95),\n         prob_if = dbinom(n_if,N-N_a,0.4),\n         prob = prob_ia*prob_if) |>\n  filter(n_i == 12) |>\n  group_by(N_a) |>\n  summarise(likelihood = sum(prob)) |>\n  mutate(prior = 1/36,\n         posterior_ = likelihood*prior,\n         posterior = posterior_/sum(posterior_))\n\np1 <- posterior %>%\n  ggplot() +\n  geom_segment(aes(x=N_a,xend=N_a,y=0,yend=prior),size=1,col=\"#56CBF9\") +\n  scale_y_continuous(limits = c(0,0.3),name = expression(\"P(\"*N[a]*\")\")) +\n  scale_x_continuous(expression(N[a]),breaks=0:35,labels=ifelse(0:35 %% 5 == 0, 0:35, \"\"))\n\np2 <- posterior %>%\n  ggplot() +\n  geom_segment(aes(x=N_a,xend=N_a,y=0,yend=posterior),size=1,col=\"#FF729F\") +\n  scale_y_continuous(limits = c(0,0.3),name = expression(\"P(\"*N[a]*\"|\"*n[i]*\")\")) +\n  scale_x_continuous(expression(N[a]),breaks=0:35,labels=ifelse(0:35 %% 5 == 0, 0:35, \"\"))\n\np1 + p2\n\n\n\n\n\n\n\n\nSupongamos que existe un idioma con seis palabras: \\[ \\text{\\{perro, parra, farra, carro, corro, tarro\\}} \\]\n\n\nTodas las palabras son igualmente probables, excepto por â€˜perroâ€™, que es \\(\\alpha=3\\) veces mÃ¡s probable que las otras.\nCuando se tipean, un caracter se introduce errÃ³neamente con probabilidad \\(\\pi=0.1\\).\nTodas las letras tienen la misma probabilidad de producir un error de tipeo.\nSi una letra se tipeÃ³ mal, la probabilidad de cometer un error en otro caracter no cambia.\nLos errores son independientes a lo largo de una palabra.\n\n\n\n\n\nÂ¿CuÃ¡l es la probabilidad de escribir correctamente â€˜tarroâ€™?\nÂ¿CuÃ¡l es la probabilidad de tipear â€˜cerroâ€™ o â€˜curroâ€™ al querer escribir â€˜carroâ€™?\nDesarrollar un corrector gramatical para esta lengua: para las palabras tipeadas â€˜farraâ€™, â€˜birraâ€™ y â€˜locosâ€™, Â¿cuÃ¡l es la palabra que se quiso escribir?\n\n\n\n\n\nLa probabilidad de escribir correctamente â€˜tarroâ€™ es \\((1-\\pi)^5\\)\nLa probabilidad de escribir correctamente â€˜cerroâ€™ o â€˜curroâ€™ al querer escribir â€˜carroâ€™ es $(1-)^4 $\nAllÃ¡ vamosâ€¦\n\n\n\n\nEstas son las probabilidades a priori de cada una de las palabras del vocabulario\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 6\n  #| fig-height: 8\n  #| fig-align: center\n\nvocabulario <- as.factor(c(\"perro\",\"parra\",\"farra\",\"carro\",\"corro\",\"tarro\"))\nprobs_ <- c(3,1,1,1,1,1)\nprobs <- probs_/sum(probs_)\n\ndata.frame(vocabulario,probs) |>\n  ggplot() +\n  geom_segment(aes(x=vocabulario,xend=vocabulario,y=0,yend=probs),size=3,col=\"#56CBF9\") +\n  scale_y_continuous(limits = c(0,0.8),name = expression(\"p(palabra)\")) +\n  xlab(\"palabra\")\n\n\n\n\n\n\n\nAlguien escribe â€˜farraâ€™, Â¿quÃ© quiso escribir?\n\nÂ¿QuÃ© serÃ­a en este caso la verosimilitud?\n\n\nLa verosimilitud de â€˜perroâ€™ es quÃ© tan probable es escribir â€˜farraâ€™ cuando se querÃ­a escribir â€˜perroâ€™: \\(p(\\mathrm{farra}\\mid\\mathrm{perro})=\\pi^3(1-\\pi)^2\\)\n\n\n\n\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 6\n  #| fig-height: 8\n  #| fig-align: center\n\npalabra <- \"farra\"\npi <- 0.1\nlikelihood <- c(pi^2*(1-pi)^3,\n                pi^1*(1-pi)^4,\n                pi^0*(1-pi)^5,\n                pi^2*(1-pi)^3,\n                pi^3*(1-pi)^2,\n                pi^2*(1-pi)^3)\n\ndata.frame(vocabulario,likelihood) |>\n  ggplot() +\n  geom_segment(aes(x=vocabulario,xend=vocabulario,y=0,yend=likelihood),size=3,col=\"#21dbbc\") +\n  scale_y_continuous(limits = c(0,0.8),name = expression(\"p(farra|palabra)\")) +\n  xlab(\"palabra\")\n\n\n\n\n\n\n\nPara obtener la probabilidad a posteriori de cada palabra, necesitamos combinar la informaciÃ³n a priori con los datos (Â¿cuÃ¡les son los datos?). Aplicamos la Regla de Bayes:\n\\[p(\\mathrm{palabra}\\mid \\mathrm{farra}) = \\frac{p(\\mathrm{farra}\\mid \\mathrm{palabra})p(\\mathrm{palabra})}{p(\\mathrm{farra})}\\]\n\n\n\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 6\n  #| fig-height: 8\n  #| fig-align: center\n\n\ndata.frame(vocabulario,likelihood,probs) |>\n  mutate(posterior_ = likelihood*probs,\n         posterior = posterior_/sum(posterior_)) |>\n  ggplot() +\n  geom_segment(aes(x=vocabulario,xend=vocabulario,y=0,yend=posterior),size=3,col=\"#FF729F\") +\n  scale_y_continuous(limits = c(0,0.9),name = expression(\"p(palabra|farra)\")) +\n  xlab(\"palabra\")\n\n\n\n\n\n\n\nLa inferencia bayesiana es la realocaciÃ³n de la credibilidad del conjunto de cantidades desconocidas (parÃ¡metros) de un modelo, una vez observado un conjunto de datos.\n\n\n\n\nSe desea estimar la proporciÃ³n de agua que cubre el planeta Tierra. Para ello se arroja hacia arriba un â€œglobo terrÃ¡queo antiestrÃ©sâ€ y se registra la posiciÃ³n del dedo Ã­ndice al volver a tomarlo.\nSe arroja el globo 11 veces hacia arriba y se obtiene la siguiente secuencia: \\[TAAATTAATAA\\]\n\n\n\n\nLlamemos:\n\n\n\\(\\pi\\) a la proporciÃ³n de agua en el planeta Tierra\n\\(N\\) al nÃºmero de tiradas\n\\(y\\) al nÃºmero de veces que saliÃ³ agua\n\n\n\n\\(\\pi\\) es una cantidad continua entre 0 y 1. Esta vez no la discretizaremos.\n\n\n\n\n\n\nÂ¿CÃ³mo asignamos una credibilidad a priori para los valores de \\(\\pi_a\\)? . . . Con una distribuciÃ³n de probabilidad.\n\n\\[\n\\pi \\sim \\mathrm{Beta}(a,b)\n\\]\n\n\n\\[\np(\\pi\\mid a,b) = p(\\pi) = \\frac{\\pi^{a-1} (1-\\pi)^{b-1}}{B(a,b)}\n\\]\n\n\n\\[\nB(a,b) = \\int_0^1 \\pi^{a-1} (1-\\pi)^{b-1} d\\pi = \\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}\n\\]\n\n\n\\[\n\\Gamma(x) = \\int_0^\\infty u^{x-1} e^{-u} du\n\\]\n\n\n\n\n\n\n\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 6\n  #| fig-height: 8\n  #| fig-align: center\n\na <- 1\nb <- seq(1,20,5)\n\ndv <- expand.grid(a=a,b=b,x=seq(0,1,0.01)) |>\n  mutate(p = dbeta(x,a,b))\n\ndv$beta <- paste0(\"a = \", dv$a, \", b = \", dv$b )\n\ndv |>\n  ggplot() +\n  geom_line(aes(x=x,y=p,col=beta,group=beta),size=1) +\n  scale_y_continuous(name = expression(\"P(\"*pi[a]*\")\")) +\n  xlab(expression(pi[a])) +\n  theme(legend.title = element_blank())\n\n\n\n\n\n\n\n\n\n\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 6\n  #| fig-height: 8\n  #| fig-align: center\n\na <- 6\nb <- seq(1,20,5)\n\ndv <- expand.grid(a=a,b=b,x=seq(0,1,0.01)) |>\n  mutate(p = dbeta(x,a,b))\n\ndv$beta <- paste0(\"a = \", dv$a, \", b = \", dv$b )\n\ndv |>\n  ggplot() +\n  geom_line(aes(x=x,y=p,col=beta,group=beta),size=1) +\n  scale_y_continuous(name = expression(\"P(\"*pi[a]*\")\")) +\n  xlab(expression(pi[a])) +\n  theme(legend.title = element_blank())\n\n\n\n\n\n\n\n\nUna posible elecciÃ³n de valores para la distribuciÃ³n a priori es \\(Beta(2,2)\\)\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 6\n  #| fig-height: 8\n  #| fig-align: center\n\na <- 2\nb <- 2\n\ndv <- expand.grid(a=a,b=b,x=seq(0,1,0.01)) |>\n  mutate(p = dbeta(x,a,b))\n\ndv$beta <- paste0(\"a = \", dv$a, \", b = \", dv$b )\n\ndv |>\n  ggplot() +\n  geom_line(aes(x=x,y=p,col=beta,group=beta),size=1) +\n  scale_y_continuous(name = expression(\"P(\"*pi[a]*\")\")) +\n  xlab(expression(pi[a])) +\n  theme(legend.title = element_blank())\n\n\n\n\n\n\n\n\n\nÂ¿CuÃ¡l es la probabilidad de observar los datos que observamos para diferentes valores del parÃ¡metro?\n\n\\[ y \\mid \\pi, N \\sim Bi(N,\\pi) \\]\n\\[p(y\\mid \\pi, N) = {N \\choose y }\\pi^y (1-\\pi)^{N-y} = p(y\\mid \\pi)\\]\n\n\n\n\n\n\n\n\\[p(\\pi\\mid y) = \\frac{p(y\\mid \\pi)p(\\pi)}{p(y)}\\]\n\n\\[p(\\pi\\mid y) = \\frac{{N \\choose y }\\pi^y (1-\\pi)^{N-y}  \\frac{\\pi^{a-1} (1-\\pi)^{b-1}}{B(a,b)}}{\\int p(y\\mid\\pi) p(\\pi) d \\pi}\\]\n\n\nLa integral en el denominador suele ser un problema. Con dos parÃ¡metros es una integral doble, con tres parÃ¡metros, una triple, etc. Esta integral puede ser intratable intractable (no tener soluciÃ³n exacta, analÃ­tica, cerrada). No hay vaca vestida de uniforme que nos salve.\n\n\n\n\n\nRecordando que: \\[\n\\mathrm{posterior} \\propto \\mathrm{prior}\\times\\mathrm{likelihood}\n\\]\n\nResulta \\[p(\\pi\\mid y) \\propto p(y\\mid\\pi) p(\\pi)\\]\n\n\n\\[p(\\pi\\mid y) \\propto {N \\choose y }\\pi^y (1-\\pi)^{N-y} \\frac{1}{B(a,b)} \\pi^{a-1}(1-\\pi)^{b-1}\\]\n\n\n\\[p(\\pi\\mid y) \\propto {N \\choose y } \\frac{1}{B(a,b)} \\pi^{(y+a)-1} (1-\\pi)^{(N-y+b)-1}\\]\n\n\n\\[p(\\pi\\mid y) = K C  \\pi^{(y+a)-1} (1-\\pi)^{(N-y+b)-1}\\]\n\n\n\\[p(\\pi\\mid y) = K^* \\pi^{(y+a)-1} (1-\\pi)^{(N-y+b)-1}\\]\n\n\n\n\nPara que \\(\\int_0^1 p(\\pi\\mid y) d \\pi = 1\\), debe ser\n\n\\[K^* = \\frac{1}{B(y+a,N-y+b)} = \\frac{\\Gamma\\left[(y+a)+(N-y+b)\\right]}{\\Gamma(y+a)\\Gamma(N-y+b)}\\]\n\n\nPor lo tanto, resulta que la distribuciÃ³n a posteriori es Beta de parÃ¡metros \\(y+a\\) y \\(N-y+b\\)\n\\[\np(\\pi\\mid y) = \\frac{\\pi^{(y+a)-1}(1-\\pi)^{(N-y+b)-1}}{B(y+a,N-y+b)}\n\\]\n\\[\n\\pi\\mid y \\sim  Beta(y+a,N-y+b)\n\\]\n\n\n\n\n\nNos las arreglamos para encontrar la soluciÃ³n exacta al problema de inferir el parÃ¡metro de una distribuciÃ³n binomial a partir del nÃºmero de Ã©xitos observados.\n\n\nEl prior y el posterior tienen la misma forma distribucional. Esto ocurre por la elecciÃ³n del prior y el likelihood.\n\n\n\n\nUna distribuciÃ³n \\(\\mathcal{F}\\) se dice conjugada de una verosimilitud \\(\\mathcal{L}\\) si cuando la distribuciÃ³n a priori es \\(\\mathcal{F}\\), la distribuciÃ³n a posteriori tambiÃ©n es \\(\\mathcal{F}\\)\n\n\n\n\nSe desea estimar la proporciÃ³n de agua que cubre el planeta Tierra. Para ello se arroja hacia arriba un â€œglobo terrÃ¡queo antiestrÃ©sâ€ y se registra la posiciÃ³n del dedo Ã­ndice al volver a tomarlo.\nSe arroja el globo 11 veces hacia arriba y se obtiene la siguiente secuencia: \\[TAAATTAATAA\\]\n\n\n\\[\n\\begin{align*}\n    y\\mid\\pi & \\sim  Bi(N,\\pi)\\\\\n    \\pi & \\sim  Beta(a,b)\n\\end{align*}\n\\]\n\n\n\n\ncon \\(N=11\\), \\(a=2\\) y \\(b=2\\).\nAl observar \\(y=7\\) resulta\n\\[\\pi\\mid y \\sim Beta(a+y,b+N-y)\\] \\[p(\\pi\\mid y) = Beta(2+7,2+4)\\]\n\n\n\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 18\n  #| fig-height: 6\n  #| fig-align: center\n  #| cache: true\n\nposterior <- data.frame(x=seq(0,1,0.01)) |>\n  mutate(prior = dbeta(x,2,2),\n         likelihood = dbinom(7,11,x),\n         posterior = dbeta(x,9,6))\n\np1 <- posterior %>%\n  ggplot() +\n  geom_line(aes(x=x,y=prior/sum(prior)),size=1,col=\"#56CBF9\") +\n  scale_y_continuous(name = expression(\"P(\"*pi*\")\")) +\n  scale_x_continuous(expression(pi)) +\n  theme(axis.text.y = element_blank())\n\np2 <- posterior %>%\n  ggplot() +\n  geom_line(aes(x=x,y=likelihood/sum(likelihood)),size=1,col=\"#21dbbc\") +\n  scale_y_continuous(name = expression(\"P(\"*pi*\")\")) +\n  scale_x_continuous(expression(pi)) +\n  theme(axis.text.y = element_blank())\n\np3 <- posterior %>%\n  ggplot() +\n  geom_line(aes(x=x,y=posterior/sum(posterior)),size=1,col=\"#FF729F\") +\n  scale_y_continuous(name = expression(\"P(\"*pi*\"|\"*y*\")\")) +\n  scale_x_continuous(expression(pi)) +\n  theme(axis.text.y = element_blank())\n\np1 + p2 + p3\n\n\n\n\n\n\n\nQueremos estimar la probabilidad \\(\\pi\\) de que salga cara al arrojar una moneda.\n\nCredibilidad a priori: \\(Beta(2,2)\\)\n\n\nÂ¿CÃ³mo cambia nuestra creencia siâ€¦\n\nâ€¦realizamos 6 tiradas y observamos 4 caras?\nâ€¦realizamos 60 tiradas y observamos 40 caras?\nâ€¦realizamos 2 tiradas y observamos 2 caras?\nâ€¦realizamos 40 tiradas y observamos 40 caras?\nâ€¦realizamos 4 tiradas y obtenemos 3 caras y luego realizamos 2 tiradas mÃ¡s y observamos 1 caras?\n\n\n\n\n\n\n\\(\\pi \\mid y \\sim Beta(2+4,2+2)\\)\n\\(\\pi \\mid y \\sim Beta(2+40,2+20)\\)\n\\(\\pi \\mid y \\sim Beta(2+2,2+0)\\)\n\\(\\pi \\mid y \\sim Beta(2+40,2+0)\\)\n\\(\\pi \\mid y \\sim Beta((2+3)+1,(2+1)+1)\\)\n\n\n\n\n4 caras en 6 tiradas\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 18\n  #| fig-height: 6\n  #| fig-align: center\n  #| cache: true\n\ntibble(x = seq(0,1,length.out = 500),\n       prior = dbeta(x,2,2),\n       likelihood = dbinom(4,6,x),\n       posterior_posterior = prior*likelihood) %>%\n  mutate(prior = prior/sum(prior),\n         likelihood = likelihood/sum(likelihood),\n         posterior_posterior = posterior_posterior/sum(posterior_posterior),\n         posterior_likelihood = likelihood,\n         posterior_prior = prior) %>% \n  plot_bayes()\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 1000 rows [1, 2, 3, 4, 5,\n6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...].\n\n\n\n\n\n\n\n\n40 caras en 60 tiradas\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 18\n  #| fig-height: 6\n  #| fig-align: center\n  #| cache: true\n\ntibble(x = seq(0,1,length.out = 500),\n       prior = dbeta(x,2,2),\n       likelihood = dbinom(40,60,x),\n       posterior_posterior = prior*likelihood) %>%\n  mutate(prior = prior/sum(prior),\n         likelihood = likelihood/sum(likelihood),\n         posterior_posterior = posterior_posterior/sum(posterior_posterior),\n         posterior_likelihood = likelihood,\n         posterior_prior = prior) %>%\n  plot_bayes()\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 1000 rows [1, 2, 3, 4, 5,\n6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...].\n\n\n\n\n\n\n\n\n2 caras en 2 tiradas\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 18\n  #| fig-height: 6\n  #| fig-align: center\n  #| cache: true\n\ntibble(x = seq(0,1,length.out = 500),\n       prior = dbeta(x,2,2),\n       likelihood = dbinom(2,2,x),\n       posterior_posterior = prior*likelihood) %>%\n  mutate(prior = prior/sum(prior),\n         likelihood = likelihood/sum(likelihood),\n         posterior_posterior = posterior_posterior/sum(posterior_posterior),\n         posterior_likelihood = likelihood,\n         posterior_prior = prior) %>%\n  plot_bayes()\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 1000 rows [1, 2, 3, 4, 5,\n6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...].\n\n\n\n\n\n\n\n\n40 caras en 40 tiradas\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 18\n  #| fig-height: 6\n  #| fig-align: center\n  #| cache: true\n\ntibble(x = seq(0,1,length.out = 500),\n       prior = dbeta(x,2,2),\n       likelihood = dbinom(40,40,x),\n       posterior_posterior = prior*likelihood) %>%\n  mutate(prior = prior/sum(prior),\n         likelihood = likelihood/sum(likelihood),\n         posterior_posterior = posterior_posterior/sum(posterior_posterior),\n         posterior_likelihood = likelihood,\n         posterior_prior = prior) %>%\n  plot_bayes()\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 1000 rows [1, 2, 3, 4, 5,\n6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...].\n\n\n\n\n\n\n\n\n3 caras en 4 tiradas, luego 1 cara en 2 tiradas\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 18\n  #| fig-height: 10\n  #| fig-align: center\n\np6.1 <- tibble(x = seq(0,1,length.out = 500),\n       prior = dbeta(x,2,2),\n       likelihood = dbinom(3,4,x),\n       posterior_posterior = prior*likelihood) %>%\n  mutate(prior = prior/sum(prior),\n         likelihood = likelihood/sum(likelihood),\n         posterior_posterior = posterior_posterior/sum(posterior_posterior),\n         posterior_likelihood = likelihood,\n         posterior_prior = prior) %>%\n  plot_bayes()\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 1000 rows [1, 2, 3, 4, 5,\n6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...].\n\np6.2 <- tibble(x = seq(0,1,length.out = 500),\n       prior = dbeta(x,5,3),\n       likelihood = dbinom(1,2,x),\n       posterior_posterior = prior*likelihood) %>%\n  mutate(prior = prior/sum(prior),\n         likelihood = likelihood/sum(likelihood),\n         posterior_posterior = posterior_posterior/sum(posterior_posterior),\n         posterior_likelihood = likelihood,\n         posterior_prior = prior) %>%\n  plot_bayes()\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 1000 rows [1, 2, 3, 4, 5,\n6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...].\n\np6.1/p6.2\n\n\n\n\n\n\n\nLa inferencia bayesiana presenta ciertas caracterÃ­sticas que se repiten independientemente de las distribuciones elegidas.\n\n\n\nVamos a formalizar lo que observamos en el ejemplo para el modelo Betaâ€“Binomial. Para esto serÃ¡ Ãºtil el siguiente resultado:\n\\[\\text{Si } X\\sim Beta(a,b)\\]\n\\[\\mathbb{E}({X}) = \\frac{a}{a+b}\\]\n\n\n\nLa distribuciÃ³n a priori es \\(Beta(a,b)\\) y la distribuciÃ³n a posteriori es \\(Beta(y+a,N-y+b)\\). La media del es:\n\\[\n\\begin{align*}\n\\mathbb{E}[{p(\\pi\\mid y)}] & = \\frac{y+a}{a+b+N} \\\\\n& = \\frac{y}{a+b+N} + \\frac{a}{a+b+N} \\\\\n& = \\frac{N}{a+b+N}\\frac{y}{N} + \\frac{a+b}{a+b+N} \\frac{a}{a+b} \\\\\n& = \\frac{N}{a+b+N}\\frac{y}{N} + \\frac{a+b}{a+b+N} \\mathbb{E}{[P(\\pi)]}\n\\end{align*}\n\\]\n\n\n\nLa distribuciÃ³n a posteriori representa un balance (promedio ponderado o combinaciÃ³n convexa) entre la proporciÃ³n observada y la proporciÃ³n esperada a priori. Hay un shrinkage hacia la media del prior.\n\n\n\nSi primero observamos \\(y_1\\) en \\(N_1\\) y luego observamos \\(y_2\\) en \\(N_2\\)â€¦ Con el primer conjunto de datos pasamos del prior al posterior y luego esa distribuciÃ³n se convierte en el nuevo prior:\n\n\\[Beta(a,b) \\rightarrow Beta(y_1 + a, N_1 - y_1 + b)\\]\n\n\n\\[Beta(y_1 + a, N_1 - y_1 + b) \\rightarrow Beta(y_2 + y_1 + a,N_2 - y_2 + N_1 - y_1 + b)\\]\n\n\n\\[Beta(a,b) \\rightarrow Beta((y_1+y_2) + a, (N_1+N_2) - (y_1+y_2) + b)\\]\n\n\nEs idÃ©ntico a observar \\(y_1+y_2\\) en \\(N_1+N_2\\)\n\n\n\n\nLa Regla de Bayes permite combinar dos fuentes de informaciÃ³n: la informaciÃ³n a priori (lo que sabemos hasta el momento), y la nueva informaciÃ³n (representada por la verosimilitud). La distribuciÃ³n a posteriori representa un compromiso entre la verosimilitud de los datos y la credibilidad a priori."
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-47",
    "href": "presentaciones/presentacion_02.html#section-47",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "#| warning: false\n  #| echo: false\n  #| fig-width: 18\n  #| fig-height: 6\n  #| fig-align: center\n  #| cache: true\n\n# el prior desconfÃ­a de valores extremos del parÃ¡metro\ntibble(x = seq(0,1,length.out = 500),\n       prior = dbeta(x,2,2),\n       likelihood = dbeta(x,2,5),\n       posterior_posterior = prior*likelihood) %>%\n  mutate(prior = prior/sum(prior),\n         likelihood = likelihood/sum(likelihood),\n         posterior_posterior = posterior_posterior/sum(posterior_posterior),\n         posterior_likelihood = likelihood,\n         posterior_prior = prior) %>%\n  plot_bayes()\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 1000 rows [1, 2, 3, 4, 5,\n6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...]."
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-48",
    "href": "presentaciones/presentacion_02.html#section-48",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "#| warning: false\n  #| echo: false\n  #| fig-width: 18\n  #| fig-height: 6\n  #| fig-align: center\n  #| cache: true\n\ntibble(x = seq(0,1,length.out = 500),\n       prior = dbeta(x,5,5),\n       likelihood = dbeta(x,2,5),\n       posterior_posterior = prior*likelihood) %>%\n  mutate(prior = prior/sum(prior),\n         likelihood = likelihood/sum(likelihood),\n         posterior_posterior = posterior_posterior/sum(posterior_posterior),\n         posterior_likelihood = likelihood,\n         posterior_prior = prior) %>%\n  plot_bayes()\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 1000 rows [1, 2, 3, 4, 5,\n6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...]."
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-49",
    "href": "presentaciones/presentacion_02.html#section-49",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "#| warning: false\n  #| echo: false\n  #| fig-width: 18\n  #| fig-height: 6\n  #| fig-align: center\n  #| cache: true\n\ntibble(x = seq(0,1,length.out = 500),\n       prior = dbeta(x,10,10),\n       likelihood = dbeta(x,2,5),\n       posterior_posterior = prior*likelihood) %>%\n  mutate(prior = prior/sum(prior),\n         likelihood = likelihood/sum(likelihood),\n         posterior_posterior = posterior_posterior/sum(posterior_posterior),\n         posterior_likelihood = likelihood,\n         posterior_prior = prior) %>%\n  plot_bayes()\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 1000 rows [1, 2, 3, 4, 5,\n6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...]."
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-50",
    "href": "presentaciones/presentacion_02.html#section-50",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "#| warning: false\n  #| echo: false\n  #| fig-width: 18\n  #| fig-height: 6\n  #| fig-align: center\n  #| cache: true\n\ntibble(x = seq(0,1,length.out = 500),\n       prior = dbeta(x,5,3),\n       likelihood = dbeta(x,2,2),\n       posterior_posterior = prior*likelihood) %>%\n  mutate(prior = prior/sum(prior),\n         likelihood = likelihood/sum(likelihood),\n         posterior_posterior = posterior_posterior/sum(posterior_posterior),\n         posterior_likelihood = likelihood,\n         posterior_prior = prior) %>%\n  plot_bayes()\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 1000 rows [1, 2, 3, 4, 5,\n6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...]."
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-51",
    "href": "presentaciones/presentacion_02.html#section-51",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "#| warning: false\n  #| echo: false\n  #| fig-width: 18\n  #| fig-height: 6\n  #| fig-align: center\n  #| cache: true\n\ntibble(x = seq(0,1,length.out = 500),\n       prior = dbeta(x,5,3),\n       likelihood = dbeta2(x,mu = 0.2,phi = 10),\n       posterior_posterior = prior*likelihood) %>%\n  mutate(prior = prior/sum(prior),\n         likelihood = likelihood/sum(likelihood),\n         posterior_posterior = posterior_posterior/sum(posterior_posterior),\n         posterior_likelihood = likelihood,\n         posterior_prior = prior) %>%\n  plot_bayes()\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 1000 rows [1, 2, 3, 4, 5,\n6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...]."
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-52",
    "href": "presentaciones/presentacion_02.html#section-52",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "#| warning: false\n  #| echo: false\n  #| fig-width: 18\n  #| fig-height: 6\n  #| fig-align: center\n  #| cache: true\n\ntibble(x = seq(0,1,length.out = 500),\n            prior = dbeta(x,5,3),\n            likelihood = dbeta2(x,mu = 0.2,phi = 20),\n            posterior_posterior = prior*likelihood) %>%\n  mutate(prior = prior/sum(prior),\n         likelihood = likelihood/sum(likelihood),\n         posterior_posterior = posterior_posterior/sum(posterior_posterior),\n         posterior_likelihood = likelihood,\n         posterior_prior = prior) %>%\n  plot_bayes()\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 1000 rows [1, 2, 3, 4, 5,\n6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...]."
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-53",
    "href": "presentaciones/presentacion_02.html#section-53",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "#| warning: false\n  #| echo: false\n  #| fig-width: 18\n  #| fig-height: 6\n  #| fig-align: center\n  #| cache: true\n\ntibble(x = seq(0,1,length.out = 500),\n       prior = dbeta(x,5,3),\n       likelihood = dbeta2(x,mu = 0.2,phi = 30),\n       posterior_posterior = prior*likelihood) %>%\n  mutate(prior = prior/sum(prior),\n         likelihood = likelihood/sum(likelihood),\n         posterior_posterior = posterior_posterior/sum(posterior_posterior),\n         posterior_likelihood = likelihood,\n         posterior_prior = prior) %>%\n  plot_bayes()\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 1000 rows [1, 2, 3, 4, 5,\n6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...]."
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-54",
    "href": "presentaciones/presentacion_02.html#section-54",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "#| warning: false\n  #| echo: false\n  #| fig-width: 18\n  #| fig-height: 6\n  #| fig-align: center\n  #| cache: true\n\ntibble(x = seq(0,1,length.out = 500),\n       prior = dbeta(x,3,2),\n       likelihood = dbeta2(x,mu = 0.6,phi = 15)) %>%\n  mutate(prior = ifelse(x>0.5 & x<0.7,0,prior),\n         posterior_posterior = prior*likelihood) %>%\n  mutate(prior = prior/sum(prior),\n         likelihood = likelihood/sum(likelihood),\n         posterior_posterior = posterior_posterior/sum(posterior_posterior),\n         posterior_likelihood = likelihood,\n         posterior_prior = prior) %>%\n  plot_bayes()\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 1000 rows [1, 2, 3, 4, 5,\n6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...]."
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-55",
    "href": "presentaciones/presentacion_02.html#section-55",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "#| warning: false\n  #| echo: false\n  #| fig-width: 18\n  #| fig-height: 6\n  #| fig-align: center\n  #| cache: true\n\ntibble(x = seq(0,1,length.out = 500),\n       prior = dbeta(x,1,1),\n       likelihood = dbeta2(x,mu = 0.6,phi = 5)) %>%\n  mutate(prior = ifelse(x>0.5,0,prior),\n         posterior_posterior = prior*likelihood) %>%\n  mutate(prior = prior/sum(prior),\n         likelihood = likelihood/sum(likelihood),\n         posterior_posterior = posterior_posterior/sum(posterior_posterior),\n         posterior_likelihood = likelihood,\n         posterior_prior = prior) %>%\n  plot_bayes()\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 1000 rows [1, 2, 3, 4, 5,\n6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...]."
  },
  {
    "objectID": "presentaciones/presentacion_02.html#predicciones",
    "href": "presentaciones/presentacion_02.html#predicciones",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Predicciones",
    "text": "Predicciones\nDistribuciÃ³n predictiva a posteriori (tambiÃ©n distribuciÃ³n posterior predictiva) (en inglÃ©s posterior predictive distribution): queremos predecir un valor futuro de la variable de interÃ©s, \\(\\tilde{y}\\). MÃ¡s aÃºn, interesa la distribuciÃ³n de \\(\\tilde{y}\\) a posteriori, es decir, luego de observar los datos \\(y\\): \\(\\tilde{y}\\mid y\\)\n\\[\np(\\tilde{y}\\mid y) = \\int p(\\tilde{y}\\mid\\pi) p(\\pi\\mid y) d\\pi\n\\]"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-56",
    "href": "presentaciones/presentacion_02.html#section-56",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "\\(\\tilde{y}\\) tiene una distribuciÃ³n de probabilidad\nSi \\(\\pi\\) fuera fijo, la distribuciÃ³n de \\(\\tilde{y}\\) viene dada por \\(p(\\tilde{y}\\mid\\pi)\\) (la verosimilitud, aunque ahora es funciÃ³n de \\(\\tilde{y}\\))\nPero ahora hay incertidumbre en \\(\\pi\\) (tiene una distribuciÃ³n a posteriori), por lo tanto se hace una ponderaciÃ³n para los distintos valores de \\(\\pi\\) (\\(\\pi\\) varÃ­a en la integral anterior)\nCombinamos lo que no sabemos porque es aleatorio per se, con aquello que desconocemos (aunque podemos reducir nuestra incertidumbre recolectando mÃ¡s informaciÃ³n)"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-57",
    "href": "presentaciones/presentacion_02.html#section-57",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Para el caso binomial que venimos estudiando, consideramos una realizaciÃ³n mÃ¡s (tirar el globo terrÃ¡queo y agarrarlo). Â¿CuÃ¡l es la probabilidad de obtener \\(A\\) (agua)?\n\\[\n\\begin{align*}\nP(\\tilde{y} = 1\\mid y) & = \\int_0^1 \\pi \\vphantom{\\tilde{y}}p(\\pi\\mid x) d \\pi = \\mathbb{E}[{p(\\pi\\mid x)}] \\\\\n& = \\frac{y+a}{y+a+N-y+b} = \\frac{y+a}{N+a+b} \\\\\n\\end{align*}\n\\]"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-58",
    "href": "presentaciones/presentacion_02.html#section-58",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "muestras_pi <- rbeta(2000,a+y,b+N-y) # muestras del posterior\nx_new <- rbinom(2000,1,muestras_pi) # predicciones para cada valor de pi"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-59",
    "href": "presentaciones/presentacion_02.html#section-59",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Consideremos un caso particular:\n\nEn una bolsa hay bolitas negras y blancas, queremos saber cuÃ¡l es la probabilidad de sacar una bolita negra. A priori no sabemos nada. Sacamos (con reposiciÃ³n) tres veces una bolita. Las tres veces sale negra. Â¿CuÃ¡l es la probabilidad de que la prÃ³xima bolita sea negra?\n\n\\[p(\\tilde{y}=1\\mid y) = \\frac{y+1}{N+2}\\]"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-60",
    "href": "presentaciones/presentacion_02.html#section-60",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Los parÃ¡metros tienen una distribuciÃ³n de probabilidad. Incorporar la incertidumbre en el valor de \\(\\pi\\) nos permite no entusiasmarnos tanto con los datos, hacer predicciones mÃ¡s conservadoras con a pocos datos, regularizar.\n\n\n\nEstadÃ­stica Bayesiana â€“ 2023"
  },
  {
    "objectID": "presentaciones/presentacion_08.html",
    "href": "presentaciones/presentacion_08.html",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Consideremos el siguiente modelo: \\[\n\\begin{align*}\n    y\\mid\\pi & \\sim  \\mathrm{Bi}(N_i,\\pi)\\\\\n    \\pi & \\sim  Beta(a,b)\n\\end{align*}\n\\]\n\n\n\nSabemos (gracias al TP2) que la funciÃ³n de densidad de la distribuciÃ³n beta se puede expresar en tÃ©rminos de su moda \\(\\omega\\) y su concentraciÃ³n \\(\\kappa\\)\n\\[\n\\begin{align*}\n    y\\mid\\pi & \\sim  \\mathrm{Bi}(N,\\pi)\\\\\n    \\pi & \\sim  Beta(\\omega(\\kappa-2)+1,\\ (1-\\omega)(\\kappa-2)+1)\n\\end{align*}\n\\]\nEl valor de \\(\\pi\\) depende del valor de \\(\\omega\\). Lo sabÃ­amos, despuÃ©s de todo, \\(\\omega\\) y \\(\\kappa\\) son las constantes de ajuste del prior o hiperparÃ¡metros. \\(\\kappa\\) refleja el grado de credibilidad a priori sobre los valores de \\(\\pi\\) (alrededor de \\(\\omega\\)).\n\n\n\nÂ¿QuÃ© pasa si \\(\\omega\\) no es fijo sino otro parÃ¡metro a estimar?\n\nEn el contexto de una moneda: \\(\\pi\\) es la probabilidad de cara de la moneda y \\(\\omega\\) es el valor de probabilidad de cara al que el fabricante de monedas le apunta en la construcciÃ³n. \\(\\kappa\\) (fijo y conocido) es una medida de la dispersiÃ³n que tiene el proceso de fabricaciÃ³n (de lo consistente que es este proceso) o, en otros tÃ©rminos, mide el grado de asociaciÃ³n entre \\(\\pi\\) y \\(\\omega\\).\n\n\nÂ¿QuÃ© necesitamos para \\(\\omega\\)? Digamos que, a priori, \\(\\omega \\sim \\mathrm{Beta}(A_\\omega,B_\\omega)\\)\n\n\n\\[\n\\begin{align*}\n    y\\mid\\pi & \\sim  \\mathrm{Bi}(N,\\pi)\\\\\n    \\pi \\mid \\omega & \\sim  \\mathrm{Beta}(\\omega(\\kappa-2)+1,\\ (1-\\omega)(\\kappa-2)+1) \\\\\n    \\omega & \\sim \\mathrm{Beta}(A_\\omega,B_\\omega)\n\\end{align*}\n\\]\nÂ¿CuÃ¡ntos parÃ¡metros tiene este modelo?\n\n\n\n\nEs un modelo de dos parÃ¡metros (hay una distribuciÃ³n conjunta a priori y una distribuciÃ³n conjunta a posteriori) pero no como el \\(\\mu\\) y el \\(\\sigma\\) de una distribuciÃ³n normal o el \\(\\beta_0\\) y \\(\\beta_1\\) de un modelo de regresiÃ³n linealâ€¦\nÂ¿CÃ³mo funciona el modelo hacia adelante? \\(\\omega \\rightarrow \\pi \\rightarrow y\\) (\\(\\omega\\) influye en el valor de \\(y\\) solo a travÃ©s de \\(\\pi\\))\nÂ¿Y el razonamiento inverso? De \\(N\\) tiradas podemos hacer una inferencia sobre \\(\\pi\\), lo que nos permitirÃ¡ hacer una inferencia sobre \\(\\omega\\)\n\n\n\nÂ¿QuÃ© distribuciÃ³n a posteriori buscamos? \\(p(\\pi,\\omega\\mid y)\\)\nÂ¿Y la Regla de Bayes? Â¿Vale? Â¿CÃ³mo la escribimos?\n\\[p(\\pi,\\omega\\mid y) = \\frac{p(y\\mid\\pi,\\omega)p(\\pi,\\omega)}{p(y)} = \\frac{p(y\\mid\\pi)p(\\pi\\mid\\omega)p(\\omega)}{p(y)}\\]\nÂ¿Tenemos forma de expresar \\(p(y\\mid\\pi)\\), \\(p(\\pi\\mid\\omega)\\), y \\(p(\\omega)\\)?\n\n\n\nEstamos haciendo inferencia bayesiana sobre una distribuciÃ³n conjunta (de \\(\\pi\\) y \\(\\omega\\)). Pero la relaciÃ³n entre los parÃ¡metros (y la funciÃ³n de verosimilitud) es jerÃ¡rquica. La jerarquÃ­a tiene una interpretaciÃ³n para el modelo.\n\n\n\n\npi <- seq(0,1,length.out=101)\nomega <- seq(0,1,length.out=101)\nA_omega <- 2\nB_omega <- 2\nkappa <- 5\nN <- 9\ny <- 3\n\n\n\n\n\nprior <- expand.grid(pi = pi, omega = omega) |>\n  mutate(p_omega = dbeta(omega, A_omega, B_omega),\n         p_pi_given_omega = dbeta(pi, omega*(kappa-2)+1, (1-omega)*(kappa-2)+1),\n         prior = p_pi_given_omega * p_omega)\n\nplot_prior <- ggplot(prior) +\n  geom_raster(aes(x=pi, y=omega, fill=prior)) +\n  geom_hline(yintercept = 0.6) +\n  geom_hline(yintercept = 0.9) +\n  scale_x_continuous(expression(pi), expand = c(0,0)) +\n  scale_y_continuous(expression(omega), expand = c(0,0)) +\n  viridis::scale_fill_viridis()\n\nplot_prior_omega <- ggplot(prior) +\n  geom_line(aes(x=omega, y=p_omega))\n\nplot_prior_pi_omega1 <- ggplot(prior |> filter(omega == 0.6)) +\n  geom_line(aes(x=pi, y=prior)) +\n  xlab(expression(pi))\n\nplot_prior_pi_omega2 <- ggplot(prior |> filter(omega == 0.9)) +\n  geom_line(aes(x=pi, y=prior)) +\n  xlab(expression(pi))\n\n\n\n\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 8\n  #| fig-height: 8\n  #| fig-align: center\n\nplot_prior + (plot_prior_pi_omega1/plot_prior_pi_omega2)\n\n\n\n\n\n\n\n\nlikelihood <- expand.grid(pi = pi, omega = omega) |>\n  mutate(likelihood = dbinom(y, size = N, prob = pi))\n\nplot_likelihood <- ggplot(likelihood) +\n  geom_raster(aes(x=pi, y=omega, fill=likelihood)) +\n  scale_x_continuous(expression(pi), expand = c(0,0)) +\n  scale_y_continuous(expression(omega), expand = c(0,0)) +\n  viridis::scale_fill_viridis()\n\nposterior <- inner_join(prior,likelihood) |>\n  mutate(posterior = prior * likelihood)\n\nJoining with `by = join_by(pi, omega)`\n\nplot_posterior <- ggplot(posterior) +\n  geom_raster(aes(x=pi, y=omega, fill=posterior)) +\n  scale_x_continuous(expression(pi), expand = c(0,0)) +\n  scale_y_continuous(expression(omega), expand = c(0,0)) +\n  viridis::scale_fill_viridis()\n\n\n\n\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 8\n  #| fig-height: 8\n  #| fig-align: center\n\nplot_prior + plot_likelihood + plot_posterior\n\n\n\n\n\n\n\n\npi <- seq(0,1,length.out=101)\nomega <- seq(0,1,length.out=101)\nA_omega <- 20\nB_omega <- 20\nkappa <- 10\nN <- 9\ny <- 3\n\n\n\n\n\n\n\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 8\n  #| fig-height: 8\n  #| fig-align: center\n\nplot_prior + (plot_prior_pi_omega1/plot_prior_pi_omega2)\n\n\n\n\n\n\n\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 8\n  #| fig-height: 8\n  #| fig-align: center\n\nlikelihood <- expand.grid(pi = pi, omega = omega) |>\n  mutate(likelihood = dbinom(y, size = N, prob = pi))\n\nplot_likelihood <- ggplot(likelihood) +\n  geom_raster(aes(x=pi, y=omega, fill=likelihood)) +\n  scale_x_continuous(expression(pi), expand = c(0,0)) +\n  scale_y_continuous(expression(omega), expand = c(0,0)) +\n  viridis::scale_fill_viridis()\n\nposterior <- inner_join(prior,likelihood) |>\n  mutate(posterior = prior * likelihood)\n\nJoining with `by = join_by(pi, omega)`\n\nplot_posterior <- ggplot(posterior) +\n  geom_raster(aes(x=pi, y=omega, fill=posterior)) +\n  scale_x_continuous(expression(pi), expand = c(0,0)) +\n  scale_y_continuous(expression(omega), expand = c(0,0)) +\n  viridis::scale_fill_viridis()\n\nplot_prior + plot_likelihood + plot_posterior\n\n\n\n\n\n\n\nLa inferencia bayesiana en un modelo jerÃ¡rquico es inferencia en el espacio de la distribuciÃ³n conjunta de los parÃ¡metros pero reformulando la distribuciÃ³n conjunta en tÃ©rminos jerÃ¡rquicos: se refactoriza \\(p(\\pi,\\omega)\\) como \\(p(\\pi\\mid\\omega)p(\\omega)\\)\n\n\n\nÂ¿QuÃ© pasarÃ­a si contamos con mÃ¡s de una moneda creada por la misma fÃ¡brica? Cada moneda tiene un valor de \\(\\pi_s\\) que es propio y que a su vez tienen algo en comÃºn: provienen de la fÃ¡brica que tiene parÃ¡metro \\(\\omega\\).\nCon \\(y_1\\) caras en \\(N_1\\) tiradas de la moneda 1 estimamos \\(\\pi_1\\), con \\(y_2\\) caras en \\(N_2\\) tiradas de la moneda 1 estimamos \\(\\pi_2\\)â€¦ y luego, con todas las tiradas, podemos estimar \\(\\omega\\).\n\n\n\nConsideremos un caso real. \\(S\\) personas reciben una droga y son sometidos a un test de memoria. La probabilidad de que el sujeto \\(s\\) recuerde un Ã­tem que se le muestra es \\(\\pi_s\\). El sujeto \\(s\\) recuerda \\(y_s\\) Ã­tems de \\(N_s\\) que se le presentan. Asumimos que la droga induce un efecto en los sujetos alrededor de una tendencia central \\(\\omega\\).\nConsideremos por simplicidad que se tienen dos sujetosâ€¦\nÂ¿CuÃ¡ntos parÃ¡metros tiene el modelo? Â¿CÃ³mo podemos representar la relaciÃ³n entre los \\(\\theta_s\\)?\n\n\n\n\\[\n\\begin{align*}\n    y_s\\mid\\pi_s & \\sim  \\mathrm{Bi}(N_s,\\pi_s)\\\\\n    \\pi_s \\mid \\omega & \\sim  \\mathrm{Beta}(\\omega(\\kappa-2)+1,\\ (1-\\omega)(\\kappa-2)+1) \\\\\n    \\omega & \\sim \\mathrm{Beta}(A_\\omega,B_\\omega)\n\\end{align*}\n\\]\nSi fijo \\(\\omega\\), los valores de los \\(\\pi_s\\) son independientes: \\(\\pi_1\\) y \\(\\pi_2\\) son independientes dado \\(\\omega\\).\nLa probabilidad a priori que es \\(p(\\pi_1,\\pi_2,\\omega)\\) ahora puede factorizarse como \\(p(\\pi_1,\\pi_2\\mid \\omega) p(\\omega) = p(\\pi_1\\mid \\omega) p(\\pi_2\\mid \\omega) p(\\omega)\\)\n\n\n\n\npi_1 <- seq(0,1,length.out=101)\npi_2 <- seq(0,1,length.out=101)\nomega <- seq(0,1,length.out=101)\nA_omega <- 2\nB_omega <- 2\nkappa <- 5\nN_1 <- 20\ny_1 <- 5\nN_2 <- 8\ny_2 <- 4\n\n\n\n\n\nprior <- expand.grid(pi_1 = pi_1, pi_2 = pi_2, omega = omega) |>\n  mutate(\n    p_omega = dbeta(omega, A_omega, B_omega),\n    p_pi1_given_omega = dbeta(pi_1, \n                              omega*(kappa-2)+1, \n                              (1-omega)*(kappa-2)+1),\n    p_pi2_given_omega = dbeta(pi_2, \n                              omega*(kappa-2)+1, \n                              (1-omega)*(kappa-2)+1),\n    prior = p_pi1_given_omega *  p_pi2_given_omega * p_omega)\n\nprior_pi1 <- ggplot(prior |> \n                      group_by(pi_1,omega) |> \n                      summarise(prior = sum(prior))) +\n  geom_raster(aes(x=pi_1, y=omega, fill=prior)) +\n  scale_x_continuous(expression(pi[1]), expand = c(0,0)) +\n  scale_y_continuous(expression(omega), expand = c(0,0)) +\n  viridis::scale_fill_viridis()\n\n`summarise()` has grouped output by 'pi_1'. You can override using the\n`.groups` argument.\n\nprior_pi2 <- ggplot(prior |> \n                      group_by(pi_2,omega) |> \n                      summarise(prior = sum(prior))) +\n  geom_raster(aes(x=pi_2, y=omega, fill=prior)) +\n  scale_x_continuous(expression(pi[2]), expand = c(0,0)) +\n  scale_y_continuous(expression(omega), expand = c(0,0)) +\n  viridis::scale_fill_viridis()\n\n`summarise()` has grouped output by 'pi_2'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 8\n  #| fig-height: 8\n  #| fig-align: center\n\nprior_pi1 + prior_pi2\n\n\n\n\n\n\n\n\nlikelihood <- expand.grid(pi_1 = pi_1, pi_2 = pi_2, omega = omega) |>\n  mutate(likelihood_pi1 = dbinom(y_1, size = N_1, prob = pi_1),\n         likelihood_pi2 = dbinom(y_2, size = N_2, prob = pi_2),\n         likelihood = likelihood_pi1 * likelihood_pi2)\n\nlikelihood1 <- ggplot(likelihood |> \n                        group_by(pi_1,omega) |> \n                        summarise(likelihood = sum(likelihood))) +\n  geom_raster(aes(x=pi_1, y=omega, fill=likelihood)) +\n  scale_x_continuous(expression(pi[1]), expand = c(0,0)) +\n  scale_y_continuous(expression(omega), expand = c(0,0)) +\n  viridis::scale_fill_viridis()\n\n`summarise()` has grouped output by 'pi_1'. You can override using the\n`.groups` argument.\n\nlikelihood2 <- ggplot(likelihood |> \n                        group_by(pi_2,omega) |> \n                        summarise(likelihood = sum(likelihood))) +\n  geom_raster(aes(x=pi_2, y=omega, fill=likelihood)) +\n  scale_x_continuous(expression(pi[2]), expand = c(0,0)) +\n  scale_y_continuous(expression(omega), expand = c(0,0)) +\n  viridis::scale_fill_viridis()\n\n`summarise()` has grouped output by 'pi_2'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 8\n  #| fig-height: 8\n  #| fig-align: center\n\nlikelihood1 + likelihood2\n\n\n\n\n\n\n\n\nposterior <- inner_join(prior, likelihood) |>\n  mutate(posterior = prior * likelihood)\n\nJoining with `by = join_by(pi_1, pi_2, omega)`\n\nposterior_pi1 <- ggplot(posterior |> \n                          group_by(pi_1,omega) |> \n                          summarise(posterior = sum(posterior))) +\n  geom_raster(aes(x=pi_1, y=omega, fill=posterior)) +\n  scale_x_continuous(expression(pi[1]), expand = c(0,0)) +\n  scale_y_continuous(expression(omega), expand = c(0,0)) +\n  viridis::scale_fill_viridis()\n\n`summarise()` has grouped output by 'pi_1'. You can override using the\n`.groups` argument.\n\nposterior_pi2 <- ggplot(posterior |> \n                          group_by(pi_2,omega) |> \n                          summarise(posterior = sum(posterior))) +\n  geom_raster(aes(x=pi_2, y=omega, fill=posterior)) +\n  scale_x_continuous(expression(pi[2]), expand = c(0,0)) +\n  scale_y_continuous(expression(omega), expand = c(0,0)) +\n  viridis::scale_fill_viridis()\n\n`summarise()` has grouped output by 'pi_2'. You can override using the\n`.groups` argument.\n\nposterior_omega <- ggplot(posterior |> \n                            group_by(omega) |> \n                            summarise(posterior = sum(posterior))) +\n  geom_line(aes(x=omega, y=posterior)) +\n  xlab(expression(omega))\n\nposterior_pi1_marg <- ggplot(posterior |> \n                               group_by(pi_1) |> \n                               summarise(posterior = sum(posterior))) +\n  geom_line(aes(x=pi_1, y=posterior)) +\n  xlab(expression(pi[1]))\n\nposterior_pi2_marg <- ggplot(posterior |> \n                               group_by(pi_2) |> \n                               summarise(posterior = sum(posterior))) +\n  geom_line(aes(x=pi_2, y=posterior)) +\n  xlab(expression(pi[2]))\n\n\n\n\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 8\n  #| fig-height: 8\n  #| fig-align: center\nposterior_pi1 + posterior_pi2\n\n\n\n\n\n\n\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 8\n  #| fig-height: 8\n  #| fig-align: center\nposterior_omega / posterior_pi1_marg / posterior_pi2_marg\n\n\n\n\n\n\n\n\nLa funciÃ³n de verosimilitud no depende de \\(\\omega\\)\nLa funciÃ³n de verosimilitud es mÃ¡s estrecha para el sujeto 1 que para el sujeto 2\nEl posterior marginal de \\(\\pi_1\\) estÃ¡ cerca de la proporciÃ³n muestral\nEl posterior marginal de \\(\\pi_2\\) estÃ¡ cerca de la proporciÃ³n muestral\nEl posterior marginal de \\(\\pi_1\\) tiene menos incertidumbre que el de \\(\\pi_2\\)\n\n\nÂ¿QuÃ© ocurre si se cambia el valor de \\(\\kappa\\)?\n\n\n\n\n\npi_1 <- seq(0,1,length.out=101)\npi_2 <- seq(0,1,length.out=101)\nomega <- seq(0,1,length.out=101)\nA_omega <- 2\nB_omega <- 2\nkappa <- 100\nN_1 <- 20\ny_1 <- 5\nN_2 <- 8\ny_2 <- 4\n\n\n\n\n\n\n`summarise()` has grouped output by 'pi_1'. You can override using the\n`.groups` argument.\n`summarise()` has grouped output by 'pi_2'. You can override using the\n`.groups` argument.\n`summarise()` has grouped output by 'pi_1'. You can override using the\n`.groups` argument.\n`summarise()` has grouped output by 'pi_2'. You can override using the\n`.groups` argument.\nJoining with `by = join_by(pi_1, pi_2, omega)`\n`summarise()` has grouped output by 'pi_1'. You can override using the\n`.groups` argument.\n`summarise()` has grouped output by 'pi_2'. You can override using the\n`.groups` argument.\n\n\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 8\n  #| fig-height: 8\n  #| fig-align: center\n\nprior_pi1 + prior_pi2\n\n\n\n\n\n\n\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 8\n  #| fig-height: 8\n  #| fig-align: center\n\nlikelihood1 + likelihood2\n\n\n\n\n\n\n\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 8\n  #| fig-height: 8\n  #| fig-align: center\n\nposterior_pi1 + posterior_pi2\n\n\n\n\n\n\n\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 8\n  #| fig-height: 8\n  #| fig-align: center\n\nposterior_omega / posterior_pi1_marg / posterior_pi2_marg\n\n\n\n\n\n\n\nEl posterior marginal de \\(\\pi_2\\) se alejÃ³ de la proporciÃ³n muestral. El sujeto 1 tenÃ­a un tamaÃ±o de muestra mayor (mÃ¡s evidencia) y por lo tanto influyÃ³ mÃ¡s en la estimaciÃ³n de \\(\\omega\\), lo que a la vez influye en la estimaciÃ³n de \\(\\pi_2\\).\n\n\n\nLa estructura jerÃ¡rquica de los modelos hace que las estimaciones de los parÃ¡metros de los niveles mÃ¡s bajos se acerquen mÃ¡s de lo que lo harÃ­an si no hubiera una distribuciÃ³n en un nivel superior. Esto es lo que se conoce como shrinkage de las estimaciones.\nLas estimaciones de los parÃ¡metros de los niveles mÃ¡s bajos son tiradas (pulled) o se estrechan o tienden a concentrarse hacia la moda de la distribuciÃ³n superior.\n\n\n\nEl shrinkage ocurre porque los parÃ¡metros de los niveles bajos (los \\(\\pi_s\\)) son influenciados por:\n\n\nEl conjunto de datos que dependen directamente de ese parÃ¡metro\nLos parÃ¡metros de niveles mÃ¡s altos de los cuales dependen los parÃ¡metros de niveles mÃ¡s bajos (Â¡y que son afectados por todos los datos!)\n\n\n\nPor ejemplo, sobre \\(\\pi_1\\) influyen \\(y_1\\) y \\(N_1\\) pero tambiÃ©n \\(\\omega\\) (cuya estimaciÃ³n depende de \\(\\pi_2\\) y \\(N_2\\)).\n\n\nNota: el shrinkage es consecuencia exclusivamente de la estructura jerÃ¡rquica (y no de la inferencia bayesiana). Existe en la teorÃ­a clÃ¡sica de estimaciÃ³n (ver estimador de James-Stein)\n\n\n\n\n\n\n\n\nEl radÃ³n es un gas radioactivo y cancerÃ­geno. Los productos de la desintegraciÃ³n del radÃ³n son tambiÃ©n radioactivos y en altas concentraciones se sabe que producen cÃ¡ncer de pulmÃ³n. Trabajaremos con datos de mediciones de radÃ³n en el estado de Minnesota. Se cuenta con mediciones en hogares de diferentes condados dentro del estado.\n\n\n\n\n\\(i\\) es el Ã­ndice de los hogares\n\\(Y_i\\) es el nivel de radÃ³n (log radÃ³n) del hogar \\(i\\)\n\\(j\\) (entre \\(1\\) y \\(J\\)) es el Ã­ndice de los condados\n\\(j[i] = \\mathrm{county}[i]\\) es el condado al que pertenece el hogar \\(i\\)\n\n\n\n\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 8\n  #| fig-height: 8\n  #| fig-align: center\n\nradon <- read.csv(\"https://raw.githubusercontent.com/estadisticaunr/estadistica-bayesiana/main/datos/radon_data.csv\")\n\nggplot() +\n  geom_jitter(aes(x=log_radon, y=county, fill=county), \n              data=radon %>% \n                filter(county %in% c(\"LAC QUI PARLE\",\"AITKIN\",\"KOOCHICHING\",\"DOUGLAS\",\"CLAY\",\"STEARNS\",\"RAMSEY\",\"ST LOUIS\")), \n              width = 0,\n              height = 0.05,\n              alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\\[\n\\begin{align*}\n    Y_i\\mid\\mu_i,\\sigma & \\sim  \\mathcal{N}(\\mu_i,\\sigma^2) \\\\\n    \\mu_i & = \\alpha  \\\\\n    \\alpha & \\sim  P(\\alpha) \\\\\n    \\sigma & \\sim  P(\\sigma)\n\\end{align*}\n\\]\nHay una Ãºnica media \\(\\alpha\\) comÃºn para todos los \\(i\\), independientemente del grupo \\(j\\) al que pertenezcan\n\n\n\n\n\n\n\\[\n\\begin{align*}\n    Y_i\\mid\\mu_i,\\sigma & \\sim  \\mathcal{N}(\\mu_i,\\sigma^2)\\\\\n    \\mu_i & = \\alpha_{j[i]}  \\\\\n    \\alpha_j & \\sim  P(\\alpha_j) \\\\\n    \\sigma & \\sim  P(\\sigma)\n\\end{align*}\n\\]\nDecimos que los \\(Y_i\\) tienen distribuciÃ³n de media \\(\\alpha_{j[i]}\\), sin imponer ninguna restricciÃ³n sobre los \\(\\alpha_j\\). \\(P(\\alpha_j)\\) es una distribuciÃ³n no informativa (muy ancha y chata). Todos los \\(\\alpha_j\\) son independientes. Coincide con la estimaciÃ³n clÃ¡sica que incluye una variable dummy para cada grupo.\n\n\n\n\nPodemos mejorar el modelo anterior incorporando un prior que regularice los \\(\\alpha_j\\)\n\\[\\begin{align*}\n    Y_i\\mid\\mu_i,\\sigma & \\sim  \\mathcal{N}(\\mu_i,\\sigma^2) \\\\\n    \\mu_i & = \\alpha_{j[i]}  \\\\\n    \\alpha_j & \\sim  \\mathcal{N}(0,10) \\\\\n    \\sigma & \\sim  P(\\sigma)\n\\end{align*}\\]\n0 y 10 son valores arbitrarios para la media y la varianza de la distribuciÃ³n a priori de los \\(\\alpha_j\\). Los \\(\\alpha_j\\) dejan de poder ser estimados libremente. Hay regularizaciÃ³n y tendemos a evitar el overfitting. Hay un partial pooling. Si en lugar de 10 se elige un valor mÃ¡s grande, tendemos a no pooling; si se elige un valor mÃ¡s chico, tendemos a pooling completo\n\n\n\nMejor aÃºn, podemos estimar el grado de regularizaciÃ³n partir de los datos. Â¿CuÃ¡nto pooling es necesario? Se estima a partir de los datosâ€¦\n\\[\\begin{align*}\n    Y_i\\mid\\mu_i,\\sigma & \\sim  \\mathcal{N}(\\mu_i,\\sigma^2) \\\\\n    \\mu_i & = \\alpha_{j[i]}  \\\\\n    \\alpha_j & \\sim  \\mathcal{N}(\\mu_\\alpha,\\sigma_\\alpha^2) \\\\\n    \\sigma & \\sim  P(\\sigma) \\\\\n    \\mu_\\alpha & \\sim  P(\\mu_\\alpha) \\\\\n    \\sigma_\\alpha & \\sim  P(\\sigma_\\alpha) \\\\\n\\end{align*}\\]\n\n\n\n\\(\\mu_\\alpha\\) y \\(\\sigma_\\alpha\\) son hiperparÃ¡metros (parÃ¡metros de la distribuciÃ³n de a priori de los parÃ¡metros) y por lo tanto tienen hiperpriors\nEl chiste es que todos los datos se usan para estimar \\(\\mu_\\alpha\\) y \\(\\sigma_\\alpha\\) y por lo tanto en la estimaciÃ³n de cada \\(\\alpha_j\\) hay informaciÃ³n de todos los datos. La regularizaciÃ³n es adaptativa (se aprende de los datos).\n\n\n\n\nSiempre que hay regularizaciÃ³n, hay shrinkage de parÃ¡metros.\nLos datos de un grupo ayudan en la estimaciÃ³n de los parÃ¡metros de los otros grupos (partial pooling: prÃ©stamo de informaciÃ³n).\nAsÃ­, los grupos que tienen menor tamaÃ±o de muestra toman mÃ¡s informaciÃ³n del resto de los grupos y el shrinkage es mÃ¡s intenso.\n\n\n\n\n\nPooling completo: hay una Ãºnica media para todos los individuos, independientemente del grupo. La variaciÃ³n entre los grupos es cero. Underfitting.\nNo pooling: cada grupo tiene una media independiente de la de los demÃ¡s. La variaciÃ³n entre los grupos es infinita. No se comparte informaciÃ³n entre los grupos, lo que se sabe de un grupo no ayuda a inferir sobre los demÃ¡s. Overfitting.\nPartial pooling: cada grupo tiene una media pero todas las medias estÃ¡n conectadas. Es una soluciÃ³n de compromiso, un punto medio entre pooling completo y no pooling.\n\n\n\n\nPara algunos condados: a la izquierda estÃ¡ la estimaciÃ³n de la media no pooling de la media, a la derecha la estimaciÃ³n del modelo multinivel (pooling parcial). En lÃ­nea de trazos el pooling completo.\n\n\n\n\nCorredores que han participado varias veces de una famosa maratÃ³n en Washington. Se registraron los tiempos de los participantes.\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 8\n  #| fig-height: 8\n  #| fig-align: center\n\ncherry <- read.csv(\"https://raw.githubusercontent.com/estadisticaunr/estadistica-bayesiana/main/datos/cherry_blossom.csv\")\n\n\n  #| warning: false\n  #| echo: false\n  #| fig-width: 8\n  #| fig-height: 8\n  #| fig-align: center\n\ncherry %>%\n  ggplot(aes(x=runner, y=net)) +\n  geom_boxplot(aes(group=runner), fill=\"gray\", alpha=0.2) +\n  geom_jitter(width = 0.05, size=1.5)\n\nWarning: Removed 67 rows containing non-finite values (`stat_boxplot()`).\n\n\nWarning: Removed 67 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n# dv <- cherry %>%\n#   group_by(runner) %>%\n#   nest() %>%\n#   mutate(coefs = purrr::map_df(data, ~lm(net ~ age, data = .x)$coefficients)) %>%\n#   select(-data) %>%\n#   ungroup() %>%\n#   unnest_wider(coefs) %>%\n#   setNames(c(\"runner\",\"intercept\",\"slope\"))\n\nggplot() +\n  geom_jitter(data = cherry, aes(x=age, y=net),width=0.1) +\n  geom_smooth(data = cherry, \n              aes(x=age, y=net, group=runner), \n              method = \"lm\",\n              size = 0.6,\n              col = \"gray50\",\n              se=FALSE) +\n  geom_smooth(data = cherry, \n              aes(x=age, y=net), \n              method = \"lm\",\n              size = 1.2,\n              se=FALSE) +\n  xlim(c(50,61))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nâ„¹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 67 rows containing non-finite values (`stat_smooth()`).\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 67 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 67 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLa informaciÃ³n de la estimaciÃ³n de la pendiente de un grupo es Ãºtil para estimar las otras pendientes\nLa informaciÃ³n de la estimaciÃ³n de las ordenadas al origen de un grupo es Ãºtil para estimar las otras ordenadas al origen\nLas pendientes y las ordenadas al origen trabajan de forma conjunta para describir a un corredor, covarÃ­an\n\n\n\n\n\\[\\begin{align*}\n    Y_i  \\mid \\mu_i,\\sigma & \\sim  \\mathcal{N}(\\mu_i,\\sigma^2) \\\\\n    \\mu_i & = \\alpha_{j[i]} + \\beta_{j[i]} x_i \\\\\n    \\left[\\begin{array}{c}\\alpha_j\\\\\\beta_j\\end{array}\\right] & \\sim \\mathcal{N}\\left(\\left[\\begin{array}{c}\\mu_\\alpha\\\\\\mu_\\beta\\end{array}\\right],\\Sigma\\right)\n\\end{align*}\\]\n\n\n\n\\(\\left[\\begin{array}{c}\\alpha_j\\\\\\beta_j\\end{array}\\right]\\) tienen una distribuciÃ³n conjunta, normal multivariada de hiperparÃ¡metros \\(\\left[\\begin{array}{c}\\mu_\\alpha\\\\\\mu_\\beta\\end{array}\\right]\\) y \\(\\Sigma\\). Â¡Necesitan !\n\n\\(\\Sigma\\) puede factorizarse segÃºn: \n\\[\n\\Sigma = \\left( \\begin{array}{cc} \\sigma_\\alpha^2 & \\sigma_\\alpha\\sigma_\\beta\\rho \\\\ \\sigma_\\alpha\\sigma_\\beta\\rho & \\sigma_\\beta^2 \\end{array}\\right) =\n\\left( \\begin{array}{cc} \\sigma_\\alpha & 0 \\\\ 0 & \\sigma_\\beta \\end{array}\\right) \\left( \\begin{array}{cc} 1 & \\rho \\\\ \\rho & 1 \\end{array}\\right)\n\\left( \\begin{array}{cc} \\sigma_\\alpha & 0 \\\\ 0 & \\sigma_\\beta \\end{array}\\right)\n\\]\nLlamando \\[R = \\left( \\begin{array}{cc} 1 & \\rho \\\\ \\rho & 1 \\end{array}\\right)\\] solo habrÃ­a que definir una distribuciÃ³n para \\(\\sigma_\\alpha\\), \\(\\sigma_\\beta\\) y \\(R\\) (o \\(\\rho\\))\n\n\n\n\nNo es solo para modelos linealesâ€¦ Se tienen 60 tanques con ranitas de la especie Hyperolius viridiflavus. Cada tanque \\(i\\) de ellos contiene una cantidad inicial de renacuajos \\(N_i\\). Al cabo de unas semanas se observa el nÃºmero \\(S_i\\) de renacuajos que sobrevivieron en el tanque \\(i\\).\n\n\n\n\n\n\nSe modeliza la probabilidad de supervivencia de cada tanque con una regresiÃ³n logÃ­stica:\n\\[\\begin{align*}\n    S_i  \\mid p_i & \\sim  Binomial(N_i,p_i) \\\\\n   \\log\\left( \\frac{p_i}{1-p_i} \\right) & = \\alpha_{i} \\\\\n   \\alpha_i & \\sim \\mathcal{N}(\\mu_\\alpha,\\sigma_\\alpha^2)\n\\end{align*}\\]\nObservar que no hay grupos (no hay Ã­ndice \\(j\\)), simplemente hacemos de los individuos.\n\n\n\nComparamos la estimaciÃ³n de \\(p_i = \\frac{e^{\\alpha_i}}{1+e^{\\alpha_i}}\\) con la obtenida por mÃ¡xima verosimilitud en cada tanque: \\(p_{i,ML} = \\frac{S_i}{N_i}\\)\n\n\n\n\n\n\n\n\nSi no existe otra informaciÃ³n mÃ¡s que los datos observados \\(y_i\\) para distinguir a los individuos \\(i\\) y estos no pueden ordenarse ninguna manera entonces se puede asumir una simetrÃ­a de los parÃ¡metros. Se dice que los parÃ¡metros \\(\\theta_i\\) son intercambiables (exchangeable).\nSi las observaciones pueden agruparse y los grupos son indistinguibles (con caracterÃ­sticas propias desconocidas) con propiedades/particularidades ignoradas entonces los grupos son intercambiables y los individuos, parcialmente o condicionalmente intercambiables.\n\n\n\nEn los modelos jerÃ¡rquicos hay dos tipos de distribuciones predictivas a posteriori:\n\nPredicciones para individuos que pertenecen a grupos ya existentes (tiradas de la moneda con la que se realizaron las inferencias, otra tarea de memoria para un individuo que ya participÃ³ del experimento)\nPredicciones para individuos pertenecientes a grupos nuevos (tiradas de una nueva moneda de la fÃ¡brica, cÃ³mo afectarÃ­a la droga a un individuo nuevo)\n\n\n\n\n\nLos modelos jerÃ¡rquicos resultan atractivos para problemas en los cuales los parÃ¡metros se pueden considerar vinculados de cierta forma, por ejemplo en grupos.\nLos modelos jerÃ¡rquicos o multinivel son extensiones de los modelos lineales (y de los modelos lineales generalizados) para datos que tienen algÃºn grado de agrupamiento y en los cuales se permite que los parÃ¡metros varÃ­en por grupo\nLos modelos multinivel permiten mejorar las inferencias en contextos donde la muestra es pequeÃ±a. Si un individuo que tiene pocas observaciones pertenece a un determinado grupo, se supone que compartirÃ¡ caracterÃ­sticas con otros individuos de ese grupo y por lo tanto la estimaciÃ³n de sus parÃ¡metros podrÃ¡ ser informada por la de sus pares."
  },
  {
    "objectID": "presentaciones/presentacion_03.html#gamma-poisson",
    "href": "presentaciones/presentacion_03.html#gamma-poisson",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Gamma-Poisson",
    "text": "Gamma-Poisson\nSea una muestra \\(\\mathbf{y} = (y_1,y_2,\\dots,y_n)\\) obtenida de un modelo Poisson, es decir:\n\\[y_i \\sim \\mathrm{Poisson}(\\lambda)\\]\nInteresa realizar una inferencia sobre el valor de \\(\\lambda\\)\n\nÂ¿CÃ³mo asignamos una credibilidad a priori para \\(\\lambda\\)?"
  },
  {
    "objectID": "presentaciones/presentacion_03.html#section",
    "href": "presentaciones/presentacion_03.html#section",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "\\[\n\\lambda \\sim \\mathrm{Gamma}(r,s)\n\\]\n\\[\np(\\lambda \\mid r,s) = p(\\lambda) = \\frac{r^s}{\\Gamma(s)} \\lambda^{s-1}e^{-r\\lambda}\n\\]\n\n\n\n\n\n\nCuidado\n\n\n\\(\\mathrm{Gamma}(r,s)\\) en R es dgamma(x, shape = s, scale = 1/r)"
  },
  {
    "objectID": "presentaciones/presentacion_03.html#section-1",
    "href": "presentaciones/presentacion_03.html#section-1",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "El modelo propuesto es \\[\n\\begin{align*}\n    y_i \\mid \\lambda & \\sim  Po(\\lambda)\\\\\n    \\lambda & \\sim  \\mathrm{Gamma}(s, r)\n\\end{align*}\n\\]\nEl likelihood es Poisson: \\[p(y_i\\mid \\lambda) = \\frac{\\lambda^{y_i}e^{-\\lambda}}{y_i!} \\rightarrow p(\\mathbf{y}\\mid \\lambda) = \\prod_i \\frac{\\lambda^{y_i}e^{-\\lambda}}{y_i!} = \\frac{\\lambda^{\\sum_i y_i}e^{-n\\lambda}}{\\prod_{i}y_i!}\\]\nEl prior es Gamma: \\[p(\\lambda) = \\frac{r^s}{\\Gamma(s)} \\lambda^{s-1}e^{-r\\lambda}\\]\nInteresa hallar \\(p(\\lambda\\mid \\mathbf{y})\\)"
  },
  {
    "objectID": "presentaciones/presentacion_03.html#section-2",
    "href": "presentaciones/presentacion_03.html#section-2",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "\\[p(\\lambda\\mid \\mathbf{y}) \\propto p(\\mathbf{y}\\mid\\lambda) p(\\lambda)\\]\n\n\\[p(\\lambda \\mid \\mathbf{y}) \\propto \\frac{\\lambda^{\\sum_i y_i}e^{-n\\lambda}}{\\prod_{i}y_i!} \\frac{r^s}{\\Gamma(s)} \\lambda^{s-1}e^{-r\\lambda}\\] \\[p(\\lambda \\mid \\mathbf{y}) \\propto \\frac{r^s}{\\Gamma(s)\\prod_i y_i!} \\lambda^{\\sum_iy_i+s-1} e^{-n\\lambda - r \\lambda}\\]\n\n\n\\[p(\\lambda \\mid \\mathbf{y}) = K C \\lambda^{\\sum_iy_i+s-1} e^{-n\\lambda - r \\lambda}\\]\n\n\n\\[p(\\lambda \\mid \\mathbf{y}) = K^* \\lambda^{\\sum_iy_i+s-1} e^{-(n + r)\\lambda}\\]"
  },
  {
    "objectID": "presentaciones/presentacion_03.html#section-3",
    "href": "presentaciones/presentacion_03.html#section-3",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Para que \\(\\int_0^\\infty p(\\lambda\\mid \\mathbf{y})d \\lambda = 1\\), debe ser\n\n\\[K^* = \\frac{(n + r )^{\\sum_i y_i + s}}{\\Gamma(\\sum_i y_i + s)}\\]\n\n\nPor lo tanto, resulta que la distribuciÃ³n a posteriori es Gamma de parÃ¡metros \\(n+r\\) y \\(\\sum_i y_i + s\\)\n\n\n\\[\np(\\lambda\\mid \\mathbf{y}) = \\frac{(n + r )^{\\sum_i y_i + s}}{\\Gamma(\\sum_i y_i + s)} \\lambda^{\\sum_iy_i+s-1} e^{-(n + r)\\lambda}\n\\]\n\\[\n\\lambda\\mid \\mathbf{y} \\sim  \\mathrm{Gamma}(n+r,\\sum_i y_i + s)\n\\]"
  },
  {
    "objectID": "presentaciones/presentacion_03.html#normal-normal",
    "href": "presentaciones/presentacion_03.html#normal-normal",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Normal-normal",
    "text": "Normal-normal\nSea una muestra \\(\\mathbf{y} = (y_1,y_2,\\dots,y_n)\\) obtenida de un modelo normal con varianza conocida \\(\\sigma^2\\), es decir:\n\\[y_i \\sim \\mathcal{N}(\\mu,\\sigma^2)\\]\nInteresa realizar una inferencia sobre el valor de \\(\\mu\\)\n\nÂ¿CÃ³mo asignamos una credibilidad a priori para \\(\\mu\\)?"
  },
  {
    "objectID": "presentaciones/presentacion_03.html#section-4",
    "href": "presentaciones/presentacion_03.html#section-4",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "El modelo propuesto es \\[\n\\begin{align*}\n    y_i\\mid\\mu & \\sim  \\mathcal{N}(\\mu,\\sigma^2)\\\\\n    \\mu & \\sim \\mathcal{N}(\\theta,\\tau^2)\n\\end{align*}\n\\]\nEl likelihood es normal: \\[p(y_i\\mid \\mu) = \\frac{1}{\\sqrt{2\\pi\\sigma}} e^{-\\frac{(y_i-\\mu)^2}{2\\sigma^2}} \\rightarrow \\\\ p(\\mathbf{y}\\mid \\mu) = \\left(\\frac{1}{2\\pi\\sigma}\\right)^{n/2}  e^{-\\frac{\\sum_i(y_i-\\mu)^2}{2\\sigma^2}} \\propto e^{-\\frac{(\\bar{y}-\\mu)^2}{2\\sigma^2/n}}\\]\nEl prior es normal: \\[p(\\mu) = \\frac{1}{\\sqrt{2\\pi\\tau}} e^{-\\frac{(\\mu-\\theta)^2}{2\\tau^2}}\\]\nInteresa hallar \\(p(\\lambda\\mid \\mathbf{y})\\)"
  },
  {
    "objectID": "presentaciones/presentacion_03.html#section-5",
    "href": "presentaciones/presentacion_03.html#section-5",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "\\[p(\\mu\\mid \\mathbf{y}) \\propto p(\\mathbf{y}\\mid\\mu) p(\\mu)\\] \\[p(\\mu \\mid \\mathbf{y}) \\propto   e^{-\\frac{(\\bar{y}-\\mu)^2}{2\\sigma^2/n}} \\frac{1}{\\sqrt{2\\pi\\tau}} e^{-\\frac{(\\mu-\\theta)^2}{2\\tau^2}}\\]\n\\[\n\\begin{align*}\np(\\mu \\mid \\mathbf{y}) & \\propto  e^{-\\frac{(\\bar{y}-\\mu)^2}{2\\sigma^2/n}} e^{-\\frac{(\\mu-\\theta)^2}{2\\tau^2}} \\\\\n&  \\propto  e^{-\\left[\\frac{(\\bar{y}-\\mu)^2}{2\\sigma^2/n}+\\frac{(\\mu-\\theta)^2}{2\\tau^2}\\right]} \\\\\n& \\propto e^{-\\left[ \\frac{\\bar{y}^2 - 2\\bar{y} \\mu + \\mu^2}{2\\sigma^2/n} + \\frac{\\mu^2 - 2\\mu\\theta^2 + \\theta^2}{2\\tau^2} \\right]} \\\\\n& \\propto e^{\\left[ \\frac{ 2\\bar{y} \\mu - \\mu^2}{2\\sigma^2/n} + \\frac{-\\mu^2 + 2\\mu\\theta^2}{2\\tau^2} \\right]} \\\\\n& \\propto e^{\\left[ \\frac{(2\\bar{y} \\mu - \\mu^2)n\\tau^2 + (-\\mu^2 + 2\\mu\\theta^2)\\sigma^2}{2\\sigma^2\\tau^2} \\right]}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "presentaciones/presentacion_03.html#section-6",
    "href": "presentaciones/presentacion_03.html#section-6",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "\\[\n    \\begin{align*}\nP(\\mu \\mid \\mathbf{y}) & \\propto e^{\\frac{2\\mu(\\theta\\sigma^2+ \\bar{y}n\\tau^2)-\\mu^2(n\\tau^2+\\sigma^2)}{2\\tau^2\\sigma^2}} \\\\\n& \\propto e^{\\frac{-\\mu^2 + 2\\mu \\left( \\frac{\\theta\\sigma^2 + \\bar{y}n\\tau^2}{n\\tau^2 + \\sigma^2} \\right)}{2\\tau^2\\sigma^2/(n\\tau^2 + \\sigma^2)}} e^{-\\left(\\frac{\\theta\\sigma^2 + \\bar{y}n\\tau^2}{n\\tau^2 + \\sigma^2}\\right)^2} \\\\\n& \\propto e^{-\\frac{\\left(\\mu -  \\frac{\\theta\\sigma^2 + \\bar{y}n\\tau^2}{n\\tau^2 + \\sigma^2} \\right)^2}{2\\tau^2\\sigma^2/(n\\tau^2+\\sigma^2)}}\n    \\end{align*}\n\\] \\[p(\\mu\\mid\\mathbf{y}) = K^* e^{-\\frac{\\left(\\mu -  \\frac{\\theta\\sigma^2 + \\bar{y}n\\tau^2}{n\\tau^2 + \\sigma^2} \\right)^2}{2\\tau^2\\sigma^2/(n\\tau^2+\\sigma^2)}}\\]"
  },
  {
    "objectID": "presentaciones/presentacion_03.html#section-7",
    "href": "presentaciones/presentacion_03.html#section-7",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Por lo tanto, resulta que la distribuciÃ³n a posteriori es normal de parÃ¡metros \\(\\theta_n\\) y \\(\\tau_n^2\\)\n\n\\[\n\\begin{align*}\n\\mu\\mid \\mathbf{y} & \\sim  \\mathcal{N}\\left( \\frac{\\theta\\sigma^2 + \\bar{y}n\\tau^2}{n\\tau^2 + \\sigma^2},\\frac{\\tau^2\\sigma^2}{n\\tau^2+\\sigma^2} \\right) \\\\\n& \\sim \\mathcal{N}\\left( \\theta_n,\\tau_n^2 \\right)\n\\end{align*}\n\\]"
  },
  {
    "objectID": "presentaciones/presentacion_03.html#section-8",
    "href": "presentaciones/presentacion_03.html#section-8",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Reflexionemosâ€¦\n\\[\n\\begin{align*}\n    y_i\\mid\\mu & \\sim  \\mathcal{N}(\\mu,\\sigma^2) \\\\\n    \\mu & \\sim  \\mathcal{N}(\\theta,\\tau^2) \\\\\n    \\mu \\mid \\mathbf{y} & \\sim \\mathcal{N}(\\theta_n,\\tau_n^2)\n\\end{align*}\n\\]\nÂ¿ParÃ¡metros desconocidos en la verosimilitud? Â¿DimensiÃ³n y caracterÃ­stica del espacio de parÃ¡metros? Â¿Constantes de ajuste del prior? Â¿Forma del posterior? Â¿QuÃ© son \\(\\theta_n\\) y \\(\\tau_n^2\\)?"
  },
  {
    "objectID": "presentaciones/presentacion_03.html#section-10",
    "href": "presentaciones/presentacion_03.html#section-10",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Â¿Puedo representar los datos en el grÃ¡fico de la izquierda?\n\nNo, es el mundo de los parÃ¡metros\n\n\nÂ¿QuÃ© representan los valores marcados con \\(\\mathbf{\\times}\\)?\n\nPosibles valores de \\(\\mu\\) que podrÃ­an esperarse a priori.\n\n\n\nÂ¿Media y varianza de la normal de la izquierda?\n\n\\(\\theta\\) y \\(\\tau^2\\)\n\n\n\nÂ¿Media y varianza de las normales de la derecha?\n\n\\(\\mu\\) y \\(\\sigma^2\\)"
  },
  {
    "objectID": "presentaciones/presentacion_03.html#section-11",
    "href": "presentaciones/presentacion_03.html#section-11",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Â¿QuÃ© estamos viendo?"
  },
  {
    "objectID": "presentaciones/presentacion_03.html#section-12",
    "href": "presentaciones/presentacion_03.html#section-12",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "A posteriori (luego de observar los datos)â€¦ Â¿quÃ© ocurre con la plausibilidad de los valores de \\(\\mu\\)?"
  },
  {
    "objectID": "presentaciones/presentacion_03.html#section-13",
    "href": "presentaciones/presentacion_03.html#section-13",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Â¿Media y varianza de la normal de la izquierda?\n\n\\(\\theta_n\\) y \\(\\tau_n^2\\)\n\nÂ¿Media y varianza de las normales de la derecha?\n\n\\(\\mu\\) y \\(\\sigma^2\\)"
  },
  {
    "objectID": "presentaciones/presentacion_03.html#section-14",
    "href": "presentaciones/presentacion_03.html#section-14",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Compromiso\n\\[\\mathbb{E}[p(\\mu\\mid \\mathbf{y})] = \\theta_n = \\frac{\\theta\\sigma^2 + \\bar{y}n\\tau^2}{n\\tau^2 + \\sigma^2}\\] \\[\\mathbb{E}[p(\\mu\\mid \\mathbf{y})] =  \\theta\\frac{\\sigma^2}{n\\tau^2 + \\sigma^2} + \\bar{y}\\frac{n\\tau^2}{n\\tau^2 + \\sigma^2}\\]\n\nRepresenta un balance (promedio ponderado o ) entre la media muestral y la media esperada .\n\n\n\\[\\mathbb{V}[p(\\mu\\mid \\mathbf{y})] = \\tau_n^2 = \\frac{\\tau^2\\sigma^2}{n\\tau^2+\\sigma^2}\\]\n\\[\\mathbb{V}[p(\\mu\\mid \\mathbf{y})] = \\frac{1}{\\frac{n}{\\sigma^2}+\\frac{1}{\\tau^2}}\\] \\[\\frac{1}{\\mathbb{V}[p(\\mu\\mid \\mathbf{y})]} =  \\frac{n}{\\sigma^2} + \\frac{1}{\\tau^2}\\]\nLa precisiÃ³n a posteriori es la suma de las precisiones del prior y la muestra."
  },
  {
    "objectID": "presentaciones/presentacion_03.html#section-15",
    "href": "presentaciones/presentacion_03.html#section-15",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "DistribuciÃ³n predictiva a posteriori\n\\[p(\\tilde{y}\\mid \\mathbf{y}) = \\int p(\\tilde{y}\\mid \\mu) p(\\mu\\mid \\mathbf{y})d\\mu\\] El integrando es el producto de dos normales: una normal bivariada. Por lo tanto toda la integral es una distribuciÃ³n marginal de una normal: otra normal."
  },
  {
    "objectID": "presentaciones/presentacion_03.html#section-16",
    "href": "presentaciones/presentacion_03.html#section-16",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "DemostraciÃ³n poco formalâ€¦\nA posteriori vale \\[\n\\begin{array}{ccc}\ny & = & (y-\\mu) + \\mu \\\\\ny-\\mu \\mid \\mu & \\sim & \\mathcal{N}(0,\\sigma^2) \\\\\n\\mu \\mid \\mathbf{y} & \\sim & \\mathcal{N}(\\theta_n,\\tau_n^2)\n\\end{array}\n\\]\nResulta\n\\[p(\\tilde{y}\\mid \\mathbf{y}) = \\mathcal{N}(\\mu_n,\\sigma^2 + \\tau_n^2)\\]"
  },
  {
    "objectID": "presentaciones/presentacion_03.html#section-17",
    "href": "presentaciones/presentacion_03.html#section-17",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "La varianza predictiva \\(\\sigma^2 + \\tau_n^2\\) es una medida de la incertidumbre a posteriori respecto a una observaciÃ³n nueva \\(\\tilde{y}\\).\n\nLa incertidumbre en \\(\\tilde{y}\\) proviene de la variabilidad debida al azar (\\(\\sigma\\)) y de la variabilidad debida al desconocimiento de \\(\\mu\\) (\\(\\tau_n\\))\n\n\nEn otras palabras, si supiÃ©ramos que \\(\\mu = 2\\), toda la variabilidad provendrÃ­a de \\(\\sigma\\), Â¡pero no sabemos cuÃ¡nto vale \\(\\mu\\)! Puede ser \\(2\\) o \\(1,98\\) o \\(1.43\\)â€¦ Por lo que hay una componente adicional de varianza."
  },
  {
    "objectID": "presentaciones/presentacion_03.html#section-18",
    "href": "presentaciones/presentacion_03.html#section-18",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "No se entendiÃ³ nada. Simular para creer.\n\nÂ¿CÃ³mo obtenemos una observaciÃ³n nueva si sabemos que \\(\\mu = 2\\) (sabiendo que \\(\\sigma = 1,2\\))? . . . Directamente tomamos una muestra \\(\\tilde{y}\\) de \\(\\mathcal{N}\\left(\\mu=2,\\sigma^2= 1.2^2\\right)\\)\n\ny_new <- rnorm(1, mean = 2, sd = 1.2)\n\n\n\nPero en estadÃ­stica bayesiana \\(\\mu\\) tiene una distribuciÃ³n de probabilidad (por ejemplo \\(\\mathcal{N}\\left(\\theta_n=2,\\tau_n^2=1.8^2\\right)\\)), Â¿cÃ³mo hacemos la simulaciÃ³n?\n\n\n\nTomamos una muestra \\(\\mu^{(s)}\\) de la distribuciÃ³n de \\(\\mu\\)\nObtenemos \\(\\tilde{y}\\) a partir de \\(\\mathcal{N}(\\mu=\\mu^{(s)},\\sigma^2=1.2^2)\\)\n\n\n\n\nmu_s <- rnorm(1, mean = 2, sd = 1.8)\ny_new <- rnorm(1, mean = mu_s, sd = 1.2)\n\n\n\nÂ¿QuÃ© va a pasar en cada caso si construimos la distribuciÃ³n de \\(\\tilde{y}\\)?"
  },
  {
    "objectID": "presentaciones/presentacion_03.html#section-19",
    "href": "presentaciones/presentacion_03.html#section-19",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "La distribuciÃ³n predictiva contiene la variabilidad inherente al fenÃ³meno en estudio (\\(\\sigma\\)) y la incertidumbre en el parÃ¡metro \\(\\mu\\)."
  },
  {
    "objectID": "presentaciones/presentacion_03.html#normal-normal-gamma-inversa",
    "href": "presentaciones/presentacion_03.html#normal-normal-gamma-inversa",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Normal â€“ normal-gamma-inversa",
    "text": "Normal â€“ normal-gamma-inversa\nSea una muestra \\(\\mathbf{y} = (y_1,y_2,\\dots,y_n)\\) obtenida de un modelo normal con varianza desconocida \\(\\sigma^2\\), es decir:\n\\[y_i \\sim \\mathcal{N}(\\mu,\\sigma^2)\\]\nE interesa realizar una inferencia sobre el valor de \\(\\mu\\) y el valor de \\(\\sigma\\)\n\nÂ¿CÃ³mo asignamos una credibilidad a priori para \\(\\mu\\) y \\(\\sigma\\)? Â¡Con una distribuciÃ³n en dos dimensiones!"
  },
  {
    "objectID": "presentaciones/presentacion_03.html#section-20",
    "href": "presentaciones/presentacion_03.html#section-20",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "El modelo es\n\\[\n\\begin{align*}\n    X_i\\mid\\mu,\\sigma^2 & \\sim  \\mathcal{N}(\\mu,\\sigma^2) \\\\\n    \\mu,\\sigma^2 & \\sim  \\mathcal{N}GI(\\theta,\\tau,\\alpha,\\beta)\n\\end{align*}\n\\]\n\\(\\mu\\) y \\(\\sigma^2\\) tienen distribuciÃ³n conjunta normal-gamma-inversa:\n\\[(\\mu,\\sigma^2) = \\frac{\\sqrt{\\tau}}{\\sqrt{2\\pi\\sigma^2}} \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} \\left( \\frac{1}{\\sigma^2} \\right)^{\\alpha+1} e^{-\\frac{2\\beta + \\tau(\\mu-\\theta)^2}{2\\sigma^2}}\\]\nSi anticipamos que la normal-gamma-inversa es conjugada de la normal (para los parÃ¡metros \\(\\mu\\) y \\(\\sigma^2\\)), Â¿quÃ© podemos decir de la distribuciÃ³n a posteriori (conjunta) de \\(\\mu\\) y \\(\\sigma^2\\)"
  },
  {
    "objectID": "presentaciones/presentacion_03.html#section-21",
    "href": "presentaciones/presentacion_03.html#section-21",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Efectivamente, se puede probar que:\n\\[\n\\begin{align*}\n\\mu,\\sigma^2 \\mid \\mathbf{y} & \\sim  \\mathcal{N}GI(\\theta_n,\\tau_n,\\alpha_n,\\beta_n)\n\\end{align*}\n\\] con\n\\[\n\\begin{cases}\n\\theta_n = \\frac{\\tau\\theta + n \\bar{y}}{\\tau+n}\\\\\n\\tau_n = \\tau + n\\\\\n\\alpha_n = \\alpha + \\frac{n}{2}\\\\\n\\beta_n = \\beta + \\frac{1}{2} \\sum_i (y_i - \\bar{y})^2 + \\frac{n\\tau}{\\tau + n} \\frac{(\\bar{y}-\\theta)^2}{2}\n\\end{cases}\n\\]\nÂ¿ParÃ¡metros desconocidos en la verosimilitud? Â¿DimensiÃ³n del espacio de parÃ¡metros? Â¿Constantes de ajuste del prior? Â¿Forma del posterior?"
  },
  {
    "objectID": "presentaciones/presentacion_03.html#section-22",
    "href": "presentaciones/presentacion_03.html#section-22",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Reflexionemosâ€¦\n\\[\n\\begin{align*}\n    y_i\\mid\\mu & \\sim  \\mathcal{N}(\\mu,\\sigma^2) \\\\\n    \\mu & \\sim  \\mathcal{N}(\\theta,\\tau^2) \\\\\n    \\mu \\mid \\mathbf{y} & \\sim \\mathcal{N}(\\theta_n,\\tau_n^2)\n\\end{align*}\n\\]\nÂ¿ParÃ¡metros desconocidos en la verosimilitud? Â¿DimensiÃ³n y caracterÃ­stica del espacio de parÃ¡metros? Â¿Constantes de ajuste del prior? Â¿Forma del posterior? Â¿QuÃ© son \\(\\theta_n\\) y \\(\\tau_n^2\\)?"
  },
  {
    "objectID": "presentaciones/presentacion_03.html#section-24",
    "href": "presentaciones/presentacion_03.html#section-24",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Â¿Puedo representar los datos en el grÃ¡fico de la izquierda?\n\nNo, es el mundo de los parÃ¡metros\n\n\nÂ¿QuÃ© representan los valores marcados con \\(\\mathbf{\\times}\\)?\n\nPosibles valores de \\(\\mu\\) y \\(\\sigma^2\\) que podrÃ­an esperarse a priori.\n\n\n\nÂ¿QuÃ© le da forma a la distribuciÃ³n de la izquierda?\n\n\\(\\theta\\), \\(\\tau\\), \\(\\alpha\\) y \\(\\beta\\)\n\n\n\nÂ¿Media y varianza de las normales de la derecha?\n\n\\(\\mu\\) y \\(\\sigma^2\\)"
  },
  {
    "objectID": "presentaciones/presentacion_03.html#section-25",
    "href": "presentaciones/presentacion_03.html#section-25",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Â¿QuÃ© estamos viendo?"
  },
  {
    "objectID": "presentaciones/presentacion_03.html#section-26",
    "href": "presentaciones/presentacion_03.html#section-26",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "A posteriori (luego de observar los datos)â€¦ Â¿quÃ© ocurre con la plausibilidad de los valores de \\(\\mu\\) y \\(\\sigma^2\\)?"
  },
  {
    "objectID": "presentaciones/presentacion_03.html#section-27",
    "href": "presentaciones/presentacion_03.html#section-27",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Â¿ParÃ¡metros de la distribuciÃ³n de la izquierda?\n\n\\(\\theta_n\\), \\(\\tau_n\\), \\(\\alpha_n\\) y \\(\\beta_n\\)\n\n\nÂ¿Media y varianza de las normales de la derecha?\n\n\\(\\mu\\) y \\(\\sigma^2\\)\n\n\n\n\nEstadÃ­stica Bayesiana â€“ 2023"
  },
  {
    "objectID": "presentaciones/presentacion_04.html#section",
    "href": "presentaciones/presentacion_04.html#section",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Un meteorÃ³logo estima, con un 95% de confianza, que la probabilidad de que el huracÃ¡n no llegue a la ciudad estÃ¡ entre 99% y 100%. Muy feliz con su precisiÃ³n y su modelo, aconseja que la evacuaciÃ³n de la ciudad no es necesaria. Desafortunadamente, el huracÃ¡n llega a la ciudad produciendo una grave inundaciÃ³n.\n\n\nâ€œI would rather be vaguely right than very wrong.â€"
  },
  {
    "objectID": "presentaciones/presentacion_04.html#section-1",
    "href": "presentaciones/presentacion_04.html#section-1",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Con el clima, las personas tienden a notar un error mÃ¡s que otro. Cuando llueve sin estar anunciado, se tiende a insultar al servicio meteorolÃ³gico mientras que la ausencia de lluvia a pesar del pronÃ³stico se toma con buena cara.\n\n\n\nEl Weather Channel exagera ligeramente la probabilidad de lluvia cuando es poco probable que ocurra: dicen que es de 20% cuando en realidad es de 5% o 10%"
  },
  {
    "objectID": "presentaciones/presentacion_04.html#section-2",
    "href": "presentaciones/presentacion_04.html#section-2",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "En la estadÃ­stica bayesiana, la distribuciÃ³n a posteriori es la base de todas inferencia: combina el conocimiento a priori con la informaciÃ³n provista por los datos. Contiene todo lo que se sabe y no se sabe sobre un parÃ¡metro desconocido.\n\nLa respuesta a los problemas es toda la distribuciÃ³n a posteriori de los parÃ¡metros (y de otras cantidades de interÃ©s)."
  },
  {
    "objectID": "presentaciones/presentacion_04.html#section-3",
    "href": "presentaciones/presentacion_04.html#section-3",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "No obstante, puede ser de utilidad (o incluso necesario) tomar decisiones concretas o resumir la distribuciÃ³n a posteriori.\n\n\\(a\\) es la acciÃ³n que tomamos (intervenir o no intervenir quirÃºrgicamente a una persona) o la respuesta que damos (ganancia de una campaÃ±a de marketing).\n\n\nPuede ser una estimaciÃ³n puntual \\(\\hat{\\theta}\\): dada una inferencia sobre la ganancia de una campaÃ±a de marketing, es necesario informar un valor puntual (quizÃ¡s con un intervalo)"
  },
  {
    "objectID": "presentaciones/presentacion_04.html#section-4",
    "href": "presentaciones/presentacion_04.html#section-4",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Tratamos a los parÃ¡metros sobre los que realizamos inferencias como variables aleatorias. Una muestra de la distribuciÃ³n a posteriori es una posible realizaciÃ³n del verdadero valor del parÃ¡metro.\n\nAl dar una respuesta (o resumir la informaciÃ³n a posteriori), podemos incurrir en un error (grande o chico) segÃºn se den los eventos posibles.\n\n\nÂ¿QuÃ© es un error? Â¿CÃ³mo definimos si el error es grande o chico? Â¿CÃ³mo definimos si el error es relevante o no?"
  },
  {
    "objectID": "presentaciones/presentacion_04.html#funciones-de-pÃ©rdida",
    "href": "presentaciones/presentacion_04.html#funciones-de-pÃ©rdida",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Funciones de pÃ©rdida",
    "text": "Funciones de pÃ©rdida\n\\[L(\\theta,\\hat{\\theta}) = f(\\theta,\\hat{\\theta})\\] es una funciÃ³n de pÃ©rdida, quÃ© tanto pierdo por usar \\(\\hat{\\theta}\\) para estimar \\(\\theta\\)."
  },
  {
    "objectID": "presentaciones/presentacion_04.html#section-5",
    "href": "presentaciones/presentacion_04.html#section-5",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Por ejemplo:\n\\[L_2 = (\\theta - \\hat{\\theta})^2\\]\n\\[L_1 = |\\theta - \\hat{\\theta}|\\]\n\\[L_{0/1} =\n\\begin{cases}\n0 \\text{ si } \\hat{\\theta} = \\theta  \\\\\n1 \\text{ si } \\hat{\\theta} \\neq \\theta\n\\end{cases}\\]\n\\[L( \\theta, \\hat{\\theta} ) = \\begin{cases} ( \\theta -  \\hat{\\theta} )^2 & \\hat{\\theta} \\lt \\theta \\\\\\\\ c( \\theta -  \\hat{\\theta} )^2 & \\hat{\\theta} \\ge \\theta, \\;\\; 0\\lt c \\lt 1 \\end{cases}\\]"
  },
  {
    "objectID": "presentaciones/presentacion_04.html#section-6",
    "href": "presentaciones/presentacion_04.html#section-6",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Buscamos elegir \\(\\hat{\\theta}\\) de manera tal que minimice \\(L\\). El problema es que no conocemos \\(\\theta\\) y por lo tanto no podemos calcular \\(L(\\theta,\\hat{\\theta})\\).\n\nÂ¿Sabemos algo sobre \\(\\theta\\) que nos pueda ayudar? Conocemos su distribuciÃ³n a posteriori\n\n\nPodemos promediar \\(L\\) para los valores posibles de \\(\\theta\\) (ponderando segÃºn la distribuciÃ³n a posteriori)"
  },
  {
    "objectID": "presentaciones/presentacion_04.html#section-7",
    "href": "presentaciones/presentacion_04.html#section-7",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "El riesgo a posteriori (posterior risk o posterior expected loss) es la pÃ©rdida esperada ponderada por los valores de \\(\\theta\\) (y su distribuciÃ³n a posteriori).\n\n\\[R(\\hat{\\theta}) = \\mathbb{E}_{\\theta\\mid y}[L(\\theta,\\hat\\theta)] = \\int L(\\theta,\\hat\\theta) p(\\theta\\mid y) d\\theta\\]\n\n\nEs una funciÃ³n de los posibles valores que puede tomar \\(\\hat\\theta\\).\n\n\nPodemos obtener el \\(\\hat\\theta\\) que minimice \\(R(\\hat\\theta)\\). Es decir, buscamos un valor (un estimador) que minimice la pÃ©rdida esperada al usarlo para resumir \\(p(\\theta\\mid y)\\): \\[\\hat{\\theta} = \\underset{\\hat\\theta}{\\mathrm{arg\\,min}}\\left[ R(\\hat\\theta) \\right]\\]"
  },
  {
    "objectID": "presentaciones/presentacion_04.html#section-8",
    "href": "presentaciones/presentacion_04.html#section-8",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Simulemosâ€¦\n\nSupongamos que \\(\\theta\\mid y \\sim \\mathrm{Beta}(2,9)\\)\n\n\n\n\\(R\\) es una funciÃ³n de \\(\\hat\\theta\\) (los distintos valores que podemos usar para resumir \\(p(\\theta\\mid y)\\))\nPara distintos valores de \\(\\hat\\theta\\) voy a tomar muestras de \\(p(\\theta\\mid y)\\) y calcular la pÃ©rdida \\(L\\)\nPara cada valor de \\(\\hat\\theta\\) voy a calcular la pÃ©rdida promedio (ya va a estar ponderada por la probabilidad a posteriori de \\(\\theta\\))"
  },
  {
    "objectID": "presentaciones/presentacion_04.html#section-9",
    "href": "presentaciones/presentacion_04.html#section-9",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "L_2 <- function(theta,theta_hat) (theta-theta_hat)^2\n\nloss <- data.frame(theta_hat = double(),\n                   theta = double(),\n                   L = double())\n\nfor(theta_hat in seq(0,1,0.008)){\n  theta <- rbeta(2000, shape1 = 2, shape2 = 9)\n  L <- L_2(theta,theta_hat)\n  loss <- bind_rows(loss,data.frame(theta_hat,theta,L))\n}\n\nexpected.loss <- loss |>\n  group_by(theta_hat) |>\n  summarise(loss.mean = mean(L))"
  },
  {
    "objectID": "presentaciones/presentacion_04.html#section-11",
    "href": "presentaciones/presentacion_04.html#section-11",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Si deseamos resumir la distribuciÃ³n a posteriori con un Ãºnico valor (Â¡perdiendo informaciÃ³n!), puede usarse:\n\n\nLa media: minimiza la pÃ©rdida cuadrÃ¡tica esperada a posteriori\nLa mediana: minimiza la pÃ©rdida absoluta esperada a posteriori\nLa moda (tambiÃ©n llamado MAP por maximum a posteriori o estimador generalizado de mÃ¡xima verosimilitud): minimiza la pÃ©rdida \\(0/1\\) esperada a posteriori"
  },
  {
    "objectID": "presentaciones/presentacion_04.html#section-12",
    "href": "presentaciones/presentacion_04.html#section-12",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Una prueba mÃ¡s formal para el caso de la mediaâ€¦\n\nSea la pÃ©rdida cuadrÃ¡tica \\(L(\\theta,\\hat\\theta)=(\\theta-\\hat\\theta)^2\\), el riesgo (posterior expected loss) es:\n\n\n\\[\n\\mathbb{E}_{\\theta\\mid y}[L(\\theta,\\hat\\theta)] = \\mathbb{E}_{\\theta\\mid y}[\\theta^2] - 2 \\hat{\\theta}\\mathbb{E}_{\\theta\\mid y}[\\theta] + {\\hat{\\theta}}^2\n\\]\n\n\nderivando respecto a \\(\\hat{\\theta}\\) e igualando a cero se obtiene que \\(\\underset{\\hat\\theta}{\\mathrm{arg\\,min}}\\left[ R(\\hat\\theta) \\right] = \\mathbb{E}_{\\theta\\mid y}[\\theta] = \\mathbb{E}[p(\\theta\\mid y)]\\)"
  },
  {
    "objectID": "presentaciones/presentacion_04.html#section-13",
    "href": "presentaciones/presentacion_04.html#section-13",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Una prueba mÃ¡s formal para el caso de la medianaâ€¦\n\nSea la pÃ©rdida absoluta \\(L(\\theta,\\hat\\theta)=|\\theta-\\hat\\theta|\\), el riesgo (posterior expected loss) es:\n\n\n\\[\n\\mathbb{E}_{\\theta\\mid y}[L(\\theta,\\hat\\theta)] = \\int_{-\\infty}^\\infty |\\theta-\\hat\\theta| p(\\theta\\mid y)d\\theta\n\\]\n\n\n\\[\n\\int_{-\\infty}^\\hat{\\theta} (\\hat\\theta-\\theta) p(\\theta\\mid y)d\\theta + \\int_{\\hat{\\theta}}^\\hat{\\infty} (\\theta-\\hat\\theta) p(\\theta\\mid y)d\\theta\n\\]\n\n\nPara derivar, se utiliza la regla integral de Leibniz:\n\n\n\\[\\frac{d}{d\\hat\\theta}\\int_{-\\infty}^{\\hat\\theta} g(\\hat\\theta,\\theta)d\\theta = g(\\hat\\theta,\\hat\\theta) + \\int_{-\\infty}^\\hat\\theta \\frac{\\partial}{\\partial\\hat\\theta}g(\\hat\\theta,\\theta)d\\theta\\]\n\n\nSe puede probar que \\(\\int_{-\\infty}^\\hat\\theta p(\\theta\\mid y)d\\theta = \\frac{1}{2}\\), por lo que el \\(\\hat\\theta\\) que minimiza la expresiÃ³n es la mediana."
  },
  {
    "objectID": "presentaciones/presentacion_04.html#intervalos-de-credibilidad",
    "href": "presentaciones/presentacion_04.html#intervalos-de-credibilidad",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Intervalos de Credibilidad",
    "text": "Intervalos de Credibilidad\nTambiÃ©n llamados: intervalos de probabilidad, intervalo de confianza bayesiano, regiÃ³n de credibilidad. Es una regiÃ³n del dominio del parÃ¡metro que tiene alta probabilidad de contenerlo. Se utiliza para resumir el posterior.\n\nUn intervalo de credibilidad es una regiÃ³n \\(C\\) tal que la probabilidad de que contenga al parÃ¡metro sea al menos \\(1 - \\alpha\\):\n\n\n\\[p(\\theta \\in C \\mid y) = \\int_C p(\\theta\\mid y) d\\theta = 1-\\alpha\\] en el caso discreto es (\\(\\geq 1-\\alpha\\))\n\n\nDecimos: la probabilidad de que \\(\\theta\\) estÃ© contenido en \\(C\\), dados los datos (y el modelo) es de \\(1-\\alpha\\)"
  },
  {
    "objectID": "presentaciones/presentacion_04.html#section-15",
    "href": "presentaciones/presentacion_04.html#section-15",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "En el anÃ¡lisis de datos bayesiano, es habitual resumir los hallazgos reportando:\n\n\nUn grÃ¡fico de la distribuciÃ³n a posteriori\nAlgÃºn medida de centralidad de la distribuciÃ³n a posteriori\nPercentiles relevantes de la distribuciÃ³n a posteriori\nProbabilidades a posteriori de interÃ©s \\(p(\\theta>c\\mid y)\\) para algÃºn \\(c\\) interesante, por ejemplo \\(c=0\\)"
  },
  {
    "objectID": "presentaciones/presentacion_04.html#simulaciones",
    "href": "presentaciones/presentacion_04.html#simulaciones",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Simulaciones",
    "text": "Simulaciones\nPara interpretar los resultados de la inferencia bayesiana podemos simplemente realizar simulaciones a partir del posterior y estimar probabilidades contando.\n\n\nlos parÃ¡metros\nfunciones de los parÃ¡metros\nla variable respuesta (predicciones)"
  },
  {
    "objectID": "presentaciones/presentacion_04.html#section-16",
    "href": "presentaciones/presentacion_04.html#section-16",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Un nuevo ejemplo del modelo betaâ€“Binomial: partimos de \\(\\mathrm{Beta}(2,2)\\), observamos \\(4\\) caras en \\(6\\) tiradas y nuestra creencia a posteriori pasa a ser \\(Beta(6,4)\\)."
  },
  {
    "objectID": "presentaciones/presentacion_04.html#section-17",
    "href": "presentaciones/presentacion_04.html#section-17",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "ParÃ¡metros\nÂ¿CuÃ¡l es la probabilidad a posteriori de que \\(\\pi\\) sea mayor a \\(0.50\\)? Â¿y de que sea mayor a ?\n\nmuestras_pi <- rbeta(2000,6,4)\nmean(muestras_pi > 0.5)\nmean(muestras_pi > 0.8)"
  },
  {
    "objectID": "presentaciones/presentacion_04.html#section-18",
    "href": "presentaciones/presentacion_04.html#section-18",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Funciones de los parÃ¡metros\nÂ¿CuÃ¡l es la distribuciÃ³n a posteriori de la chance de obtener cara \\(\\frac{\\pi}{1-\\pi}\\)?\n\nmuestras_pi <- rbeta(2000,6,4)\nmuestras_odds <- muestras_pi/(1-muestras_pi)"
  },
  {
    "objectID": "presentaciones/presentacion_04.html#section-19",
    "href": "presentaciones/presentacion_04.html#section-19",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Predicciones\nSi se arroja la moneda 11 veces mÃ¡s Â¿cuÃ¡l es la distribuciÃ³n de probabilidad de la cantidad de caras? (es la distribuciÃ³n predictiva a posteriori)\n\nmuestras_pi <- rbeta(2000,6,4)\ny_new <- rbinom(2000,11,muestras_pi)"
  },
  {
    "objectID": "presentaciones/presentacion_04.html#section-20",
    "href": "presentaciones/presentacion_04.html#section-20",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Toda cantidad que dependa de los parÃ¡metros tiene una distribuciÃ³n a posteriori: una incertidumbre asociada.\n\n\n\nEstadÃ­stica Bayesiana â€“ 2023"
  },
  {
    "objectID": "presentaciones/presentacion_01.html#lÃ³gica-deductiva",
    "href": "presentaciones/presentacion_01.html#lÃ³gica-deductiva",
    "title": "EstadÃ­stica Bayesiana",
    "section": "LÃ³gica deductiva",
    "text": "LÃ³gica deductiva\n\\[A \\Rightarrow B\\] \\(A\\) es verdadero, por lo tanto \\(B\\) es verdadero\n\\(B\\) es falso, por lo tanto \\(A\\) falso\n\n\\(A\\): Tom es un gato\n\\(B\\): Tom es un animal\n\n\\(B\\) es verdadero, por lo tantoâ€¦"
  },
  {
    "objectID": "presentaciones/presentacion_01.html#section",
    "href": "presentaciones/presentacion_01.html#section",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Pero este no es el tipo de razonamiento que utilizamos en la vida cotidiana:\n\n\\(A\\): va a llover a las 10 de la maÃ±ana\n\\(B\\): se nubla antes de las 10 de la maÃ±ana\n\n\\(B\\) es verdadero, por lo tanto \\(A\\) se vuelve mÃ¡s plausible"
  },
  {
    "objectID": "presentaciones/presentacion_01.html#section-1",
    "href": "presentaciones/presentacion_01.html#section-1",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "En una noche oscura, un policÃ­a camina por una calle aparentemente desierta. De repente, se escucha la alarma de un local. Se da vuelta y ve, en la vereda de enfrente, una joyerÃ­a con la vidriera rota. Un hombre con una mÃ¡scara sale agachado a travÃ©s del vidrio roto, con una bolsa llena de joyas caras. El policÃ­a no duda en concluir que el hombre no tiene buenas intenciones.\n\nEl razonamiento del policÃ­a no fue una deducciÃ³n lÃ³gica, ya que podrÃ­a existir una explicaciÃ³n alternativa para lo ocurrido.\n\nDada la evidencia, no podemos decir con seguridad que las intenciones del hombre no son buenas, pero sÃ­ que es extremadamente plausible que no lo sean."
  },
  {
    "objectID": "presentaciones/presentacion_01.html#razonamiento-plausible",
    "href": "presentaciones/presentacion_01.html#razonamiento-plausible",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Razonamiento plausible",
    "text": "Razonamiento plausible\nEl cerebro humano permanentemente determina si algo se vuelve mÃ¡s o menos plausible. MÃ¡s aÃºn, de alguna manera, evalÃºa el grado de plausibilidad de una proposiciÃ³n.\n\n\nLa plausibilidad de que llueva a las 10 de la maÃ±ana depende fuertemente de la oscuridad de las nubes a las 9:45.\n\n\n\nEste razonamiento hace uso de nuestra experiencia previa. Combina informaciÃ³n a priori con evidencia disponible. Esto da lugar a un proceso secuencial."
  },
  {
    "objectID": "presentaciones/presentacion_01.html#apuestas",
    "href": "presentaciones/presentacion_01.html#apuestas",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Apuestas",
    "text": "Apuestas\n\n\n\nPÃ¡guese $1000 al portador de esta tarjeta si en este grupo hay alguien que tiene un loro como mascota\n\n\n\n\n\n\nPÃ¡guese $1000 al portador de esta tarjeta si en este grupo nadie tiene un loro como mascota\n\n\n\n\nTienen a su disposiciÃ³n estas tarjetas. Podemos comprarlas o venderlas. Al final de la clase develamos el misterio y, quien tenga la tarjeta, cobra.\n\n\nÂ¿Por cuÃ¡l pagarÃ­an mÃ¡s? Â¿CuÃ¡nto estarÃ­an dispuestos a pagar como mÃ¡ximo?\n\n\nNotar que el precio mÃ¡ximo que estarÃ­an dispuestos a pagar para comprarla es el precio mÃ­nimo por el que estarÃ­an dispuestos a venderla."
  },
  {
    "objectID": "presentaciones/presentacion_01.html#section-2",
    "href": "presentaciones/presentacion_01.html#section-2",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Todos pagarÃ­amos \\(p\\cdot\\$ 1000\\) con \\(0 \\leq p \\leq 1\\).\n\nDecidimos cuÃ¡nto apostar en funciÃ³n de nuestra incertidumbre en la ocurrencia de un evento (de lo plausible que lo consideremos). Decidimos apostar \\(p\\cdot\\$ 1000\\) en favor de un evento, porque le asignamos una plausibilidad o credibilidad de grado \\(p\\)."
  },
  {
    "objectID": "presentaciones/presentacion_01.html#section-3",
    "href": "presentaciones/presentacion_01.html#section-3",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "PÃ¡guese $1000 al portador de esta tarjeta si el profe tiene una remera negra\n\n\n\nÂ¿CuÃ¡nto estÃ¡n dispuestos a pagar para tener esta tarjeta? Â¿Por cuÃ¡nto venderÃ­an la tarjeta si la tuvieran?"
  },
  {
    "objectID": "presentaciones/presentacion_01.html#section-4",
    "href": "presentaciones/presentacion_01.html#section-4",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "PÃ¡guese $1000 al portador de esta tarjeta si esta materia es la mejor del cuatrimestre\n\n\n\n\n\n\nPÃ¡guese $1000 al portador de esta tarjeta si esta materia no es la mejor del cuatrimestre\n\n\n\n\nPor la primera pagarÃ­an como mÃ¡ximo \\(p\\cdot\\$ 1000\\) y por la segunda, \\(q\\cdot\\$ 1000\\). Es necesario que \\(p+q=1\\). Â¿Por quÃ©?"
  },
  {
    "objectID": "presentaciones/presentacion_01.html#dutch-book",
    "href": "presentaciones/presentacion_01.html#dutch-book",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Dutch book",
    "text": "Dutch book\nSupongamos que \\(p=0.7\\) y \\(q=0.5\\). Eso significa que:\n\nSi no tienen las tarjetas, estarÃ­an dispuestos a comprar ambas por \\(\\$1200\\).\n\nSupongamos que \\(p=0.3\\) y \\(q=0.2\\). Eso significa que:\n\nSi tienen las tarjetas, estarÃ­an dispuestos a vender ambas por \\(\\$500\\).\n\n\nSabemos que a fin de cuatrimestre, quien tenga las dos tarjetas ganarÃ¡ \\(\\$1000\\)â€¦\n\nThe canonical way to measure degrees of belief appeals to the notion of fair odds.\nThe degree of belief that a given epistemic agentâ€”letâ€™s say itâ€™s youâ€”has in this proposition A can be determined by what you deem to be the fair price of this lottery. Here the â€œfair priceâ€ is the price at which you are willing to either buy or sell the lottery ticket."
  },
  {
    "objectID": "presentaciones/presentacion_01.html#dutch-book-1",
    "href": "presentaciones/presentacion_01.html#dutch-book-1",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Dutch book",
    "text": "Dutch book\n\n\n\nDutch book\n\n\nUn Dutch book es un conjunto de apuestas que aseguran una pÃ©rdida. El argumento del Dutch book dice que una persona que tiene creencias inconsistentes actÃºa irracionalmente y puede ser llevado a una pÃ©rdida segura en un juego de apuestas\n\n\n\n\nLos grados de plausibilidad o grados de creencia que una persona le asigna a un conjunto de eventos deben respetar los axiomas de probabilidad.\n\n\nSe puede asignar un valor de probabilidad a cualquier proposiciÃ³n."
  },
  {
    "objectID": "presentaciones/presentacion_01.html#section-5",
    "href": "presentaciones/presentacion_01.html#section-5",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Las probabilidades son la mejor herramienta disponible para cuantificar la incertidumbre y las leyes de la probabilidad, la mejor herramienta para operar con ella."
  },
  {
    "objectID": "presentaciones/presentacion_01.html#probabilidad-1",
    "href": "presentaciones/presentacion_01.html#probabilidad-1",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Probabilidad",
    "text": "Probabilidad\nTres ideas de probabilidad\n\nClÃ¡sica: si \\(n\\) eventos son equiprobables, la probabilidad de uno de ellos es \\(1/n\\). AdemÃ¡s, la probabilidad de un evento se puede calcular como el nÃºmero de casos favorables dividido el nÃºmero de casos posibles.\nFrecuentista: la probabilidad de un evento se puede estimar observando su frecuencia relativa sobre un gran nÃºmero de realizaciones o ensayos.\nSubjetiva: las probabilidades reflejan el grado de creencia o plausibilidad que una persona le asigna a un evento."
  },
  {
    "objectID": "presentaciones/presentacion_01.html#probabilidad-subjetiva",
    "href": "presentaciones/presentacion_01.html#probabilidad-subjetiva",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Probabilidad subjetiva",
    "text": "Probabilidad subjetiva\n\nEs la forma mÃ¡s general de interpretar la probabilidad (eventos no equiprobables y eventos que no pueden repetirse)\nSe utiliza para cuantificar la incertidumbre o ignorancia (o certidumbre o conocimiento) acerca de un evento o proposiciÃ³n\nEs personal\nDepende del estado actual de conocimiento del mundo\n\n\nTodos los mÃ©todos estadÃ­sticos son subjetivos en el sentido que se basan en idealizaciones matemÃ¡ticas de la realidad (modelos)."
  },
  {
    "objectID": "presentaciones/presentacion_01.html#incertidumbre",
    "href": "presentaciones/presentacion_01.html#incertidumbre",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Incertidumbre",
    "text": "Incertidumbre\nDistinguimos dos tipos de incertidumbre:\n\n\nIncertidumbre epistÃ©mica\nIncertidumbre aleatoria\n\n\n\nLo retomaremos a lo largo del curso."
  },
  {
    "objectID": "presentaciones/presentacion_01.html#elicitaciÃ³n-de-probabilidades",
    "href": "presentaciones/presentacion_01.html#elicitaciÃ³n-de-probabilidades",
    "title": "EstadÃ­stica Bayesiana",
    "section": "ElicitaciÃ³n de probabilidades",
    "text": "ElicitaciÃ³n de probabilidades\nConsideremos la siguiente proposiciÃ³n:\n\nVoy a aprobar todas las materias de este cuatrimestre (\\(W\\))\n\n\nUna caja con 5 bolas azules y 5 bolas rojas. Se extrae una bola al azar. \\(A\\) es el evento extraer una bola azul\n\n\n\n\\(A_1\\): $1000 si \\(W\\)\n\\(A_2\\): $1000 si \\(A\\)\n\n\n\nSi prefieren \\(A_1\\) entoncesâ€¦ 8 bolas azules y 2 bolas rojas. Se extrae una bola al azar. \\(A\\) es el evento extraer una bola azul.\n\n\n\n\\(A_3\\): $1000 si \\(W\\)\n\\(A_4\\): $1000 si \\(A\\)"
  },
  {
    "objectID": "presentaciones/presentacion_01.html#section-6",
    "href": "presentaciones/presentacion_01.html#section-6",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Interludioâ€¦\n\nÂ¿QuÃ© es mÃ¡s probable?\n\nQue el PSG le gane al Lyon\nQue el PSG le gane al Lyon y Messi haga un gol"
  },
  {
    "objectID": "presentaciones/presentacion_01.html#sesgos",
    "href": "presentaciones/presentacion_01.html#sesgos",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Sesgos",
    "text": "Sesgos\nLos seres humanos no estamos optimizados para operar con probabilidades (al menos no intuitivamente)."
  },
  {
    "objectID": "presentaciones/presentacion_05.html#el-problema",
    "href": "presentaciones/presentacion_05.html#el-problema",
    "title": "EstadÃ­stica Bayesiana",
    "section": "El Problema",
    "text": "El Problema\nTÃ­picamente interesa resolver los siguientes problemas:\n\n\nCalcular integrales de la forma \\(\\mathbb{E}[\\phi(x)] = \\int \\phi(x) p(x) d x\\) (law of the unconscious statistician)\nGenerar \\(S\\) muestras independientes \\(x^{(s)}\\) de una distribuciÃ³n de probabilidad \\(p(x)\\)\n\n\n\nEn la estadÃ­stica bayesiana, \\(x\\) es \\(\\theta\\), el parÃ¡metro desconocido de alguna distribuciÃ³n de probabilidad y \\(p(x)\\) es el posterior"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#mÃ©todos-de-montecarlo",
    "href": "presentaciones/presentacion_05.html#mÃ©todos-de-montecarlo",
    "title": "EstadÃ­stica Bayesiana",
    "section": "MÃ©todos de Montecarlo",
    "text": "MÃ©todos de Montecarlo"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section",
    "href": "presentaciones/presentacion_05.html#section",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Para el primer problema, sabemos que si \\(X_i \\sim p(x)\\), bajo ciertas condiciones podemos aproximar\n\n\\[\\mathbb{E}[X] \\approx \\frac{1}{N} \\sum_{i=1}^N x_i\\]\n\n\nSi \\(X\\) es una variable aleatoria, entonces para funciones continuas \\(\\phi\\) tenemos que \\(\\phi(X)\\) tambiÃ©n es una variable aleatoria y por lo tanto\n\n\n\\[\\mathbb{E}[\\phi(X)] = \\int\\phi(x)p(x)dx \\approx \\frac{1}{N} \\sum_{i=1}^N \\phi(x_i)\\]\n\n\nEs decir, si los \\(x_i\\) son muestras de \\(p(x)\\), entonces la integral \\(\\int\\phi(x)p(x)dx\\) puede aproximarse por \\(\\frac{1}{N} \\sum_{i=1}^N \\phi(x_i)\\)."
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-1",
    "href": "presentaciones/presentacion_05.html#section-1",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Esto ya lo hemos hecho\n\n\nLa distribuciÃ³n predictiva a posteriori es \\(\\int p(y\\mid \\theta) p(\\theta\\mid y) d\\theta\\) y puede aproximarse por \\(\\frac{1}{N} \\sum_{i=1}^N p(y\\mid \\theta_i)\\)\nEl riesgo bayesiano es \\(\\int L(\\theta,\\hat\\theta) p(\\theta\\mid y) d\\theta\\) y puede aproximarse por \\(\\frac{1}{N} \\sum_{i=1}^N L(\\theta_i,\\hat\\theta)\\)\nSi consideramos la integral \\(\\int \\mathbb{I}_{\\theta \\in A} p(\\theta\\mid y) d\\theta = \\int_A p(\\theta\\mid y)d\\theta\\) es la probabilidad de que \\(\\theta\\) estÃ© en \\(A\\) y puede aproximarse por \\(\\frac{1}{N} \\sum_{i=1}^N \\mathbb{I}_{\\theta_i \\in A}\\)"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-2",
    "href": "presentaciones/presentacion_05.html#section-2",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Teniendo muestras de \\(p(x)\\) es fÃ¡cil estimar las integrales \\(\\mathbb{E}[\\phi(x)] = \\int \\phi(x) p(x) d x\\) por lo que nos centraremos en el problema de cÃ³mo obtener muestras de \\(p(x)\\).\n\nPara algunas distribuciones de probabilidad es fÃ¡cil obtener muestras. Pero no siempre existe una funciÃ³n rbinom, rbeta, rnorm, rpoiss, etc."
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-3",
    "href": "presentaciones/presentacion_05.html#section-3",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Tomar muestras de una distribuciÃ³n de probabilidad \\(p(x)\\) implica obtener valores que provienen, con mayor frecuencia, de regiones donde \\(p(x)\\) es grande. Â¿Por quÃ© es difÃ­cil tomar muestras de una distribuciÃ³n de probabilidad?\n\nEn estadÃ­stica bayesiana tenemos \\(p(\\theta \\mid y ) \\propto p(y\\mid\\theta) p(\\theta)\\) por lo que en general llegamos a \\(p^*(\\theta \\mid y) = \\frac{1}{Z} p(\\theta\\mid y)\\)\n\n\n\nLa determinaciÃ³n de \\(Z\\) implica resolver una integral (potencialmente multivariada) que puede no tener soluciÃ³n analÃ­tica (intractability of the integral)\nAÃºn conociendo \\(Z\\), no hay una manera determinada de obtener muestras de \\(p(\\theta\\mid y)\\)\nTomar muestras de distribuciones discretas es mÃ¡s fÃ¡cil que hacerlo de distribuciones continuas"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-4",
    "href": "presentaciones/presentacion_05.html#section-4",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Â¿CÃ³mo tomamos muestras de una distribuciÃ³n discreta?"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#grid-approximation",
    "href": "presentaciones/presentacion_05.html#grid-approximation",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Grid approximation",
    "text": "Grid approximation\nUna soluciÃ³n puede ser discretizar la variable. Esta soluciÃ³n vale incluso si no conocemos \\(Z\\). Conocemos \\(p^*(x) = \\frac{1}{Z} p(x)\\) (izquierda) y pasamos a una discreta \\(\\tilde{p}^*(x) = \\frac{1}{\\tilde{Z}} \\tilde{p}(x)\\) (centro).\n\nEvaluando \\(\\tilde{p}\\) en todos los posibles \\(x_i\\) de la grilla podemos calcular \\(Z=\\sum_{i} \\tilde{p}^*(x_i)\\). Luego tomamos muestras de \\(\\tilde{p}(x)\\) (derecha)."
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-5",
    "href": "presentaciones/presentacion_05.html#section-5",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "En cÃ³digo:\n\nprob <- function(x) return(exp(0.4*(x-0.4)^2 - 0.08*x^4)) # sabemos evaluar p\nx <- seq(-4.5, 4.5, 0.5)\np_ <- prob(x) # ~p*\nZ <- sum(p_)\np_rulito <- p_/Z # ~p\nsample(x, replace = TRUE, prob = p_rulito)"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-6",
    "href": "presentaciones/presentacion_05.html#section-6",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Â¿CÃ³mo se aplica esto en estadÃ­stica bayesiana?\n\nEl posterior es \\(\\frac{1}{Z} p(\\theta\\mid y) p(\\theta)\\). Sabemos calcular el valor del posterior (sin normalizar) para cualquier valor de \\(\\theta\\): haciendo el producto del prior por el likelihood.\n\n\nPodemos considerar una grilla de valores del parÃ¡metro (o los parÃ¡metros), computar el posterior sin normalizar para cada valor de la grilla, normalizarlo y tomar muestras de Ã©l.\n\n\nEscala muy mal con el nÃºmero de parÃ¡metrosâ€¦"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-7",
    "href": "presentaciones/presentacion_05.html#section-7",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Ejemplo\n\n\n\nQueremos realizar inferencias sobre la media y la varianza de una normal. Para eso proponemos el siguiente modelo: \\[    \n\\begin{align*}\n    y_i\\mid\\mu,\\sigma^2 & \\sim  \\mathcal{N}(\\mu,\\sigma^2) \\\\\n    \\mu,\\sigma^2 & \\sim  \\frac{1}{K} \\frac{e^{-\\sigma^2}}{\\eta} e^{-\\frac{(\\mu - \\xi)^2}{2\\psi^2}}\n\\end{align*}\n\\] (Â¿CuÃ¡les son las constantes que ajustan el prior)"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-8",
    "href": "presentaciones/presentacion_05.html#section-8",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "DeberÃ­amos tomar valores de \\(\\mu\\) en el intervalo \\((-4,4)\\) y valores de \\(\\sigma\\) en el intervalo \\((0,3)\\) y construir una grilla de valores.\nPara cada valor de la grilla podrÃ­amos calular el posterior sin normalizar haciendo el producto del prior por el likelihood (necesitamos la muestra)."
  },
  {
    "objectID": "presentaciones/presentacion_05.html#rejection-sampling",
    "href": "presentaciones/presentacion_05.html#rejection-sampling",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Rejection sampling",
    "text": "Rejection sampling\nSe basa en buscar una distribuciÃ³n de probabilidad candidata \\(q(x)\\) tal que \\(Cq(x)\\geq p^*(x)\\). Se toma una muestra de \\(q(x)\\). Luego se toma una muestra \\(u\\) de \\(\\mathrm{Unif}(0,Cq(x))\\). La muestra de \\(q(x)\\) se retiene si \\(u<p^*(x)\\)."
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-9",
    "href": "presentaciones/presentacion_05.html#section-9",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Necesitamos elegir con cuidado \\(q(x)\\)"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#markov-chain-monte-carlo",
    "href": "presentaciones/presentacion_05.html#markov-chain-monte-carlo",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Markov chain Monte-Carlo",
    "text": "Markov chain Monte-Carlo\nQueremos obtener muestras de \\(p(x)\\). Vamos a hacer un viaje por los distintos valores de \\(x\\) tratando de pasar mÃ¡s tiempo (mÃ¡s iteraciones) en los puntos donde \\(p(x)\\) es grande.\n\nIdea general:\n\nVisitar los distintos valores posibles de \\(x\\)\nGenerar una secuencia de iteraciones: \\(\\{x^{(1)},x^{(2)},\\dots,x^{(S)}\\}\\)\nEn general, para obtener \\(x^{(i+1)}\\) usamos \\(x^{(i)}\\)\n\n\nEn nuestro caso tenemos \\(p(\\theta) \\propto p(y\\mid\\theta)p(\\theta) = p^*(\\theta\\mid y)\\) (unnormalized posterior)\nÂ¿QuÃ© necesitamos? Poder evaluar el prior y poder evaluar el likelihood para cualquier valor de \\(\\theta\\)"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#metropolis-hastings-mh",
    "href": "presentaciones/presentacion_05.html#metropolis-hastings-mh",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Metropolis-Hastings (MH)",
    "text": "Metropolis-Hastings (MH)\nEl algoritmo de Metropolisâ€“Hastings (1953)\n\nEstamos la iteraciÃ³n \\(i\\) estamos en el valor del parÃ¡metro \\(\\theta^{(i)}\\)\nEn funciÃ³n del valor de parÃ¡metro actual \\(\\theta^{(i)}=\\theta\\), proponemos un nuevo valor \\(\\theta'\\) en funciÃ³n de \\(q(\\theta'\\mid\\theta)\\)\nDecidimos si vamos a la nueva ubicaciÃ³n \\(\\theta^{(i+1)} = \\theta'\\) o si nos quedamos \\(\\theta^{(i+1)} = \\theta\\):\n\nCalcular la probabilidad de salto: \\[\\alpha = \\min\\left\\{ 1,\\frac{f(\\theta')}{f(\\theta)} \\right\\}\\]\nPasar a \\(\\theta'\\) con probabilidad \\(\\alpha\\): \\[\\theta^{(i+1)} =\n\\begin{cases}\n\\theta' \\text{ con probabilidad } \\alpha \\\\\n\\theta \\text{ con probabilidad } (1-\\alpha)\n\\end{cases}\\]"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-10",
    "href": "presentaciones/presentacion_05.html#section-10",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "\\(q(\\theta'\\mid\\theta)\\) se llama distribuciÃ³n de proposiciÃ³n o de salto propuesto. Todo lo que necesitamos saber es dÃ³nde estamos \\(f(\\theta)\\) y hacia donde queremos ir \\(f(\\theta')\\).\n\nPuede probarse que para cualquier \\(q(\\theta'\\mid\\theta)\\), cuando \\(s\\to \\infty\\) la distribuciÃ³n de probabilidad de la secuencia \\(\\left\\{\\theta^{(s)} \\right\\}_{s=1}^S\\) tiende a \\(p(\\theta)\\). No sabemos nada sobre la rapidez con la que lo hace.\n\n\nEn infinitos pasos, cualquier cadena darÃ¡ muestras de la distribuciÃ³n \\(p(\\theta)\\), en la prÃ¡ctica hay que tener algunos cuidados."
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-12",
    "href": "presentaciones/presentacion_05.html#section-12",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Necesitamos muestras de \\(p(\\theta)\\)\nTomamos un punto inicial\nElegimos una distribuciÃ³n de saltos posibles \\(q(\\theta'\\mid\\theta)\\)\nProponemos un salto\nÂ¿Saltamos?"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-13",
    "href": "presentaciones/presentacion_05.html#section-13",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "theta <- double()\ntheta[1] <- -1    \ni <- 1\n\npropuesta <- rnorm(1, mean = theta[i], sd = 0.8)\n\nf_actual <- fx(theta[i])\nf_propuesta <- fx(propuesta)\n\nalpha <- min(c(1,f_propuesta/f_actual))\n\nquehacemos <- sample(c(\"salto\",\"no salto\"), \n                    size = 1, \n                    prob = c(alpha,1-alpha))\n\nif(quehacemos==\"salto\") {\n  theta[i+1] <- propuesta \n} else {\n  theta[i+1] <- theta[i]\n  }\n\nDebe repetirse el proceso en un for"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-14",
    "href": "presentaciones/presentacion_05.html#section-14",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "\\[\\sigma = 0.8\\]\n\n\n \\[\\sigma = 0.1\\]\n\n\n \\[\\sigma = 0.6\\]\n\n\n \\[\\sigma = 4.8\\]"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-15",
    "href": "presentaciones/presentacion_05.html#section-15",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Â¿QuÃ© esperamos de nuestra cadena?\n\nRepresentatividad: haber explorado el rango completo de la distribuciÃ³n a posteriori, independientemente de las condiciones iniciales\nPrecisiÃ³n y estabilidad: a lo largo de diferentes cadenas (distintas condiciones iniciales)\nEficiencia: esperamos requerir la menor cantidad posible de muestras\n\nNingÃºn objetivo se alcanza absolutamente, existen chequeos grÃ¡ficos y numÃ©ricos para saber si las cadenas de MCMC estÃ¡n sanas."
  },
  {
    "objectID": "presentaciones/presentacion_05.html#trace-plots",
    "href": "presentaciones/presentacion_05.html#trace-plots",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Trace Plots",
    "text": "Trace Plots\nGraficar los valores que toma el algoritmo como funciÃ³n del tiempo (lo que tÃ­picamente llamamos la cadena). Se tiene que ver como un fuzzy caterpillar (buen mixing). Para los impresionables: ruido blanco sin ningÃºn patrÃ³n particular."
  },
  {
    "objectID": "presentaciones/presentacion_05.html#autocorrelaciÃ³n",
    "href": "presentaciones/presentacion_05.html#autocorrelaciÃ³n",
    "title": "EstadÃ­stica Bayesiana",
    "section": "AutocorrelaciÃ³n",
    "text": "AutocorrelaciÃ³n\nLas muestras tienen que ser independientes. La dependencia de valores anteriores tiene que desaparecer rÃ¡pido . Podemos medirlo con la autocorrelaciÃ³n.\nPara cada valor de lag \\(k\\) se calcula la correlaciÃ³n de la serie consigo misma originando la funciÃ³n de autocorrelaciÃ³n (\\(ACF(k)\\))"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#nÃºmero-efectivo-de-muestras",
    "href": "presentaciones/presentacion_05.html#nÃºmero-efectivo-de-muestras",
    "title": "EstadÃ­stica Bayesiana",
    "section": "NÃºmero efectivo de muestras",
    "text": "NÃºmero efectivo de muestras\nLas muestras no son independientes. Â¿A cuÃ¡ntas muestras independientes equivalen nuestras \\(S\\) muestras? \\(N_{eff}\\) es el nÃºmero de muestras independientes que tienen el mismo poder de estimaciÃ³n que \\(S\\) muestras correlacionadas (el error de estimaciÃ³n es proporcional a \\(\\frac{1}{\\sqrt{N_{eff}}}\\))\n\\[N_{eff} = \\frac{S}{1 + 2 \\sum_{k=1}^\\infty ACF(k)}\\]"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#hatr",
    "href": "presentaciones/presentacion_05.html#hatr",
    "title": "EstadÃ­stica Bayesiana",
    "section": "\\(\\hat{R}\\)",
    "text": "\\(\\hat{R}\\)\nEl estadÃ­stico de Rubinâ€“Gelman \\(\\hat{R}\\) es un indicador de convergencia. Si mÃºltiples cadenas se establizaron en un muestreo representativo del posterior, la diferencia promedio entre cadenas debe ser similar a la diferencia promedio en la cadena.\n\\[\\hat{R} = \\sqrt{\\frac{\\frac{S-1}{S} W  +  \\frac{1}{S}  B}{W}}\\]\nEl valor 1 indica convergencia. Si una cadena se perdiÃ³/divergiÃ³, el \\(\\hat{R}\\) serÃ¡ mucho mayor a 1."
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-17",
    "href": "presentaciones/presentacion_05.html#section-17",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Si tenemos \\(M\\) cadenas, \\(\\theta_m\\), cada una de las cuales tiene \\(S\\) muestras \\(\\theta_m^{(s)}\\). La varianza entre cadenas (\\(B\\)) es:\n\\[B = \\frac{S}{M-1} \\sum_{m=1}^M (\\bar{\\theta}^{(\\bullet)}_{m} - \\bar{\\theta}^{(\\bullet)}_{\\bullet})^2\\]\n\\[\\bar{\\theta}_m^{(\\bullet)} = \\frac{1}{S} \\sum_{s = 1}^S \\theta_m^{(s)}\\]\n\\[\\bar{\\theta}^{(\\bullet)}_{\\bullet} = \\frac{1}{M} \\, \\sum_{m=1}^M \\bar{\\theta}_m^{(\\bullet)}\\]\nLa varianza intra cadena (\\(W\\)) es:\n\\[W = \\frac{1}{M} \\, \\sum_{m=1}^M s_m^2\\]\n\\[ s_m^2 = \\frac{1}{S-1} \\, \\sum_{s=1}^S (\\theta^{(s)}_m - \\bar{\\theta}^{(\\bullet)}_m)^2\\]"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-18",
    "href": "presentaciones/presentacion_05.html#section-18",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "El estimador de la varianza total\n\\[\\widehat{\\mbox{var}}^{+}\\!(\\theta|y) = \\frac{N-1}{N}\\, W \\, + \\, \\frac{1}{N} \\, B\\]\n\\[\\hat{R} \\, = \\, \\sqrt{\\frac{\\widehat{\\mbox{var}}^{+}\\!(\\theta|y)}{W}}\\]"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#hamiltonian-montecarlo",
    "href": "presentaciones/presentacion_05.html#hamiltonian-montecarlo",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Hamiltonian Montecarlo",
    "text": "Hamiltonian Montecarlo\n\nMetropolis-Hastings (MG) es una exploraciÃ³n a ciegas del espacio de parÃ¡metros\nLa distribuciÃ³n de propuesta de salto es fija\nEn las colas de la distribuciÃ³n, se proponen tanto saltos que se acercan al grueso (bulk) de la distribuciÃ³n como saltos que se alejan. Se rechazan muchos saltos propuestos.\nHamiltonian-Montecarlo (HMC) es una variante mÃ¡s eficiente de MCMC. Para lograr la eficiencia, los saltos propuestos se adaptan a la forma del posterior.\nLa forma del posterior estÃ¡ en su gradiente"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-20",
    "href": "presentaciones/presentacion_05.html#section-20",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "HMC trata de aprovechar la geometrÃ­a local del posterior para decidir dÃ³nde ir en la prÃ³xima iteraciÃ³n.\nSi bien MH no ignora por completo la forma del posterior, HMC utiliza mÃ¡s informaciÃ³n (el gradiente)\nPara entender conceptualmente HMC se necesita un poco de imaginaciÃ³n y entender algo de FÃ­sica"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-21",
    "href": "presentaciones/presentacion_05.html#section-21",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "\\(p^*(\\theta\\mid y)\\) es el posterior sin normalizar. Consideraremos \\(-\\log[p^*(\\theta\\mid y)]\\).\nLos puntos de alta densidad de probabilidad (mÃ¡ximos locales de \\(p^*(\\theta\\mid y)\\)) se convierten en mÃ­nimos locales de \\(-\\log[p^*(\\theta\\mid y)]\\)\nLa lÃ³gica es la misma que en MH (despuÃ©s de todo, se trata de un algoritmo de MCMC): estamos en algÃºn punto del espacio de parÃ¡metros y decidimos movernos a otroâ€¦ AquÃ­ cambia cÃ³mo proponemos un salto.\nPara ello, imaginamos un trineo (o culipatÃ­n, o bolita) que puede deslizarse por la superficie determinada por \\(-\\log[p^*(\\theta\\mid y)]\\)"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-22",
    "href": "presentaciones/presentacion_05.html#section-22",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Si soltamos el trineo en algÃºn punto de la superficie, tenderÃ¡ a deslizar hacia abajo de \\(-\\log[p^*(\\theta\\mid y)]\\) por efecto de la gravedad. E irÃ¡ cada vez mÃ¡s rÃ¡pido.\nEstÃ¡ bueno que el trineo deslice hacia los mÃ­nimos de \\(-\\log[p^*(\\theta\\mid y)]\\) pues son zonas de alta densidad de probabilidad\nQuisiÃ©ramos que nuestro trineo explore otras zonas del posterior, para eso en lugar de soltar el trineo le damos un impulso inicial (velocidad inicial o momento).\nEste impulso inicial serÃ¡ aleatorio"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-23",
    "href": "presentaciones/presentacion_05.html#section-23",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Conociendo la posiciÃ³n inicial del trineo y el impulso que se le da (la velocidad inicial), la FÃ­sica permite calcular cuÃ¡l serÃ¡ su trayectoria (y por ende su posiciÃ³n despuÃ©s de un tiempo)\nLa posiciÃ³n final despuÃ©s de un tiempo serÃ¡ el nuevo \\(\\theta\\) propuesto. Es decir: mientras que en MH proponÃ­amos un salto con la distribuciÃ³n \\(q(\\theta'\\mid\\theta)\\), aquÃ­ lo hacemos con un momento inicial y estudiando la posiciÃ³n del trineo.\nLuego se acepta o se rechaza el salto propuesto"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-26",
    "href": "presentaciones/presentacion_05.html#section-26",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "HMC propone nuevos saltos de manera mÃ¡s sofisticada que MH\nBusca que los saltos propuestos sean hacia valores del parÃ¡metro mÃ¡s prometedores"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-27",
    "href": "presentaciones/presentacion_05.html#section-27",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "CÃ³mo calcular la trayectoria del trineo es una de las cuestiones claves del algoritmo. Planteamos la conservaciÃ³n de la energÃ­a:\n\\[\\mathcal{H}(\\theta,v) = U(\\theta) + K(v)\\]\n\\(\\mathcal{H}\\) se conoce como hamiltoniano y representa la energÃ­a total del sistema que es la suma de la energÃ­a potencial \\(U(\\theta)\\) (funciÃ³n de la posiciÃ³n \\(\\theta\\)) y la energÃ­a cinÃ©tica \\(K(v)\\) (funciÃ³n de la velocidad \\(v\\)).\nSe toma \\(U(\\theta) = -\\log[p^*(\\theta\\mid y)]\\) y \\(K(v) = \\frac{1}{2} m v^2\\)"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-28",
    "href": "presentaciones/presentacion_05.html#section-28",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Las ecuaciones de Hamilton describen el cambio de \\(\\theta\\) y de \\(v\\) en funciÃ³n del tiempo\n\\[\\frac{d\\theta}{dt} = \\frac{\\partial \\mathcal{H}}{\\partial v}\\] \\[\\frac{dv}{dt} = -\\frac{\\partial \\mathcal{H}}{\\partial \\theta}\\]"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-29",
    "href": "presentaciones/presentacion_05.html#section-29",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Es necesario resolver estas ecuacionesâ€¦ Queremos hallar la posiciÃ³n (\\(\\theta\\)) del trineo tras un tiempo. No se pueden resolver analÃ­ticamente. Discretizamos el tiempo estudiando \\(L\\) pequeÃ±os intervalitos de duraciÃ³n \\(\\varepsilon\\)"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-30",
    "href": "presentaciones/presentacion_05.html#section-30",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Se tiene:\n\\[\\frac{dv}{dt} \\approx \\frac{v_{t+\\varepsilon} - v_{t}}{\\varepsilon} = \\frac{v_{t_2} - v_{t_1}}{\\varepsilon}\\]\n\\[\\frac{d\\theta}{dt} \\approx \\frac{\\theta_{t+\\varepsilon} - \\theta_{t}}{\\varepsilon} = \\frac{\\theta_{t_2} - \\theta_{t_1}}{\\varepsilon}\\]\ncon lo cual\n\\[v_{t_2} = v_{t_1} + \\varepsilon \\frac{dv}{dt} = v_{t_1}-\\varepsilon \\frac{\\partial \\mathcal{H}}{\\partial \\theta}\\]\n\\[\\theta_{t_2} = \\theta_{t_1} + \\varepsilon \\frac{d\\theta}{dt} = \\theta_{t_1}-\\varepsilon \\frac{\\partial \\mathcal{H}}{\\partial \\theta}\\]\nEstas aproximaciones no son buenasâ€¦"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#leapfrog-integrator",
    "href": "presentaciones/presentacion_05.html#leapfrog-integrator",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Leapfrog integrator",
    "text": "Leapfrog integrator\nSe parte de \\(t\\) y se busca \\(v\\) en \\(t+\\frac{\\varepsilon}{2}\\). Luego se busca \\(\\theta\\) en \\(t+\\varepsilon\\) usando el resultado anterior \\(v\\) en \\(\\frac{\\varepsilon}{2}\\).\n\\[v(t+\\frac{\\varepsilon}{2}) = v(t) - \\frac{\\varepsilon}{2} \\frac{\\partial \\mathcal{H}}{\\partial \\theta}\\rvert_t\\]\n\\[\\theta(t+\\varepsilon) = \\theta(t) + \\varepsilon \\frac{\\partial \\mathcal{H}}{\\partial v}\\rvert_{t+\\frac{\\varepsilon}{2}}\\]\n\\[v(t+\\varepsilon) = v(t+\\frac{\\varepsilon}{2}) - \\frac{\\varepsilon}{2} \\frac{\\partial \\mathcal{H}}{\\partial \\theta}\\rvert_{t+\\varepsilon}\\]"
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-32",
    "href": "presentaciones/presentacion_05.html#section-32",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "La elecciÃ³n de \\(\\varepsilon\\) es clave para el algoritmo. Si \\(L\\cdot\\varepsilon\\) es pequeÃ±o, tomarÃ¡ mucho tiempo explorar el posterior. Con un valor muy grande, ocurrirÃ¡n giros en U."
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-34",
    "href": "presentaciones/presentacion_05.html#section-34",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Propuesta: A partir de \\(\\theta^{(i)}\\) disparar una bolita en alguna direcciÃ³n aleatoria, con una velocidad (momento lineal) aleatoria\nLeapfrog integration: Calcular una serie de \\(L\\) pasos (leapfrog steps) de duraciÃ³n fija \\(\\varepsilon\\) (step size): instantes dÃ³nde vamos a sacar una foto de la posiciÃ³n de la partÃ­cula\nAceptaciÃ³n: Obtener la posiciÃ³n final \\(\\theta^{(i+1)}\\) como la posiciÃ³n final luego de \\(L\\) steps siempre y cuando la aproximaciÃ³n haya sido buena (la energÃ­a se haya conservado)\n\n\nUn \\(\\varepsilon\\) pequeÃ±o da mÃ¡s resoluciÃ³n sobre la trayectoria, permitiendo que la bolita gire Ã¡ngulos pronunciados (Â¿pero?).\n\n\nUn \\(\\varepsilon\\) grande harÃ¡ que los saltos sean largos y podemos saltear el punto donde la partÃ­cula iba a girar (divergent transition)."
  },
  {
    "objectID": "presentaciones/presentacion_05.html#section-35",
    "href": "presentaciones/presentacion_05.html#section-35",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "EstadÃ­stica Bayesiana â€“ 2023"
  },
  {
    "objectID": "presentaciones/presentacion_07.html#introducciÃ³n",
    "href": "presentaciones/presentacion_07.html#introducciÃ³n",
    "title": "EstadÃ­stica Bayesiana",
    "section": "IntroducciÃ³n",
    "text": "IntroducciÃ³n\n\nEn un problema de regresiÃ³n, no siempre la respuesta (condicionada) es normal\nA veces, la respuesta ni siquiera es cuantitativa"
  },
  {
    "objectID": "presentaciones/presentacion_07.html#section",
    "href": "presentaciones/presentacion_07.html#section",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Supongamos que nos interesa modelizar las siguientes variables:\n\nSi una persona vota o no por un determinado candidato\nSi un estudiante aprueba o no un examen\nSi maÃ±ana lloverÃ¡ o no\n\nEs decir, nos interesa modelizar una variable \\(Y\\), una variable respuesta categÃ³rica binaria:\n\\[Y = \\begin{cases}\n1 \\text{ si maÃ±ana llueve} \\\\\n0 \\text{ en caso contrario}\n\\end{cases}\\]\nen funciÃ³n de ciertas variables explicativas potencialesâ€¦\nEn otros contextos se habla de un problema de clasificaciÃ³n"
  },
  {
    "objectID": "presentaciones/presentacion_07.html#section-1",
    "href": "presentaciones/presentacion_07.html#section-1",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "SegÃºn los valores que puede tomar \\(Y\\), Â¿quÃ© modelo de probabilidad podemos asumir?\n\\[Y_i \\mid \\pi_i \\sim \\mathrm{Bern}(\\pi_i)\\]\n\\[\\mathbb{E}(Y_i) = \\pi_i\\]"
  },
  {
    "objectID": "presentaciones/presentacion_07.html#section-2",
    "href": "presentaciones/presentacion_07.html#section-2",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "En la regresiÃ³n normal que conocÃ­amos, tenÃ­amos\n\\[Y_i \\mid \\mu_i \\sim \\mathcal{N}(\\mu_i,\\sigma^2)\\]\n\\[\\mathbb{E}(Y_i) = \\mu_i\\]\nPor analogÃ­a, Â¿podemos hacer \\(\\pi_i = \\beta_0 + \\beta_1 x_{1_i} + \\beta_2 x_{2_i} + \\dots\\)?\nÂ¿QuÃ© problemas identificamos?"
  },
  {
    "objectID": "presentaciones/presentacion_07.html#section-3",
    "href": "presentaciones/presentacion_07.html#section-3",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Tendremos que hacer\n\\[g(\\pi_i) = \\beta_0 + \\beta_1 x_{1_i} + \\beta_2 x_{2_i} + \\dots\\]\n\\(g(\\cdot)\\) se conoce como funciÃ³n de enlace (link function). Â¿CuÃ¡l es una \\(g\\) apropiada en este caso?"
  },
  {
    "objectID": "presentaciones/presentacion_07.html#section-4",
    "href": "presentaciones/presentacion_07.html#section-4",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Si \\(\\pi_i\\) es la probabilidad del evento de interÃ©s, \\(\\frac{\\pi_i}{1-\\pi_i}\\) es la chance (odds) del evento de interÃ©s.\nMientras que \\(\\pi_i \\in [0,1]\\), \\(\\frac{\\pi_i}{1-\\pi_i} \\in [0,+\\infty)\\)"
  },
  {
    "objectID": "presentaciones/presentacion_07.html#section-5",
    "href": "presentaciones/presentacion_07.html#section-5",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Establecemos un modelo lineal para el log-odds del evento de interÃ©s\n\\[\\log(\\mathrm{odds}_i)=\\log\\left( \\frac{\\pi_i}{1-\\pi_i} \\right) = \\beta_0 + \\beta_1 x_{1_i} + \\beta_2 x_{2_i} + \\dots\\]\nLa funciÃ³n \\(g(x) = \\log\\left(\\frac{x}{1-x}\\right)\\) se conoce como funciÃ³n logit. Es una funciÃ³n no lineal."
  },
  {
    "objectID": "presentaciones/presentacion_07.html#section-6",
    "href": "presentaciones/presentacion_07.html#section-6",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Analicemos lo que vimos hasta ahora:\n\nÂ¿CuÃ¡l es el dominio de la funciÃ³n logit?\nÂ¿Para quÃ© necesitamos la funciÃ³n \\(g(\\cdot)\\)?\nÂ¿CuÃ¡l es la relaciÃ³n entre el predictor lineal y la variable respuesta?\nÂ¿CuÃ¡l es la distribuciÃ³n de la variable respuesta?"
  },
  {
    "objectID": "presentaciones/presentacion_07.html#section-7",
    "href": "presentaciones/presentacion_07.html#section-7",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Consideremos el caso con una sola variable explicativa\n\\[\\log\\left(\\frac{\\pi_i}{1-\\pi_i}\\right) = \\beta_0 + \\beta_1 x_{1_i}\\]\nSe cumple:\n\\[\n\\frac{\\pi_i}{1-\\pi_i} = e^{\\beta_0 + \\beta_1 x_{1_i}} \\qquad\n\\pi_i = \\frac{e^{\\beta_0 + \\beta_1 x_{1_i}}}{1 + e^{\\beta_0 + \\beta_1 x_{1_i}}}\n\\]\nÂ¡La esperanza de la variable respuesta se relaciona de manera no lineal con las variables explicativas!"
  },
  {
    "objectID": "presentaciones/presentacion_07.html#ejemplo",
    "href": "presentaciones/presentacion_07.html#ejemplo",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Ejemplo",
    "text": "Ejemplo\nConsideremos la siguiente relaciÃ³n\n\\[\\log\\left(\\frac{\\pi_i}{1-\\pi_i}\\right) = -4 + 0.1\\ x_{1_i}\\]\ne imaginemos que \\(\\pi_i\\) es la probabilidad de que llueva el dÃ­a \\(i\\) y \\(x_{1_i}\\) la humedad a las 9 de la maÃ±ana del dÃ­a anterior al dÃ­a \\(i\\)."
  },
  {
    "objectID": "presentaciones/presentacion_07.html#section-8",
    "href": "presentaciones/presentacion_07.html#section-8",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "x1 <- seq(0, 100, length.out = 100)\nbeta0 <- -4\nbeta1 <- 0.1\n\ndata <- tibble(x1 = x1,\n               log_odds = beta0 + beta1*x1,\n               odds = exp(log_odds),\n               pi = odds/(1+odds))"
  },
  {
    "objectID": "presentaciones/presentacion_07.html#interpretaciÃ³n-de-los-coeficientes",
    "href": "presentaciones/presentacion_07.html#interpretaciÃ³n-de-los-coeficientes",
    "title": "EstadÃ­stica Bayesiana",
    "section": "InterpretaciÃ³n de los coeficientes",
    "text": "InterpretaciÃ³n de los coeficientes\n\\(\\beta_0\\)\n\\(\\beta_0\\) es la log-chance (log-odds) del evento de interÃ©s cuando todas las variables explicativas valen 0. \\(e^{\\beta_0}\\) es la chance. En tÃ©rminos del problema: \\(e^{\\beta_0}\\) es la chance de que llueva maÃ±ana si la humedad de hoy a las 9 de la maÃ±ana es 0."
  },
  {
    "objectID": "presentaciones/presentacion_07.html#section-10",
    "href": "presentaciones/presentacion_07.html#section-10",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "\\(\\beta_1\\)\n\\(\\beta_1\\) no es el incremento en la probabilidad del evento de interÃ©s cuando \\(x_1\\) aumenta en una unidadâ€¦\n\n\\(\\mathrm{odds}_x\\) es la chance del evento de interÃ©s cuando \\(x_1=x\\)\n\\(\\mathrm{odds}_{x+\\Delta x}\\) es la chance del evento de interÃ©s cuando \\(x_1 = x + \\Delta x\\)\n\n\\[\\log (\\mathrm{odds}_x) =\\log\\left( \\frac{\\pi_x}{1-\\pi_x} \\right) = \\beta_0 + \\beta_1 x\\]\n\\[\\log (\\mathrm{odds}_{x+\\Delta x}) =\\log\\left( \\frac{\\pi_{x+\\Delta x}}{1-\\pi_{x+\\Delta x}} \\right) = \\beta_0 + \\beta_1 (x+\\Delta x)\\]"
  },
  {
    "objectID": "presentaciones/presentacion_07.html#section-11",
    "href": "presentaciones/presentacion_07.html#section-11",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Entonces\n\\[\\log (\\mathrm{odds}_{x+\\Delta x}) - \\log (\\mathrm{odds}_{x}) = \\beta_1 \\Delta x\\]\n\\[ e^{\\beta_1 \\Delta x} = \\frac{\\mathrm{odds}_{x+\\Delta x}}{\\mathrm{odds}_{x}}\\]\nLa chance del evento de interÃ©s aumenta \\(e^{\\beta_1 \\Delta x}\\) veces cuando \\(x_1\\) aumenta en \\(\\Delta x\\) (y el resto de las variables se mantienen constantes). En tÃ©rminos del problema: La chance de que llueva maÃ±ana aumenta \\(e^{\\beta_1}\\) veces si la humedad aumenta en 1."
  },
  {
    "objectID": "presentaciones/presentacion_07.html#section-12",
    "href": "presentaciones/presentacion_07.html#section-12",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "MÃ¡s en tÃ©rminos del problema:\n\\[e^{\\beta_1} = \\frac{\\mathrm{odds}_{x+1}}{\\mathrm{odds}_{x}} \\Rightarrow \\mathrm{odds}_{x+1} = e^{\\beta_1} \\mathrm{odds}_{x}\\]\n\\[e^{\\beta_1} = 1.11\\]\n\nLa chance de que llueva maÃ±ana aumenta \\(1.11\\) veces cuando la humedad a las 9 de la maÃ±ana de hoy aumenta en una unidad\nLa chance de que llueva maÃ±ana aumenta en un \\(11\\%\\) cuando la humedad a las 9 de la maÃ±ana de hoy aumenta en una unidad"
  },
  {
    "objectID": "presentaciones/presentacion_07.html#section-13",
    "href": "presentaciones/presentacion_07.html#section-13",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Analicemos juntos el siguiente caso:\n\\[\\log\\left(\\frac{\\pi_i}{1-\\pi_i}\\right) = 1.1 - 0.2\\ \\mathrm{despierto}_{i}\\]\ne imaginemos que \\(\\pi_i\\) es la probabilidad de que un estudiante \\(i\\) apruebe el parcial de AnÃ¡lisis de Datos de DuraciÃ³n \\(i\\) y \\(\\mathrm{despierto}_i\\) la cantidad de horas que el estudiante \\(i\\) estuvo despierto la noche anterior al parcial."
  },
  {
    "objectID": "presentaciones/presentacion_07.html#section-14",
    "href": "presentaciones/presentacion_07.html#section-14",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Â¿Y Bayes?\nLa especificaciÃ³n del modelo se completa con la elecciÃ³n de distribuciones a priori para \\(\\beta_0,\\ \\beta_1,\\ \\dots\\)â€¦\nCada cantidad que dependa de los \\(\\beta_0,\\ \\beta_1,\\ \\dots\\) tendrÃ¡ una distribuciÃ³n de probabilidad.\nLas predicciones tambiÃ©n son probabilÃ­sticas."
  },
  {
    "objectID": "presentaciones/presentacion_07.html#section-15",
    "href": "presentaciones/presentacion_07.html#section-15",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Â¿CÃ³mo se estiman \\(\\beta_0,\\ \\beta_1,\\ \\dots\\)? Como siempre. Aplicando la Regla de Bayes. Solo que la verosimilitud ahora es Bernoulli.\n\n\n\nEstadÃ­stica Bayesiana â€“ 2023"
  },
  {
    "objectID": "presentaciones/presentacion_06.html#optimizaciÃ³n",
    "href": "presentaciones/presentacion_06.html#optimizaciÃ³n",
    "title": "EstadÃ­stica Bayesiana",
    "section": "OptimizaciÃ³n",
    "text": "OptimizaciÃ³n\nPara modelizar la relaciÃ³n entre una variable dependiente \\(Y\\) y ciertos predictores \\(X_l\\) asumimos un modelo de la forma\n\\[Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p + \\eta\\]\nEn realidad tenemos \\(N\\) observaciones y por lo tanto para cada observaciÃ³n \\((y_i,\\mathbf{x}_i)\\) tenemos\n\\[y_i = \\beta_0 + \\beta_1 x_{1_i} + \\beta_2 x_{2_i} + \\dots + \\beta_p x_{p_i} + \\eta\\]\nO bien, matricialmente\n\\[y_i = \\boldsymbol{\\beta}^T \\mathbf{x}_i + \\eta\\]\nEl error \\(\\eta\\) es desconocido y, en principio, no es necesario asumir nada sobre este."
  },
  {
    "objectID": "presentaciones/presentacion_06.html#section",
    "href": "presentaciones/presentacion_06.html#section",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Para predecir valores de \\(y_i\\) es necesario estimar \\(\\boldsymbol{\\beta}\\) por \\(\\hat{\\boldsymbol{\\beta}}\\) dando lugar al siguiente modelo predictivo:\n\\[\\hat{y}_i = \\hat\\beta_0 + \\hat\\beta_1 x_{1_i} + \\hat\\beta_2 x_{2_i} + \\dots + \\hat\\beta_p x_{p_i} = \\hat{\\boldsymbol{\\beta}}^T \\mathbf{x}_i\\]\nUna forma de estimar \\(\\boldsymbol{\\beta}\\) es minimizar alguna funciÃ³n del error de aproximar \\(y\\) por \\(\\hat{y}_i\\):\n\\[\\hat{\\boldsymbol{\\beta}} = \\underset{\\boldsymbol\\beta}{\\mathrm{arg\\,min}}\\left[ J(\\boldsymbol\\beta) \\right] = \\underset{\\boldsymbol\\beta}{\\mathrm{arg\\,min}}\\left[ \\sum_{i=1}^N \\left(y_i - \\boldsymbol\\beta^T \\mathbf{x}_i\\right)^2 \\right]\\]\nEl \\(\\boldsymbol{\\beta}\\) que minimiza el error cuadrÃ¡tico se conoce como estimador de mÃ­nimos cuadrados. Esto es lo que se conoce como enfoque de optimizaciÃ³n."
  },
  {
    "objectID": "presentaciones/presentacion_06.html#estadÃ­stica-clÃ¡sica",
    "href": "presentaciones/presentacion_06.html#estadÃ­stica-clÃ¡sica",
    "title": "EstadÃ­stica Bayesiana",
    "section": "EstadÃ­stica clÃ¡sica",
    "text": "EstadÃ­stica clÃ¡sica\nAsumiendo un modelo probabilÃ­stico para el error, \\(\\eta \\sim \\mathcal{N}(0,\\sigma^2)\\) se puede obtener el estimador de mÃ¡xima verosimilitud de \\(\\boldsymbol\\beta\\).\nLa funciÃ³n de verosimilitud viene dada por el producto de las funciones de densidad normales:\n\\[\\ell(\\boldsymbol\\beta,\\sigma|\\mathbf{y}) = \\prod_{i=1}^N p(y_i|\\mathbf{x_i},\\boldsymbol\\beta^T,\\sigma^2) = \\prod_{i=1}^N \\frac{1}{\\sqrt{2\\pi\\sigma}} e^{-\\frac{(y_i - \\boldsymbol\\beta^T\\mathbf{x}_i)^2}{2\\sigma^2}}\\]"
  },
  {
    "objectID": "presentaciones/presentacion_06.html#section-2",
    "href": "presentaciones/presentacion_06.html#section-2",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Maximizar la verosimilitud equivale a minimizar el opuesto de la log-verosimilitud \\(\\mathcal{L}(\\boldsymbol\\beta,\\sigma|\\mathbf{y}) = \\log(\\ell(\\boldsymbol\\beta,\\sigma|\\mathbf{y}))\\)\n\\[\\hat{\\boldsymbol{\\beta}}_{ML} = \\underset{\\boldsymbol\\beta}{\\mathrm{arg\\,min}}\\left[ - \\sum_{i=1}^N \\log \\left( \\left( \\frac{1}{2\\pi\\sigma^2} \\right)^{1/2} e^{-\\frac{(y_i - \\boldsymbol\\beta^T\\mathbf{x}_i)^2}{2\\sigma^2}} \\right) \\right]\\]\nLa expresiÃ³n anterior puede minimizarse primero respecto de \\(\\boldsymbol\\beta\\) y luego respecto de \\(\\sigma\\). Resulta que maximizar la verosimilitud respecto de \\(\\boldsymbol\\beta\\) equivale a minimizar el error cuadrÃ¡tico."
  },
  {
    "objectID": "presentaciones/presentacion_06.html#estadÃ­stica-bayesiana",
    "href": "presentaciones/presentacion_06.html#estadÃ­stica-bayesiana",
    "title": "EstadÃ­stica Bayesiana",
    "section": "EstadÃ­stica bayesiana",
    "text": "EstadÃ­stica bayesiana\nEn estadÃ­stica bayesiana, consideramos a los parÃ¡metros como variables aleatorias y les asignamos una distribuciÃ³n a priori.\nAdemÃ¡s, contamos con un modelo generativo (probabilÃ­stico) para las observaciones: Â¿cÃ³mo obtendrÃ­amos observaciones si conociÃ©ramos los parÃ¡metros? Es una decisiÃ³n de la modelizaciÃ³n."
  },
  {
    "objectID": "presentaciones/presentacion_06.html#section-3",
    "href": "presentaciones/presentacion_06.html#section-3",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "AquÃ­ asumimos:\n\\[Y_i \\mid \\boldsymbol\\beta,\\sigma \\sim \\mathcal{N}(\\boldsymbol\\beta^T \\mathbf{x}_i, \\sigma^2)\\]\no bien decimos\n\\[\n\\begin{align*}\n    Y_i & \\sim  \\mathcal{N}(\\mu_i, \\sigma^2) \\\\\n    \\mu_i & = \\beta_0 + \\beta_1 x_{1_i} + \\beta_2 x_{2_i} + \\dots + \\beta_p x_{p_i}\n\\end{align*}\n\\]\nY completamos el modelo especificando una distribuciÃ³n a priori \\(p(\\boldsymbol\\beta,\\sigma)\\)"
  },
  {
    "objectID": "presentaciones/presentacion_06.html#section-4",
    "href": "presentaciones/presentacion_06.html#section-4",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "La estimaciÃ³n se hace siempre de la misma manera\n\\(p(\\boldsymbol\\beta,\\sigma\\mid\\mathbf{y}) \\propto p(\\mathbf{y}|\\boldsymbol\\beta,\\sigma)p(\\boldsymbol\\beta,\\sigma)\\)"
  },
  {
    "objectID": "presentaciones/presentacion_06.html#section-5",
    "href": "presentaciones/presentacion_06.html#section-5",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Observando un datoâ€¦"
  },
  {
    "objectID": "presentaciones/presentacion_06.html#section-6",
    "href": "presentaciones/presentacion_06.html#section-6",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Observando el dato que sigueâ€¦"
  },
  {
    "objectID": "presentaciones/presentacion_06.html#section-7",
    "href": "presentaciones/presentacion_06.html#section-7",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Observando dos puntos juntosâ€¦"
  },
  {
    "objectID": "presentaciones/presentacion_06.html#section-8",
    "href": "presentaciones/presentacion_06.html#section-8",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Comparemos con un prior mÃ¡s fuerteâ€¦"
  },
  {
    "objectID": "presentaciones/presentacion_06.html#section-10",
    "href": "presentaciones/presentacion_06.html#section-10",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "\\(\\mu\\) depende de los parÃ¡metros (y por supuesto del valor de \\(x\\)), por lo que tiene una distribuciÃ³n de probabilidad asociada"
  },
  {
    "objectID": "presentaciones/presentacion_06.html#section-11",
    "href": "presentaciones/presentacion_06.html#section-11",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Por supuesto, las predicciones para \\(y\\) tambiÃ©n son probabilÃ­sticasâ€¦"
  },
  {
    "objectID": "presentaciones/presentacion_06.html#resumen",
    "href": "presentaciones/presentacion_06.html#resumen",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Resumen",
    "text": "Resumen\n\nTenemos una distribuciÃ³n de probabilidad para los parÃ¡metros. Es decir, tenemos incertidumbre en los valores de los parÃ¡metros\nTenemos que trabajar con todo el posterior (a travÃ©s de muestras) y no con estimaciones puntuales\nNo confundir predicciÃ³n de la media (tambiÃ©n llamado predictor lineal) con distribuciÃ³n predictiva (para las observaciones)\nA medida que aumenta el tamaÃ±o de muestra, los coeficientes de la regresiÃ³n se estiman cada vez con mayor precisiÃ³n y la incertidumbre del predictor lineal desaparece. No obstante, la incertidumbre en la distribuciÃ³n predictiva no desaparece (siempre quedarÃ¡ \\(\\sigma\\))"
  },
  {
    "objectID": "presentaciones/presentacion_06.html#validaciÃ³n-interna",
    "href": "presentaciones/presentacion_06.html#validaciÃ³n-interna",
    "title": "EstadÃ­stica Bayesiana",
    "section": "ValidaciÃ³n interna",
    "text": "ValidaciÃ³n interna\n\nEl modo fundamental de validar el ajuste de un modelo bayesiano es generar rÃ©plicas del conjunto de datos (utilizando el modelo ajustado) y compararlas con los datos reales. Esto es lo que se conoce como validaciÃ³n interna.\nPara cada muestra de parÃ¡metros del posterior podemos generar un dataset \\[\n\\left[\n\\begin{array}{l|l|l|l}\nY_1^{(1)} & Y_2^{(1)} & \\cdots & Y_{N}^{(1)} \\\\\nY_1^{(2)} & Y_2^{(2)} & \\cdots & Y_{N}^{(2)} \\\\\n\\vdots & \\vdots &  & \\vdots \\\\\nY_1^{(S)} & Y_2^{(S)} & \\cdots & Y_{N}^{(S)} \\\\\n\\end{array}\n\\right]\n\\]\nEsta prÃ¡ctica da lugar a los posterior predictive checks (PPC)"
  },
  {
    "objectID": "presentaciones/presentacion_06.html#validaciÃ³n-externa",
    "href": "presentaciones/presentacion_06.html#validaciÃ³n-externa",
    "title": "EstadÃ­stica Bayesiana",
    "section": "ValidaciÃ³n externa",
    "text": "ValidaciÃ³n externa\n\nIdealmente quisiÃ©ramos ver si nuestro modelo tiene capacidad predictiva para datos nuevos (no usados para ajustarlo)\nAntes de preocuparnos por los datos nuevos, pensemos en las prediccionesâ€¦ Las predicciones son probabilÃ­sticas\nNo podemos simplemente comparar \\(y\\) con \\(\\hat{y}\\)\nDebemos utilizar toda la distribuciÃ³n a posteriori para evaluar el ajuste y (la capacidad predictiva) del modelo"
  },
  {
    "objectID": "presentaciones/presentacion_06.html#section-14",
    "href": "presentaciones/presentacion_06.html#section-14",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Un posible score predictivo para un determinado valor \\(y_i\\) es la probabilidad que el modelo le asociaba, \\(\\int p\\left(y_i\\mid\\theta\\right) p(\\theta\\mid y) d\\theta \\approx \\frac{1}{S}\\sum_{s=1}^S p(y_i\\mid \\theta^{(s)})\\). El score predictivo total (para todas las posibles observaciones) es la log-posterior pointwise predictive density\n\\[\n\\mathrm{lppd} = \\sum_{i=1}^{N} \\log \\left( \\int p\\left(y_i\\mid\\theta\\right) p(\\theta\\mid y) d\\theta \\right)\n\\]\n\\[\n\\mathrm{lppd} = \\sum_{i=1}^{N} \\log \\left( \\frac{1}{S} \\sum_{s=1}^{S} p\\left(y_i\\mid\\theta^{(s)}\\right) \\right)\n\\]\nA mayor \\(\\mathrm{lppd}\\), mejor es el modelo para realizar predicciones"
  },
  {
    "objectID": "presentaciones/presentacion_06.html#section-15",
    "href": "presentaciones/presentacion_06.html#section-15",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "La deviance de un modelo es\n\\[D = -2 \\mathrm{lppd}\\]\n\nLa deviance (o la \\(\\mathrm{lppd}\\)) evalÃºa las predicciones de un modelo (el ajuste), no nos dice quÃ© tan correcto esâ€¦\nSon medidas que siempre mejoran con mÃ¡s parÃ¡metros y en realidad nos importa cÃ³mo se desempeÃ±a el modelo con datos nuevos."
  },
  {
    "objectID": "presentaciones/presentacion_06.html#section-16",
    "href": "presentaciones/presentacion_06.html#section-16",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "La \\(\\mathrm{lppd}\\) predice el \\(i\\)-Ã©simo valor con un posterior que usa todos los datos, incluido el \\(i\\). MÃ¡s que la \\(\\mathrm{lppd}\\) nos interesa su valor esperado en datos nuevos (\\(\\mathrm{elpd}\\)). Por supuesto, no conocemos datos nuevos. Podemos aproximar o estimar \\(\\mathrm{elpd}\\) haciendo cross-validation (CV) o, en particular, leave-one-out cross-validation (LOO-CV).\n\\[\\mathrm{elpd} \\approx \\mathrm{lppd}_{LOO} = \\sum_{i=1}^{N} \\log \\left( \\frac{1}{S} \\sum_{s=1}^{S} p\\left(y_i\\mid\\theta_{-i}^{(s)}\\right) \\right)\\]\ndonde los \\(\\theta_{-i}^{(s)}\\) son muestras del posterior de \\(\\theta\\) obtenido sin considerar la \\(i\\)-Ã©sima observaciÃ³n.\nEl problema de hacer LOO-CV es que, si tenemos 1000 observaciones, hay que calcular 1000 distribuciones a posteriori."
  },
  {
    "objectID": "presentaciones/presentacion_06.html#section-17",
    "href": "presentaciones/presentacion_06.html#section-17",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "No contamos con muestras de \\(P(\\theta\\mid \\mathbf{Y}_{-i})\\) sino simplemente de \\(P(\\theta\\mid \\mathbf{Y})\\). No sabemos la distribuciÃ³n a posteriori de \\(\\theta\\) sin considerar la observaciÃ³n \\(i\\). Hay formas de aproximar el desempeÃ±o en LOO-CV sin necesidad de reajustar el modelo. Una forma de hacerlo es usar la â€œimportanciaâ€ de cada observaciÃ³n en el posterior. Esto da lugar a una tÃ©cnica que se conoce como Pareto-smoothed importance sampling cross-validation (PSIS)"
  },
  {
    "objectID": "presentaciones/presentacion_06.html#section-18",
    "href": "presentaciones/presentacion_06.html#section-18",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "HistÃ³ricamente se han desarrollado los llamados criterios de informaciÃ³n que penalizan la verosimilitud con un tÃ©rmino adicional para compensar la capacidad de sobreajuste de un modelo que tiene mÃ¡s parÃ¡metros."
  },
  {
    "objectID": "presentaciones/presentacion_06.html#section-19",
    "href": "presentaciones/presentacion_06.html#section-19",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "El AIC (Akaike information criterion) es \\[AIC = D + 2p = -2\\ lppd + 2p\\] donde \\(p\\) es el nÃºmero de parÃ¡metros del modelo y \\(D=-2\\ \\mathrm{lppd}\\) se conoce como deviance. Penalizamos el \\(\\mathrm{lppd}\\) con la tendencia (o capacidad) del modelo de sobreajustar. ##\nEl WAIC (widely applicable information criterion) es un criterio mÃ¡s general que el AIC (y un poquitito mÃ¡s difÃ­cil de calcular):\n\\[WAIC = - 2\\left(\\mathrm{lppd} - \\sum_{i=1}^N \\mathbb{V}_\\theta\\left[\\log\\left(p(y_i\\mid\\theta\\right)\\right]\\right)\\]\n\\(\\sum_{i=1}^N \\mathrm{V}_\\theta\\left[\\log\\left(p(y_i\\mid\\theta\\right)\\right]\\) es un tÃ©rmino de penalizaciÃ³n que se suele llamar â€œnÃºmero efectivo de parÃ¡metrosâ€. Es la suma de las varianzas en la log-probabilidad de cada observaciÃ³n \\(i\\) (o sea, la varianza total). Si, para un determinado dato \\(i\\), las diferentes muestras del posterior \\(\\theta_{(s)}\\) dan como resultado predicciones muy diferentes, es porque el modelo tiene mucha incertidumbre (y es posiblemente muy flexible).\n\n\n\nEstadÃ­stica Bayesiana â€“ 2023"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#el-problema-de-las-urnas",
    "href": "presentaciones/presentacion_02.html#el-problema-de-las-urnas",
    "title": "EstadÃ­stica Bayesiana",
    "section": "El problema de las urnas",
    "text": "El problema de las urnas\n\nSe cuenta con 11 urnas etiquetadas segÃºn \\(u = 0,1,\\dots,10\\), que contienen diez bolas cada una. La urna \\(u\\) contiene \\(u\\) bolas azules y \\(10-u\\) bolas blancas. Fede elige una urna \\(u\\) al azar y extrae con reposiciÃ³n \\(N\\) bolas, obteniendo \\(n_A\\) azules y \\(N-n_A\\) blancas. Nico, el amigo de Fede, observa atentamente. Si despuÃ©s de \\(N=10\\) extracciones resulta \\(n_A = 3\\), Â¿cuÃ¡l es la probabilidad de que la urna que Fede estÃ¡ usando sea la \\(u\\)?"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section",
    "href": "presentaciones/presentacion_02.html#section",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "La teorÃ­a de las probabilidades permite predecir una distribuciÃ³n sobre posibles valores de un resultado dado cierto conocimiento (o estado) del universo: probabilidad hacia adelante\n\nPor el contrario, muchas veces estamos interesados en realizar inferencias sobre el estado del universo a partir de observaciones: probabilidad inversa.\n\n\n\\[p(\\mathcal{H}\\mid E) = \\frac{p(E\\mid\\mathcal{H}) p(\\mathcal{H})}{p(E)}\\]\n\\[p(\\mathcal{H}\\mid E) \\propto p(E\\mid\\mathcal{H}) p(\\mathcal{H})\\]"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-1",
    "href": "presentaciones/presentacion_02.html#section-1",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Conociendo \\(N\\), si conociÃ©ramos \\(u\\) podrÃ­amos calcular las probabilidades de los diferentes \\(n_A\\): probabilidad hacia adelante.\n\nAquÃ­ observamos un \\(n_A\\) y queremos calcular las probabilidades de los posibles valores de \\(u\\): probabilidad inversa.\n\n\n\\[p(u\\mid n_A, N) = \\frac{p(n_A\\mid u, N)p(u)}{p(n_A\\mid N)}\\]\n\n\\(N\\) es una cantidad fija\n\\(n_A\\) es otra cantidad fija: lo que observamos al realizar el experimento\n\\(u\\) es la cantidad desconocida"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-2",
    "href": "presentaciones/presentacion_02.html#section-2",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Probabilidad conjunta de las cantidades observables (datos) y cantidades no observables (parÃ¡metros):\n\n\\[\np(u,n_A\\mid N) = p(n_A\\mid u, N) p(u)\n\\]\n\n\nPodemos escribir la probabilidad de \\(u\\) condicionada a \\(n_A\\):\n\\[\n\\begin{array}{ccl}\np(u\\mid n_A,N) & = & \\frac{p(u,n_A\\mid N)}{p(n_A\\mid N)} \\\\\n& = & \\frac{p(n_A\\mid u, N) p(u)}{p(n_A\\mid N)}\n\\end{array}\n\\]\n\n\nEs la probabilidad de cada valor de \\(u\\) luego de haber observado \\(n_A = 3\\) bolas azules"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-3",
    "href": "presentaciones/presentacion_02.html#section-3",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "La probabilidad marginal de \\(u\\) es\n\n\\[p(u) = \\frac{1}{11}\\]\nEs la probabilidad inicial de haber tomado la urna \\(u\\)"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-4",
    "href": "presentaciones/presentacion_02.html#section-4",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "La probabilidad de \\(n_A\\) dado \\(u\\) (y \\(N\\)) es:\n\n\\[p(n_A\\mid u,N) = {N \\choose n_A} \\left( \\frac{u}{10} \\right)^{n_A} \\left( 1 - \\frac{u}{10} \\right)^{N-n_A}\\]\n\n\nComo \\(n_A=3\\) es fijo (Â¡son los datos observados!), \\(p(n_A\\mid u,N)\\) es una funciÃ³n de \\(u\\). Indica quÃ© tan compatibles son los datos observados con los distintos valores de \\(u\\)"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-5",
    "href": "presentaciones/presentacion_02.html#section-5",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "El denominador, \\(p(n_A\\mid N) = p(n_A)\\), es\n\n\\[\n\\begin{array}{ccl}\np(n_A\\mid N) & = & \\sum_u p(u,n_A\\mid N) \\\\\n& = & \\sum_u p(n_A\\mid u, N) p(u) \\\\\n& = & \\frac{1}{11} \\sum_u p(n_A\\mid u, N)\n\\end{array}\n\\]"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-6",
    "href": "presentaciones/presentacion_02.html#section-6",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Finalmente, la probabilidad de interÃ©s \\(p(u\\mid n_A,N)\\) es\n\n\\[\np(u\\mid n_A,N) = \\frac{p(n_A\\mid u,N)p(u)}{p(n_A\\mid N)}\n\\]\n\n\n\\[\np(u\\mid n_A,N) = {N \\choose n_A} \\left( \\frac{u}{10} \\right)^{n_A} \\left( 1 - \\frac{u}{10} \\right)^{N-n_A} \\frac{1}{11} \\frac{1}{p(n_A\\mid N)}\n\\]\n\n\n\n\\(N\\) es una cantidad fija\n\\(n_N\\) es 3, otra cantidad fija: lo que observamos al realizar el experimento\n\\(u\\) es la cantidad desconocida\n\n\n\n\\(p(u\\mid n_A,N)\\) es una funciÃ³n de \\(u\\): es la credibilidad de los valores de \\(u\\) luego de observar los datos (es decir, condicionada a \\(n_A=3\\))."
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-7",
    "href": "presentaciones/presentacion_02.html#section-7",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "GrÃ¡ficamenteâ€¦"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-8",
    "href": "presentaciones/presentacion_02.html#section-8",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "GrÃ¡ficamenteâ€¦"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-9",
    "href": "presentaciones/presentacion_02.html#section-9",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Pasamos de una credibilidad a priori antes de observar los datos, a una a posteriori luego de observar \\(n_A = 3\\)"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#intolerancia-al-gluten",
    "href": "presentaciones/presentacion_02.html#intolerancia-al-gluten",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Intolerancia al gluten",
    "text": "Intolerancia al gluten\n\nÂ¿Pueden las personas alÃ©rgicas al gluten distinguir harina comÃºn de harina sin gluten en un ensayo ciego? En un experimento, de 35 sujetos, 12 identificaron correctamente la harina comÃºn y 23 se equivocaron o no supieron decir de quÃ© harina se trataba.\nIncluso si no hubiera alÃ©rgicos al gluten en el experimento, esperarÃ­amos encontrar algunas identificaciones correctasâ€¦ BasÃ¡ndonos en el nÃºmero de identificaciones correctas, Â¿cuÃ¡ntos de los sujetos son alÃ©rgicos al gluten y cuÃ¡ntos estaban adivinando?\n\n\nSupongamos que una persona alÃ©rgica al gluten tiene una probabilidad de \\(0.90\\) de detectar la harina comÃºn mientras que una persona sin alergia detecta harina comÃºn con una probabilidad de \\(0.40\\) (y con una probabilidad de \\(0.6\\) se equivoca o no sabe decir)."
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-10",
    "href": "presentaciones/presentacion_02.html#section-10",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Llamemos:\n\n\n\\(N\\) a la cantidad total de personas en el ensayo\n\\(N_a\\) al nÃºmero de personas alÃ©rgicas al gluten\n\\(\\pi_a\\) a la probabilidad de que un alÃ©rgico identifique correctamente\n\\(\\pi_f\\) a la probabilidad de que un no alÃ©rgico identifique correctamente\n\\(n_i\\) al nÃºmero de identificaciones correctas\n\n\n\nÂ¿CuÃ¡les son las cantidades conocidas? Â¿CuÃ¡les son las cantidades desconocidas? Â¿CÃ³mo es el modelo de probabilidad hacia adelante? Â¿CÃ³mo es el problema inverso?"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-11",
    "href": "presentaciones/presentacion_02.html#section-11",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Conociendo \\(N\\), \\(\\pi_a\\) y \\(\\pi_f\\), si conociÃ©ramos \\(N_a\\) podrÃ­amos calcular las probabilidades de los diferentes \\(n_i\\): probabilidad hacia adelante\n\nAquÃ­ observamos \\(n_i\\) y queremos realizar inferencias sobre \\(N_a\\): probabilidad inversa"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-12",
    "href": "presentaciones/presentacion_02.html#section-12",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Digamos que a priori cualquier nÃºmero de \\(N_a\\) es igualmente probable o esperable:\n\n\\[p(N_a) = \\frac{1}{36}\\]"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-13",
    "href": "presentaciones/presentacion_02.html#section-13",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Â¿CÃ³mo construimos la verosimilitud de los diferentes valores de \\(N_a\\) \\(p(n_i\\mid N_a)\\)?\n\nPensemos de forma generativa (con el modelo de probabilidad hacia adelante). Imaginemos que conocemos \\(N_a\\) (ademÃ¡s de \\(N\\), \\(\\pi_a\\) y \\(\\pi_f\\)), Â¿podrÃ­amos escribir un programa que simule diferentes valores de \\(n_i\\)?"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-14",
    "href": "presentaciones/presentacion_02.html#section-14",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "El nÃºmero de identificaciones correctas \\(n_i\\) es la suma de las identificaciones correctas entre los \\(N_a\\) alÃ©rgicos (\\(n_{ia}\\)) y los \\(N-N_a\\) no alÃ©rgicos (\\(n_{if}\\)). Â¿CuÃ¡ntas identificaciones habrÃ¡ en cada grupo?\n\n\\[n_{ia} \\sim Bi(N_a,\\pi_a)\\] \\[n_{if} \\sim Bi(N-N_a,\\pi_f)\\] \\[n_i = n_{ia} + n_{if}\\]\n\n\n\nN <- 35\npi_a <- 0.9\npi_f <- 0.4\nN_a <- 10 # lo suponemos conocido para simular\n\nn_ia <- rbinom(1, N_a, pi_a)\nn_if <- rbinom(1, N-N_a, pi_f)\n\nn_i <- n_ia + n_if\n\n\n\nSabrÃ­amos calcular las probabilidades de los diferentes valores de \\(n_{ia}\\) y \\(n_{if}\\), Â¿no?."
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-15",
    "href": "presentaciones/presentacion_02.html#section-15",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Recordemos que no conocemos \\(N_a\\). En nuestro caso, la verosimilitud de cada valor de \\(N_a\\) es la probabilidad de observar \\(n_i=12\\) para ese valor de \\(N_a\\).\n\n\\[\n\\begin{array}{lll}\np(n_i=12\\mid N_a) & = & p(n_{ia}=0\\mid N_a)p(n_{if}=12\\mid N_a) \\\\\n& & \\quad + p(n_{ia}=1\\mid N_a)p(n_{if}=11\\mid N_a) + \\dots\n\\end{array}\n\\]\n\n\nQueda como ejercicio calcular a mano \\(p(n_i\\mid N_a)\\) o, mejor aÃºn, escribir un programita que calcule \\(p(n_i\\mid N_a)\\)"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-16",
    "href": "presentaciones/presentacion_02.html#section-16",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Finalmente,\n\\[p(N_a\\mid n_i) = \\frac{p(n_i\\mid N_a) p(N_a)}{p(n_i)}\\]"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#vocabulario-limitado",
    "href": "presentaciones/presentacion_02.html#vocabulario-limitado",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Vocabulario limitado",
    "text": "Vocabulario limitado\n\nSupongamos que existe un idioma con seis palabras: \\[ \\text{\\{perro, parra, farra, carro, corro, tarro\\}} \\]\n\n\nTodas las palabras son igualmente probables, excepto por â€˜perroâ€™, que es \\(\\alpha=3\\) veces mÃ¡s probable que las otras.\nCuando se tipean, un caracter se introduce errÃ³neamente con probabilidad \\(\\pi=0.1\\).\nTodas las letras tienen la misma probabilidad de producir un error de tipeo.\nSi una letra se tipeÃ³ mal, la probabilidad de cometer un error en otro caracter no cambia.\nLos errores son independientes a lo largo de una palabra."
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-18",
    "href": "presentaciones/presentacion_02.html#section-18",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Â¿CuÃ¡l es la probabilidad de escribir correctamente â€˜tarroâ€™?\nÂ¿CuÃ¡l es la probabilidad de tipear â€˜cerroâ€™ o â€˜curroâ€™ al querer escribir â€˜carroâ€™?\nDesarrollar un corrector gramatical para esta lengua: para las palabras tipeadas â€˜farraâ€™, â€˜birraâ€™ y â€˜locosâ€™, Â¿cuÃ¡l es la palabra que se quiso escribir?"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-19",
    "href": "presentaciones/presentacion_02.html#section-19",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "La probabilidad de escribir correctamente â€˜tarroâ€™ es \\((1-\\pi)^5\\)\nLa probabilidad de escribir correctamente â€˜cerroâ€™ o â€˜curroâ€™ al querer escribir â€˜carroâ€™ es $(1-)^4 $\nAllÃ¡ vamosâ€¦"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-20",
    "href": "presentaciones/presentacion_02.html#section-20",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Estas son las probabilidades a priori de cada una de las palabras del vocabulario"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-21",
    "href": "presentaciones/presentacion_02.html#section-21",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Alguien escribe â€˜farraâ€™, Â¿quÃ© quiso escribir?\n\nÂ¿QuÃ© serÃ­a en este caso la verosimilitud?\n\n\nLa verosimilitud de â€˜perroâ€™ es quÃ© tan probable es escribir â€˜farraâ€™ cuando se querÃ­a escribir â€˜perroâ€™: \\(p(\\mathrm{farra}\\mid\\mathrm{perro})=\\pi^3(1-\\pi)^2\\)"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-23",
    "href": "presentaciones/presentacion_02.html#section-23",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Para obtener la probabilidad a posteriori de cada palabra, necesitamos combinar la informaciÃ³n a priori con los datos (Â¿cuÃ¡les son los datos?). Aplicamos la Regla de Bayes:\n\\[p(\\mathrm{palabra}\\mid \\mathrm{farra}) = \\frac{p(\\mathrm{farra}\\mid \\mathrm{palabra})p(\\mathrm{palabra})}{p(\\mathrm{farra})}\\]"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-25",
    "href": "presentaciones/presentacion_02.html#section-25",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "La inferencia bayesiana es la realocaciÃ³n de la credibilidad del conjunto de cantidades desconocidas (parÃ¡metros) de un modelo, una vez observado un conjunto de datos."
  },
  {
    "objectID": "presentaciones/presentacion_02.html#pequeÃ±o-mundo",
    "href": "presentaciones/presentacion_02.html#pequeÃ±o-mundo",
    "title": "EstadÃ­stica Bayesiana",
    "section": "PequeÃ±o mundo",
    "text": "PequeÃ±o mundo\n\nSe desea estimar la proporciÃ³n de agua que cubre el planeta Tierra. Para ello se arroja hacia arriba un â€œglobo terrÃ¡queo antiestrÃ©sâ€ y se registra la posiciÃ³n del dedo Ã­ndice al volver a tomarlo.\nSe arroja el globo 11 veces hacia arriba y se obtiene la siguiente secuencia: \\[TAAATTAATAA\\]"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-26",
    "href": "presentaciones/presentacion_02.html#section-26",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Llamemos:\n\n\n\\(\\pi\\) a la proporciÃ³n de agua en el planeta Tierra\n\\(N\\) al nÃºmero de tiradas\n\\(y\\) al nÃºmero de veces que saliÃ³ agua\n\n\n\n\\(\\pi\\) es una cantidad continua entre 0 y 1. Esta vez no la discretizaremos."
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-27",
    "href": "presentaciones/presentacion_02.html#section-27",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Prior\nÂ¿CÃ³mo asignamos una credibilidad a priori para los valores de \\(\\pi_a\\)? . . . Con una distribuciÃ³n de probabilidad.\n\n\\[\n\\pi \\sim \\mathrm{Beta}(a,b)\n\\]\n\n\n\\[\np(\\pi\\mid a,b) = p(\\pi) = \\frac{\\pi^{a-1} (1-\\pi)^{b-1}}{B(a,b)}\n\\]\n\n\n\\[\nB(a,b) = \\int_0^1 \\pi^{a-1} (1-\\pi)^{b-1} d\\pi = \\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}\n\\]\n\n\n\\[\n\\Gamma(x) = \\int_0^\\infty u^{x-1} e^{-u} du\n\\]"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-28",
    "href": "presentaciones/presentacion_02.html#section-28",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "La distribuciÃ³n beta"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-29",
    "href": "presentaciones/presentacion_02.html#section-29",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "La distribuciÃ³n beta"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-30",
    "href": "presentaciones/presentacion_02.html#section-30",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Una posible elecciÃ³n de valores para la distribuciÃ³n a priori es \\(Beta(2,2)\\)"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-31",
    "href": "presentaciones/presentacion_02.html#section-31",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Likelihood\nÂ¿CuÃ¡l es la probabilidad de observar los datos que observamos para diferentes valores del parÃ¡metro?\n\n\\[ y \\mid \\pi, N \\sim Bi(N,\\pi) \\]\n\\[p(y\\mid \\pi, N) = {N \\choose y }\\pi^y (1-\\pi)^{N-y} = p(y\\mid \\pi)\\]"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-32",
    "href": "presentaciones/presentacion_02.html#section-32",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Posterior\n\\[p(\\pi\\mid y) = \\frac{p(y\\mid \\pi)p(\\pi)}{p(y)}\\]\n\n\\[p(\\pi\\mid y) = \\frac{{N \\choose y }\\pi^y (1-\\pi)^{N-y}  \\frac{\\pi^{a-1} (1-\\pi)^{b-1}}{B(a,b)}}{\\int p(y\\mid\\pi) p(\\pi) d \\pi}\\]\n\n\nLa integral en el denominador suele ser un problema. Con dos parÃ¡metros es una integral doble, con tres parÃ¡metros, una triple, etc. Esta integral puede ser intratable intractable (no tener soluciÃ³n exacta, analÃ­tica, cerrada). No hay vaca vestida de uniforme que nos salve."
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-33",
    "href": "presentaciones/presentacion_02.html#section-33",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Recordando que: \\[\n\\mathrm{posterior} \\propto \\mathrm{prior}\\times\\mathrm{likelihood}\n\\]\n\nResulta \\[p(\\pi\\mid y) \\propto p(y\\mid\\pi) p(\\pi)\\]\n\n\n\\[p(\\pi\\mid y) \\propto {N \\choose y }\\pi^y (1-\\pi)^{N-y} \\frac{1}{B(a,b)} \\pi^{a-1}(1-\\pi)^{b-1}\\]\n\n\n\\[p(\\pi\\mid y) \\propto {N \\choose y } \\frac{1}{B(a,b)} \\pi^{(y+a)-1} (1-\\pi)^{(N-y+b)-1}\\]\n\n\n\\[p(\\pi\\mid y) = K C  \\pi^{(y+a)-1} (1-\\pi)^{(N-y+b)-1}\\]\n\n\n\\[p(\\pi\\mid y) = K^* \\pi^{(y+a)-1} (1-\\pi)^{(N-y+b)-1}\\]"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-34",
    "href": "presentaciones/presentacion_02.html#section-34",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Para que \\(\\int_0^1 p(\\pi\\mid y) d \\pi = 1\\), debe ser\n\n\\[K^* = \\frac{1}{B(y+a,N-y+b)} = \\frac{\\Gamma\\left[(y+a)+(N-y+b)\\right]}{\\Gamma(y+a)\\Gamma(N-y+b)}\\]\n\n\nPor lo tanto, resulta que la distribuciÃ³n a posteriori es Beta de parÃ¡metros \\(y+a\\) y \\(N-y+b\\)\n\\[\np(\\pi\\mid y) = \\frac{\\pi^{(y+a)-1}(1-\\pi)^{(N-y+b)-1}}{B(y+a,N-y+b)}\n\\]\n\\[\n\\pi\\mid y \\sim  Beta(y+a,N-y+b)\n\\]"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#quÃ©-hicimos",
    "href": "presentaciones/presentacion_02.html#quÃ©-hicimos",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Â¿QuÃ© hicimos?",
    "text": "Â¿QuÃ© hicimos?\n\nNos las arreglamos para encontrar la soluciÃ³n exacta al problema de inferir el parÃ¡metro de una distribuciÃ³n binomial a partir del nÃºmero de Ã©xitos observados.\n\n\nEl prior y el posterior tienen la misma forma distribucional. Esto ocurre por la elecciÃ³n del prior y el likelihood."
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-35",
    "href": "presentaciones/presentacion_02.html#section-35",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Una distribuciÃ³n \\(\\mathcal{F}\\) se dice conjugada de una verosimilitud \\(\\mathcal{L}\\) si cuando la distribuciÃ³n a priori es \\(\\mathcal{F}\\), la distribuciÃ³n a posteriori tambiÃ©n es \\(\\mathcal{F}\\)"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#pequeÃ±o-mundo-1",
    "href": "presentaciones/presentacion_02.html#pequeÃ±o-mundo-1",
    "title": "EstadÃ­stica Bayesiana",
    "section": "PequeÃ±o mundo",
    "text": "PequeÃ±o mundo\n\nSe desea estimar la proporciÃ³n de agua que cubre el planeta Tierra. Para ello se arroja hacia arriba un â€œglobo terrÃ¡queo antiestrÃ©sâ€ y se registra la posiciÃ³n del dedo Ã­ndice al volver a tomarlo.\nSe arroja el globo 11 veces hacia arriba y se obtiene la siguiente secuencia: \\[TAAATTAATAA\\]\n\n\n\\[\n\\begin{align*}\n    y\\mid\\pi & \\sim  Bi(N,\\pi)\\\\\n    \\pi & \\sim  Beta(a,b)\n\\end{align*}\n\\]"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-36",
    "href": "presentaciones/presentacion_02.html#section-36",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "con \\(N=11\\), \\(a=2\\) y \\(b=2\\).\nAl observar \\(y=7\\) resulta\n\\[\\pi\\mid y \\sim Beta(a+y,b+N-y)\\] \\[p(\\pi\\mid y) = Beta(2+7,2+4)\\]"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#mÃ¡s-ejemplos",
    "href": "presentaciones/presentacion_02.html#mÃ¡s-ejemplos",
    "title": "EstadÃ­stica Bayesiana",
    "section": "MÃ¡s ejemplos",
    "text": "MÃ¡s ejemplos\nQueremos estimar la probabilidad \\(\\pi\\) de que salga cara al arrojar una moneda.\n\nCredibilidad a priori: \\(Beta(2,2)\\)\n\n\nÂ¿CÃ³mo cambia nuestra creencia siâ€¦\n\nâ€¦realizamos 6 tiradas y observamos 4 caras?\nâ€¦realizamos 60 tiradas y observamos 40 caras?\nâ€¦realizamos 2 tiradas y observamos 2 caras?\nâ€¦realizamos 40 tiradas y observamos 40 caras?\nâ€¦realizamos 4 tiradas y obtenemos 3 caras y luego realizamos 2 tiradas mÃ¡s y observamos 1 caras?"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-38",
    "href": "presentaciones/presentacion_02.html#section-38",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "\\(\\pi \\mid y \\sim Beta(2+4,2+2)\\)\n\\(\\pi \\mid y \\sim Beta(2+40,2+20)\\)\n\\(\\pi \\mid y \\sim Beta(2+2,2+0)\\)\n\\(\\pi \\mid y \\sim Beta(2+40,2+0)\\)\n\\(\\pi \\mid y \\sim Beta((2+3)+1,(2+1)+1)\\)"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-39",
    "href": "presentaciones/presentacion_02.html#section-39",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "4 caras en 6 tiradas"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-40",
    "href": "presentaciones/presentacion_02.html#section-40",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "40 caras en 60 tiradas"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-41",
    "href": "presentaciones/presentacion_02.html#section-41",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "2 caras en 2 tiradas"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-42",
    "href": "presentaciones/presentacion_02.html#section-42",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "40 caras en 40 tiradas"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-43",
    "href": "presentaciones/presentacion_02.html#section-43",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "3 caras en 4 tiradas, luego 1 cara en 2 tiradas"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#caracterÃ­sticas-generales",
    "href": "presentaciones/presentacion_02.html#caracterÃ­sticas-generales",
    "title": "EstadÃ­stica Bayesiana",
    "section": "CaracterÃ­sticas generales",
    "text": "CaracterÃ­sticas generales\nLa inferencia bayesiana presenta ciertas caracterÃ­sticas que se repiten independientemente de las distribuciones elegidas."
  },
  {
    "objectID": "presentaciones/presentacion_02.html#compromiso",
    "href": "presentaciones/presentacion_02.html#compromiso",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Compromiso",
    "text": "Compromiso\nVamos a formalizar lo que observamos en el ejemplo para el modelo Betaâ€“Binomial. Para esto serÃ¡ Ãºtil el siguiente resultado:\n\\[\\text{Si } X\\sim Beta(a,b)\\]\n\\[\\mathbb{E}({X}) = \\frac{a}{a+b}\\]"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-44",
    "href": "presentaciones/presentacion_02.html#section-44",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "La distribuciÃ³n a priori es \\(Beta(a,b)\\) y la distribuciÃ³n a posteriori es \\(Beta(y+a,N-y+b)\\). La media del es:\n\\[\n\\begin{align*}\n\\mathbb{E}[{p(\\pi\\mid y)}] & = \\frac{y+a}{a+b+N} \\\\\n& = \\frac{y}{a+b+N} + \\frac{a}{a+b+N} \\\\\n& = \\frac{N}{a+b+N}\\frac{y}{N} + \\frac{a+b}{a+b+N} \\frac{a}{a+b} \\\\\n& = \\frac{N}{a+b+N}\\frac{y}{N} + \\frac{a+b}{a+b+N} \\mathbb{E}{[P(\\pi)]}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-45",
    "href": "presentaciones/presentacion_02.html#section-45",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "La distribuciÃ³n a posteriori representa un balance (promedio ponderado o combinaciÃ³n convexa) entre la proporciÃ³n observada y la proporciÃ³n esperada a priori. Hay un shrinkage hacia la media del prior."
  },
  {
    "objectID": "presentaciones/presentacion_02.html#secuencialidad",
    "href": "presentaciones/presentacion_02.html#secuencialidad",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Secuencialidad",
    "text": "Secuencialidad\nSi primero observamos \\(y_1\\) en \\(N_1\\) y luego observamos \\(y_2\\) en \\(N_2\\)â€¦ Con el primer conjunto de datos pasamos del prior al posterior y luego esa distribuciÃ³n se convierte en el nuevo prior:\n\n\\[Beta(a,b) \\rightarrow Beta(y_1 + a, N_1 - y_1 + b)\\]\n\n\n\\[Beta(y_1 + a, N_1 - y_1 + b) \\rightarrow Beta(y_2 + y_1 + a,N_2 - y_2 + N_1 - y_1 + b)\\]\n\n\n\\[Beta(a,b) \\rightarrow Beta((y_1+y_2) + a, (N_1+N_2) - (y_1+y_2) + b)\\]\n\n\nEs idÃ©ntico a observar \\(y_1+y_2\\) en \\(N_1+N_2\\)"
  },
  {
    "objectID": "presentaciones/presentacion_02.html#section-46",
    "href": "presentaciones/presentacion_02.html#section-46",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "La Regla de Bayes permite combinar dos fuentes de informaciÃ³n: la informaciÃ³n a priori (lo que sabemos hasta el momento), y la nueva informaciÃ³n (representada por la verosimilitud). La distribuciÃ³n a posteriori representa un compromiso entre la verosimilitud de los datos y la credibilidad a priori."
  },
  {
    "objectID": "presentaciones/presentacion_08.html#introducciÃ³n",
    "href": "presentaciones/presentacion_08.html#introducciÃ³n",
    "title": "EstadÃ­stica Bayesiana",
    "section": "IntroducciÃ³n",
    "text": "IntroducciÃ³n\nConsideremos el siguiente modelo: \\[\n\\begin{align*}\n    y\\mid\\pi & \\sim  \\mathrm{Bi}(N_i,\\pi)\\\\\n    \\pi & \\sim  Beta(a,b)\n\\end{align*}\n\\]"
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section",
    "href": "presentaciones/presentacion_08.html#section",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Sabemos (gracias al TP2) que la funciÃ³n de densidad de la distribuciÃ³n beta se puede expresar en tÃ©rminos de su moda \\(\\omega\\) y su concentraciÃ³n \\(\\kappa\\)\n\\[\n\\begin{align*}\n    y\\mid\\pi & \\sim  \\mathrm{Bi}(N,\\pi)\\\\\n    \\pi & \\sim  Beta(\\omega(\\kappa-2)+1,\\ (1-\\omega)(\\kappa-2)+1)\n\\end{align*}\n\\]\nEl valor de \\(\\pi\\) depende del valor de \\(\\omega\\). Lo sabÃ­amos, despuÃ©s de todo, \\(\\omega\\) y \\(\\kappa\\) son las constantes de ajuste del prior o hiperparÃ¡metros. \\(\\kappa\\) refleja el grado de credibilidad a priori sobre los valores de \\(\\pi\\) (alrededor de \\(\\omega\\))."
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-1",
    "href": "presentaciones/presentacion_08.html#section-1",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Â¿QuÃ© pasa si \\(\\omega\\) no es fijo sino otro parÃ¡metro a estimar?\n\nEn el contexto de una moneda: \\(\\pi\\) es la probabilidad de cara de la moneda y \\(\\omega\\) es el valor de probabilidad de cara al que el fabricante de monedas le apunta en la construcciÃ³n. \\(\\kappa\\) (fijo y conocido) es una medida de la dispersiÃ³n que tiene el proceso de fabricaciÃ³n (de lo consistente que es este proceso) o, en otros tÃ©rminos, mide el grado de asociaciÃ³n entre \\(\\pi\\) y \\(\\omega\\).\n\n\nÂ¿QuÃ© necesitamos para \\(\\omega\\)? Digamos que, a priori, \\(\\omega \\sim \\mathrm{Beta}(A_\\omega,B_\\omega)\\)\n\n\n\\[\n\\begin{align*}\n    y\\mid\\pi & \\sim  \\mathrm{Bi}(N,\\pi)\\\\\n    \\pi \\mid \\omega & \\sim  \\mathrm{Beta}(\\omega(\\kappa-2)+1,\\ (1-\\omega)(\\kappa-2)+1) \\\\\n    \\omega & \\sim \\mathrm{Beta}(A_\\omega,B_\\omega)\n\\end{align*}\n\\]\nÂ¿CuÃ¡ntos parÃ¡metros tiene este modelo?"
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-2",
    "href": "presentaciones/presentacion_08.html#section-2",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Es un modelo de dos parÃ¡metros (hay una distribuciÃ³n conjunta a priori y una distribuciÃ³n conjunta a posteriori) pero no como el \\(\\mu\\) y el \\(\\sigma\\) de una distribuciÃ³n normal o el \\(\\beta_0\\) y \\(\\beta_1\\) de un modelo de regresiÃ³n linealâ€¦\nÂ¿CÃ³mo funciona el modelo hacia adelante? \\(\\omega \\rightarrow \\pi \\rightarrow y\\) (\\(\\omega\\) influye en el valor de \\(y\\) solo a travÃ©s de \\(\\pi\\))\nÂ¿Y el razonamiento inverso? De \\(N\\) tiradas podemos hacer una inferencia sobre \\(\\pi\\), lo que nos permitirÃ¡ hacer una inferencia sobre \\(\\omega\\)"
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-3",
    "href": "presentaciones/presentacion_08.html#section-3",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Â¿QuÃ© distribuciÃ³n a posteriori buscamos? \\(p(\\pi,\\omega\\mid y)\\)\nÂ¿Y la Regla de Bayes? Â¿Vale? Â¿CÃ³mo la escribimos?\n\\[p(\\pi,\\omega\\mid y) = \\frac{p(y\\mid\\pi,\\omega)p(\\pi,\\omega)}{p(y)} = \\frac{p(y\\mid\\pi)p(\\pi\\mid\\omega)p(\\omega)}{p(y)}\\]\nÂ¿Tenemos forma de expresar \\(p(y\\mid\\pi)\\), \\(p(\\pi\\mid\\omega)\\), y \\(p(\\omega)\\)?"
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-4",
    "href": "presentaciones/presentacion_08.html#section-4",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Estamos haciendo inferencia bayesiana sobre una distribuciÃ³n conjunta (de \\(\\pi\\) y \\(\\omega\\)). Pero la relaciÃ³n entre los parÃ¡metros (y la funciÃ³n de verosimilitud) es jerÃ¡rquica. La jerarquÃ­a tiene una interpretaciÃ³n para el modelo."
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-5",
    "href": "presentaciones/presentacion_08.html#section-5",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "pi <- seq(0,1,length.out=101)\nomega <- seq(0,1,length.out=101)\nA_omega <- 2\nB_omega <- 2\nkappa <- 5\nN <- 9\ny <- 3"
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-6",
    "href": "presentaciones/presentacion_08.html#section-6",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "prior <- expand.grid(pi = pi, omega = omega) |>\n  mutate(p_omega = dbeta(omega, A_omega, B_omega),\n         p_pi_given_omega = dbeta(pi, omega*(kappa-2)+1, (1-omega)*(kappa-2)+1),\n         prior = p_pi_given_omega * p_omega)\n\nplot_prior <- ggplot(prior) +\n  geom_raster(aes(x=pi, y=omega, fill=prior)) +\n  geom_hline(yintercept = 0.6) +\n  geom_hline(yintercept = 0.9) +\n  scale_x_continuous(expression(pi), expand = c(0,0)) +\n  scale_y_continuous(expression(omega), expand = c(0,0)) +\n  viridis::scale_fill_viridis()\n\nplot_prior_omega <- ggplot(prior) +\n  geom_line(aes(x=omega, y=p_omega))\n\nplot_prior_pi_omega1 <- ggplot(prior |> filter(omega == 0.6)) +\n  geom_line(aes(x=pi, y=prior)) +\n  xlab(expression(pi))\n\nplot_prior_pi_omega2 <- ggplot(prior |> filter(omega == 0.9)) +\n  geom_line(aes(x=pi, y=prior)) +\n  xlab(expression(pi))"
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-8",
    "href": "presentaciones/presentacion_08.html#section-8",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "likelihood <- expand.grid(pi = pi, omega = omega) |>\n  mutate(likelihood = dbinom(y, size = N, prob = pi))\n\nplot_likelihood <- ggplot(likelihood) +\n  geom_raster(aes(x=pi, y=omega, fill=likelihood)) +\n  scale_x_continuous(expression(pi), expand = c(0,0)) +\n  scale_y_continuous(expression(omega), expand = c(0,0)) +\n  viridis::scale_fill_viridis()\n\nposterior <- inner_join(prior,likelihood) |>\n  mutate(posterior = prior * likelihood)\n\nplot_posterior <- ggplot(posterior) +\n  geom_raster(aes(x=pi, y=omega, fill=posterior)) +\n  scale_x_continuous(expression(pi), expand = c(0,0)) +\n  scale_y_continuous(expression(omega), expand = c(0,0)) +\n  viridis::scale_fill_viridis()"
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-10",
    "href": "presentaciones/presentacion_08.html#section-10",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "pi <- seq(0,1,length.out=101)\nomega <- seq(0,1,length.out=101)\nA_omega <- 20\nB_omega <- 20\nkappa <- 10\nN <- 9\ny <- 3"
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-13",
    "href": "presentaciones/presentacion_08.html#section-13",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "La inferencia bayesiana en un modelo jerÃ¡rquico es inferencia en el espacio de la distribuciÃ³n conjunta de los parÃ¡metros pero reformulando la distribuciÃ³n conjunta en tÃ©rminos jerÃ¡rquicos: se refactoriza \\(p(\\pi,\\omega)\\) como \\(p(\\pi\\mid\\omega)p(\\omega)\\)"
  },
  {
    "objectID": "presentaciones/presentacion_08.html#extensiÃ³n",
    "href": "presentaciones/presentacion_08.html#extensiÃ³n",
    "title": "EstadÃ­stica Bayesiana",
    "section": "ExtensiÃ³n",
    "text": "ExtensiÃ³n\nÂ¿QuÃ© pasarÃ­a si contamos con mÃ¡s de una moneda creada por la misma fÃ¡brica? Cada moneda tiene un valor de \\(\\pi_s\\) que es propio y que a su vez tienen algo en comÃºn: provienen de la fÃ¡brica que tiene parÃ¡metro \\(\\omega\\).\nCon \\(y_1\\) caras en \\(N_1\\) tiradas de la moneda 1 estimamos \\(\\pi_1\\), con \\(y_2\\) caras en \\(N_2\\) tiradas de la moneda 1 estimamos \\(\\pi_2\\)â€¦ y luego, con todas las tiradas, podemos estimar \\(\\omega\\)."
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-14",
    "href": "presentaciones/presentacion_08.html#section-14",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Consideremos un caso real. \\(S\\) personas reciben una droga y son sometidos a un test de memoria. La probabilidad de que el sujeto \\(s\\) recuerde un Ã­tem que se le muestra es \\(\\pi_s\\). El sujeto \\(s\\) recuerda \\(y_s\\) Ã­tems de \\(N_s\\) que se le presentan. Asumimos que la droga induce un efecto en los sujetos alrededor de una tendencia central \\(\\omega\\).\nConsideremos por simplicidad que se tienen dos sujetosâ€¦\nÂ¿CuÃ¡ntos parÃ¡metros tiene el modelo? Â¿CÃ³mo podemos representar la relaciÃ³n entre los \\(\\theta_s\\)?"
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-15",
    "href": "presentaciones/presentacion_08.html#section-15",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "\\[\n\\begin{align*}\n    y_s\\mid\\pi_s & \\sim  \\mathrm{Bi}(N_s,\\pi_s)\\\\\n    \\pi_s \\mid \\omega & \\sim  \\mathrm{Beta}(\\omega(\\kappa-2)+1,\\ (1-\\omega)(\\kappa-2)+1) \\\\\n    \\omega & \\sim \\mathrm{Beta}(A_\\omega,B_\\omega)\n\\end{align*}\n\\]\nSi fijo \\(\\omega\\), los valores de los \\(\\pi_s\\) son independientes: \\(\\pi_1\\) y \\(\\pi_2\\) son independientes dado \\(\\omega\\).\nLa probabilidad a priori que es \\(p(\\pi_1,\\pi_2,\\omega)\\) ahora puede factorizarse como \\(p(\\pi_1,\\pi_2\\mid \\omega) p(\\omega) = p(\\pi_1\\mid \\omega) p(\\pi_2\\mid \\omega) p(\\omega)\\)"
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-16",
    "href": "presentaciones/presentacion_08.html#section-16",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "pi_1 <- seq(0,1,length.out=101)\npi_2 <- seq(0,1,length.out=101)\nomega <- seq(0,1,length.out=101)\nA_omega <- 2\nB_omega <- 2\nkappa <- 5\nN_1 <- 20\ny_1 <- 5\nN_2 <- 8\ny_2 <- 4"
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-17",
    "href": "presentaciones/presentacion_08.html#section-17",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "prior <- expand.grid(pi_1 = pi_1, pi_2 = pi_2, omega = omega) |>\n  mutate(\n    p_omega = dbeta(omega, A_omega, B_omega),\n    p_pi1_given_omega = dbeta(pi_1, \n                              omega*(kappa-2)+1, \n                              (1-omega)*(kappa-2)+1),\n    p_pi2_given_omega = dbeta(pi_2, \n                              omega*(kappa-2)+1, \n                              (1-omega)*(kappa-2)+1),\n    prior = p_pi1_given_omega *  p_pi2_given_omega * p_omega)\n\nprior_pi1 <- ggplot(prior |> \n                      group_by(pi_1,omega) |> \n                      summarise(prior = sum(prior))) +\n  geom_raster(aes(x=pi_1, y=omega, fill=prior)) +\n  scale_x_continuous(expression(pi[1]), expand = c(0,0)) +\n  scale_y_continuous(expression(omega), expand = c(0,0)) +\n  viridis::scale_fill_viridis()\n\nprior_pi2 <- ggplot(prior |> \n                      group_by(pi_2,omega) |> \n                      summarise(prior = sum(prior))) +\n  geom_raster(aes(x=pi_2, y=omega, fill=prior)) +\n  scale_x_continuous(expression(pi[2]), expand = c(0,0)) +\n  scale_y_continuous(expression(omega), expand = c(0,0)) +\n  viridis::scale_fill_viridis()"
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-19",
    "href": "presentaciones/presentacion_08.html#section-19",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "likelihood <- expand.grid(pi_1 = pi_1, pi_2 = pi_2, omega = omega) |>\n  mutate(likelihood_pi1 = dbinom(y_1, size = N_1, prob = pi_1),\n         likelihood_pi2 = dbinom(y_2, size = N_2, prob = pi_2),\n         likelihood = likelihood_pi1 * likelihood_pi2)\n\nlikelihood1 <- ggplot(likelihood |> \n                        group_by(pi_1,omega) |> \n                        summarise(likelihood = sum(likelihood))) +\n  geom_raster(aes(x=pi_1, y=omega, fill=likelihood)) +\n  scale_x_continuous(expression(pi[1]), expand = c(0,0)) +\n  scale_y_continuous(expression(omega), expand = c(0,0)) +\n  viridis::scale_fill_viridis()\n\nlikelihood2 <- ggplot(likelihood |> \n                        group_by(pi_2,omega) |> \n                        summarise(likelihood = sum(likelihood))) +\n  geom_raster(aes(x=pi_2, y=omega, fill=likelihood)) +\n  scale_x_continuous(expression(pi[2]), expand = c(0,0)) +\n  scale_y_continuous(expression(omega), expand = c(0,0)) +\n  viridis::scale_fill_viridis()"
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-21",
    "href": "presentaciones/presentacion_08.html#section-21",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "posterior <- inner_join(prior, likelihood) |>\n  mutate(posterior = prior * likelihood)\n\nposterior_pi1 <- ggplot(posterior |> \n                          group_by(pi_1,omega) |> \n                          summarise(posterior = sum(posterior))) +\n  geom_raster(aes(x=pi_1, y=omega, fill=posterior)) +\n  scale_x_continuous(expression(pi[1]), expand = c(0,0)) +\n  scale_y_continuous(expression(omega), expand = c(0,0)) +\n  viridis::scale_fill_viridis()\n\nposterior_pi2 <- ggplot(posterior |> \n                          group_by(pi_2,omega) |> \n                          summarise(posterior = sum(posterior))) +\n  geom_raster(aes(x=pi_2, y=omega, fill=posterior)) +\n  scale_x_continuous(expression(pi[2]), expand = c(0,0)) +\n  scale_y_continuous(expression(omega), expand = c(0,0)) +\n  viridis::scale_fill_viridis()\n\nposterior_omega <- ggplot(posterior |> \n                            group_by(omega) |> \n                            summarise(posterior = sum(posterior))) +\n  geom_line(aes(x=omega, y=posterior)) +\n  xlab(expression(omega))\n\nposterior_pi1_marg <- ggplot(posterior |> \n                               group_by(pi_1) |> \n                               summarise(posterior = sum(posterior))) +\n  geom_line(aes(x=pi_1, y=posterior)) +\n  xlab(expression(pi[1]))\n\nposterior_pi2_marg <- ggplot(posterior |> \n                               group_by(pi_2) |> \n                               summarise(posterior = sum(posterior))) +\n  geom_line(aes(x=pi_2, y=posterior)) +\n  xlab(expression(pi[2]))"
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-24",
    "href": "presentaciones/presentacion_08.html#section-24",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "La funciÃ³n de verosimilitud no depende de \\(\\omega\\)\nLa funciÃ³n de verosimilitud es mÃ¡s estrecha para el sujeto 1 que para el sujeto 2\nEl posterior marginal de \\(\\pi_1\\) estÃ¡ cerca de la proporciÃ³n muestral\nEl posterior marginal de \\(\\pi_2\\) estÃ¡ cerca de la proporciÃ³n muestral\nEl posterior marginal de \\(\\pi_1\\) tiene menos incertidumbre que el de \\(\\pi_2\\)\n\n\nÂ¿QuÃ© ocurre si se cambia el valor de \\(\\kappa\\)?"
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-25",
    "href": "presentaciones/presentacion_08.html#section-25",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "pi_1 <- seq(0,1,length.out=101)\npi_2 <- seq(0,1,length.out=101)\nomega <- seq(0,1,length.out=101)\nA_omega <- 2\nB_omega <- 2\nkappa <- 100\nN_1 <- 20\ny_1 <- 5\nN_2 <- 8\ny_2 <- 4"
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-30",
    "href": "presentaciones/presentacion_08.html#section-30",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "El posterior marginal de \\(\\pi_2\\) se alejÃ³ de la proporciÃ³n muestral. El sujeto 1 tenÃ­a un tamaÃ±o de muestra mayor (mÃ¡s evidencia) y por lo tanto influyÃ³ mÃ¡s en la estimaciÃ³n de \\(\\omega\\), lo que a la vez influye en la estimaciÃ³n de \\(\\pi_2\\)."
  },
  {
    "objectID": "presentaciones/presentacion_08.html#shrinkage",
    "href": "presentaciones/presentacion_08.html#shrinkage",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Shrinkage",
    "text": "Shrinkage\nLa estructura jerÃ¡rquica de los modelos hace que las estimaciones de los parÃ¡metros de los niveles mÃ¡s bajos se acerquen mÃ¡s de lo que lo harÃ­an si no hubiera una distribuciÃ³n en un nivel superior. Esto es lo que se conoce como shrinkage de las estimaciones.\nLas estimaciones de los parÃ¡metros de los niveles mÃ¡s bajos son tiradas (pulled) o se estrechan o tienden a concentrarse hacia la moda de la distribuciÃ³n superior."
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-31",
    "href": "presentaciones/presentacion_08.html#section-31",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "El shrinkage ocurre porque los parÃ¡metros de los niveles bajos (los \\(\\pi_s\\)) son influenciados por:\n\n\nEl conjunto de datos que dependen directamente de ese parÃ¡metro\nLos parÃ¡metros de niveles mÃ¡s altos de los cuales dependen los parÃ¡metros de niveles mÃ¡s bajos (Â¡y que son afectados por todos los datos!)\n\n\n\nPor ejemplo, sobre \\(\\pi_1\\) influyen \\(y_1\\) y \\(N_1\\) pero tambiÃ©n \\(\\omega\\) (cuya estimaciÃ³n depende de \\(\\pi_2\\) y \\(N_2\\)).\n\n\nNota: el shrinkage es consecuencia exclusivamente de la estructura jerÃ¡rquica (y no de la inferencia bayesiana). Existe en la teorÃ­a clÃ¡sica de estimaciÃ³n (ver estimador de James-Stein)"
  },
  {
    "objectID": "presentaciones/presentacion_08.html#otro-ejemplo",
    "href": "presentaciones/presentacion_08.html#otro-ejemplo",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Otro ejemplo",
    "text": "Otro ejemplo\nEl radÃ³n es un gas radioactivo y cancerÃ­geno. Los productos de la desintegraciÃ³n del radÃ³n son tambiÃ©n radioactivos y en altas concentraciones se sabe que producen cÃ¡ncer de pulmÃ³n. Trabajaremos con datos de mediciones de radÃ³n en el estado de Minnesota. Se cuenta con mediciones en hogares de diferentes condados dentro del estado."
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-33",
    "href": "presentaciones/presentacion_08.html#section-33",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "\\(i\\) es el Ã­ndice de los hogares\n\\(Y_i\\) es el nivel de radÃ³n (log radÃ³n) del hogar \\(i\\)\n\\(j\\) (entre \\(1\\) y \\(J\\)) es el Ã­ndice de los condados\n\\(j[i] = \\mathrm{county}[i]\\) es el condado al que pertenece el hogar \\(i\\)"
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-35",
    "href": "presentaciones/presentacion_08.html#section-35",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Complete pooling\n\\[\n\\begin{align*}\n    Y_i\\mid\\mu_i,\\sigma & \\sim  \\mathcal{N}(\\mu_i,\\sigma^2) \\\\\n    \\mu_i & = \\alpha  \\\\\n    \\alpha & \\sim  P(\\alpha) \\\\\n    \\sigma & \\sim  P(\\sigma)\n\\end{align*}\n\\]\nHay una Ãºnica media \\(\\alpha\\) comÃºn para todos los \\(i\\), independientemente del grupo \\(j\\) al que pertenezcan"
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-36",
    "href": "presentaciones/presentacion_08.html#section-36",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "No pooling\n\\[\n\\begin{align*}\n    Y_i\\mid\\mu_i,\\sigma & \\sim  \\mathcal{N}(\\mu_i,\\sigma^2)\\\\\n    \\mu_i & = \\alpha_{j[i]}  \\\\\n    \\alpha_j & \\sim  P(\\alpha_j) \\\\\n    \\sigma & \\sim  P(\\sigma)\n\\end{align*}\n\\]\nDecimos que los \\(Y_i\\) tienen distribuciÃ³n de media \\(\\alpha_{j[i]}\\), sin imponer ninguna restricciÃ³n sobre los \\(\\alpha_j\\). \\(P(\\alpha_j)\\) es una distribuciÃ³n no informativa (muy ancha y chata). Todos los \\(\\alpha_j\\) son independientes. Coincide con la estimaciÃ³n clÃ¡sica que incluye una variable dummy para cada grupo."
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-37",
    "href": "presentaciones/presentacion_08.html#section-37",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Podemos mejorar el modelo anterior incorporando un prior que regularice los \\(\\alpha_j\\)\n\\[\\begin{align*}\n    Y_i\\mid\\mu_i,\\sigma & \\sim  \\mathcal{N}(\\mu_i,\\sigma^2) \\\\\n    \\mu_i & = \\alpha_{j[i]}  \\\\\n    \\alpha_j & \\sim  \\mathcal{N}(0,10) \\\\\n    \\sigma & \\sim  P(\\sigma)\n\\end{align*}\\]\n0 y 10 son valores arbitrarios para la media y la varianza de la distribuciÃ³n a priori de los \\(\\alpha_j\\). Los \\(\\alpha_j\\) dejan de poder ser estimados libremente. Hay regularizaciÃ³n y tendemos a evitar el overfitting. Hay un partial pooling. Si en lugar de 10 se elige un valor mÃ¡s grande, tendemos a no pooling; si se elige un valor mÃ¡s chico, tendemos a pooling completo"
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-38",
    "href": "presentaciones/presentacion_08.html#section-38",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Mejor aÃºn, podemos estimar el grado de regularizaciÃ³n partir de los datos. Â¿CuÃ¡nto pooling es necesario? Se estima a partir de los datosâ€¦\n\\[\\begin{align*}\n    Y_i\\mid\\mu_i,\\sigma & \\sim  \\mathcal{N}(\\mu_i,\\sigma^2) \\\\\n    \\mu_i & = \\alpha_{j[i]}  \\\\\n    \\alpha_j & \\sim  \\mathcal{N}(\\mu_\\alpha,\\sigma_\\alpha^2) \\\\\n    \\sigma & \\sim  P(\\sigma) \\\\\n    \\mu_\\alpha & \\sim  P(\\mu_\\alpha) \\\\\n    \\sigma_\\alpha & \\sim  P(\\sigma_\\alpha) \\\\\n\\end{align*}\\]"
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-39",
    "href": "presentaciones/presentacion_08.html#section-39",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "\\(\\mu_\\alpha\\) y \\(\\sigma_\\alpha\\) son hiperparÃ¡metros (parÃ¡metros de la distribuciÃ³n de a priori de los parÃ¡metros) y por lo tanto tienen hiperpriors\nEl chiste es que todos los datos se usan para estimar \\(\\mu_\\alpha\\) y \\(\\sigma_\\alpha\\) y por lo tanto en la estimaciÃ³n de cada \\(\\alpha_j\\) hay informaciÃ³n de todos los datos. La regularizaciÃ³n es adaptativa (se aprende de los datos)."
  },
  {
    "objectID": "presentaciones/presentacion_08.html#shrinkage-1",
    "href": "presentaciones/presentacion_08.html#shrinkage-1",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Shrinkage",
    "text": "Shrinkage\n\nSiempre que hay regularizaciÃ³n, hay shrinkage de parÃ¡metros.\nLos datos de un grupo ayudan en la estimaciÃ³n de los parÃ¡metros de los otros grupos (partial pooling: prÃ©stamo de informaciÃ³n).\nAsÃ­, los grupos que tienen menor tamaÃ±o de muestra toman mÃ¡s informaciÃ³n del resto de los grupos y el shrinkage es mÃ¡s intenso."
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-40",
    "href": "presentaciones/presentacion_08.html#section-40",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Pooling completo: hay una Ãºnica media para todos los individuos, independientemente del grupo. La variaciÃ³n entre los grupos es cero. Underfitting.\nNo pooling: cada grupo tiene una media independiente de la de los demÃ¡s. La variaciÃ³n entre los grupos es infinita. No se comparte informaciÃ³n entre los grupos, lo que se sabe de un grupo no ayuda a inferir sobre los demÃ¡s. Overfitting.\nPartial pooling: cada grupo tiene una media pero todas las medias estÃ¡n conectadas. Es una soluciÃ³n de compromiso, un punto medio entre pooling completo y no pooling."
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-41",
    "href": "presentaciones/presentacion_08.html#section-41",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Para algunos condados: a la izquierda estÃ¡ la estimaciÃ³n de la media no pooling de la media, a la derecha la estimaciÃ³n del modelo multinivel (pooling parcial). En lÃ­nea de trazos el pooling completo."
  },
  {
    "objectID": "presentaciones/presentacion_08.html#otro-ejemplo-1",
    "href": "presentaciones/presentacion_08.html#otro-ejemplo-1",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Otro ejemplo",
    "text": "Otro ejemplo\nCorredores que han participado varias veces de una famosa maratÃ³n en Washington. Se registraron los tiempos de los participantes."
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-45",
    "href": "presentaciones/presentacion_08.html#section-45",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "La informaciÃ³n de la estimaciÃ³n de la pendiente de un grupo es Ãºtil para estimar las otras pendientes\nLa informaciÃ³n de la estimaciÃ³n de las ordenadas al origen de un grupo es Ãºtil para estimar las otras ordenadas al origen\nLas pendientes y las ordenadas al origen trabajan de forma conjunta para describir a un corredor, covarÃ­an"
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-46",
    "href": "presentaciones/presentacion_08.html#section-46",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "\\[\\begin{align*}\n    Y_i  \\mid \\mu_i,\\sigma & \\sim  \\mathcal{N}(\\mu_i,\\sigma^2) \\\\\n    \\mu_i & = \\alpha_{j[i]} + \\beta_{j[i]} x_i \\\\\n    \\left[\\begin{array}{c}\\alpha_j\\\\\\beta_j\\end{array}\\right] & \\sim \\mathcal{N}\\left(\\left[\\begin{array}{c}\\mu_\\alpha\\\\\\mu_\\beta\\end{array}\\right],\\Sigma\\right)\n\\end{align*}\\]"
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-47",
    "href": "presentaciones/presentacion_08.html#section-47",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "\\(\\left[\\begin{array}{c}\\alpha_j\\\\\\beta_j\\end{array}\\right]\\) tienen una distribuciÃ³n conjunta, normal multivariada de hiperparÃ¡metros \\(\\left[\\begin{array}{c}\\mu_\\alpha\\\\\\mu_\\beta\\end{array}\\right]\\) y \\(\\Sigma\\). Â¡Necesitan !\n\n\\(\\Sigma\\) puede factorizarse segÃºn: \n\\[\n\\Sigma = \\left( \\begin{array}{cc} \\sigma_\\alpha^2 & \\sigma_\\alpha\\sigma_\\beta\\rho \\\\ \\sigma_\\alpha\\sigma_\\beta\\rho & \\sigma_\\beta^2 \\end{array}\\right) =\n\\left( \\begin{array}{cc} \\sigma_\\alpha & 0 \\\\ 0 & \\sigma_\\beta \\end{array}\\right) \\left( \\begin{array}{cc} 1 & \\rho \\\\ \\rho & 1 \\end{array}\\right)\n\\left( \\begin{array}{cc} \\sigma_\\alpha & 0 \\\\ 0 & \\sigma_\\beta \\end{array}\\right)\n\\]\nLlamando \\[R = \\left( \\begin{array}{cc} 1 & \\rho \\\\ \\rho & 1 \\end{array}\\right)\\] solo habrÃ­a que definir una distribuciÃ³n para \\(\\sigma_\\alpha\\), \\(\\sigma_\\beta\\) y \\(R\\) (o \\(\\rho\\))"
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-48",
    "href": "presentaciones/presentacion_08.html#section-48",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "No es solo para modelos linealesâ€¦ Se tienen 60 tanques con ranitas de la especie Hyperolius viridiflavus. Cada tanque \\(i\\) de ellos contiene una cantidad inicial de renacuajos \\(N_i\\). Al cabo de unas semanas se observa el nÃºmero \\(S_i\\) de renacuajos que sobrevivieron en el tanque \\(i\\)."
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-49",
    "href": "presentaciones/presentacion_08.html#section-49",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Se modeliza la probabilidad de supervivencia de cada tanque con una regresiÃ³n logÃ­stica:\n\\[\\begin{align*}\n    S_i  \\mid p_i & \\sim  Binomial(N_i,p_i) \\\\\n   \\log\\left( \\frac{p_i}{1-p_i} \\right) & = \\alpha_{i} \\\\\n   \\alpha_i & \\sim \\mathcal{N}(\\mu_\\alpha,\\sigma_\\alpha^2)\n\\end{align*}\\]\nObservar que no hay grupos (no hay Ã­ndice \\(j\\)), simplemente hacemos de los individuos."
  },
  {
    "objectID": "presentaciones/presentacion_08.html#section-50",
    "href": "presentaciones/presentacion_08.html#section-50",
    "title": "EstadÃ­stica Bayesiana",
    "section": "",
    "text": "Comparamos la estimaciÃ³n de \\(p_i = \\frac{e^{\\alpha_i}}{1+e^{\\alpha_i}}\\) con la obtenida por mÃ¡xima verosimilitud en cada tanque: \\(p_{i,ML} = \\frac{S_i}{N_i}\\)"
  },
  {
    "objectID": "presentaciones/presentacion_08.html#intercambiabilidad",
    "href": "presentaciones/presentacion_08.html#intercambiabilidad",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Intercambiabilidad",
    "text": "Intercambiabilidad\nSi no existe otra informaciÃ³n mÃ¡s que los datos observados \\(y_i\\) para distinguir a los individuos \\(i\\) y estos no pueden ordenarse ninguna manera entonces se puede asumir una simetrÃ­a de los parÃ¡metros. Se dice que los parÃ¡metros \\(\\theta_i\\) son intercambiables (exchangeable).\nSi las observaciones pueden agruparse y los grupos son indistinguibles (con caracterÃ­sticas propias desconocidas) con propiedades/particularidades ignoradas entonces los grupos son intercambiables y los individuos, parcialmente o condicionalmente intercambiables."
  },
  {
    "objectID": "presentaciones/presentacion_08.html#distribuciones-predictivas",
    "href": "presentaciones/presentacion_08.html#distribuciones-predictivas",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Distribuciones predictivas",
    "text": "Distribuciones predictivas\nEn los modelos jerÃ¡rquicos hay dos tipos de distribuciones predictivas a posteriori:\n\nPredicciones para individuos que pertenecen a grupos ya existentes (tiradas de la moneda con la que se realizaron las inferencias, otra tarea de memoria para un individuo que ya participÃ³ del experimento)\nPredicciones para individuos pertenecientes a grupos nuevos (tiradas de una nueva moneda de la fÃ¡brica, cÃ³mo afectarÃ­a la droga a un individuo nuevo)"
  },
  {
    "objectID": "presentaciones/presentacion_08.html#resumen",
    "href": "presentaciones/presentacion_08.html#resumen",
    "title": "EstadÃ­stica Bayesiana",
    "section": "Resumen",
    "text": "Resumen\n\nLos modelos jerÃ¡rquicos resultan atractivos para problemas en los cuales los parÃ¡metros se pueden considerar vinculados de cierta forma, por ejemplo en grupos.\nLos modelos jerÃ¡rquicos o multinivel son extensiones de los modelos lineales (y de los modelos lineales generalizados) para datos que tienen algÃºn grado de agrupamiento y en los cuales se permite que los parÃ¡metros varÃ­en por grupo\nLos modelos multinivel permiten mejorar las inferencias en contextos donde la muestra es pequeÃ±a. Si un individuo que tiene pocas observaciones pertenece a un determinado grupo, se supone que compartirÃ¡ caracterÃ­sticas con otros individuos de ese grupo y por lo tanto la estimaciÃ³n de sus parÃ¡metros podrÃ¡ ser informada por la de sus pares.\n\n\n\n\nEstadÃ­stica Bayesiana â€“ 2023"
  }
]
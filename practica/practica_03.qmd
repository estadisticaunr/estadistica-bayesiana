---
title: PrÃ¡ctica - Unidad 3
nocite: "@Martin2021, @Downey2021"
practica: "PrÃ¡ctica 3"
---

```{r}
#| echo: false
#| include: false
library(dplyr)
library(ggplot2)
library(patchwork)
is_html <- knitr::is_html_output()
options("knitr.graphics.error" = FALSE)
source(here::here("scripts", "utils.R"))
captions <- list()
captions[["monty_hall"]] <- "Las 3 puertas del problema de Monty Hall"
```

## ğŸ’» MÃ©todos Computacionales 

Esta secciÃ³n contiene una lista exhaustiva de ejercicios que requieren el uso de 
herramientas computacionales para resolver problemas que involucran una variedad de 
cÃ¡lculos, como el cÃ¡lculo de probabilidades y el cÃ¡lculo de integrales. 
Se vuelve indispensable el uso de R y se promueve el uso de buenas prÃ¡cticas de 
programaciÃ³n cientÃ­fica, como el uso de funciones compartimentar los componentes de un 
programa. 

1.  ğŸ“Œ **Â¡A calcular probabilidades! (I)**

    Sea $X \sim \text{Normal}(\mu=3, \sigma=1.2)$.

    i. Elabore un grÃ¡fico que permita visualizar la funciÃ³n de densidad de probabilidad 
    de $X$.
    i. Â¿CuÃ¡l es la probabilidad de que $X$ sea menor a 2.5?
    i. Â¿CuÃ¡l es la probabilidad de que $X$ sea mayor a 4?
    i. Â¿CuÃ¡l es la probabilidad de que $X$ sea mayor 2 y menor 3?

1.  ğŸ“Œ **Â¡A calcular probabilidades! (II)**

    Sea $X \sim \text{Beta}(\alpha=10, \beta=2)$.

    i. Elabore un grÃ¡fico que permita visualizar la funciÃ³n de densidad de probabilidad 
    de $X$.
    i. Â¿CuÃ¡l es la probabilidad de que $X$ sea menor a 0.5?
    i. Â¿CuÃ¡l es la probabilidad de que $X$ sea mayor a 0.8?
    i. Â¿CuÃ¡l es la probabilidad de que $X$ sea mayor 0.25 y menor 0.75?

1.  ğŸ“Œ **Magia blanca: Obtener probabilidades mediante simulaciÃ³n**

    Responda los dos puntos anteriores sin evaluar la funciÃ³n de densidad ni la funciÃ³n
    de distribuciÃ³n de las variables aleatorias mencionadas. Para eso genere muestras
    que provengan de las correspondientes distribuciones y utilÃ­celas para responder las 
    preguntas mencionadas. Reflexione sobre las ventajas y desventajas de utilizar un 
    enfoque basado en la simulaciÃ³n para resolver problemas.

1.  ğŸ“Œ **Media y varianza de una variable aleatoria**

    Una variable aleatoria $X$ toma valores en el conjunto $\{2, 4, 6, 8, 10\}$ con igual
    probabilidad. Encuentre la media y el desvÃ­o estÃ¡ndar de las variables $X$ e 
    $Y = 2X + 1$.
    <!-- Tal vez se puede hacer un poco mÃ¡s difÃ­cil si hacemos que la funciÃ³n sea no-lineal -->

1.  ğŸ“Œ **Probabilidades _a posteriori_**

    En un problema determinado la distribuciÃ³n _a posteriori_ de la parÃ¡metro de inteÅ•es
    $\alpha$ es $\Gamma(k=3, \theta=1.5)$, donde $k$ es el parÃ¡metro de forma y $\theta$ 
    es el parÃ¡metro de escala. Calcule la probabilidad de que $\alpha^2$ sea mayor a 10.
    <!-- https://stats.stackexchange.com/questions/154135/square-of-gamma-random-variable -->

1.  ğŸ“Œ **Probabilidades con dos variables aleatorias**

    Sean $X$ e $Y$ dos variables aleatorias independientes con distribuciÃ³n uniforme en el
    intervalo $[0, 1]$. 

    i.  Â¿CuÃ¡l es la probabilidad de que $X \le Y$?
    i.  Grafique los puntos muestreados coloreando de acuerdo a si la muestra satisface
    el evento antes mencionado o no.

1.  **Te veo en la fotocopiadora**
    
    Dos estudiantes de estadÃ­stica deciden encontrarse en la fotocopiadora de la Facultad
    entre las 10 y las 11 de la maÃ±ana, eligiendo el tiempo de llegada al azar. 
    La estudiante A esperarÃ¡ 10 minutos luego de llegar. Si el estudiante B no llega en
    ese intervalo, se irÃ¡. Lo mismo hace el estudiante B, pero este decide esperar
    14 minutos. Â¿CuÃ¡l es la probabilidad de que se produzca el encuentro en la 
    fotocopiadora entre la estudiante A y el estudiante B?

1.  ğŸ§© **Armando celulares en Tierra del Fuego**

    Una mÃ¡quina que se utiliza para ensamblar telÃ©fonos celulares en una fÃ¡brica en 
    Tierra del Fuego cuenta con tres componentes crÃ­ticos para su funcionamiento. 
    Ante una falla en cualquiera de estos componentes, la mÃ¡quina se detiene. 
    Las probabilidades de que estos elementos operen correctamente durante un dÃ­a 
    cualquiera  son $p_1 = 0.8$, $p_2 = 0.9$ y $p_3 = 0.7$. 
    Responda las siguientes preguntas utilizando tÃ©cnicas de simulaciÃ³n:

    i.  Â¿CuÃ¡l es la probabilidad de que la mÃ¡quina falle en el primer dÃ­a de uso?
    i.  Â¿CuÃ¡l es la probabilidad de que la mÃ¡quina siga funcionando luego de 10 dÃ­as?
    i.  Â¿CuÃ¡l es la probabilidad de que la mÃ¡quina falle en el dÃ­a 7 de uso?
    i.  Sea $T=$ Cantidad de dÃ­as que la mÃ¡quina funciona ininterrumpidamente. 
    Grafique la funciÃ³n de densidad de probabilidad de $T$.

1.  **Bolas infinitas**

    [Este tuit](https://twitter.com/pgroisma/status/1616137795180822528) propone un
    problema muy interesante. Una urna contiene una bola azul y una amarilla. 
    Se elije una bola al azar y se la vuelve a colocar junto con otra bola adicional 
    del mismo color. Se repite este proceso indefinidamente. 
    Â¿QuÃ© ocurre con la proporciÃ³n de bolas azules en la urna a medida que 
    repetimos mÃ¡s y mÃ¡s veces?

    i. Tiende a 1/2.
    i. Tiende a 0 Ã³ a 1.
    i. No se estabiliza.
    i. Ninguna de las anteriores.

    Escriba un programa en R para responder esta pregunta utilizando simulaciones.
    Genere grÃ¡ficos que faciliten la comprensiÃ³n del resultado.
    <!-- https://twitter.com/pgroisma/status/1616820135313932288 -->

1.  ğŸ“Œ **Estimando el valor de** $\pi$

    Imagine un cÃ­rculo de radio $r$ y un cuadrado de lado $2r$, ambos centrados en el 
    mismo punto, que de manera arbitraria puede ser el punto $(0, 0)$. Obtenga muestras
    de una distribuciÃ³n uniforme en el plano $(x, y)$, cuyo dominio estÃ¡ acotado por 
    el cuadrado antes mencionado. Para cada muestra extraida, determine si se encuentra 
    dentro del cÃ­rculo o no -- todos las muestras se encontrarÃ¡n dentro del cuadrado. 
    Utilice esta informaciÃ³n para estimar el valor de $\pi$.
    
    ```{r circulo-cuadrado-pi}
    #| warning: false
    #| echo: false
    #| fig-width: 4.5
    #| fig-height: 4.5
    #| fig-align: center
    centro <- c(0, 0)
    radio <- 1
    angulos <- seq(0, 2 * pi, length.out = 512)

    x_circulo <- centro[1] + radio * cos(angulos)
    y_circulo <- centro[2] + radio * sin(angulos)

    x_cuadrado <- c(
        seq(-1, 1, length.out = 128),
        rep(1, 128),
        seq(1, -1, length.out = 128),
        rep(-1, 128)
    )
    y_cuadrado <- c(
        rep(1, 128), 
        seq(1, -1, length.out = 128), 
        rep(-1, 128), 
        seq(-1, 1, length.out = 128)
    )

    x <- c(x_circulo)
    y <- c(y_circulo)
    figura <- rep(c("circulo", "cuadrado"), each = 512)
        
    df <- data.frame(x = x, y = y, figura = figura)
    ggplot(df) + 
        geom_hline(yintercept = 0, linetype = "dashed", color = "#999999") +
        geom_vline(xintercept = 0, linetype = "dashed", color = "#999999") +
        geom_path(aes(x = x, y = y), linewidth = 1.25, color = "#0984C0") +
        geom_rect(
            xmin = -1, xmax = 1, ymin = -1, ymax = 1, 
            fill = NA, color = "#999999", linewidth = 1.25
        )
    ```

    Algunos datos Ãºtiles

    * Area de un cÃ­rculo: $\pi \cdot r^2$.
    * Area de un cuadrado: $a^2$, donde $a$ es la longitud del lado.

1.  **Los puntos uniformes**

    Se seleccionan dos puntos de manera uniforme e independiente dentro de un cÃ­rculo. 
    Â¿CuÃ¡l es la probabilidad de que la distancia entre dos puntos sea menor al radio?

    i.  Resuelva el problema utilizando R.
    i.  Elabore una visualizaciÃ³n que facilite la comunicaciÃ³n de los resultados.

    ::: {.callout-tip collapse="true"}

    ## Ayuda
    
    TO DO Algo sobre como simular de una uniforme en 2d
    
    :::

1.  **Sobre el histÃ³rico 7 a 1 del 2014**

    En la Copa del Mundo de la FIFA 2014, Alemania jugÃ³ contra Brasil en la semifinal. 
    Los alemanes hicieron el primer gol a los 11 minutos y el segundo a los 23.
    Asuma que el tiempo entre goles sigue una distribuciÃ³n exponencial. 
    Elija una distribuciÃ³n _a priori_ para el tiempo entre goles (puede ser conjugada o 
    no). En ese momento del partido,

    i. Â¿CuÃ¡l es la distribuciÃ³n _a posteriori_ del tiempo entre goles de Alemania?
    i. Â¿CuÃ¡ntos goles cabrÃ­a esperar que Alemania hiciera al finalizar los 90 minutos?
    i. Â¿CuÃ¡l era la probabilidad de que Alemania hiciera mÃ¡s de 5 goles (cosa que ocurriÃ³)?
    <!-- http://allendowney.github.io/ThinkBayes2/chap08.html -->

1.  ğŸ’» **Â¿TendrÃ© que esperar mucho?**

    El tiempo que un empleado de recursos humanos demora en hacer una entrevista tiene
    distribuciÃ³n exponencial con media 30 minutos. Los tiempos de duraciÃ³n de cada 
    entrevista se pueden considerar independientes entre sÃ­. 
    Las entrevistas a postulantes para un trabajo estÃ¡n programadas cada 15 minutos, 
    comenzando desde las 8. Es vÃ¡lido considerar que todos los postulantes llegan 
    puntuales a su entrevista. Cuando la persona del turno de las 8:15 llega a la oficina

    i. Â¿CuÃ¡l es la probabilidad de que tenga que esperar antes de ser entrevistada?
    i. Â¿CuÃ¡l es el horario esperado al que terminarÃ¡ su entrevista?
    <!-- Modern Data Science with R -->

1.  ğŸ§© **Â¡QuÃ© casualidad!**
    
    Dos personas se conocen en la fila de embarque para un vuelo en un aviÃ³n Airbus A330-300. 
    Considere que el Airbus A330-300 tiene 30 filas de 2-4-2 asientos.

    i. Â¿CuÃ¡l es la probabilidad de que tengan asientos en la misma fila?
    i. Â¿CuÃ¡l es la probabilidad de que estÃ©n sentados en asientos adyacentes?

1.  âœï¸ ğŸ’» ğŸ“Œ **El Problema de Monty Hall**

    El Problema de Monty Hall es un problema de probabilidad basado en un juego del
    concurso televisivo estadounidense "Trato hecho". 
    En este problema, el concursante debe elegir una puerta entre tres, todas cerradas. 
    El premio consiste en llevarse lo que se encuentra detrÃ¡s de la elegida. 
    Se sabe con certeza que tras una de ellas se oculta un automÃ³vil, y tras las otras dos 
    hay cabras. Una vez que el concursante haya elegido una puerta y comunicado su elecciÃ³n a 
    los presentes, el presentador, que sabe lo que hay detrÃ¡s de cada puerta, abrirÃ¡ una de las
    otras dos en la que haya una cabra. A continuaciÃ³n, le da la opciÃ³n al concursante de 
    cambiar, si lo desea, de puerta (tiene dos opciones). 
    Â¿Debe el concursante mantener su elecciÃ³n original o escoger la otra puerta? 
    Â¿Hay alguna diferencia? Resuelva este ejercicio utilizando simulaciones.
    <!-- Modern Data Science with R -->

    ```{r}
    #| echo: false
    #| out-width: 70%
    #| fig-align: center
    #| fig-cap: !expr captions[["monty_hall"]]
    if (is_html) knitr::include_graphics(file.path("imgs", "monty_hall.png"))
    ```

1.  ğŸ’» **Que los cumplan feliz**

    BasÃ¡ndose en el [siguiente tuit](https://twitter.com/Kit_Yates_Maths/status/1542767039814713346)
    y conociendo el problema del cumpleaÃ±os (Â¿cuÃ¡ntas personas debe
    haber en una habitaciÃ³n para que la probabilidad de que dos de ellas
    cumplan aÃ±os el mismo dÃ­a sea mayor a X%?) construir un grÃ¡fico
    similar al del tuit donde se grafique la probabilidad de que haya
    $n$ personas que cumplan aÃ±os el mismo dÃ­a para $K$ personas
    presentes en la habitaciÃ³n.

1.  ğŸ’» **QuÃ© suerte, Â¿no?**
    
    Previo a la final de la Copa AmÃ©rica 2021, los jugadores de la SelecciÃ³n Argentina se
    reÃºnen en la habitaciÃ³n del hotel como se describe en 
    [este tuit](https://twitter.com/PlanetaDeCABJ/status/1587925636869300224).

    i. Â¿CuÃ¡l es la probabilidad de que un jugador adivine una de diez cartas?
    i. Â¿CuÃ¡l es la probabilidad de que tres de ellos adivinen una de diez cartas?

1.  **El Ã¡lbum del CampeÃ³n**

    El Ã¡lbum oficial del Mundial de FÃºtbol de Qatar 2022 consta de 638 figuritas. 
    Cada paquete trae cinco figuritas.

    i. Comprando cinco paquetes, Â¿cuÃ¡l es la probabilidad de tener a Messi?
    i. Comprando cinco paquetes, Â¿cuÃ¡l es la probabilidad de sacar a Messi repetido?
    i. Â¿CuÃ¡ntos paquetes se necesitan, en promedio, para completar el Ã¡lbum?
    i. Si a una persona le faltan diez figuritas para completar el Ã¡lbum, 
    Â¿cuÃ¡ntos paquetes tiene que comprar para asegurarse de lograrlo?

1.  ğŸ’» **Â¿Que tÃ¡n raras son estas secuencias raras?**

    Si se arroja una moneda $n$ veces, Â¿cuÃ¡l es la probabilidad de que no haya secuencias 
    de $k$ caras?

1.  ğŸ“Œ **Un viaje por el elevador**

    Â¿CuÃ¡l es la probabilidad de que tres personas en un ascensor con doce pisos presionen 
    para ir a tres pisos consecutivos? Â¿QuÃ© supuestos realiza para resolver el problema?
    EscrÃ­balos en una lista de manera explÃ­cita.
   
1.  **La vida es muy corta como para perderla ordenando medias**
    
    Un cajÃ³n contiene 10 pares de medias. No hay dos pares iguales. 
    Por fiaca, el dueÃ±o de las medias no las agrupa despuÃ©s de lavarlas y simplemente las
    pone en el cajÃ³n. Al momento de necesitar un par de medias, saca una tras una hasta 
    que se forma un par. En promedio, Â¿cuÃ¡ntas medias sacarÃ¡ hasta encontrar un par?
    <!-- https://fivethirtyeight.com/features/can-you-find-a-matching-pair-of-socks/ -->
    
1.  **Â¿Vale la pena hacer un ensayo clÃ­nico a gran escala?**

    Dados los resultados de un estudio piloto, la probabilidad _a posteriori_ de que la droga
    desarrollada por tu compaÃ±Ã­a sea mas efectiva que el tratamiento actual es $\theta \in [0, 1]$.
    Tu compaÃ±Ã­a estÃ¡ considerando realizar un ensayo clÃ­nico a gran escala para confirmar que
    la droga que desarrollan es de hecho mejor. El costo del estudio es **\$X**. 
    Si la droga es mejor, la probabilidad de que esto se confirme en el ensayo es del 80%.
    Si la droga no es mejor, hay una probabilidad del 5% de que el estudio confirme que es mejor.
    Si el ensayo sugiere que tu droga es mejor, ganarÃ¡s **\$cX**. 
    Â¿Para quÃ© valores de $\theta$ y $c$ tiene sentido realizar el estudio?
    <!-- @Reich2020 -->

1.  **El problema de concordancia**

    Resuelva el problema de concordancia de de Montmort presentado en la **PrÃ¡ctica 0**
    utilizando simulaciones.
    <!-- Blitzstein, Introdudction to Probability -->

1.  **El problema de los sobres**

    Resuelva el problema de los dos sobres presentado en la **PrÃ¡ctica 0** utilizando 
    simulaciones.

1.  ğŸ§© **IntegraciÃ³n por muestreo**

    Calcule las siguientes integrales utilizando muestras.

    i. $\displaystyle \int_{-\infty}^{\infty}{\frac{x^2}{\sqrt{2\pi}}\exp \left(-\frac{x^2}{2} \right)dx}$
    i. $\displaystyle \int_{1}^{\infty}{\frac{x^3}{\sqrt{2\pi}}\exp \left(-\frac{x^2}{2} \right)dx}$
    i. $\displaystyle \int_{1}^{\infty}{\frac{x^6}{\sqrt{2\pi}}\exp \left(-\frac{x^2 - 4x}{2} \right)dx}$
    i. $\displaystyle \int_{1}^{10}{x^6\frac{e^{-x^4/2}}{\sqrt{2\pi}}dx}$
    <!-- @Lambert2018 Capitulo 9 -->

1.  Â¿CuÃ¡l es la distribuciÃ³n de muestreo aproximada al usar muestreo independiente para 
    evaluar integrales?
    <!-- @Lambert2018 Capitulo 9 -->

## ğŸ’» AproximaciÃ³n de una distribuciÃ³n mediante una grilla 

En esta parte de la prÃ¡ctica se comienza a utilizar tÃ©cnicas computacionales que se 
asocian directamente a la prÃ¡ctica de la estadÃ­stica bayesiana. Los problemas tienen como 
objetivo la familiarizaciÃ³n con el uso prÃ¡ctico de estas tÃ©cnicas y la comprensiÃ³n de sus 
caracterÃ­sticas principales.

1. ğŸ“Œ **AproximaciÃ³n de grilla**

    Se tiene un experimento binomial donde $n=80$ y se observan $y=7$ Ã©xitos. 
    Considere que el _prior_ de la probabilidad de Ã©xito $\theta$ es $\text{Beta}(2, 10)$.

    i. Obtenga la distribuciÃ³n _a posteriori_ de $\theta$ de manera analÃ­tica y grafÃ­quela.
    i. Obtenga la distribuciÃ³n _a posteriori_ de $\theta$ utilizando el mÃ©todo de la 
    grilla en base a una grilla de 10 puntos y dibuje la curva obtenida en el grÃ¡fico 
    creado anteriormente.
    i. Repita el proceso del punto anterior utilizando una grilla de 100 puntos.
    i. Concluya sobre la fidelidad de las aproximaciones. Â¿Considera que es necesario
    utilizar una grilla mÃ¡s densa? Â¿CuÃ¡les serÃ­an las ventajas y desventajas?

1. ğŸ“Œ **CÃ¡lculo de probabilidades en base a la grilla (I)**

    En base al _posterior_ obtenido en el ejercicio anterior mediante el mÃ©todo de la 
    grilla calcule las siguientes probabilidades

    * $P(\theta < 0.7)$.
    * $P(\theta > 0.05)$.
    * $P(0.05 < \theta < 0.15)$.

    De ser necesario, obtenga el _posterior_ mediante una grilla de mayor densidad.

1. ğŸ“Œ **CÃ¡lculo de probabilidades en base a la grilla (II)**

    Utilice los valores de la grilla y sus probabilidades _a posteriori_ para obtener
    muestras del _posterior_ y calcular las mismas probabilidades que en el ejercicio
    anterior en base a muestras. Ayuda: Para obtener muestras utilice la funciÃ³n `sample()`.

1.  ğŸ“Œ **AproximaciÃ³n de grilla en 2 dimensiones**

    Sean dos variables aleatorias continuas $X$ e $Y$ tales que $(X, Y) \in \mathbb{R}^2$,
    y sea el siguiente modelo de regresiÃ³n lineal simple:

    $$
    \begin{aligned}
    \alpha &\sim \text{Normal}(0, 1.5) \\
    \beta  &\sim \text{Normal}(0, 2) \\
    Y      &\sim \text{Normal}(\alpha + \beta X, 0.8)
    \end{aligned}
    $$

    i. Obtenga el _posterior_ conjunto del vector de parÃ¡metros $[\alpha, \beta]^T$ 
    mediante el mÃ©todo de la grilla. Elabore un grÃ¡fico que permita visualizar esta 
    distribuciÃ³n.
    i. Obtenga el _posterior_ marginal de $\alpha$ y grafÃ­quelo.
    i. Obtenga el _posterior_ marginal de $\beta$ y grafÃ­quelo.
    i. Calcule la probabilidad de que el intercepto sea mayor a 0.95.
    i. Calcule la probabilidad de que la pendiente sea menor a -2.
    
    Para responder las consignas utilice los datos simulados que se obtienen con el 
    siguiente bloque de cÃ³digo:

    ```{r}
    set.seed(121195)
    alpha <- 1
    beta <- -2
    sigma <- 0.8
    n <- 80
    x <- rnorm(n)
    y <- rnorm(n, alpha + beta * x, sigma)
    df <- data.frame(x = x, y = y)
    ```

    **Bonus:** Â¿CÃ³mo podrÃ­a responder las consignas (ii)-(v) utilizando muestras del 
    _posterior_? 

    ```{r scatterplot-lin-reg}
    #| eval: false
    #| warning: false
    #| echo: false
    #| fig.width: 5.5
    #| fig.height: 4.5
    #| fig.align: center
    # Generar grÃ¡fico de dispersiÃ³n para ver los datos
    plt <- ggplot(df, aes(x = x, y = y)) +
        geom_point(alpha = 0.6, fill = "gray60", size = 2)
    plt
    ```

    ```{r}
    #| eval: false
    #| warning: false
    #| echo: false
    #| fig.width: 5.5
    #| fig.height: 4.5
    #| fig.align: center

    # Esto es una posible soluciÃ³n a la primera parte
    grid_a <- seq(0.5, 1.5, length.out = 50)
    grid_b <- seq(-2.5, -1.5, length.out = 50)
    grid_df <- expand.grid(grid_a, grid_b)

    names(grid_df) <- c("a", "b")
    likelihood <- numeric(nrow(grid_df))
    posterior <- numeric(nrow(grid_df))

    # No se que problema hay si lo hago con `mutate()` que todo queda en 0.
    for (i in seq_along(likelihood)) {
        likelihood[i] <- prod(dnorm(y, grid_df$a[i] + grid_df$b[i] * x, sigma))
    }
    posterior <- (
        likelihood 
        * dnorm(grid_df$a, mean = 0, sd = 1.5) # alpha ~ Normal(0, 1.5)
        * dnorm(grid_df$b, mean = 0, sd = 2)   # beta ~ Normal(0, 2)
    )

    grid_df$likelihood <- likelihood
    grid_df$posterior <- posterior

    plt <- ggplot(grid_df, aes(x = a, y = b)) +
        geom_raster(aes(fill = posterior)) +
        stat_contour(aes(z = posterior), col = "white", bins = 5) +
        geom_point(x = alpha, y = beta, color = "black", fill = "red", size = 3, pch = 21) + 
        labs(x = expression(alpha), y = expression(beta)) +
        viridis::scale_fill_viridis() + 
        theme(legend.position = "none")
    plt
    ```

1.  ğŸ“Œ **Escalando la aproximaciÃ³n de la grilla**

    Suponga que se tiene que estimar un _posterior_ utilizando la aproximaciÃ³n mediante
    una grilla de 200 puntos en cada dimensiÃ³n. Calcule cÃºantas veces se tiene que evaluar
    el posterior en cada uno de los siguientes escenarios:

    i. 1 dimensiÃ³n.
    i. 2 dimensiones.
    i. 3 dimensiones.
    i. 5 dimensiones.
    i. 10 dimensiones.

    Concluya sobre las ventajas y desventajas de la aproximaciÃ³n de la grilla teniendo
    en cuenta sus caracterÃ­sticas conforme se incrementa el nÃºmero de dimensiones del
    _posterior_.

1.  **_Benchmark_ de la aproximaciÃ³n de la grilla**
    
    El siguiente bloque de cÃ³digo define una funciÃ³n llamada `create_and_eval_grid()` 
    que evalÃºa la funciÃ³n de densidad normal en una cantidad arbitraria dimensiones. 
    El argumento `dimension_n` indica la dimensionalidad de la distribuciÃ³n normal, y 
    `grid_n` indica la cantidad de puntos en la grilla de cada dimensiÃ³n. Debajo, 
    se utiliza la funciÃ³n `mark()` del paquete `{bench}` para comparar el desempeÃ±o de la
    funciÃ³n `create_and_eval_grid()` con diferentes nÃºmeros de dimensiones.

    ```{r}
    #| eval: false
    create_and_eval_grid <- function(dimension_n, grid_n = 100) {
        grid <- seq(-3, 3, length.out = grid_n)
        grids <- replicate(dimension_n, grid, simplify = FALSE)
        df <- expand.grid(grids, KEEP.OUT.ATTRS = FALSE)
        Mu <- rep(0, dimension_n)
        Sigma <- diag(dimension_n)
        mvtnorm::dmvnorm(df, mean = Mu, sigma = Sigma)
    }
    bench::mark(
        create_and_eval_grid(1),
        create_and_eval_grid(2),
        check = FALSE,
        max_iterations = 500
    )
    ```

    Modifique el cÃ³digo brindado para evaluar la funciÃ³n de densidad en hasta un mÃ¡ximo
    de 10 dimensiones. Concluya sobre el tiempo de ejecuciÃ³n, el consumo de memoria, y 
    otras cantidades que se encuentren en la salida y crea adecuadas para el anÃ¡lisis.

<!-- 
TO DO

1.  Grid approximation para una _skew-normal_. Estimar los parÃ¡metros $\xi$ (posiciÃ³n), 
    $\omega$ (escala) y $\alpha$ (asimetrÃ­a).
    
    $$
    f(x) = \frac{2}{\omega} \phi\left(\frac{x-\xi}{\omega}\right)\Phi\left( \alpha \frac{x-\xi}{\omega} \right)
    $$
    https://en.wikipedia.org/wiki/Skew_normal_distribution 

-->

## ğŸ’» **Metropolis-Hastings** {#sec-mh}

<!--
Copio algunos pasajes del libro porque la verdad me parece super claro. 
Puede ser Ãºtil para la presentaciÃ³n de teorÃ­a.
Although not as efficient as independent sampling, dependent sampling is easier to 
implement, and only requires calculation of the un-normalised posterior, avoiding the 
troublesome denominator term

We also know that MCMC is typically used to do dependent sampling. It is called Monte Carlo 
because the decision of where to step next involves a random component

In this chapter we see that there are two components to this decision: 
in the first, we choose _where_ to propose a next step from the current position; 
in the second, we choose _whether_ we accept this step or stay where we are
@Lambert2018
-->

<!--
El algoritmo Metropolis es un caso especial del algoritmo general Metropolis-Hastings 
(Hoff, 2009). La principal diferencia es que el algoritmo Metropolis-Hastings no tiene el 
requisito de distribuciÃ³n simÃ©trica.
-->

En esta secciÃ³n, se profundiza en la prÃ¡ctica de uno de los algoritmos fundamentales de la
inferencia estadÃ­stica bayesiana: el algoritmo de Metropolis-Hastings. 

1.  ğŸ“Œ **Muestreo utilizando el algoritmo de Metropolis-Hastings (I)** 

    Use el algoritmo de Metropolis-Hastings y una distribuciÃ³n de propuesta 
    $\text{Normal}(0, 0.1)$ para obtener 5000 muestras de las siguientes distribuciones 
    de probabilidad:

    i. $\text{Normal}(\mu = 3, \sigma = 6)$.
    i. $\text{StudentT}(\nu = 5)$.
    i. $\frac{2}{3}\text{Normal}(\mu = 0, \sigma = 0.5) + \frac{1}{3}\text{Normal}(\mu = 3, \sigma = 2)$.

    Grafique las distribuciones obtenidas utilizando un histograma o una estimaciÃ³n
    de densidad y superponga la funciÃ³n de densidad verdadera para realizar una
    comparaciÃ³n. Concluya sobre la similitud de las mismas y la aptitud de la distribuciÃ³n
    de propuesta utilizada.

1.  ğŸ“Œ **Simplificando el algoritmo de Metropolis-Hastings**
    
    La distribuciÃ³n de propuesta utilizada en el ejercicio anterior goza de una propiedad
    que permite simplificar el algoritmo de Metropolis-Hastings.

    i. Â¿CuÃ¡l es esta propiedad?
    i. Â¿QuÃ© simplificaciÃ³n se puede hacer?
    i. Â¿QuÃ© nombre recibe la versiÃ³n simplificada del algoritmo?
    i. Implemente la versiÃ³n simplificada del algoritmo de Metropolis-Hastings y obtenga
    nuevamente 5000 muestras para las distribuciones presentadas en el ejercicio anterior
    utilizando la nueva implementaciÃ³n.

1.  ğŸ“Œ **Muestreo utilizando el algoritmo de Metropolis-Hastings (II)**

    Use el algoritmo de Metropolis-Hastings y una distribuciÃ³n de propuesta que crea
    conveniente para obtener 5000 muestras de las siguientes distribuciones de 
    probabilidad:

    i. $\text{Beta}(\alpha=4, \beta=8)$.
    i. $\text{Gamma}(k = 3, \theta = 2)$.
    i. $\frac{1}{2}\text{Beta}(\alpha=10, \beta=3) + \frac{1}{2}\text{Beta}(\alpha=3, \beta=10)$.

    Realice un anÃ¡lisis similar al realizado en el Ejercicio 1.

1.  **Â¡A jugar con la distribuciÃ³n de propuesta!**

    Suponga que se desea obtener muestras de una distribuciÃ³n $\text{Normal}(4, 1)$ 
    utilizando Metropolis-Hastings y la siguiente distribuciÃ³n de propuesta:

    $$
    \mu' | \mu \sim \text{Uniforme}(\mu - w, \mu + w)
    $$

    Obtenga $n=5000$ muestras con $w \in \{0.01, 1, 100\}$ y compute la probabilidad de
    aceptaciÃ³n. Luego, para cada $w$, grafique la distribuciÃ³n obtenida y visualice la 
    cadena de Markov utilizando un _traceplot_.

    * Â¿CÃ³mo se relaciona $w$ con el desempeÃ±o del muestreo?
    * Â¿CÃ³mo se relaciona $w$ con la probabilidad de aceptaciÃ³n? Justifique su respuesta
    utilizando la ecuaciÃ³n del criterio de aceptaciÃ³n.


1.  ğŸ“Œ [**Modelo Normal-Normal**]{#ex-mh-mm}

    Se desea estudiar el tiempo promedio que los estudiantes de estadÃ­stica dedican por
    semana a la materia EstadÃ­stica Bayesiana. Para eso se propone utilizar un
    modelo Normal-Normal, con $\sigma=1.2$ conocido.

    i. Elija una distribuciÃ³n _a priori_ para el parÃ¡metro $\mu$. 
    i. Describa el modelo matemÃ¡ticamente.
    i. Determine una distribuciÃ³n de propuesta adecuada para este problema. Explique.
    i. Obtenga 2000 muestras del _posterior_ de $\mu$. Ajuste los parÃ¡metros de la 
    distribuciÃ³n de propuesta hasta que los resultados se vean adecuados.
    i. Grafique un histograma de las muestras obtenidas y concluya sobre el desempeÃ±o 
    de la aproximaciÃ³n.

    Para resolver este problema utilice los datos que se leen con el siguiente codigo:

    ```{r}
    #| eval: false
    url <- paste0(
        "https://raw.githubusercontent.com/estadisticaunr/",
        "estadistica-bayesiana/main/datos/tiempo-estudio-eb.csv"
    )
    df_estudio <- readr::read_csv(url)
    ```

1.  ğŸ“Œ [**Modelo Beta-Binomial**]{#ex-mh-bb}

    Se desea estimar el _posterior_ del parÃ¡metro $\pi$ en el siguiente modelo 
    Beta-Binomial:

    $$
    \begin{aligned}
    Y &\sim \text{Binomial}(n, \pi) \\
    \pi &\sim \text{Beta}(2, 3)
    \end{aligned}
    $$

    Se observan $n=10$ ensayos de Bernoulli y se registran $y=3$ Ã©xitos. Determine una 
    distribuciÃ³n de propuesta adecuada y obtenga muestras de la distribuciÃ³n 
    _a posteriori_ del parÃ¡metro $\pi$ utilizando el algoritmo de Metropolis-Hastings.

    De ser necesario, ajuste los parÃ¡metros de la distribuciÃ³n de propuesta. 

1.  ğŸ“Œ **Modelo Poisson**

    En el ejercicio **Â¡Ostras! Â¡Estoy haciendo inferencia bayesiana!** de la PrÃ¡ctica 1
    se reportÃ³ que la cantidad de especies marinas bivalvas descubiertas cada aÃ±o entre 
    2010 y 2015 fue 64, 13, 33, 18, 30 y 20.

    Sea $Y_t$ la cantidad de especies descubiertas en el aÃ±o $2009 + t$ (e.g. $Y_1 = 64$ 
    es el conteo para el aÃ±o 2010) y el siguiente modelo:

    $$
    \begin{aligned}
    Y_t        &\sim \text{Poisson}(\lambda_t) \\
    \lambda_t  &= \exp (\alpha + \beta t) \\
    \alpha     &\sim \text{Normal}(0, 10^2) \\
    \beta      &\sim \text{Normal}(0, 10^2)
    \end{aligned}
    $$

    Ajuste el modelo utilizando Metropolis-Hastings y verifique la convergencia de las 
    cadenas de Markov.
    <!-- @Reich2020 3.10/3.11  -->

1.  ğŸ“Œ **Metropolis-Hastings multivariado**

    Use el algoritmo de Metropolis Hastings para obtener 1000 muestras de la distribuciÃ³n
    $\text{MVN}(\boldsymbol{\mu}, \boldsymbol{\Sigma})$ donde

    $$
    \begin{array}{cc}
        \boldsymbol{\mu} = \begin{bmatrix}1.2 \\ 0.8 \end{bmatrix}, &
        \boldsymbol{\Sigma} = \begin{bmatrix}3 & 0.2 \\ 0.2 & 2 \end{bmatrix}
    \end{array}
    $$

    Utilice una distribuciÃ³n de propuesta $\text{MVN}(\boldsymbol{0}_2, \boldsymbol{I}_2\sigma)$
    con $\sigma = 0.2$.

1.  ğŸ“Œ **Metropolis-Hastings para regresiÃ³n**

    Repita el ejercicio **AproximaciÃ³n de grilla en 2 dimensiones** pero utilice 
    Metropolis-Hastings para obtener muestras del _posterior_ en vez del mÃ©todo de
    la grilla.

<!-- 1.  **DemostraciÃ³n sobre la distribuciÃ³n estacionaria**
    
    Demostrar que la distribuciÃ³n estacionaria del algoritmo de Metropolis-Hastings es
    la distribuciÃ³n objetivo $p(\boldsymbol{\theta} | \boldsymbol{y})$ -->

<!--
TO DO

## **Hamiltonian Monte Carlo (HMC) y el Not-U-Turn Sampler (NUTS)**

Tenemos que completarlo...
-->

## **DiagnÃ³sticos**

El uso de algoritmos de MCMC provee de un gran poder que conlleva una gran responsabilidad.
En los ejercicios de esta secciÃ³n ya se cuenta con un _posterior_ y se busca evaluar
la fiabilidad de las muestras utilizando diferentes medidas de diagnÃ³stico anÃ¡liticas
y grÃ¡ficas.

1.  ğŸ“Œ **Describir medidas de diagnÃ³stico (I)**
    
    En sus propias palabras, explique que son $\text{ESS}$, $\hat{R}$ y $\text{MCSE}$. 
    Considere:

    * Â¿QuÃ© miden?
    * Â¿QuÃ© potencial problema de MCMC detectan?
    <!-- @Martin2021 2E2 -->

1.  ğŸ“Œ **Describir medidas de diagnÃ³stico (II)**

    En sus propias palabras, explique por quÃ© las tÃ©cnicas de estimaciÃ³n del _posterior_
    basadas en MCMC necesitan diagnÃ³sticos de convergencia.
    En particular, contraste estos con los mÃ©todos conjugados descritos en la Unidad 2 
    que no necesitan esos diagnÃ³sticos. 
    Â¿QuÃ© es diferente entre los dos mÃ©todos de inferencia?
    <!-- @Martin2021 2E8 -->

1.  ğŸ“Œ **Problemitas de MCMC**

    Para cada escenario de simulaciÃ³n mediante MCMC descrito a continuaciÃ³n, explique 
    cÃ³mo el escenario podrÃ­a afectar la aproximaciÃ³n del _posterior_.

    * La cadena se mezcla muy lentamente.
    * La cadena presenta alta auto-correlaciÃ³n.
    * La cadena tiende a quedarse "trabada".
    <!-- @Johnson2021 Exercise 6.3  -->

1.  ğŸ“Œ **Vamos de paseo**

    Elabore _traceplots_ que le permitan visualizar la traza de la cadena de Markov
    utilizada en el ejercicio [**Modelo Normal-Normal**](#ex-mh-mm) de la secciÃ³n 
    [**Metropolis-Hastings**](#sec-mh). 
    
    Luego, repita el ejercicio utilizando 4 cadenas independientes y grafique sus trazas
    en un mismo grÃ¡fico. Â¿QuÃ© puede concluir sobre la convergencia y la mezcla de las 
    cadenas?

1.  ğŸ“Œ [**Primeros pasitos con $\hat{R}$**]{#ex-diag-pprhat}

    Repita lo realizado en el ejercicio [**Modelo Beta-Binomial**](#ex-mh-bb) de la 
    secciÃ³n [**Metropolis-Hastings**](#sec-mh) utilizando 4 cadenas independientes. Luego:

    i. Calcule la varianza intra-cadenas $W$.
    i. Calcule la varianza entre-cadenas $B$.
    i. Calcule $\hat{R}$ y concluya sobre el resultado obtenido.

    <!-- **NOTA:** No hay una Ãºnica alternativa de $\hat{R}$ dando vueltas por ahÃ­. EstÃ¡
    la versiÃ³n de BDA3, que entiendo que es la misma que la del libro de Lambert, pero hoy
    se estÃ¡ recomendando una versiÃ³n "rank-normalized". Ver [este paper](https://projecteuclid.org/journals/bayesian-analysis/advance-publication/Rank-Normalization-Folding-and-Localization--An-Improved-R%CB%86-for/10.1214/20-BA1221.full)
    y esta [discusiÃ³n](https://statmodeling.stat.columbia.edu/2019/03/19/maybe-its-time-to-let-the-old-ways-die-or-we-broke-r-hat-so-now-we-have-to-fix-it/) -->

1.  **$\hat{R}$ para un muestreo independiente**

    En un determinado problema se encuentra que el _posterior_ del parÃ¡metro $\pi$ de un
    modelo con verosimilitud binomial estÃ¡ dado por

    $$
    \pi | \boldsymbol{y} \sim \text{Beta}(12, 6)
    $$

    i. Obtenga 4 conjuntos independientes de 1000 muestras independientes de esta 
    distribuciÃ³n.
    i. Calcule $W$, $B$, y $\hat{R}$ considerando que cada conjunto representa una cadena.
    i. Explique el resultado de $\hat{R}$.

    **Bonus**

    i. Â¿Se puede concluir que cada uno de los muestreos realizados representan 
    realizaciones de una cadena de Markov? Â¿Por quÃ©?
    i. Â¿Por quÃ© no fue necesario descartar un conjunto de muestras de _warm-up_?

1.  ğŸ“Œ **FunciÃ³n de autocorrelaciÃ³n**

    Utilice las 4 cadenas obtenidas en el ejercicio 
    [**Primeros pasitos con $\hat{R}$**](#ex-diag-pprhat) y grafique la funciÃ³n de 
    autocorrelaciÃ³n y calcule el coeficiente de autocorrelaciÃ³n utilizando un rezago
    unitario. Concluya sobre la dependencia entre las muestras obtenidas.

1.  ğŸ“Œ **TamaÃ±o de muestra efectivo**

    Utilice las muestras obtenidas en el ejercicio anterior para calcular el tamaÃ±o
    de muestra efectivo. 

1.  **Experimentos con el tamaÃ±o de muestra efectivo**

    Suponga una distribuciÃ³n $\text{Normal}(0, 1^2)$. Obtenga $n$ muestras independientes
    utilizando `rnorm()` y $n$ muestras dependientes utilizando Metropolis-Hastings 
    con $n \in \{10, 50, 100, 500, 1000, 10000\}$. 
    
    i. Calcule el temaÃ±o de muestra efectivo en todos los escenarios simulados.
    i. Describa el comportamiento del tamaÃ±o de muestra efectivo conforme se incrementa
    el nÃºmero de muestras.
    i. Â¿Por quÃ© se observan los comportamientos descritos?

1.  ğŸ“Œ **Â¡Rompan todo! Un caso simulado**

    Los siguientes grÃ¡ficos muestran las trazas y las distribuciones que resultan al 
    obtener muestras de un _posterior_ utilizando dos cadenas de Markov independientes. 
    Estos muestreos fueron realizados de manera que presenten algunos problemas. 
    Describa cuales son los problemas que puede observar en los siguientes grÃ¡ficos y 
    explique por quÃ© no utilizarÃ­a estas muestras para obtener conclusiones sobre
    el _posterior_.
    
    ```{r}
    #| warning: false
    #| echo: false
    set.seed(121195)
    STEPS <- 200
    x <- rep(seq(STEPS), times = 2)

    plot_trace_and_histogram <- function(df) {
        plt_lines <- ggplot(df, aes(x = x, y = y, color = chain)) +
            geom_line(linewidth = 1.2) + 
            labs(x = "NÃºmero de muestra", y = "Valor") + 
            guides(color = guide_legend(title = NULL)) +
            theme(
                legend.position = "top",
                legend.text = element_text(size = 12)
            )
        
        plt_hist <- ggplot(df, aes(y = y, fill = chain)) +
            geom_histogram(bins = 40, alpha = 0.7, position = "identity") +
            theme(
                axis.title = element_blank(),
                axis.text = element_blank(),
                axis.ticks = element_blank(),
                legend.position = "none"
            )
        plt <- plt_lines + plt_hist + plot_layout(widths = c(5, 1))
        return(plt)
    } 
    ```

    ```{r trace-and-histogram-1}
    #| warning: false
    #| echo: false
    #| fig-width: 8
    #| fig-height: 4.5
    #| fig-align: center
    #| fig-cap: GrÃ¡fico 1
    y1 <- rnorm(STEPS)
    y2 <- rnorm(STEPS) + 5
    chain <- rep(c("Cadena 1", "Cadena 2"), each = STEPS)
    df <- data.frame(x = x, y = c(y1, y2), chain = chain)
    plot_trace_and_histogram(df)
    ```

    ```{r trace-and-histogram-2}
    #| warning: false
    #| echo: false
    #| fig-width: 8
    #| fig-height: 4.5
    #| fig-align: center
    #| fig-cap: GrÃ¡fico 2
    y1 <- 0.035 * seq(STEPS) + rnorm(STEPS, sd = 0.4)
    y2 <- -0.035 * seq(STEPS) + rnorm(STEPS, sd = 0.4) + 5
    chain <- rep(c("Cadena 1", "Cadena 2"), each = STEPS)
    df <- data.frame(x = x, y = c(y1, y2), chain = chain)
    plot_trace_and_histogram(df)
    ```

    ```{r trace-and-histogram-3}
    #| warning: false
    #| echo: false
    #| fig-width: 8
    #| fig-height: 4.5
    #| fig-align: center
    #| fig-cap: GrÃ¡fico 3
    y1 <- 0.035 * seq(STEPS) + rnorm(STEPS, sd = 0.4)
    y2 <- 0.035 * seq(STEPS) + rnorm(STEPS, sd = 0.4) + 5
    chain <- rep(c("Cadena 1", "Cadena 2"), each = STEPS)
    df <- data.frame(x = x, y = c(y1, y2), chain = chain)
    plot_trace_and_histogram(df)
    ```

    ```{r trace-and-histogram-4}
    #| warning: false
    #| echo: false
    #| fig-width: 8
    #| fig-height: 4.5
    #| fig-align: center
    #| fig-cap: GrÃ¡fico 4
    set.seed(121195)
    y1 <- cumsum(rnorm(STEPS, sd = 0.5))
    y2 <- cumsum(rnorm(STEPS, sd = 0.15)) + 5
    chain <- rep(c("Cadena 1", "Cadena 2"), each = STEPS)
    df <- data.frame(x = x, y = c(y1, y2), chain = chain)
    plot_trace_and_histogram(df)
    ```

1.  ğŸ“Œ **Â¡Rompan todo! Un caso real**

    Al igual que en el ejercicio anterior, se presentan _traceplots_ donde el muestreo del
    _posterior_ presenta problemas. En este caso, los grÃ¡ficos que se observan fueron 
    obtenidos en el marco de un problema real, y se usan 4 cadenas en vez de 2. 
    Nuevamente, describa cuales son los problemas que puede observar en los siguientes 
    grÃ¡ficos y explique por quÃ© no utilizarÃ­a estas muestras para obtener conclusiones 
    sobre el _posterior_.

    ```{r}
    #| echo: false
    #| out-width: 100%
    #| fig-align: center
    #| fig-cap: GrÃ¡fico 1
    knitr::include_graphics(file.path("imgs", "posterior_rota.png"))
    ```
    
    ```{r}
    #| echo: false
    #| out-width: 100%
    #| fig-align: center
    #| fig-cap: GrÃ¡fico 2
    knitr::include_graphics(file.path("imgs", "posterior_rota_2.png"))
    ```

    AdemÃ¡s, responda:

    i. Â¿CuÃ¡l grÃ¡fico se asocia a un mayor tamaÃ±o de muestra efectivo?
    i. Â¿QuÃ© grafico muestra peor mezcla entre cadenas?
    i. Â¿En quÃ© grÃ¡fico se puede observar que las cadenas convergen a la misma distribuciÃ³n?

## **ProgramaciÃ³n probabilÃ­stica - Stan y RStan**

En esta secciÃ³n se comienza a utilizar Stan para realizar los cÃ¡lculos relacionados a la
inferencia bayesiana. Stan es uno de los lenguajes de programaciÃ³n probabilÃ­stica mas 
potentes y populares en la actualidad. Los ejercicios contienen modelos estadÃ­sticos que
deben ser resueltos con la interface de `Stan` a R, `{RStan}`.

1.  ğŸ“Œ **MCMC con RStan: Precalentamiento (I)**

    Utilice la informaciÃ³n proporcionada para definir la estructura del modelo bayesiano 
    utilizando `{RStan}`. No es necesario ejecutar nada, solo necesita proporcionar el 
    cÃ³digo correcto.

    i. $Y | \pi \sim \text{Binomial}(\pi, 20)$ con $\pi \sim \text{Beta}(1, 1)$.
    i. $Y | \lambda \sim \text{Poisson}(\lambda)$ con $\lambda \sim \text{Gamma}(4, 2)$.
    i. $Y | \mu \sim \text{Normal}(\mu, 1^2)$ con $\mu \sim \text{Normal}(0, 10^2)$.
    <!-- @Johnson2021 6.11 -->

1.  ğŸ“Œ **MCMC con RStan: Precalentamiento (II)**

    Utilice la informaciÃ³n proporcionada para (1) definir la estructura del modelo 
    bayesiano y (2) obtener muestras del _posterior_ utilizando `{RStan}`. 
    No es necesario ejecutar nada, solo necesita proporcionar el 
    cÃ³digo correcto.

    i. $Y | \pi \sim \text{Binomial}(\pi, 20)$ con $\pi \sim \text{Beta}(1, 1)$ e $y = 12$.
    i. $Y | \lambda \sim \text{Poisson}(\lambda)$ con $\lambda \sim \text{Gamma}(4, 2)$ e 
    $y = 3$.
    i. $Y | \mu \sim \text{Normal}(\mu, 1^2)$ con $\mu \sim \text{Normal}(0, 10^2)$ e 
    $y = 12.2$.
    <!-- @Johnson2021 6.12 -->

1.  ğŸ“Œ **Modelo Beta-Binomial con RStan (I)**

    Considere el modelo Beta-Binomial para $\pi$ con $Y | \pi \sim \text{Binomial}(\pi, n)$
    y $\pi \sim \text{Beta}(3, 8)$. Suponga que en $n = 10$ ensayos independientes
    observa $y = 2$ Ã©xitos.

    i. Obtenga muestras del _posterior_ de $\pi$ con `{RStan}` utilizando 3 cadenas y 12000
    iteraciones por cadena.
    i. Grafique la traza de cada una de las tres cadenas.
    i. Â¿CuÃ¡l es el rango de valores en el eje x del _traceplot_? 
    Â¿Por quÃ© el valor mÃ¡ximo de este rango no es 12000?
    i. Cree un grÃ¡fico que permita visualizar la funciÃ³n de densidad de los valores obtenidos
    con cada una de las tres cadenas.
    i. Utilizando lo estudiado en la Unidad 2, especifique el _posterior_ de $\pi$. 
    Â¿CÃ³mo se compara con la aproximaciÃ³n mediante MCMC?

1.  ğŸ“Œ **Modelo Beta-Binomial con RStan (II)**

    Repita el ejercicio anterior utilizando $\pi \sim \text{Beta}(4, 3)$, donde observa
    $y = 4$ Ã©xitos en $n = 12$ ensayos independientes.

1.  ğŸ“Œ **Modelo Gamma-Poisson con RStan (I)**

    Considere el modelo Gamma-Poisson para $\lambda$ con 
    $Y_i \mid \lambda \sim \text{Poisson}(\lambda)$ y $\lambda \sim \text{Gamma}(20, 5)$.
    Suponga que cuenta con $n = 3$ observaciones independientes $(y_1, y_2, y_3) = (0, 1, 0)$

    i. Obtenga muestras del _posterior_ de $\lambda$ con `{RStan}` utilizando 4 cadenas y 
    10000 iteraciones por cadena.
    i. Grafique la traza y la funciÃ³n de densidad de cada una de las tres cadenas.
    i. A partir del grÃ¡fico de la funciÃ³n de densidad, Â¿cuÃ¡les suelen ser, _a posteriori_,
    los valores mÃ¡s probables de $\lambda$?
    i. Utilizando lo estudiado en la Unidad 2, especifique el _posterior_ de $\lambda$. 
    Â¿CÃ³mo se compara con la aproximaciÃ³n mediante MCMC?

1.  ğŸ“Œ **Modelo Gamma-Poisson con RStan (II)**

    Repita el ejercicio anterior utilizando el _prior_ $\lambda \sim \text{Gamma}(5, 5)$.

1.  ğŸ“Œ **Modelo Normal-Normal con RStan (I)**

    Repita los mismos pasos del ejercicio **Modelo Gamma-Poisson con Rstan (I)** pero
    considere el modelo Normal-Normal para $\mu$ con 
    $Y_i | \mu \sim \text{Normal}(\mu, 1.3^2)$ y $\mu \sim \text{Normal}(10, 1.2^2)$.
    Suponga que cuenta con $n = 4$ observaciones independientes 
    $(y_1, y_2, y_3, y_4) = (7.1, 8.9, 8.4, 8.6)$

1.  ğŸ“Œ **Modelo Normal-Normal con RStan (II)**

    Repita el ejercicio anterior con el modelo Normal-Normal pero ahora considere 
    $Y_i | \mu \sim \text{Normal}(\mu, 8^2)$ y $\mu \sim \text{Normal}(-15, 2^2)$.
    Suponga que en $n = 5$ observaciones independientes observa 
    $(y_1, y_2, y_3, y_4, y_5) = (âˆ’10.1, 5.5, 0.1,âˆ’1.4, 11.5)$


1.  **Un modelo que es un poco Â¿complicado?**

    Considere el siguiente modelo

    $$
    \begin{aligned}
    \text{mass}_i &\sim \text{Normal}(\mu_i, \sigma^2) \\
    \mu_i         &= \theta_1 + \theta_2 + \text{age}_i^{\theta_3} \\
    \theta_1      &\sim \text{Normal}(0, 100^2) \\
    \theta_2      &\sim \text{Uniforme}(0, 20000) \\
    \theta_3      &\sim \text{Normal}(0, 1) \\
    \sigma^2      &\sim \text{InvGamma}(0.01, 0.01)
    \end{aligned}
    $$

    y los siguientes datos

    ```{R}
    #| eval: false
    edad <- c(2, 15, 14, 16, 18, 22, 28)
    peso <- c(29.9, 1761, 1807, 2984, 3230, 5040, 5654)
    n <- length(edad)
    data_list <- data.frame(peso = peso, edad = edad, n = n)
    ```

    i. Ajuste el modelo utilizando `{RStan}`.
    i. Obtenga una visualizaciÃ³n de la edad versus el peso junto con una curva que indique
    la media _a posteriori_ de $\mu_i$ para evaluar si el modelo ajusta bien.
    i. Estudie la convergencia de las cadenas de Markov.
    i. Mencione tres medidas que podrÃ­a tomar para mejorar la convergencia.
    <!-- @Reich2020 3.15 -->

## **Otros**

1.  ğŸ“Œ **El peso de los pescados**

    Una compaÃ±Ã­a pesquera de Comodoro Rivadavia se encuentra probando un nuevo mÃ©todo para
    estimar el peso de los peces que extrae del Mar Argentino. El objetivo de este mÃ©todo
    es obtener una estimaciÃ³n lo suficientemente buena del peso de cada pescado sin tener
    que pesarlos uno por uno, ya que es un proceso costoso en tiempo y labor. 
    Para eso, seleccionaron una muestra de pescados, los pesaron
    y les midieron ciertos aspectos morfolÃ³gicos (ancho, alto y largo). En el futuro,
    esperan recolectar estas mismas medidas morfolÃ³gicas mediante una cÃ¡mara especializada
    y utilizar un modelo para estimar el peso.
    
    El modelo propuesto por el equipo de investigaciÃ³n es el siguiente:

    $$
    \begin{aligned}
    \log(\text{Peso}_i) &\sim \text{Normal}(\mu, \sigma) \\
    \mu_i               &= \beta_0 + \beta_1 \log(\text{Largo}_i) \\
    \sigma              &\sim \text{Gamma}(k, \theta)
    \end{aligned}
    $$

    El peso se encuentra medido en gramos y la longitud en centÃ­metros. El equipo provee 
    las muestras que obtuvieron del _posterior_. Las mismas se pueden leer en R 
    utilizando el siguiente bloque de cÃ³digo. 

    ```{r}
    #| eval: false
    url <- paste0(
        "https://raw.githubusercontent.com/estadisticaunr/",
        "estadistica-bayesiana/main/datos/fish-market-posterior.csv"
    )
    df_posterior <- readr::read_csv(url)
    head(df_posterior)
    ```
    ```
    # A tibble: 6 Ã— 3
      intercepto pendiente sigma
           <dbl>     <dbl> <dbl>
    1      -4.44      3.08 0.408
    2      -4.30      3.05 0.431
    3      -4.49      3.12 0.433
    4      -4.04      2.96 0.341
    5      -4.76      3.18 0.413
    6      -4.65      3.15 0.350
    ```

    i.  Analice de manera grÃ¡fica y analÃ­tica los _posteriors_ marginales de los 
    parÃ¡metros del modelo. Realice las transformaciones de parÃ¡metros que crea
    conveniente para facilitar la comprensiÃ³n del anÃ¡lisis.
    i.  Considere un pescado cuya longitud es de 30 centÃ­metros.
        a. Obtenga y grafique la distribuciÃ³n _a posteriori_ del peso medio.
        a. Obtenga y grafique la distribuciÃ³n predictiva _a posteriori_ del peso.
        a. Interprete los resultados. 
    i.  Grafique la curva de regresiÃ³n junto a una banda de credibilidad del 95% 
    en el plano de las variables originales y en el plano de las variables transformadas.
    i.  Agregue a los grÃ¡ficos anteriores una banda de credibilidad del 95% para la 
    distribuciÃ³n predictiva _a posteriori_. Interprete los resultados.


<!--
TO DO: Mover a otro lado?

1.  Considere la siguiente familia de distribuciones normales en 2D

    $$
    f(\boldsymbol{x} | \boldsymbol{\Sigma}, \boldsymbol{\mu} = \boldsymbol{0}) 
    = \frac{1}{\det(2\pi\boldsymbol{\Sigma})^{-\frac{1}{2}}}
    \exp[{-\frac{1}{2} \boldsymbol{x}^T \boldsymbol{\Sigma}^{-1} \boldsymbol{x}}]
    $$

    y las siguientes matrices de covarianza

    $$
    \begin{array}{cc}
        \boldsymbol{\Sigma}_1 = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} & 
        \boldsymbol{\Sigma}_2 = \begin{bmatrix} 1 & 0.2 \\ 0.2 & 1 \end{bmatrix}
        \\ \\ 
        \boldsymbol{\Sigma}_1 = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix} & 
        \boldsymbol{\Sigma}_2 = \begin{bmatrix} 0.1 & 0 \\ 0 & 1 \end{bmatrix}
        \\ \\
        \boldsymbol{\Sigma}_1 = \begin{bmatrix} 1 & 0.9 \\ 0.9 & 1 \end{bmatrix} & 
        \boldsymbol{\Sigma}_2 = \begin{bmatrix} 0.01 & 0 \\ 0 & 1 \end{bmatrix}
    \end{array}
    $$

    Que dan lugar a las siguientes funciones de densidad:

    ```{r plot-matrix-of-gaussians}
    #| warning: false
    #| cache: true
    #| echo: false
    #| fig.width: 8
    #| fig.height: 12
    #| fig.align: center
    data <- tidyr::crossing(x1 = seq(-3, 3, 0.1), x2 = seq(-3, 3, 0.1))
    Mu <- replicate(6, c(0, 0), simplify = FALSE)
    Sigma <- list(
        matrix(c(1, 0, 0, 1), nrow = 2),
        matrix(c(1, 0.2, 0.2, 1), nrow = 2),
        matrix(c(1, 0.5, 0.5, 1), nrow = 2),
        matrix(c(0.1, 0, 0, 1), nrow = 2),
        matrix(c(1, 0.9, 0.9, 1), nrow = 2),
        matrix(c(0.01, 0, 0, 1), nrow = 2)
    )

    index <- 1
    plot_list <- purrr::map2(Mu, Sigma, function(x, y) {
        title_str <- paste0("$\\Sigma_", index, "$")
        plt <- data |>
            mutate(f = mvtnorm::dmvnorm(data, x, y)) |>
            ggplot() +
            geom_raster(aes(x = x1, y = x2, fill = f)) +
            stat_contour(aes(x = x1, y = x2, z = f), col = "white", bins = 5) +
            viridis::scale_fill_viridis() +
            labs(title = latex2exp::TeX(title_str)) + 
            theme(
                legend.position = "none", 
                plot.title = element_text(hjust = 0.5, size = 18)
            )
        index <<- index + 1
        return(plt)
    })

    plt <- Reduce(`+`, plot_list) + 
    plot_layout(ncol = 2)
    plt
    ```

    **Parte 1:** Metropolis-Hastings

    i. Utilice el algoritmo Metropolis-Hastings para obtener $n=10000$ muestras de
    cada una de las distribuciones.
    i. Calcule la probabilidad de aceptaciÃ³n.
    i. Grafique la funciÃ³n de autocorrelaciÃ³n y calcule la cantidad de muestras efectivas.
    i. Analice como varÃ­a la probabilidad de aceptaciÃ³n y la cantidad de muestras 
    efectivas segÃºn las diferentes caracterÃ­sticas de la distribuciÃ³n objetivo.
    i. Â¿CuÃ¡les son las ventajas y desventajas del algoritmo de Metropolis-Hastings segÃºn
    lo que puede concluir a partir de esta aplicaciÃ³n? Comente dificultades con las que
    se haya encontrado. 

    **Parte 2:** Hamiltonian Monte Carlo

    i. Utilice el algoritmo HMC para obtener $n=10000$ muestras de
    cada una de las distribuciones.
    i. Calcule la probabilidad de aceptaciÃ³n.
    i. Grafique la funciÃ³n de autocorrelaciÃ³n y calcule la cantidad de muestras efectivas.
    i. Analice como varÃ­a la probabilidad de aceptaciÃ³n y la cantidad de muestras 
    efectivas segÃºn las diferentes caracterÃ­sticas de la distribuciÃ³n objetivo.
    i. Â¿CuÃ¡les son las ventajas y desventajas del algoritmo de Metropolis-Hastings segÃºn
    lo que puede concluir a partir de esta aplicaciÃ³n? Comente dificultades con las que
    se haya encontrado. 

    **To Do** Proveer valores para los parÃ¡metros 'mu' y 'sigma'

-->


<!--
TO DO

### Ejercicios que faltan

* Utilizar HMC para la normal multivariada con correlaciÃ³n moderada y alta correlaciÃ³n
* Utilizar HMC para los modelos donde se usÃ³ MH
* Algun caso donde los diagnosticos no den bien...
    * Puede ser cuando el HMC no esta bien tuneado
    * Pensar algunos otros (deberia buscar en cosas que he hecho)
* Algo con brms?

**Nota:** Para los que dicen "utilizar HMC" estaria bueno que proveamos una funcion
que use HMC, sin que tengan que usar Stan.
-->

<!-- 
1. **La maldiciÃ³n de la dimensionalidad**

    **Nota:** Creo que esto puede ir para el TP 2 de este aÃ±o, o ser parte del TP 2
    del aÃ±o que viene. Esto todo en el contexto de grid approximation.

    * Mostrar que casi todo el volumen de un hipercubo estÃ¡ en las esquinas.
    * Hablar de la distnacia a la moda en una normal multivariada conforme d -> inftys 

1.  **Tomar el Torus por las astas**

    Ver el script "torus.R"
-->
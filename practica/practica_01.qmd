---
title: "Pr치ctica - Unidad 1"
bibliography: ../references.bib
nocite: |
  @Johnson2021, @McElreath2020, @Martin2021, @Hoff2009, @Downey2021, @Barber2012
pdf_file: https://github.com/estadisticaunr/estadistica-bayesiana/raw/pdf/practica/practica_01.pdf
editor_options: 
  markdown: 
    wrap: sentence
---

```{r echo=FALSE, include=FALSE}
is_html <- knitr::is_html_output()
options("knitr.graphics.error" = FALSE)
source(here::here("scripts", "utils.R"))
caption_data <- list(
    "bebe_panda" = list(author = "Stone Wang", handle = "stonewyq", code = "0wk7m5SVPsM"),
    "colectivo" = list(author = "Markus Winkler", handle = "markuswinkler", code = "HII6PEEvLHw")
)
captions <- lapply(caption_data, function(x) do.call(make_unsplash_caption, x))
captions[["crepusculo"]] <- "Robert Pattinson como Edward en Crep칰sculo"
captions[["ceibo"]] <- "Flor del Ceibo, la flor nacional"
```

::: {.content-visible when-format="html"}
[Descargar PDF](%7B%7B%3C%20meta%20pdf_file%20%3E%7D%7D)
:::

## Regla de Bayes

El prop칩sito de esta secci칩n de la pr치ctica es resolver situaciones que impliquen la 
aplicaci칩n de la Regla de Bayes como se presenta tradicionalmente en un curso de Probabilidad.
    
1.  **Demostraci칩n**

    Demuestra la validez de la siguiente expresi칩n de la Regla de Bayes

    $$
    P(B_j | A) = \frac{P(A | B_j) P(B_j)}{\sum_{k=1}^{K}P(A | B_k) P(B_k)}
    $$

    donde $A$ es un evento cualquiera y $\{B_1, \cdots, B_K\}$ forman una partici칩n.
    Para ello siga los siguientes pasos

    i.  Demuestre que $P(B_j | A) P(A) = P(A | B_j) P(B_j)$.
    ii. Demuestre que $P(A) = P(A \cap B_1) + P(A \cap \{\cup_{k=2}^{K}B_j\})$.
    iii. Demuestre que $P(A) = \sum_{k=1}^{K} P(A \cap B_j)$.
    iv. Junte las partes para formar la Regla de Bayes. 
    <!-- @Hoff2009 -->
    <!-- Se necesitan los axiomas P1-P3 del capitulo 2. -->

1.  **El test ~~in~~falible**

    En una poblaci칩n dada, una de cada mil personas tiene una enfermedad.
    Se toma una persona al azar de la poblaci칩n, se le aplica un test para detectar dicha
    enfermedad, y el resultado es positivo.
    El test se caracteriza por dar positivo el 99% de las veces que una persona tiene la
    enfermedad. Adem치s, dicho test tiene una tasa de falsos positivos del 5%.

    - 쮺u치l es la probabilidad de que la persona tenga efectivamente la enfermedad?
    - Si realizamos el mismo an치lisis una segunda vez sobre el mismo paciente y obtenemos nuevamente positivo
        - 쮺u치l seria la probabilidad que el paciente est칠 enfermo?
        - 쯏 si diera negativo?
        - 쮼s el _prior_ el mismo para el segundo an치lisis que para el primero? 
    <!-- @Martin2021 -->

1.  **쮼s verdad que existen los vampiros? Versi칩n Crep칰sculo**

    Edward quiere probarle a Bella que los vampiros existen.
    Seg칰n Bella, hay una probabilidad del 5% de que los vampiros existan.
    Tambi칠n cree que la probabilidad de que exista alguien con la piel brillante dado que
    los vampiros existen es del 70%, y que la probabilidad de que alguien tenga la piel 
    rillante si los vampiros no existen es del 3%.
    Edward lleva a Bella al bosque y le muestra que de hecho su piel brilla como un 游눑 
    쮺u치l es la probabilidad que existan los vampiros?
    <!-- @Johnson2021 -->

    ```{r, echo=FALSE, out.width="70%", fig.align="center", fig.cap=captions[["crepusculo"]]}
    if (is_html) knitr::include_graphics(file.path("imgs", "crepusculo.jpg"))
    ```


1.  **츼rboles enfermos**

    Un vivero de la ciudad se destaca por vender una variedad de 치rboles nativos, 
    incluyendo al jacarand치, ceibo, omb칰, entre otros.
    Lamentablemente, el 18% de los 치rboles del vivero estan infectados con moho.
    Los 치rboles enfremos se componen en un 15% por jacarand치s, 80% de ceibos, y 5% de 
    otras especies.
    Los 치rboles sanos se componen por un 20% de jacarand치s, 10% de ceibos, y 70% de otras 
    especies.
    Con el objetivo de monitorear cuanto se propag칩 la enfermedad, una de las personas que
    trabaja en el vivero selecciona al azar uno de los 치rboles para testear.

    - 쮺u치l es la probabilidad a priori de que el 치rbolo tenga moho?
    - Resulta que el 치rbol seleccionado es un ceibo. 쮺u치l es la probabilidad de haber
    seleccionado un ceibo?
    - 쮺u치l es la probabilidad a posteriori de que el ceibo seleccionado tenga moho?
    - Compare las probabilidades a priori y a posteriori de que el 치rbol tenga moho. 
    쮺칩mo afecta el an치lisis el saber que el 치rbol es un ceibo? 
    <!-- @Johnson2021 -->

    ```{r, echo=FALSE, out.width="70%", fig.align="center", fig.cap=captions[["ceibo"]]}
    if (is_html) knitr::include_graphics(file.path("imgs", "ceibo.png"))
    ```

1.  **Transporte "El Impuntual"**

    Una cierta empresa de transporte regional, que decidimos llamar "El Impuntual", tiene
    servicios que van desde Rosario hasta Wheelwright varias veces al d칤a, 
    todos los d칤as de la semana.
    Un 30% de los viajes salen a la ma침ana, otro 30% salen a la tarde, y el restante 40%
    salen a la noche.
    Los pasajeros suelen estar muy frustrados ya que un 25% de los viajes salen tarde.
    De estos viajes demorados, el 40% corresponden a la ma침ana, un 50% suceden a la tarde,
    y el 10% restante ocurre a la noche[^el_impuntual].

    Lucio y Franco son dos amigos del pueblo, y se volvieron a sus casas en colectivos diferentes.

    - Lucio se fue en uno de los colectivos de la ma침ana. 쮺u치l es la probabilidad que su 
    viaje est칠 demorado?
    - El colectivo de Franco no est치 demorado. 쮺u치l es la probabilidad de que est칠 
    viajando en uno de los colectivos de la ma침ana?
    <!-- @Johnson2021 -->

    ```{r, echo=FALSE, out.width="70%", fig.align="center", fig.cap=captions[["colectivo"]]}
    if (is_html) knitr::include_graphics(file.path("imgs", "colectivo.jpg"))
    ```

1.  **Beb칠 panda**

    Supongamos que hay dos especies de osos panda.
    Ambas especies son igual de frecuentes y viven en la misma regi칩n.
    Es m치s, lucen de la misma forma y comen la misma comida.
    A칰n no existe una prueba gen칠tica que pueda diferenciarlos.
    Lo 칰nico que los diferencia es la cantidad de cr칤as que suelen tener.
    Las madres de la especie A dan luz a mellizos el 10% del tiempo.
    Y las madres de la especie B dan a luz mellizos el 20% del tiempo.
    En todos los otros casos, estas madres dan a luz un solo beb칠 panda.

    Usando un poco la imaginaci칩n, supongamos que somos la persona encargada de un 
    programa de reproducci칩n de pandas.
    Tenemos una panda femenina que acaba de dar a luz a un par de mellizos, pero no 
    sabemos a que especie pertenece.

    - 쮺u치l es la probabilidad que la mam치 panda sea de la especie A?
    - 쮺u치l es la probabilidad que vuelva a tener mellizos en la pr칩xima parici칩n?
    - Un tiempo despu칠s sos encontramos con que en la segunda parici칩n da a luz a un 칰nico
    beb칠 panda. 쮺u치l es la probabilidad de que este panda sea de la especie A? 
    <!-- @McElreath2020 -->

    ```{r, echo=FALSE, out.width="70%", fig.align="center", fig.cap=captions[["bebe_panda"]]}
    if (is_html) knitr::include_graphics(file.path("imgs", "bebe_panda.jpg"))
    ```

1. **Paraguas**

    Est치s a punto de subir a un avi칩n rumbo a Mendoza.
    Quer칠s saber si ten칠s que llevar un paraguas o no.
    Llam치s a tres amigos que viven en Mendoza y les pregunt치s si est치 lloviendo.
    Cada uno de ellos tiene una probabilidad de 2/3 de decirte la verdad y 1/3 de mentirte
    para hacerte una broma.
    Los tres responden que s칤 est치 lloviendo.
    쮺u치l es la probabilidad de que realmente est칠 lloviendo en las Mendoza?
    Se puede asumir que en Mendoza llueve en 1 de cada 10 d칤as.
    <!-- http://allendowney.github.io/ThinkBayes2/chap06.html -->

1. **Sherlock**

    Dos personas dejaron rastros de sangre en la escena del crimen.
    La sangre de Guido, un sospechoso, es analizada y resulta ser de tipo '0'.
    Los rastros de sangre de la escena son de tipo '0' (un tipo com칰n en la poblaci칩n, 
    presente en el 60% de las personas) y de tipo 'AB' (un tipo raro, con una frecuencia 
    del 1% en la poblaci칩n).
    쮼stos datos representan evidencia de que Guido estaba presente en la escena del crimen?
    <!-- http://allendowney.github.io/ThinkBayes2/chap06.html -->

1. **Hijxs de la probabilidad**

    Nos encontramos con alguien en la calle y nos dice que tiene dos hijxs.
    Le preguntamos si algunx de ellxs es mujer y nos responde que s칤.
    쮺u치l es la probabilidad de que ambxs sean ni침as?
    <!-- http://allendowney.github.io/ThinkBayes2/chap03.html -->

1. **Los Reyes del Rock**

    Elvis Presley ten칤a un hermano var칩n que naci칩 en el mismo parto pero que muri칩 al 
    poco tiempo. 쮺u치l es la probabilidad de que Elvis tuviera un gemelo?
    Alguna informaci칩n adicional: en 1935, cuando Elvis naci칩, 1/3 de los hermanxs del 
    mismo parto eran gemelxs y 2/3 mellizxs; adem치s, la probabilidad de que dos mellizxs 
    sean del mismo sexo biol칩gico puede estimarse en 50%, mientras que dos gemelxs son 
    siempre del mismo sexo biol칩gico.
    <!-- http://allendowney.github.io/ThinkBayes2/chap03.html -->

1. **쮸lguien ordena las medias?**

    Dos cajones contienen medias.
    Uno de ellos tiene igual cantidad de medias blancas y negras.
    El otro contiene un n칰mero igual de medias rojas, verdes y azules.
    Se elige un caj칩n al azar, se sacan dos medias sin mirar y resultan ser las dos iguales.
    쮺u치l es la probabilidad de que las medias sean blancas?
    Sup칩ngase que sacar la primera media no altera las proporciones.
    <!-- http://allendowney.github.io/ThinkBayes2/chap03.html -->
    
1. **La Falacia del Fiscal**

    Sally Clark era una abogada brit치nica que fue err칩neamente sentenciada a prisi칩n 
    perpetua en 1999 por la muerte de sus dos hijos beb칠s. Su hijo mayor, Christopher, 
    muri칩 con 11 semanas en diciembre de 1996 y su hijo m치s joven, Harry, con 8 semanas en
    enero de 1998. Durante el juicio, la defensa argument칩 que las muertes se debieron al
    s칤ndrome de muerte s칰bita del lactante (SIDS). Clark fue condenada a partir del 
    testimonio del pediatra Sir Roy Meadow, quien argument칩 en la corte lo siguiente:
    
    - En familias sanas, la chance de muerte por SIDS es de $\frac{1}{8500}$
    - La probabilidad de dos muertes por SIDS en la misma familia es aproximadamente 
    $\frac{1}{8500^2} \approx \frac{1}{73000000}$
    - Es, por ende, muy poco probable que Clark sea inocente
    
    Luego de pasar 3 a침os en prisi칩n, Clark fue liberada en 2003 luego de que se 
    determinara que el testimonio _experto_ de Meadows era equivocado. Dos mujeres, a las
    cuales el testimonio de Meadows hab칤a enviado a prisi칩n, tambi칠n fueron liberadas.
    
    i. Identifica una falla en la probabilidad de $\frac{1}{73000000}$ dada por Meadows
    i. Incluso aceptando el n칰mero anterior como correcto, 쯖u치l es el problema de 
    interpretar esa probabilidad como la probabilidad de inocencia de Clark?
    
    <!-- https://web.stanford.edu/class/archive/cs/cs109/cs109.1206/section/1/section1_soln.pdf -->
    
## Inferencia Bayesiana

En esta parte de la pr치ctica, se le otorga un significado a las cantidades que aparecen en
la Regla de Bayes modificando conceptualmente el enfoque de las situaciones problem치ticas.
Ahora los problemas se tratan de realizar inferencias sobre posibles causas de ciertos 
datos observados. Se incrementa el rigor matem치tico, aparecen distribuciones de 
probabilidad y la necesidad de dejar ciertos c치lculos en manos de la computadora.

1.  **El lenguaje de las probabilidades**

    Escribir la expresi칩n matem치tica para cada una de las siguientes descripciones verbales:

    a.  Probabilidad de un par치metro dados los datos observados
    b.  La distribuci칩n de probabilidad de los par치metros antes de ver los datos
    c.  La verosimilitud de los datos para un valor dado de los par치metros
    d.  La probabilidad de una observaci칩n nueva luego de observar los datos
    e.  La probabilidad de una observaci칩n antes de ver los datos
    <!-- @Martin2021 -->

1.  **Qu칠 datazo me tiraste, rey**

    Los M&Ms azul fueron introducidos en el a침o 1995 ([antes hab칤a dos tipos de marr칩n](http://content.time.com/time/specials/packages/article/0,28804,2011482_2011480_2011460,00.html))

    - Antes de 1995, la mezcla de colores en una bolsa de M&Ms era: 
    30% marron, 20% amarillo, 20% rojo, 10% verde, 10% naranja y 10% marr칩n *bronceado*.
    - Luego de 1995, la mezcla pas칩 a ser: 24% azul, 20% verde, 16% naranja, 14% amarillo,
    13% rojo y 13% marr칩n.

    Un amigo tiene dos bolsas de M&M y nos dice que una bolsa es de 1994 y la otra es de 
    1996, pero no nos dice cu치l es cu치l.
    Nos da un M&M de cada bolsa: uno es amarillo y el otro es verde (ambos posiblemente est칠n vencidos).
    쮺u치l es la probabilidad de que el amarillo venga de la bolsa de 1994?
    
1.  **La Gran Estafa**

    Hay dos monedas en una caja.
    Una de ellas es una moneda com칰n y la otra es una moneda que tiene dos caras.

    i.  Se elige una moneda al azar, se arroja, y se obtiene cara. 쮺u치l es la 
    probabilidad de que la moneda elegida sea la falsa?
    ii. Se elige una moneda al azar y se arroja al aire tres veces, obteni칠ndose tres 
    caras. 쮺u치l es la probabilidad de que la moneda elegida sea la falsa?
    
1.  **Vocabulario limitado**

    Supongamos que existe un idioma con seis palabras:

    $$
    \text{\{perro, parra, farra, carro, corro, tarro\}}
    $$

    Un an치lisis ling칲칤stico exhaustivo de esta lengua ha descubierto que todas las 
    palabras son igualmente probables, excepto por 'perro', que es $\alpha$ veces m치s 
    probable que las otras.
    
    Adem치s:

    -   Cuando se tipean, un caracter se introduce err칩neamente con probabilidad $\theta$
    -   Todas las letras tienen la misma probabilidad de producir un error de tipeo
    -   Si una letra se tipe칩 mal, la probabilidad de cometer un error en otro caracter no cambia
    -   Los errores son independientes a lo largo de una palabras.

    i. 쮺u치l es la probabilidad de escribir correctamente 'tarro'?
    i. 쮺u치l es la probabilidad de tipear 'cerro' o 'curro' al querer escribir 'carro'?
    i. Utilizando la Regla de Bayes, desarrollar un corrector gramatical para esta lengua.
    Para las palabras tipeadas 'farra', 'birra' y 'locos', hallar la probabilidad de que
    cada palabra del diccionario sea la palabra que se hab칤a querido escribir. Utilizar
    las siguientes combinaciones de par치metros:
         a.  $\alpha = 2$ y $\theta = 0.1$
         b.  $\alpha = 50$ y $\theta = 0.1$
         c.  $\alpha = 2$ y $\theta = 0.9$
         

1.  **Bosque**

    Sea $X_1 \sim \text{Bernoulli}(\theta)$ una variable que indica si una especie de 
    치rboles se halla en un determinado bosque y $\theta \in [0, 1]$ representa la 
    probabilidad *a priori* de que la especie se encuentre en el bosque.
    Una investigadora selecciona una muestra de $n$ 치rboles del bosque y encuentra que 
    $X_2$ de ellas pertenecen a la especie de inter칠s.

    El modelo luego es

    $$
    \begin{array}{lc}
    X_2|X_1 \sim \text{Binomial}(n, \lambda X_1) & \text{con} \ \lambda \in [0, 1]
    \end{array}
    $$

    $\lambda$ representa la probabilidad de detectar la especie, dado que la especie se 
    encuentra en el bosque.

    Encuntre expresiones matem치ticas en t칠rmino de $n$, $\theta$ y $\lambda$ para las 
    siguientes probabilidades:

    i.  $P(X_1 = 0, X_2 = 0)$
    ii. $P(X_1 = 0)$
    iii. $P(X_2 = 0)$
    iv. $P(X_1 = 0 | X_2 = 0)$
    v.  $P(X_2 = 0 | X_1 = 0)$
    vi. $P(X_1 = 0 | X_2 = 1)$
    vii. $P(X_2 = 0 | X_1 = 1)$
    viii. Explique de manera intuitiva c칩mo es que las probabilidades calculadas en 
    (iv)-(vii) cambian seg칰n $n$, $\theta$ y $\lambda$.
    ix. Asuma $\theta=0.5$, $\lambda=0.1$ y $X_2 = 0$ 쮺u치n grande debe ser $n$ para que 
    se puede concluir con 95% de confianza que la especie no se encuentra en el bosque? 
    <!-- @Reich2020 -->

1.  **춰Ostras! 춰Estoy haciendo inferencia bayesiana!**

    En un estudio que utiliza m칠todos de la Estad칤stica Bayesiana para predecir el n칰mero
    de especies que ser치n descubiertas en el futuro se reporta que la cantidad de especies
    marinas bivalvas[^bivalvas] descubiertas cada a침o entre 2010 y 2015 fue 
    64, 13, 33, 18, 30 y 20.

    Si se representa con $Y_t$ a la cantidad de especies descubierta en el a침o $t$, 
    y asumiendo:

    $$
    \begin{aligned}
    Y_t | \lambda &\underset{iid}{\sim} \text{Poisson}(\lambda) \\
    \lambda       &\sim \text{Uniforme}(0, 100)
    \end{aligned}
    $$

    Graficar la distribuci칩n a posteriori de $\lambda$.
    <!-- @Reich2020 -->

1.  **Es negocio...**

    Sea $n$ la cantidad desconocida de clientes que visitan una tienda en un dia cualquiera.
    El n칰mero de clientes que realizan una compra es $Y$ y se cumple que

    $$
    Y | n \sim \text{Binomial}(n, \theta)
    $$

    donde $\theta$ es la probabilidad de compra, dado que se produce la visita a la tienda.
    La distribuci칩n *a priori* de $n$ es $n \sim \text{Poisson}(5)$.
    Bajo el supuesto que $\theta$ es conocido y que $n$ es desconocido, graficar la distribuci칩n *a posteriori* de $n$ para todas las combinaciones de $Y \in \{0, 5, 10 \}$ y $\theta \in \{0.2, 0.5\}$.
    Explique cual es del efecto de cambiar $Y$ y $\theta$ sobre la distribuci칩n *a posteriori*.
    <!-- Me parece interesante porque plantea la inferencia sobre "n" en vez de "p" --> <!-- @Reich2020 -->

1.  **Con amigos as칤, qui칠n necesita enemigos**

    Un amigo arroja un dado y anota en secreto el n칰mero que sale (llam칠moslo $T$).
    A continuaci칩n, nosotros, con los ojos vendados, arrojamos el dado varias veces.
    No podemos ver el n칰mero que sale pero nuestro amigo nos dice si el n칰mero que sacamos es mayor, menor o igual a $T$.

    Supongamos que nos da la secuencia: $G,\ G,\ C,\ I,\ C,\ C,\ C, I,\ G,\ C$ (siendo $G$ m치s grande, $C$ m치s chico e $I$ igual).
    쮺u치l es la distribuci칩n *a posteriori* de los valores de $T$?
    <!-- http://allendowney.github.io/ThinkBayes2/bayes_dice.html -->
    
1.  **Orden en la sala**

    En las Jornadas Rosarinas de Ciencia de Datos, una expositora est치 dando una charla en
    un sal칩n cuando el personal de seguridad la interrumpe porque cree que puede haber m치s
    de 1000 personas en la sala, superando el m치ximo permitido.

    La expositora piensa que hay menos de 1000 personas y se ofrece a demostrarlo, aunque
    piensa que contarlas podr칤a llevar mucho tiempo. Decide hacer un experimento:

    -  Pregunta cu치ntas personas nacieron el 11 de mayo. Dos personas levantan la mano.
    -  Pregunta cu치ntas personas nacieron el 23 de mayo. Una persona levanta la mano.
    -  Pregunta cu치ntas personas nacieron el 1 de agosto. Nadie levanta la mano.

    쮺u치ntas personas hay en la sala?
    O, mejor dicho, 쯖u치l es la probabilidad de que haya m치s de 1000 personas en la sala?
    <!-- http://allendowney.github.io/ThinkBayes2/chap04html -->
     
1.  **_House of Cards_**

    Hay 538 miembros en el Congreso de Estados Unidos.
    Supongamos que se auditan sus inversiones y se encuentra que 312 de ellos obtuvieron
    rendimientos por encima del mercado.
    Asumamos que un miembro honesto del Congreso tiene solo una probabilidad del 50% de
    tener rendimientos por encima del mercado, pero uno deshonesto que opera con
    informaci칩n confidencial tiene una chance del 90% de hacerlo.
    쮺u치ntos miembros del Congreso son honestos?
    <!-- http://allendowney.github.io/ThinkBayes2/chap06.html -->

1.  **Puede fallar...**

    Cansada de los experimentos de arrojar una moneda cientos de veces al aire, una 
    estudiante dise침a un sistema de reconocimiento de im치genes que determina si sali칩 cara
    o ceca y registra el resultado.

    L칩gicamente, el sistema dise침ado no es perfecto sino que presenta una tasa de error.
    En particular, la probabilidad de que clasificar mal es de 0.2 (20% de las veces que 
    sale cara, el sistema dice ceca, y viceversa).

    Se arroja la moneda 250 veces y el sistema detecta 140 caras,

    i. 쮺u치l es la distribuci칩n *a posteriori* de $\theta$, la probabilidad de obtener cara?
    i. 쯈u칠 ocurre a medida que la probabilidad de clasificar mal var칤a? 
    <!-- http://allendowney.github.io/ThinkBayes2/chap04html -->
    
1.  **춰Saludos a los cubos con puntos! (...) Ser치n dados**

    Dos dados de seis caras son arrojados. Se sabe que la suma de los dos puntajes obtenidos
    es 9. 쮺u치l es la distribuci칩n _a posteriori_ de los puntajes de los dados?
    <!-- @Barber2012 -->


## Conceptuales

En esta secci칩n, se nos invita a pensar sobre las caracter칤sticas de la Estad칤stica Bayesiana. 
En lugar de encontrar una respuesta 칰nica mediante c치lculos matem치ticos, 
se necesita comprender en profundidad tanto el enfoque frecuentista como el bayesiano
para interpretar estas visiones en diferentes escenarios.

1.  **Voy a conseguir esa pasant칤a**

    La empresa de tecnolog칤a en la que todo el mundo quiere trabajar tiene varias vacantes
    para pasantes en ciencia de datos.
    Luego de leer la descripci칩n de la b칰squeda, te das cuenta que sos una persona 
    calificada para el puesto: estos son tus **datos**.
    Tu objetivo es averiguar si te van a ofrecer el puesto: esta es tu **hip칩tesis**.

    i. Desde la perspectiva de una persona con un razonamiento frecuentista, 
    쯈u칠 es lo que se responde al evaluar la hip칩tesis de que te ofrecen el puesto?
    i. Repita el punto anterior considerando la perspectiva de una persona con un 
    razonamiento Bayesiano.
    i. 쯈u칠 pregunta tiene m치s sentido responder: la frecuentista o la Bayesiana? 
    Justifica tu respuesta. 
    <!-- @Johnson2021 -->

1.  **Beneficios de la Estad칤stica Bayesiana**

    Una amiga te cuenta que est치 interesada en aprender m치s sobre Estad칤stica Bayesiana.
    Expl칤cale lo siguiente:

    i.  쯇or qu칠 es 칰til el enfoque Bayesiano?
    ii. 쮺u치les son las similitudes entre el enfoque frecuentista y el Bayesiano? 
    <!-- @Johnson2021 -->


[^el_impuntual]: Hay gente que dice que "cada dos por tres" te deja a pata.
    No nos vamos a pelear explic치ndoles que estan siendo demasiado exigentes, ya que un 25% tambi칠n es un mont칩n!
    
[^bivalvas]: Una clase de molusco.
    El mejill칩n, la ostra y la almeja son bivalvos

<!-- 1.  Me gusta mucho el ejercicio 1.1 de @Johnson2021 pero creo que es muy yankee-c칠ntrico. 
    Habr칤a que buscar uno que hable de una historia que sea mas familiar en nuestro 
    
<!-- * Me parece que algunas preguntas conceptuales podrian estar incluso al final del curso
    * O podriamos volver a hacerlas, a ver como cambian las respuestas
    * Eso permitiria dejarlas aca, pero sacarle presion
* Prefiero el contraste entre "enfoque bayesiano" y "enfoque frecuentista" que 
"estadistica bayesiana" y "estadistica frecuentista". Creo que hay una sola "estadistica"
y hay muchisimos principios que son comunes. Luego varia el "enfoque" con el cual se mira
a los parametros y el proceso generador de datos. En otras palabras, puedo expresar el mismo
modelo estadistico pero encararlo desde distinto enfoque. El modelo sigue siendo el mismo,
lo que cambia es el enfoque con el que lo miro, y en consecuencia, el significado de 
algunas partes.     
* Tambien me parece que "frecuentista" vs "bayesiano" es una simplificacion que mete
dentro de frecuentista a muchas cosas que no son exactamente lo mismo, hay
unos trabajos de Bradley Efron que ayudan (ver abajo)

Hay un par de trabajos/comentarios criticos que me parecen interesantes y creo que 
la materia deberia tenerlos en cuenta
https://www2.stat.duke.edu/courses/Spring10/sta122/Handouts/EfronWhyEveryone.pdf
https://www.jstor.org/stable/27590513
https://www.colorado.edu/amath/sites/default/files/attached-files/efron.pdf
https://twitter.com/dan_p_simpson/status/1564579319758073856
https://math.stackexchange.com/a/2079842
https://www.ime.usp.br/~abe/lista/pdfxeAKkfZxJM.pdf
http://www.math.chalmers.se/Stat/Grundutb/GU/MSA220/S16/Efron250years.pdf
Computer Age Statistical Inference:
    * Los capitulos 2, 3, y 4 tratan 
    "Frequentist Inference", "Bayesian Inference", 
    y "Fisherian Inference and Maximum Likelihood Estimation"
-->

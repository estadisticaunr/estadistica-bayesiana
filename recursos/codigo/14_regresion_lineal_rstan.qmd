---
title: "14 - Regresión lineal con `{RStan}`"
execute:
    message: false
    warning: false
---

El siguiente programa muestra el código necesario para con `R` los ejercicios 
**Mi primer regresión bayesiana** y **Mejorando mi regresión bayesiana** de la Práctica 4.

En primer lugar, se cargan librerías necesarias.

```{r}
library(dplyr)
library(ggplot2)
library(readr)
library(rstan)
```

Luego se leen y visualizan los datos.

```{r}
#| fig-align: center
#| fig-width: 7
# Leer los datos desde el repositorio
df_sales <- read_csv(
    "https://raw.githubusercontent.com/estadisticaunr/estadistica-bayesiana/main/datos/sales.csv"
)

# Explorar los datos
ggplot(df_sales) +
  geom_point(aes(x = x, y = y), alpha = 0.6, size = 2) +
  labs(x = "Publicidad ($)", y = "Ventas ($)")
```

Se crea el siguiente modelo de regresión lineal bayesiana:
$$
\begin{aligned}
\text{ventas}_i &\sim \text{Normal}(\mu_i, \sigma^2) \\
\mu_i &= \beta_0 + \beta_1 \text{publicidad}_i \\
\end{aligned}
$$

donde los parámetros $\beta_0$, $\beta_1$ y $\sigma$ siguen distribuciones _a priori_
uniformes. El programa de Stan para implementar el modelo es el siguiente:

```{stan}
#| echo: true
#| eval: false 
#| file: stan/01_regresion_lineal_simple.stan
#| output.var: modelo_01
```

Ahora se crea una lista con los datos para el modelo y se obtienen muestras del
_posterior_ utilizando la función `stan()`.

```{r}
stan_data <- list(
    N = nrow(df_sales), # Cantidad de observaciones
    x = df_sales$x,     # Publicidad
    y = df_sales$y      # Ventas
)

ruta_modelo <- here::here("recursos", "codigo", "stan", "01_regresion_lineal_simple.stan")

stan_model <- stan( 
    file = ruta_modelo, # Ubicación del archivo con el codigo del modelo en Stan
    chains = 4,         # Cantidad de cadenas
    data = stan_data,   # Datos
    refresh = 0,        # No mostrar mensajes del sampler
    seed = 121195       # Para que el resultado sea reproducible
)
```

Al imprimir el objeto que devuelve `stan()` se puede encontrar un resumen del _posterior_,
incluyendo medidas de diagnóstico como el tamaño de muestra efectivo y 
$\hat{R}$.

```{r}
stan_model
```

Para continuar explorando el _posterior_ y calcular cantidades de interés, conviene 
trabajar con las muestras en un `data.frame`. Para ello resulta fundamental la 
función `extract()` que extrae las muestras del _posterior_ y las devuelve en una lista.

```{r}
df_draws_1 <- as.data.frame(extract(stan_model))
head(df_draws_1)
```

Lo siguiente es un enfoque posible, aunque bastante manual, para graficar los _posteriors_ 
marginales de los parámetros del modelo.

```{r}
#| fig-align: center
#| fig-width: 10
df_draws_long_1 <- df_draws_1 |>
  select(beta0, beta1, sigma) |>
  tidyr::pivot_longer(c("beta0", "beta1", "sigma"), names_to = "parametro")

ggplot(df_draws_long_1) +
  geom_histogram(aes(x = value, y = after_stat(density)), bins = 40) +
  facet_wrap(~ parametro, scales = "free") +
  labs(x = "Valor", y = "Densidad")
```

Un primer paso en el análisis de un modelo lineal simple es visualizar la recta de 
regresión estimada.

```{r}
#| fig-align: center
#| fig-width: 7

# Calcular la media a posteriori del intercepto y la pendiente
intercept_mean <- mean(df_draws_1$beta0)
slope_mean <- mean(df_draws_1$beta1)

# Utilizar estos dos valores para graficar la media de la recta de regresión
ggplot(df_sales) + 
  geom_point(aes(x = x, y = y), alpha = 0.6, size = 2) +
  geom_abline(
    intercept = intercept_mean, 
    slope = slope_mean, 
    linewidth = 1, 
    color = "red"
  ) +
  labs(x = "Publicidad ($)", y = "Ventas ($)")
```

Pero no hay que olvidar que estamos trabajando con un modelo bayesiano. 
Por lo tanto, más que visualizar una recta basada en la media de las distribuciones 
marginales, es mejor visualizar las rectas asociadas a muestras del _posterior_.
Esto también brinda una idea de la variabilidad en la estimación de la recta.

```{r}
#| fig-align: center
#| fig-width: 7

ggplot(df_sales) +
  geom_point(aes(x = x, y = y), alpha = 0.6, size = 2) +
  geom_abline(
    aes(intercept = beta0, slope = beta1),
    alpha = 0.3,
    color = "gray30",
    data = df_draws_1[sample(nrow(df_draws_1), 40), ] # <1> 
  ) +
  geom_abline(
    intercept = intercept_mean, 
    slope = slope_mean, 
    linewidth = 1, 
    color = "red"
  ) +
  labs(x = "Publicidad ($)", y = "Ventas ($)")
```


1.  Se utiliza `sample(nrow(df_draws_1), 40)` para seleccionar 40 muestras del _posterior_ 
al azar. La figura resultaría muy difícil de leer si se intenta visualizar las rectas 
asociadas a muchas más muestras.

También es posible utilizar todas las muestras del _posterior_ para obtener bandas
de credibilidad para la recta de regresión. A continuación, se obtiene la distribución
condicional de $\mu_i$ para valores de $\text{ventas}_i$ en una grilla que cubre el rango
de valores observados. A partir de esas muestras, se calculan intervalos de credibilidad.

```{r}
x_grid <- seq(4, 20, length.out = 100) # <1> 
mu_matrix <- matrix(nrow = 4000, ncol = 100) # <2> 

for (i in seq_along(x_grid)) {
    mu_matrix[, i] <- df_draws_1$beta0 + df_draws_1$beta1 * x_grid[i] # <3> 
}

mu_mean <- apply(mu_matrix, 2, mean) # <4> 
mu_qts <- t(apply(mu_matrix, 2, function(x) quantile(x, c(0.025, 0.975)))) # <5> 
mu_qts2 <- t(apply(mu_matrix, 2, function(x) quantile(x, c(0.25, 0.75))))  # <6> 

# Finalmente, se lamacenan los valores calculados en un data frame
data_mu <- data.frame(
  x = x_grid, 
  y = mu_mean,
  lower_95 = mu_qts[, 1],
  upper_95 = mu_qts[, 2],
  lower_50 = mu_qts2[, 1],
  upper_50 = mu_qts2[, 2]
)

head(data_mu)
```

1.  Se crea la grilla de valores para $\text{ventas}$.
2.  Se crea una matriz con tantas filas como muestras del _posterior_ y tantas columnas
como cantidad de valores en la grilla. Acá almacenamos los valores de $\mu_i$.
3.  Para cada valor de la grilla, se obtiene la distribución condicional de $\mu_i$.
4.  Se calcula la media _a posteriori_ de $\mu_i$ para cada valor en la grilla.
5.  Se calculan los percentiles de $\mu_i$ que se corresponden con un intervalo de colas 
iguales del 95%.
6.  Se calculan los percentiles de $\mu_i$ que se corresponden con un intervalo de colas 
iguales del 50%.

Las bandas de credibilidad se construyen usando `geom_ribbon` de `{ggplot2}`.

```{r}
#| fig-align: center
#| fig-width: 7

ggplot(df_sales) +
  geom_ribbon(
    aes(x, ymin = lower_95, ymax = upper_95),
    fill = "grey50",
    alpha = 0.6,
    data = data_mu
  ) +
  geom_ribbon(
    aes(x, ymin = lower_50, ymax = upper_50),
    fill = "grey35",
    alpha = 0.6,
    data = data_mu
  ) +
  geom_point(aes(x = x, y = y), alpha = 0.6, size = 2) +
  geom_line(
    aes(x, y), 
    color = "firebrick",
    data = data_mu
  ) +
  labs(x = "Publicidad ($)", y = "Ventas ($)")
```

Finalmente, se muestra como visualizar la distribución condicional de $\mu_i$ para un 
valor particular de la variable predictora $\text{ventas}$.

```{r}
#| fig-align: center
#| fig-width: 7
publicidad <- 15
mu <- df_draws_1$beta0 + df_draws_1$beta1 * publicidad
data.frame(mu = mu) |> 
    ggplot() + 
    geom_histogram(aes(mu, y = after_stat(density)), bins = 40) +
    labs(
        x = expression(mu[i] ~ " | " ~ publicidad[i] ~ " = 15"),
        y = "Densidad"
    )
```


Ahora se muestra como utilizar distribuciones _a priori_ no uniformes para los parámetros
del modelo. El modelo se describe:
$$
\begin{aligned}
\text{ventas}_i &\sim \text{Normal}(\mu_i, \sigma^2) \\
\mu_i &= \beta_0 + \beta_1 \text{publicidad}_i \\
\beta_0  &\sim \text{Normal}(\overline{\text{ventas}}, 10^2) \\
\beta_1  &\sim \text{Normal}(0, 0.5^2) \\
\sigma &\sim \text{Normal}^+(5)
\end{aligned}
$$

y el programa de Stan que lo implementa es el siguiente

```{stan}
#| echo: true
#| eval: false 
#| file: stan/02_regresion_linea_simple_priors.stan
#| output.var: modelo_02
```

La estructura del código para ajustar el modelo es idéntica a la utilizada anteriormente.
La única diferencia es que debemos pasar el valor de la media del _prior_ del intercepto
$\beta_0$.

```{r}
stan_data <- list(
    N = nrow(df_sales),          # Cantidad de observaciones
    x = df_sales$x,              # Publicidad
    y = df_sales$y,              # Ventas
    beta0_mu = mean(df_sales$y)  # Media del prior del intercepto  
)

ruta_modelo <- here::here(
    "recursos", "codigo", "stan", "02_regresion_linea_simple_priors.stan"
)

stan_model <- stan( 
    file = ruta_modelo, # Ubicación del archivo con el codigo del modelo en Stan
    chains = 4,         # Cantidad de cadenas
    data = stan_data,   # Datos
    refresh = 0,        # No mostrar mensajes del sampler
    seed = 121195       # Para que el resultado sea reproducible
)
```

Se puede ver el resumen del _posterior_

```{r}
stan_model
```

y también se podrían crear visualizaciones como las anteriores utilizando el mismo código.

Se recomienda echar un vistazo a las funciones disponibles en la librería `{bayesplot}`
[aquí](https://mc-stan.org/bayesplot/reference/index.html). Por ejemplo, `mcmc_trace()`,
que permite obtener un _traceplot_ que sirve para evaluar la convergencia y mezcla de 
las cadenas.

```{r}
#| fig-align: center
#| fig-width: 7
library(bayesplot)
mcmc_trace(
  stan_model, 
  pars = c("beta0", "beta1", "sigma"),
  facet_args = list(nrow = 3)
)
```